{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "from splitcross import SplitCrossEntropyLoss\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import math\n",
    "import json\n",
    "import time\n",
    "\n",
    "### Imported from nasbench nlp\n",
    "import data\n",
    "import os\n",
    "from utils import batchify\n",
    "from argparse import Namespace\n",
    "from model import AWDRNNModel\n",
    "from train import train, evaluate\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ansonhon/mase_project/machop\n"
     ]
    }
   ],
   "source": [
    "%cd machop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from naslib.search_spaces.nasbenchnlp.graph import NasBenchNLPSearchSpace\n",
    "from naslib.utils.get_dataset_api import get_nlp_api\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = NasBenchNLPSearchSpace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.sample_random_architecture(None)\n",
    "new_compact = graph.get_compact()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_compact_mutable(compact):\n",
    "    # convert tuple to list so that it is mutable\n",
    "    edge_list = []\n",
    "    for edge in compact[0]:\n",
    "        edge_list.append(list(edge))\n",
    "    return [edge_list, list(compact[1]), list(compact[2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "compact = new_compact\n",
    "compact = make_compact_mutable(compact)\n",
    "edges, ops, hiddens = compact\n",
    "\n",
    "nbr = NasBenchNLPSearchSpace()\n",
    "nbr.set_compact(new_compact)\n",
    "nbr_model = torch.nn.Module()\n",
    "nbr_model.arch = nbr\n",
    "\n",
    "\n",
    "idx_choices = [i for i in range(len(ops)) if ops[i] not in [0, 6, 7]]\n",
    "for idx in idx_choices:\n",
    "    num_inputs = len([edge for edge in edges if edge[1] == idx])\n",
    "    groups = [[0], [1, 2, 3], [4, 5]]\n",
    "    group = groups[num_inputs]\n",
    "    choices = [i for i in group if i != ops[idx]]\n",
    "    for choice in choices:\n",
    "        new_ops = ops.copy()\n",
    "        new_ops[idx] = choice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\"\"\"\n",
    "Return all neighbors of the architecture\n",
    "Currently has the same todo's as in mutate()\n",
    "\"\"\"\n",
    "compact = new_compact\n",
    "compact = make_compact_mutable(compact)\n",
    "edges, ops, hiddens = compact\n",
    "nbhd = []\n",
    "\n",
    "def add_to_nbhd(new_compact, nbhd):\n",
    "    nbr = NasBenchNLPSearchSpace()\n",
    "    nbr.set_compact(new_compact)\n",
    "    nbr_model = torch.nn.Module()\n",
    "    nbr_model.arch = nbr\n",
    "    nbhd.append(nbr_model)\n",
    "    return nbhd\n",
    "\n",
    "# add op neighbors\n",
    "idx_choices = [i for i in range(len(ops)) if ops[i] not in [0, 6, 7]]\n",
    "for idx in idx_choices:\n",
    "    num_inputs = len([edge for edge in edges if edge[1] == idx])\n",
    "    groups = [[0], [1, 2, 3], [4, 5]]\n",
    "    group = groups[num_inputs]\n",
    "    choices = [i for i in group if i != ops[idx]]\n",
    "    for choice in choices:\n",
    "        new_ops = ops.copy()\n",
    "        new_ops[idx] = choice\n",
    "        nbhd = add_to_nbhd([copy.deepcopy(edges), new_ops, hiddens.copy()], nbhd)\n",
    "\n",
    "# add edge neighbors\n",
    "edge_choices = [i for i in range(len(edges)) if edges[i][0] >= 4]\n",
    "for i in edge_choices:\n",
    "    node_choices = [j for j in range(4, edges[i][1])]\n",
    "    for j in node_choices:\n",
    "        new_edges = copy.deepcopy(edges)\n",
    "        new_edges[i][0] = j\n",
    "        nbhd = add_to_nbhd([new_edges, ops.copy(), hiddens.copy()], nbhd)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbr_model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(nbr_model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepare dataloader for obtaining proxy values\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "data = np.load(r'/home/ansonhon/mase_project/machop/nas-bench-nlp-release/data/ptb/ptb_train_data_tokenized.npy')\n",
    "\n",
    "text_data_tensor = torch.tensor(data)\n",
    "dataset = TensorDataset(text_data_tensor)\n",
    "batch_size = 20\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_compact_to_recipe(compact):\n",
    "    nodes = ['x', 'h_prev_0', 'h_prev_1', 'h_prev_2']\n",
    "    op_dict = ['in', 'activation_sigm', 'activation_tanh', 'activation_leaky_relu',\n",
    "               'elementwise_sum', 'elementwise_prod', 'linear', 'blend']\n",
    "\n",
    "    edges, ops, hiddens = compact\n",
    "    max_node_idx = max([max(edge) for edge in edges])\n",
    "\n",
    "    # create the set of node names\n",
    "    reg_node_idx = 0\n",
    "    hidden_node_idx = 0\n",
    "    for i in range(len(nodes), max_node_idx + 1):\n",
    "        if i not in hiddens:\n",
    "            nodes.append('node_{}'.format(reg_node_idx))\n",
    "            reg_node_idx += 1\n",
    "        else:\n",
    "            nodes.append('h_new_{}'.format(hidden_node_idx))\n",
    "            hidden_node_idx += 1\n",
    "\n",
    "    recipe = {}\n",
    "    for i in range(4, len(nodes)):\n",
    "        node_dict = {}\n",
    "        node_dict['op'] = op_dict[ops[i]]\n",
    "        inputs = []\n",
    "        for edge in edges:\n",
    "            if edge[1] == i:\n",
    "                inputs.append(nodes[edge[0]])\n",
    "        node_dict['input'] = inputs\n",
    "        recipe[nodes[i]] = node_dict\n",
    "\n",
    "    return recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_receipe = convert_compact_to_recipe(new_compact)\n",
    "test_receipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple_list = []\n",
    "\n",
    "while len(tuple_list) < 10:\n",
    "    temp = graph.sample_random_architecture(None)\n",
    "    if temp not in tuple_list:\n",
    "        graph\n",
    "\n",
    "\n",
    "\n",
    "        tuple_list.append(temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "['epe_nas', 'fisher', 'grad_norm', 'grasp', 'jacov', 'l2_norm', 'nwot', 'plain', 'snip', 'synflow', 'zen', 'params', 'flops']\n",
    "from naslib.predictors.utils.pruners.predictive import find_measures\n",
    "\n",
    "metrics = {}\n",
    "dataloader=self.data_module.train_dataloader()\n",
    "dataload_info=[\"random\",len(dataloader),10]\n",
    "loss_function = nn.MSELoss()\n",
    "model=model.model\n",
    "device = torch.device('cuda')\n",
    "model.to(device)\n",
    "num_batches_to_keep = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from naslib.predictors import ZeroCost\n",
    "from naslib.predictors.utils.pruners.predictive import find_measures\n",
    "zc_proxy_list = ['epe_nas', 'fisher', 'grad_norm', 'grasp', 'jacov', 'l2_norm', 'nwot', 'plain', 'snip', 'synflow', 'zen', 'params', 'flops']\n",
    "zc_proxy = zc_proxy_list[0]\n",
    "\n",
    "zc_predictor = ZeroCost(method_type=zc_proxy)\n",
    "score = zc_predictor.query(graph=graph, dataloader= train_loader)\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
