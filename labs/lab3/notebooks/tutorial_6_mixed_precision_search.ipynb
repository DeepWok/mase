{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 6: Mixed Precision Quantization Search with Mase and Optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we'll see how Mase can be integrated with Optuna, the popular hyperparameter optimization framework, to search for a Bert model optimized for sequence classification on the IMDb dataset. We'll take the Optuna-generated model and import it into Mase, then run the CompressionPipeline to prepare the model for edge deployment by quantizing and pruning its weights.\n",
    "\n",
    "As we'll see, running Architecture Search with Mase/Optuna involves the following steps.\n",
    "\n",
    "1. **Define the search space**: this is a dictionary containing the range of values for each parameter at each layer in the model.\n",
    "\n",
    "2. **Write the model constructor**: this is a function which uses Optuna utilities to sample a model from the search space, and constructs the model using transformers from_config class method.\n",
    "\n",
    "3. **Write the objective function**: this function calls on the model constructor defined in Step 2 and defines the training/evaluation setup for each search iteration.\n",
    "\n",
    "4. **Go!** Choose an Optuna sampler, create a study and launch the search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"prajjwal1/bert-tiny\"\n",
    "tokenizer_checkpoint = \"bert-base-uncased\"\n",
    "dataset_name = \"imdb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are starting from scratch, you can load the Bert checkpoint directly from HuggingFace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py:105: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "model = AutoModel.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have previously ran the tutorial on Neural Architecture Search (NAS), run the following cell to import the best model obtained from the search process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import dill\n",
    "\n",
    "lab2_out_dir = Path(\"/workspace/labs/lab2/outputs\")\n",
    "lab3_out_dir = Path(\"/workspace/labs/lab3/outputs\")\n",
    "\n",
    "with open(f\"{lab2_out_dir}/tutorial_5_best_model.pkl\", \"rb\") as f:\n",
    "    base_model = dill.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, fetch the dataset using the `get_tokenized_dataset` utility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mTokenizing dataset imdb with AutoTokenizer for bert-base-uncased.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from chop.tools import get_tokenized_dataset\n",
    "\n",
    "dataset, tokenizer = get_tokenized_dataset(\n",
    "    dataset=dataset_name,\n",
    "    checkpoint=tokenizer_checkpoint,\n",
    "    return_tokenizer=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Defining the Search Space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by defining a search space, i.e. enumerating the possible combinations of hyperparameters that Optuna can choose during search. We'll explore the following range of values for the model's hidden size, intermediate size, number of layers and number of heads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from chop.nn.quantized.modules.linear import (\n",
    "    LinearInteger,\n",
    "    LinearMinifloatDenorm,\n",
    "    LinearMinifloatIEEE,\n",
    "    LinearLog,\n",
    "    LinearBlockFP,\n",
    "    LinearBlockMinifloat,\n",
    "    LinearBlockLog,\n",
    "    LinearBinary,\n",
    "    LinearBinaryScaling,\n",
    "    LinearBinaryResidualSign,\n",
    ")\n",
    "\n",
    "search_space = {\n",
    "    \"linear_layer_choices\": [\n",
    "        torch.nn.Linear,\n",
    "        LinearInteger,\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Writing a Model Constructor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the following function, which will get called in each iteration of the search process. The function is passed the `trial` argument, which is an Optuna object that comes with many functionalities - see the [Trial documentation](https://optuna.readthedocs.io/en/stable/reference/trial.html) for more details. Here, we use the `trial.suggest_categorical` function, which triggers the chosen sampler to choose a layer type. The suggested integer is the index into the search space for each parameter, which we defined in the previous cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chop.tools.utils import deepsetattr\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "def construct_model(trial):\n",
    "\n",
    "    # Fetch the model\n",
    "    trial_model = deepcopy(base_model)\n",
    "\n",
    "    # Quantize layers according to optuna suggestions\n",
    "    for name, layer in trial_model.named_modules():\n",
    "        if isinstance(layer, torch.nn.Linear):\n",
    "            new_layer_cls = trial.suggest_categorical(\n",
    "                f\"{name}_type\",\n",
    "                search_space[\"linear_layer_choices\"],\n",
    "            )\n",
    "\n",
    "            if new_layer_cls == torch.nn.Linear:\n",
    "                continue\n",
    "\n",
    "            kwargs = {\n",
    "                \"in_features\": layer.in_features,\n",
    "                \"out_features\": layer.out_features,\n",
    "            }\n",
    "\n",
    "            # If the chosen layer is integer, define the low precision config\n",
    "            if new_layer_cls == LinearInteger:\n",
    "                kwargs[\"config\"] = {\n",
    "                    \"data_in_width\": 8,\n",
    "                    \"data_in_frac_width\": 4,\n",
    "                    \"weight_width\": 8,\n",
    "                    \"weight_frac_width\": 4,\n",
    "                    \"bias_width\": 8,\n",
    "                    \"bias_frac_width\": 4,\n",
    "                }\n",
    "            # elif... (other precisions)\n",
    "\n",
    "            # Create the new layer (copy the weights)\n",
    "            new_layer = new_layer_cls(**kwargs)\n",
    "            new_layer.weight.data = layer.weight.data\n",
    "\n",
    "            # Replace the layer in the model\n",
    "            deepsetattr(trial_model, name, new_layer)\n",
    "\n",
    "    return trial_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Defining the Objective Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define the objective function for the search, which gets called on each trial. In each trial, we create a new model instace with chosen hyperparameters according to the defined sampler. We then use the `get_trainer` utility in Mase to run a training loop on the IMDb dataset for a number of epochs. Finally, we use `evaluate` to report back the classification accuracy on the test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chop.tools import get_trainer\n",
    "import random\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    # Define the model\n",
    "    model = construct_model(trial)\n",
    "\n",
    "    trainer = get_trainer(\n",
    "        model=model,\n",
    "        tokenized_dataset=dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        evaluate_metric=\"accuracy\",\n",
    "        num_train_epochs=1,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    eval_results = trainer.evaluate()\n",
    "\n",
    "    trial.set_user_attr(\"model\", model)\n",
    "\n",
    "    return eval_results[\"eval_accuracy\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Launching the Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optuna provides a number of samplers, for example:\n",
    "\n",
    "* **GridSampler**: iterates through every possible combination of hyperparameters in the search space\n",
    "* **RandomSampler**: chooses a random combination of hyperparameters in each iteration\n",
    "* **TPESampler**: uses Tree-structured Parzen Estimator algorithm to choose hyperparameter values.\n",
    "\n",
    "You can define the chosen sampler by simply importing from `optuna.samplers` as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.samplers import GridSampler, RandomSampler, TPESampler\n",
    "\n",
    "sampler = RandomSampler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all the pieces in place, we can launch the search as follows. The number of trials is set to 1 so you can go get a coffee for 10 minutes, then proceed with the tutorial. However, this will essentially be a random model - for better results, set this to 100 and leave it running overnight!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-03 01:59:46,061]\u001b[0m A new study created in memory with name: bert-tiny-nas-study\u001b[0m\n",
      "/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.nn.modules.linear.Linear'> which is of type type.\n",
      "  optuna_warn(message)\n",
      "/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'chop.nn.quantized.modules.linear.LinearInteger'> which is of type type.\n",
      "  optuna_warn(message)\n",
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:57, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.304900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.306100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.306300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.325600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.307800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.360600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:37]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-03 02:02:22,909]\u001b[0m Trial 0 finished with value: 0.87464 and parameters: {'bert.encoder.layer.0.attention.self.query_type': <class 'chop.nn.quantized.modules.linear.LinearInteger'>, 'bert.encoder.layer.0.attention.self.key_type': <class 'torch.nn.modules.linear.Linear'>, 'bert.encoder.layer.0.attention.self.value_type': <class 'chop.nn.quantized.modules.linear.LinearInteger'>, 'bert.encoder.layer.0.attention.output.dense_type': <class 'chop.nn.quantized.modules.linear.LinearInteger'>, 'bert.encoder.layer.0.intermediate.dense_type': <class 'chop.nn.quantized.modules.linear.LinearInteger'>, 'bert.encoder.layer.0.output.dense_type': <class 'torch.nn.modules.linear.Linear'>, 'bert.encoder.layer.1.attention.self.query_type': <class 'torch.nn.modules.linear.Linear'>, 'bert.encoder.layer.1.attention.self.key_type': <class 'chop.nn.quantized.modules.linear.LinearInteger'>, 'bert.encoder.layer.1.attention.output.dense_type': <class 'torch.nn.modules.linear.Linear'>, 'bert.encoder.layer.1.intermediate.dense_type': <class 'torch.nn.modules.linear.Linear'>, 'bert.encoder.layer.1.output.dense_type': <class 'torch.nn.modules.linear.Linear'>, 'classifier_type': <class 'torch.nn.modules.linear.Linear'>}. Best is trial 0 with value: 0.87464.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=\"bert-tiny-nas-study\",\n",
    "    sampler=sampler,\n",
    ")\n",
    "\n",
    "study.optimize(\n",
    "    objective,\n",
    "    n_trials=1,\n",
    "    timeout=60 * 60 * 24,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py:105: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTokenizing dataset imdb with AutoTokenizer for bert-base-uncased.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Task 1: Integer per-layer width/frac search ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-05 01:30:55,243]\u001b[0m Using an existing study with name 'tutorial6_integer_layerwise_widthfrac' instead of creating a new one.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[skip] tutorial6_integer_layerwise_widthfrac: already has 24 COMPLETE trials\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsoAAAHWCAYAAABuaq89AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjgsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvwVt1zgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAfbRJREFUeJzt3XlcVFX/B/DPMMCwCcouioJoKLljILiWAi5Rlo+ZJoKmpo+4QMsDJqKVoj5GZKFWj9JilmVqWkoiikuaGC5l7iul7AooyH5/f/Cbq8MMyLA4zMzn/XrN6+U9c+ec750zA18P554jEQRBABERERERKTDQdABERERERC0RE2UiIiIiIhWYKBMRERERqcBEmYiIiIhIBSbKREREREQqMFEmIiIiIlKBiTIRERERkQpMlImIiIiIVGCiTERERESkAhNlomZ0/fp1SCQSrFq1StOh0EM+//xzSCQSXL9+XdOhPBbyz+Hnn3+u6VAeKSQkBC4uLo88T51repzfw3//+9/w8/Nr9naaw9ChQzF06FBNh9Ei5OXlwdzcHLt27dJ0KKRhTJRJ70gkkno9UlJSNB0qNm/ejEmTJqFLly6QSCRN8ktMniT+/vvvar+2uLgYixcvbhHvDVFNu3btwuLFizXW/rVr1/C///0PCxYsEMvkSbr8YWBgAGtra4wcORJHjx7VWKwtjYuLi8L7ZGJigi5duuDNN9/E7du3m63d2j4zNjY2mDZtGqKiopqtbdIOhpoOgOhx++qrrxSOv/zySyQlJSmVd+vW7XGGpdLatWuRlpaGp556Cnl5eZoOB8XFxViyZAkAcORJi3Ts2BH379+HkZGRpkN5pM8++wxVVVUNeu2uXbsQHx+vsWT5ww8/hKurK55++mml5yZMmIBRo0ahsrISFy9exJo1a/D000/j+PHj6NGjhwaiVbZnzx6Ntt+7d2+8/vrrAICSkhKkpaUhLi4OBw4cQGpqarO0WddnZubMmVi9ejX27duHZ555plnap5aPiTLpnUmTJikc//bbb0hKSlIqbwm++uortGvXDgYGBujevbumw9EqRUVFMDc313QYDdLUsctH6LSBNiTzqpSXl+Prr7/GzJkzVT7ft29fhZ8xgwYNwsiRI7F27VqsWbPmcYVZJ2NjY422365dO4X3aNq0abCwsMCqVatw6dIldOnS5bHG061bN3Tv3h2ff/45E2U9xqkXRCokJCTgmWeegb29PWQyGTw8PLB27Vql837//XcEBATA1tYWpqamcHV1xdSpU+usWxAEzJgxA8bGxti6dWud5zo7O8PAoH5f0/PnzyM9Pb1e59YUEhICCwsL3Lx5E2PGjIGFhQXs7OzwxhtvoLKyEkD1n5Dt7OwAAEuWLBH/RPrwSMz58+fxr3/9C9bW1jAxMUG/fv2wY8cOpfb++OMPDBkyBKampmjfvj3ee+89JCQkqJw3vHv3bgwaNAjm5uZo1aoVRo8ejb/++ktl/FeuXMGoUaPQqlUrvPLKK2q9Bz/++CNGjx4NJycnyGQyuLm54d133xWvHwCio6NhZGSEnJwcpdfPmDEDrVu3RklJSbPFHh4eDhsbGwiCIJbNmTMHEokEq1evFsuysrIgkUjEz6yq+byZmZmYMmUK2rdvD5lMhrZt2+L5559v0PtfU35+PqRSqUJMubm5MDAwUIp/1qxZcHR0VHg/as5Rzs/PR0hICKysrNC6dWsEBwcjPz9f6X2Mj48HoDi9qqZPP/0Ubm5ukMlkeOqpp3D8+HGF5+v7vtR0+PBh5ObmYvjw4XWeJzdo0CAAwJUrV8SyxYsXq4xZ1Zx6FxcXPPvsszh8+DC8vLxgYmKCTp064csvv1T52l9//RXh4eGws7ODubk5XnjhBaXPcc05yikpKZBIJPjuu++wdOlStG/fHiYmJhg2bBguX76sFGd8fDw6deoEU1NTeHl54dChQ42e9yz/bBgaKo7r1ednTXl5OZYsWYIuXbrAxMQENjY2GDhwIJKSkgDU7zPj5+eHnTt3KnxmSb9wRJlIhbVr1+LJJ5/Ec889B0NDQ+zcuRP//ve/UVVVhdmzZwMAsrOz4e/vDzs7O0RERKB169a4fv16nclvZWUlpk6dis2bN2Pbtm0YPXp0k8XcrVs3DBkypMHzhysrKxEQEABvb2+sWrUKe/fuxfvvvw83NzfMmjULdnZ2WLt2LWbNmoUXXngBL774IgCgZ8+eAIC//voLAwYMQLt27RAREQFzc3N89913GDNmDH744Qe88MILAICbN2/i6aefhkQiQWRkJMzNzfG///0PMplMKaavvvoKwcHBCAgIwIoVK1BcXIy1a9di4MCBOHnypEJCVVFRgYCAAAwcOBCrVq2CmZmZWtf/+eefw8LCAuHh4bCwsMC+ffuwaNEiFBYW4r///S8AICgoCO+88w42b96M0NBQ8bVlZWXYsmULxo4dK47cNkfsgwYNwgcffIC//vpL/AvDoUOHYGBggEOHDmHu3LliGQAMHjy41usdO3Ys/vrrL8yZMwcuLi7Izs5GUlIS0tPTxdjUuYaHtW7dGt27d8fBgwfFmA4fPgyJRILbt2/j7NmzePLJJ8VY5UmjKoIg4Pnnn8fhw4cxc+ZMdOvWDdu2bUNwcLDCea+99hpu3bqlchqV3KZNm3D37l289tprkEgkWLlyJV588UVcvXpVHMmuz/uiypEjRyCRSNCnT59az3mYPOlt06ZNvc5X5fLly/jXv/6FV199FcHBwdiwYQNCQkLg6ekpvr9yc+bMQZs2bRAdHY3r168jLi4OoaGh2Lx58yPbWb58OQwMDPDGG2+goKAAK1euxCuvvIJjx46J56xduxahoaEYNGgQwsLCcP36dYwZMwZt2rRB+/bt63U95eXlyM3NBVA99eLkyZOIjY3F4MGD4erqKp5X3581ixcvRkxMDKZNmwYvLy8UFhbi999/x4kTJ+Dn51evz4ynp6fSd470jECk52bPni3U/CoUFxcrnRcQECB06tRJPN62bZsAQDh+/HitdV+7dk0AIPz3v/8VysvLhfHjxwumpqbCL7/8onacTz75pDBkyJBanwdQ5/NyCQkJSnEHBwcLAIR33nlH4dw+ffoInp6e4nFOTo4AQIiOjlaqd9iwYUKPHj2EkpISsayqqkrw9fUVunTpIpbNmTNHkEgkwsmTJ8WyvLw8wdraWgAgXLt2TRAEQbh7967QunVrYfr06QrtZGZmClZWVgrl8vgjIiIeef0PvwfytgRBdZ+/9tprgpmZmcI1+fj4CN7e3grnbd26VQAg7N+/v1ljz87OFgAIa9asEQRBEPLz8wUDAwNh3LhxgoODg3je3LlzBWtra6GqqkoQhAefw4SEBEEQBOHOnTvi57I26lyDKrNnz1aIKTw8XBg8eLBgb28vrF27VhCE6n6XSCTChx9+qPB+dOzYUTzevn27AEBYuXKlWFZRUSEMGjRI4Zrkbar6tSa/fhsbG+H27dti+Y8//igAEHbu3Fnv96U2kyZNEmxsbGpte8mSJUJOTo6QmZkpHDp0SHjqqacEAML3338vnhsdHa0yflWf144dOwoAhIMHD4pl2dnZgkwmE15//XWl1w4fPlz8PAiCIISFhQlSqVTIz88Xy4YMGaLwM2T//v0CAKFbt25CaWmpWP7hhx8KAIQ///xTEARBKC0tFWxsbISnnnpKKC8vF8/7/PPP6/1zSX49NR8DBgwQcnNzFc6t78+aXr16CaNHj66z3do+M3JHjhwRAAibN29+5DWQbuLUCyIVTE1NxX8XFBQgNzcXQ4YMwdWrV1FQUACgetQMAH766SeUl5fXWV9ZWRnGjRuHn376Cbt27YK/v3+TxywIQqNXo6g5v3LQoEG4evXqI193+/Zt7Nu3Dy+99BLu3r2L3Nxc5ObmIi8vDwEBAbh06RJu3rwJAEhMTISPjw969+4tvt7a2lppukFSUhLy8/MxYcIEsb7c3FxIpVJ4e3tj//79SnHMmjWrAVdd7eE+l1/DoEGDUFxcjPPnz4vPTZ48GceOHVP4k/nXX38NZ2dnDBkypFljt7OzQ9euXXHw4EEAwK+//gqpVIo333wTWVlZuHTpEoDqUdqBAweq/DO+/FqNjY2RkpKCO3fuqDynIdfwsEGDBiErKwsXLlwQYxo8eDAGDRokjngfPnwYgiDUOaK8a9cuGBoaKrw/UqkUc+bMqbN9VcaPH68wgitvV/4Zr8/7Upu8vLw6R4ejo6NhZ2cHR0dHDBo0COfOncP777+Pf/3rX2pfh5yHh4fCe2dnZwd3d3eV39kZM2YofB4GDRqEyspK3Lhx45HtTJkyRWH+cs337ffff0deXh6mT5+uMEXilVdeUWvE3NvbG0lJSUhKSsJPP/2EpUuX4q+//sJzzz2H+/fvA1DvZ03r1q3x119/id+LhpDHLx/pJv3DqRdEKvz666+Ijo7G0aNHUVxcrPBcQUEBrKysMGTIEIwdOxZLlizBBx98gKFDh2LMmDGYOHGi0jSCmJgY3Lt3D7t3726xq0WYmJiIc5Dl2rRpU6+E4fLlyxAEAVFRUbUup5SdnY127drhxo0b8PHxUXq+c+fOCsfyX2613URjaWmpcGxoaFjvP/Gq8tdff2HhwoXYt28fCgsLFZ6T/+cIqE625s+fj6+//hqLFi1CQUEBfvrpJ4SFhYmJSGNjv3fvHu7duyceS6VSsW8GDRokru166NAh9OvXD/369YO1tTUOHToEBwcHnD59GhMnTqz1WmUyGVasWIHXX38dDg4O6N+/P5599llMnjxZnBOq7jXUJE+mDh06hPbt2+PkyZN47733YGdnJ65nfOjQIVhaWqJXr1611nPjxg20bdsWFhYWCuXu7u51tq9Khw4dFI7lSZD8M16f96UuQh3zWGfMmIFx48ahpKQE+/btw+rVqxXmvzdEzesBav/OPura1Wmn5mvlyXbN77ChoWG91sSWs7W1VZjjPXr0aLi7u+Nf//oX/ve//2HOnDlq/ax555138Pzzz+OJJ55A9+7dMWLECAQFBYnTxepD3qe1/aeTdB8TZaIarly5gmHDhqFr166IjY2Fs7MzjI2NsWvXLnzwwQfi0lUSiQRbtmzBb7/9hp07d+KXX37B1KlT8f777+O3335T+MUeEBCAxMRErFy5EkOHDm2RKxBIpdIGv1b+nrzxxhsICAhQeU7NX6L1rfOrr75SmaTUvLlHJpPV+8bHmvLz8zFkyBBYWlrinXfegZubG0xMTHDixAn85z//UViurE2bNnj22WfFRHnLli0oLS1VuFu/sbGvWrVKXIYPqF7eTT6ndeDAgfjss89w9epVcX6vRCLBwIEDcejQITg5OaGqqqrOUVoAmD9/PgIDA7F9+3b88ssviIqKQkxMDPbt24c+ffqofQ01OTk5wdXVFQcPHoSLiwsEQYCPjw/s7Owwb9483LhxA4cOHYKvr2+D+01dtX3GH05wH/W+1MbGxqbOpLNLly5iEvjss89CKpUiIiICTz/9NPr16weg9mSstoS6PtfTkHOb8rWNNWzYMADAwYMHMWfOHLV+1gwePBhXrlzBjz/+iD179uB///sfPvjgA6xbtw7Tpk2rV/vyPrW1tW3spZCWYqJMVMPOnTtRWlqKHTt2KIyk1Pan5v79+6N///5YunQpNm3ahFdeeQXffvutwg/i/v37Y+bMmXj22Wcxbtw4bNu27ZGJRktU2y/yTp06Aahe2utRd/137NhR5R3zNcvc3NwAAPb29vVeSaChUlJSkJeXh61btyrcAHft2jWV50+ePBnPP/88jh8/jq+//hp9+vRRuHmqsbFPnjwZAwcOFI8fnhYiT4CTkpJw/PhxREREAKhOCtauXQsnJyeYm5vD09Pzke24ubnh9ddfx+uvv45Lly6hd+/eeP/997Fx48Ymef8HDRqEgwcPwtXVFb1790arVq3Qq1cvWFlZITExESdOnFD4D4EqHTt2RHJyMu7du6fwn0/5lI6HNdWoX13vS226du2Kr7/+WvyL06O8/fbb+Oyzz7Bw4UIkJiYCeDBSm5+fL07tAlCv6RGa1LFjRwDV3+GH15CuqKjA9evX1RrBramiogIAxL+wqPOzBqie1jVlyhRMmTIF9+7dw+DBg7F48WLx5/OjPjPynwEtYV190gzOUSaqQT568vBoSUFBARISEhTOu3PnjtKIinzebWlpqVK9w4cPx7fffovExEQEBQU1eFOF2jRmebj6kq/GUHNpLnt7ewwdOhSffPIJMjIylF738DJUAQEBOHr0KE6dOiWW3b59G19//bXCawICAmBpaYlly5apnAOuaom2hlLV52VlZbWubzty5EjY2tpixYoVOHDggNIa3I2NvVOnThg+fLj4GDBggPicq6sr2rVrhw8++ADl5eXic4MGDcKVK1ewZcsW9O/fv87/iBUXFyssYwdUJ4etWrUSP7tN8f4PGjQI169fx+bNm8UE38DAAL6+voiNjUV5efkjR75HjRqFiooKheUZKysr8dFHHymdK197uubns77q877UxsfHB4IgIC0trV5ttW7dGq+99hp++eUX8bsg/8+JfA46UL2m9hdffKHGVTx+/fr1g42NDT777DMxsQWq5+6rO9e7pp07dwKAOD1HnZ81NTdpsrCwQOfOnRX68lGfmbS0NFhZWSmtIkL6Q/uGtIiamb+/P4yNjREYGIjXXnsN9+7dw2effQZ7e3uFH8xffPEF1qxZgxdeeAFubm64e/cuPvvsM1haWmLUqFEq6x4zZgwSEhIwefJkWFpa4pNPPqkzloMHD4q/NHNyclBUVIT33nsPQPUI4sOjn41dHq4+TE1N4eHhgc2bN+OJJ56AtbU1unfvju7duyM+Ph4DBw5Ejx49MH36dHTq1AlZWVk4evQo/vnnH5w+fRoA8NZbb2Hjxo3w8/PDnDlzxOXhOnTogNu3b4sjPJaWlli7di2CgoLQt29fvPzyy7Czs0N6ejp+/vlnDBgwAB9//HGTXJevry/atGmD4OBgzJ07FxKJBF999VWtf1o2MjLCyy+/jI8//hhSqRQTJkxQeL65Yx80aBC+/fZb9OjRQxyF7Nu3L8zNzXHx4sU65ycDwMWLFzFs2DC89NJL8PDwgKGhIbZt24asrCy8/PLLTXYN8iT4woULWLZsmVg+ePBg7N69W1zLuC6BgYEYMGAAIiIicP36dXh4eGDr1q0K88bl5KPoc+fORUBAAKRSqXg99VGf96U2AwcOhI2NDfbu3VvvzSnmzZuHuLg4LF++HN9++y38/f3RoUMHvPrqq3jzzTchlUqxYcMG8X1vqYyNjbF48WLMmTMHzzzzDF566SVcv34dn3/+Odzc3Oo90n/z5k1x1L6srAynT5/GJ598AltbW4WbN+v7s8bDwwNDhw6Fp6cnrK2t8fvvv2PLli0KSzs+6jOTlJSEwMBAzlHWZ49/oQ2ilkXV8kA7duwQevbsKZiYmAguLi7CihUrhA0bNigs0XTixAlhwoQJQocOHQSZTCbY29sLzz77rPD777+L9Ty8PNzD1qxZIwAQ3njjjTpjky8XpepRc4k2NHJ5OHNz81rbf9iRI0cET09PwdjYWCmOK1euCJMnTxYcHR0FIyMjoV27dsKzzz4rbNmyRaGOkydPCoMGDRJkMpnQvn17ISYmRli9erUAQMjMzFQ4d//+/UJAQIBgZWUlmJiYCG5ubkJISIjC+1xb/I96Dx5ebuvXX38V+vfvL5iamgpOTk7CW2+9Jfzyyy8Ky749LDU1VQAg+Pv719pOc8QuCIIQHx8vABBmzZqlUD58+HABgJCcnKxQXnN5uNzcXGH27NlC165dBXNzc8HKykrw9vYWvvvuuwZdQ13s7e0FAEJWVpZYdvjwYQGAMGjQIKXzay4PJwjVy8gFBQUJlpaWgpWVlRAUFCScPHlSaXm4iooKYc6cOYKdnZ0gkUjEz25t30NBEBQ+w+q8L6rMnTtX6Ny5s0JZXW0LgiCEhIQIUqlUuHz5siAIgpCWliZ4e3sLxsbGQocOHYTY2Nhal4dTtfRZzSXeVH3fBeHB0m8Pf7ZrWx7u4SXsHr6mh997QRCE1atXCx07dhRkMpng5eUl/Prrr4Knp6cwYsQIldf+sJrLwxkYGAj29vbChAkTxPfmYfX5WfPee+8JXl5eQuvWrQVTU1Oha9euwtKlS4WysjLxnNo+M4IgCOfOnRMACHv37n1k/KS7JILA7WaISPPmz5+PTz75BPfu3WvUjYWPy+nTp9G7d298+eWXCAoK0nQ41AJcvXoVXbt2xe7du8Wb0PRZVVUV7Ozs8OKLL+Kzzz7TdDhqmz9/Pg4ePIi0tDSOKOsxzlEmosdOviaqXF5eHr766isMHDhQK5JkAPjss89gYWEh7lBI1KlTJ7z66qtYvny5pkN57EpKSpSmKn355Ze4fft2i10Ssy55eXn43//+h/fee49Jsp7jiDIRPXa9e/fG0KFD0a1bN2RlZWH9+vW4desWkpOT69x2uSXYuXMnzp49i6ioKISGhiI2NlbTIRFpXEpKCsLCwjBu3DjY2NjgxIkTWL9+Pbp164a0tDSFDUuItAkTZSJ67BYsWIAtW7bgn3/+gUQiQd++fREdHd3sy8A1BRcXF2RlZSEgIABfffUVWrVqpemQiDTu+vXrmDt3LlJTU3H79m1YW1tj1KhRWL58Oezt7TUdHlGDMVEmIiIiIlKBc5SJiIiIiFRgokxEREREpAI3HGmgqqoq3Lp1C61ateIdsUREREQtkCAIuHv3LpycnGBgoP74MBPlBrp16xacnZ01HQYRERERPcLff/+N9u3bq/06JsoNJL/T/e+//4alpSXKy8uxZ88e+Pv7w8jISMPRUXNhP+sP9rV+YD/rD/a1fqjZz4WFhXB2dm7wCkVMlBtIPt3C0tJSTJTNzMxgaWnJL6AOYz/rD/a1fmA/6w/2tX6orZ8bOk2WN/MREREREanARJmIiIiISAUmykREREREKjBRJiIiIiJSgYkyEREREZEKTJSJiIiIiFRgokxEREREpAITZSIiIiIiFZgoExERERGpwJ35iIiIiPRcZZWA1Gu3kX23BPatTODlag2pQcN2s9NkG02NiTIRERGRHks8k4ElO88io6BELGtrZYLoQA+M6N5Wa9poDpx6QURERKSnEs9kYNbGEwoJLABkFpRg1sYTSDyToRVtNBcmykRERER6qLJKwJKdZyGoeE5etmTnWVRWqTqj5bTRnDj1goiIiEgPpV67rTTK+zABQEZBCYb+dz/MZQ1LGYtKK+rVRuq12/Bxs2lQG82JiTIRERGRHqmqEvDXrUJ8dfR6vc7/+8795g0IQPbd2pNpTWKiTERERKTjCorLcfBSDlIu5ODAxRzk3iut92sXjOoGj7aWDWr3bEYhlu0698jz7FuZNKj+5sZEmYiIiKiFU3dpNfmoccqFbKRczMHJ9Dt4eBqwmbEUvm42SL12G4UlFSrrkABwtDLBqwNdG7yMm4+bDRJ+vYbMghKV85TlbXi5Wjeo/ubGRJmIiIioBavv0mqPGjXuYm+Boe52GOpuj34ubSAzlIorUgBQSGTlaXF0oEej1jqWGkgQHeiBWRtPQNJMbTQnJspERERELZQ8ka05GitfWi1iZFeUVVSpHDU2N5bCt7MthrrbYcgTdmjfxkyp/hHd22LtpL5KibhjE65x/DjaaC5MlImIiIhaoPosrRaz+7xCeRd7Czzd1R5Dn7BDPxdrGBs+eiXgEd3bws/DsVl3zXscbTQHJspERERELdCjlm+T8+zYBi/2bYeh7vZo19q0QW1JDSTNvjzb42ijqbWIDUfi4+Ph4uICExMTeHt7IzU1tc7z4+Li4O7uDlNTUzg7OyMsLAwlJQ8+SC4uLpBIJEqP2bNnAwCuX7+u8nmJRILvv/++Wa+ViIiI6FHul1XWe8e6yT4d8Yp3xwYnyVQ7jY8ob968GeHh4Vi3bh28vb0RFxeHgIAAXLhwAfb29krnb9q0CREREdiwYQN8fX1x8eJFhISEQCKRIDY2FgBw/PhxVFZWiq85c+YM/Pz8MG7cOACAs7MzMjIUP3yffvop/vvf/2LkyJHNeLVEREREqlVWCThyJRfbT97CL39l4l6p6tUoamqpS6vpAo0nyrGxsZg+fTqmTJkCAFi3bh1+/vlnbNiwAREREUrnHzlyBAMGDMDEiRMBVI8eT5gwAceOHRPPsbOzU3jN8uXL4ebmhiFDhgAApFIpHB0dFc7Ztm0bXnrpJVhYWDTp9RERERHVRhAEnLlZiO2nbmLn6VvIvvtgpYp2rU2Qf78cRaWVKl/b0pdW0wUaTZTLysqQlpaGyMhIsczAwADDhw/H0aNHVb7G19cXGzduRGpqKry8vHD16lXs2rULQUFBtbaxceNGhIeHQyJRPWE8LS0Np06dQnx8fK2xlpaWorT0wYe3sLAQAFBeXi4+5Meku9jP+oN9rR/Yz/qjpfV1+u1i7PwjEztOZ+BqbpFY3trUCCO7O+D5Xm3Rt0Nr7DmbjTnfngagemm1t0e6o6qyAlWqc2m9U7OfG9vfEkEQVN1M+VjcunUL7dq1w5EjR+Dj4yOWv/XWWzhw4IDCKPHDVq9ejTfeeAOCIKCiogIzZ87E2rVrVZ773XffYeLEiUhPT4eTk5PKc/79738jJSUFZ8+erTXWxYsXY8mSJUrlmzZtgpmZ8nIrRERE1DJUCcCVQgkKywFLI8DNUkBTLrZQ3/rvlQMn8yRIyzXAtbsPTjCSCOhuLcDTVkC31gJqLlRxOk+CrdcNkF/24DWtjQW86FKFXjYaS+O0QnFxMSZOnIiCggJYWqq/u6DGp16oKyUlBcuWLcOaNWvg7e2Ny5cvY968eXj33XcRFRWldP769esxcuTIWpPk+/fvY9OmTSpf+7DIyEiEh4eLx4WFhXB2doa/vz8sLS1RXl6OpKQk+Pn5wcjIqHEXSS0W+1l/sK/1A/tZ9/3yVxZidp1HZuGDvwo7WsqwcFRXBDzp0Oz13y+rRPL5bOz4IwOHLuWh4v8XOpZIAJ9O1niuZ1v4eziglUntKdkoAG9VCfj9xh1k3y2FfSsZ+nVs0+KXVtOEmt9p+QyAhtJoomxrawupVIqsrCyF8qysLKU5xHJRUVEICgrCtGnTAAA9evRAUVERZsyYgbfffhsGBg/+G3bjxg3s3bsXW7durTWGLVu2oLi4GJMnT64zVplMBplMplRuZGSk8MO15jHpJvaz/mBf6wf2s25KPJOBOd+eVlqHOKuwFHO+PY21k/o2arOLuuoP/fY0vF2tceZmAYrKHsyL6N7OEmN6t0NgLyc4WNb/JjwjAAOfaHxiry/k3+nGfq81migbGxvD09MTycnJGDNmDACgqqoKycnJCA0NVfma4uJihWQYqL45D6ieEP+whIQE2NvbY/To0bXGsH79ejz33HNKNwASERGR9nrUZh0SANE7/sJTLg3b9KKySkD0jr/q3Azk2LXbAID2bUwxpnc7jOnjhM72rdRuizRH41MvwsPDERwcjH79+sHLywtxcXEoKioSV8GYPHky2rVrh5iYGABAYGAgYmNj0adPH3HqRVRUFAIDA8WEGahOuBMSEhAcHAxDQ9WXefnyZRw8eBC7du1q/gslIiKix+ZRm3UIqB759Xxvb7PGsTjQA8G+LrUuKEAtm8YT5fHjxyMnJweLFi1CZmYmevfujcTERDg4VP95IT09XWEEeeHChZBIJFi4cCFu3rwJOzs7BAYGYunSpQr17t27F+np6Zg6dWqtbW/YsAHt27eHv79/81wcERERaUT23UfvaPc4tDE3ZpKsxTSeKANAaGhorVMtUlJSFI4NDQ0RHR2N6OjoOuv09/dXmopR07Jly7Bs2TK1YiUiIqKWz6Tm0hG12PiqF/p3Un9b5d+u5mHS+rp3Ega4GYi2axGJMhEREVFTOf13Phbv+KvOc+Sbdfi42TZojrKPmy3aWpkgs6BE5TxlbgaiG+r33y0iIiIiLfBtajrGrTuKjMLqZdSAB5tzyMmPowM9GrzEmtRAguhAj2arn1oGJspERESk9UrKKxHxwx+I2Ponyiqr4OfhgL2vD8G6SX3haKU4/cHRyqTRS8MBwIjubbG2GesnzePUCyIiItJqN/PvY9bGNPzxTwEkEuANf3fMGuIGAwMJRnRvCz8PRxy9nI09h47Bf5A3fDrbN9lIr7z+1Gu3kX23BPatqqdbcCRZNzBRJiIiIq316+VczPnmJG4XlaG1mRE+fLkPhjyhuDeC1EACb1dr5J0T4N0MSazUQAIfN/VvCKSWj4kyERERaR1BELDuwFX895fzqBKAJ50ssW6SJ5ytzTQdGukQJspERESkVe6WlOPN7/9A4l+ZAIB/ebbHe2O6w8RI+ohXEqmHiTIRERFpjcvZd/HaV2m4klMEI6kE0YFP4hXvDtzUg5oFE2UiIiLSCrv/zMAb359GUVklHC1NsGZSX/Tt0EbTYZEOY6JMRERELVpFZRX++8sFfHLwKgDA29UaH0/sC7v/XyeZqLkwUSYiIqIWK+9eKeZ8cxJHruQBAKYNdEXEyK4wlHIrCGp+TJSJiIioRTr9dz5mbUzDrYISmBlLsWJsTwT2ctJ0WKRHmCgTUZOqrBKadeH95q5f3saxa7eRliuBzbXbTbo5gbz+x3ENutAPzX0NzdnP8jbYDw2r/5vUdET/+BfKKqvgamuOT4I88YRDqyZrl6g+mCgTUZNJPJOBJTvPIqOgRCxra2WC6ECPJtnKtbnrV25Dii8v/a7l19D0bejeNTR9Pyu3UY398Oj6HS1lcLOzwK//P9XCz8MB77/UC5YmRo1uj0hdnOBDRE0i8UwGZm08ofALDwAyC0owa+MJJJ7JaNH1P442eA0tow1eQ8too9b6C0vFJPnNAHd8MsmTSTJpDBNlImq0yioBS3aehaDiOXnZkp1nUVml6gzN1/842uA1tIw2eA0to4266pezNjfGzCFuMGjiqSRE6pAIgtDwb5IeKywshJWVFQoKCmBpaYny8nLs2rULo0aNgpER/+erq9jPqh29kocJn/32yPOc25jCXKb+jK+i0gr8fed+s9X/ONrgNbSMNngNLaON+tb/zfT+8HGzUbt+VfjzWz/U7Oea+Zq6OEeZiBot+27Jo08C6vWLsTGau/7H0QavoWW0wWtoGW3U92cLUXNhokxEjWbfyqRe5y0Y1Q0ebdX/H/3ZjEIs23Wu2ep/HG3wGlpGG7yGltFGfeuv788WoubCRJmIGs3L1RptrUyUbsqRkwBwtDLBqwNdG7SslI+bDRJ+vYbMghKVcxobW//jaIPX0DLa4DW0jDbqW7+Xq7XadRM1Jd7MR0SNJjWQINjHReVz8l+h0YEeDf6lLTWQIDrQQ6G+pqz/cbTBa2gZbfAaWkYbj+MaiJoCE2UiajRBEHDgYg4AwNRI8ceKo5UJ1k7q2+g1V0d0b4u1k/rC0UrxT7FNVf/jaIPX0DLa4DW0jDYexzUQNRZXvWggrnqhn9jPqh24mIPgDakwlhpgT9hgZBSUaP1OZEcvZ2PPoWPwH+TNnfk0UP/jaKO5+1neBvtBs/XL8ee3fuCqF0TUolRVCVix+zwAIMinI1xszeFia95s7UkNJE22XFRdbXi7WiPvnADvZvil/biuoTnb0JVraM5+lrfBftBs/USNwakXRNQoO/+4hbMZhWglM8TspztrOhwiIqImw0SZiBqstKIS//3lAgBg5lA3WJsbazgiIiKipsNEmYgabNOxdPxz5z7sW8kwZYCLpsMhIiJqUkyUiahB7paU46N9lwEA84c/ATNj3vJARES6hYkyETXIZwev4nZRGTrZmuOlfu01HQ4REVGTY6JMRGrLvluCzw5dAwC8NcIdhlL+KCEiIt3D325EpLbVyZdwv7wSvZ1bI+BJR02HQ0RE1CyYKBORWq7lFuHb1L8BABEju0Ii4RazRESkm5goE5FaVu25gIoqAU+726F/J24SQEREuqtFJMrx8fFwcXGBiYkJvL29kZqaWuf5cXFxcHd3h6mpKZydnREWFoaSkhLxeRcXF0gkEqXH7NmzFeo5evQonnnmGZibm8PS0hKDBw/G/fv3m+UaiXTB6b/z8fMfGZBIgLdGdNV0OERERM1K4+s5bd68GeHh4Vi3bh28vb0RFxeHgIAAXLhwAfb29krnb9q0CREREdiwYQN8fX1x8eJFhISEQCKRIDY2FgBw/PhxVFZWiq85c+YM/Pz8MG7cOLHs6NGjGDFiBCIjI/HRRx/B0NAQp0+fhoFBi/i/A1GLIwgClv//VtUv9GmHbm0tNRwRERFR89J4ohwbG4vp06djypQpAIB169bh559/xoYNGxAREaF0/pEjRzBgwABMnDgRQPXo8YQJE3Ds2DHxHDs7O4XXLF++HG5ubhgyZIhYFhYWhrlz5yq04e7uXmucpaWlKC0tFY8LCwsBAOXl5eJDfky6S5/7+dClXBy9mgcjqQRzn+6k8++BPve1PmE/6w/2tX6o2c+N7W+NJsplZWVIS0tDZGSkWGZgYIDhw4fj6NGjKl/j6+uLjRs3IjU1FV5eXrh69Sp27dqFoKCgWtvYuHEjwsPDxZuOsrOzcezYMbzyyivw9fXFlStX0LVrVyxduhQDBw5UWU9MTAyWLFmiVL5nzx6YmZmJx0lJSfW+ftJe+tbPVQKw6g8pAAkG2Ffi9JH9OK3poB4TfetrfcV+1h/sa/0g7+fi4uJG1aPRRDk3NxeVlZVwcHBQKHdwcMD58+dVvmbixInIzc3FwIEDIQgCKioqMHPmTCxYsEDl+du3b0d+fj5CQkLEsqtXrwIAFi9ejFWrVqF379748ssvMWzYMJw5cwZdunRRqicyMhLh4eHicWFhIZydneHv7w9LS0uUl5cjKSkJfn5+MDIyUvetIC2hr/384+kM3PztT1jIDLEyZCDamBlrOqRmp699rW/Yz/qDfa0favazfAZAQ2l86oW6UlJSsGzZMqxZswbe3t64fPky5s2bh3fffRdRUVFK569fvx4jR46Ek5OTWFZVVQUAeO2118QpH3369EFycjI2bNiAmJgYpXpkMhlkMplSuZGRkcIXruYx6SZ96ufSikrEJVdvVT1rqBvsrcw1HNHjpU99rc/Yz/qDfa0f5P3c2L7WaKJsa2sLqVSKrKwshfKsrCw4OqrexCAqKgpBQUGYNm0aAKBHjx4oKirCjBkz8PbbbyvcjHfjxg3s3bsXW7duVaijbdu2AAAPDw+F8m7duiE9Pb3R10WkSzYdS8c/d+7DvpUMUwe4ajocIiKix0ajSzwYGxvD09MTycnJYllVVRWSk5Ph4+Oj8jXFxcVKK1NIpVIA1XflPywhIQH29vYYPXq0QrmLiwucnJxw4cIFhfKLFy+iY8eODb4eIl1zt6QcH+2rHk2eP/wJmBpLNRwRERHR46PxqRfh4eEIDg5Gv3794OXlhbi4OBQVFYlTIiZPnox27dqJ0yECAwMRGxuLPn36iFMvoqKiEBgYKCbMQHXCnZCQgODgYBgaKl6mRCLBm2++iejoaPTq1Qu9e/fGF198gfPnz2PLli2P7+KJWrjPDl7F7aIydLI1x0v92ms6HCIiosdK44ny+PHjkZOTg0WLFiEzMxO9e/dGYmKieINfenq6wgjywoULIZFIsHDhQty8eRN2dnYIDAzE0qVLFerdu3cv0tPTMXXqVJXtzp8/HyUlJQgLC8Pt27fRq1cvJCUlwc3NrfkulkiLZN8twWeHrgEA3hrhDkMp1xgnIiL9ovFEGQBCQ0MRGhqq8rmUlBSFY0NDQ0RHRyM6OrrOOv39/ZWmYtQUERGhcq1mIgJWJ1/C/fJK9HZujYAnVd8zQEREpMs4RERESq7m3MM3qX8DACJGdhXXICciItInTJSJSMn7ey6iskrAM13t0b+TjabDISIi0ggmykSk4NTf+fj5zwxIJNVzk4mIiPQVE2UiEgmCgBW7q3fFfLFPe3R1tNRwRERERJrDRJmIRAcv5eLo1TwYSw0Q5qe8lTsREZE+YaJMRACAqioBy/9/NHmyT0e0b2Om4YiIiIg0i4kyEQEAdpy+hXMZhWglM8TspztrOhwiIiKNY6JMRCitqMSqPdVbus8c6oY25sYajoiIiEjzmCgTEb7+LR3/3LkP+1YyTB3gqulwiIiIWgQmykR6rrCkHB/tuwQACPN7AqbGUg1HRERE1DIwUSbSc58dvIo7xeXoZGeOcZ7tNR0OERFRi8FEmUiPZReW4H+HrgEA3groCkMpfyQQERHJ8bcikR5bve8S7pdXok+H1gh40kHT4RAREbUoTJSJ9NTVnHv4JvVvAEDEiK6QSCQajoiIiKhlMdR0AERNpbJKQOq128i+WwL7VibwcrWG1KDpkr/KKgHHrt1GWq4ENtduw6ezfZPWL2+jua9BXv83x9JRWSXgma728O5k02RtEBER6QomyqQTEs9kYMnOs8goKBHL2lqZIDrQAyO6t23i+qX48tLvTVq/chvVmu8aHvDtzCSZiIhIFU69IK2XeCYDszaeUEoAMwtKMGvjCSSeyWjR9T+ONmqrHwCW/nSuSa6BiIhI13BEmbRaZZWAJTvPQlDxnLwscuufqKoSYNCAKQxVVQIWbD/TbPU/jjbqql9uyc6z8PNwbPKpJERERNqMiTJptdRrt1WOkj7sTnE5/r3pZLPF0Nz1N3cbAoCMghKkXrsNHzdOwyAiIpJjokxaLftu3UmynKutOWzMjdWuP6+oDNdyi5qt/sfRRn3rr+97SUREpC+YKJNWs29lUq/zlr3Qo0GjpUev5GHCZ781W/2Po4361l/f95KIiEhf8GY+0mpertZwsJTV+rwE1StHeLlaN7j+tlYmqG3mbmPrfxxtPI5rICIi0kVMlEmrSQ0keMpFdYInTwyjAz0afJOa1ECC6EAPhfqasv7H0cbjuAYiIiJdxESZtFruvVLsP58NAGhtZqTwnKOVCdZO6tvoNYhHdG+LtZP6wtFKcWpCU9X/ONp4HNdARESkazhHmbTax/suo6isEj3bW+GHmb74/cadZtnVbkT3tvDzcMTRy9nYc+gY/Ad5N/nOfPI2mmtnvuaun4iISNcwUSatdSOvCF8fuwEAiBjRFUaGBs26vJnUQAJvV2vknRPg3UwJptRA0uzXwCXgiIiI6odTL0hrvb/nIsorBQx+wg6+nW01HQ4RERHpGCbKpJXO3CzAjtO3AAD/GeGu4WiIiIhIFzFRJq20IvE8AGBMbyc86WSl4WiIiIhIFzFRJq1z6FIODl3KhZFUgtf9OZpMREREzYOJMmmVqipBHE1+xbsjnK3NNBwRERER6SomyqRVfvozA2duFsJCZog5z3TWdDhERESkw1pEohwfHw8XFxeYmJjA29sbqampdZ4fFxcHd3d3mJqawtnZGWFhYSgpKRGfd3FxgUQiUXrMnj1bPGfo0KFKz8+cObPZrpEar6yiCu/vuQAAmDG4E2wsat+6moiIiKixNL6O8ubNmxEeHo5169bB29sbcXFxCAgIwIULF2Bvb690/qZNmxAREYENGzbA19cXFy9eREhICCQSCWJjYwEAx48fR2VlpfiaM2fOwM/PD+PGjVOoa/r06XjnnXfEYzMz/hm/Jfv2eDpu5BXD1kKGVwe6ajocIiIi0nEaT5RjY2Mxffp0TJkyBQCwbt06/Pzzz9iwYQMiIiKUzj9y5AgGDBiAiRMnAqgePZ4wYQKOHTsmnmNnZ6fwmuXLl8PNzQ1DhgxRKDczM4Ojo2NTXxI1g3ulFVidfAkAMG94F5jLNP7RJSIiIh2n0WyjrKwMaWlpiIyMFMsMDAwwfPhwHD16VOVrfH19sXHjRqSmpsLLywtXr17Frl27EBQUVGsbGzduRHh4OCQSxZ3Uvv76a2zcuBGOjo4IDAxEVFRUraPKpaWlKC0tFY8LCwsBAOXl5eJDfkxN79OUK8i9V4aO1mYY29tRY+8z+1l/sK/1A/tZf7Cv9UPNfm5sf6udKA8ZMgSvvvoqxo0bB1NT00Y1npubi8rKSjg4OCiUOzg44Pz58ypfM3HiROTm5mLgwIEQBAEVFRWYOXMmFixYoPL87du3Iz8/HyEhIUr1dOzYEU5OTvjjjz/wn//8BxcuXMDWrVtV1hMTE4MlS5Yole/Zs0chuU5KSqrrkqkBCsuAT05KAUjwtO1dJP2SqOmQ2M96hH2tH9jP+oN9rR/k/VxcXNyoeiSCIAjqvGD+/PnYtGkTSktL8dJLL+HVV19F//79G9T4rVu30K5dOxw5cgQ+Pj5i+VtvvYUDBw4oTKeQS0lJwcsvv4z33nsP3t7euHz5MubNm4fp06cjKipK6fyAgAAYGxtj586ddcayb98+DBs2DJcvX4abm5vS86pGlJ2dnZGbmwtLS0uUl5cjKSkJfn5+MDIyUudtoEd456dz+OrY3+jZzhJbXvNW+svA48R+1h/sa/3AftYf7Gv9ULOfCwsLYWtri4KCAlhaWqpdn9ojynFxcVi1ahV27NiBL774AoMHD0bnzp0xdepUBAUFKY0O18XW1hZSqRRZWVkK5VlZWbXOHY6KikJQUBCmTZsGAOjRoweKioowY8YMvP322zAweLCQx40bN7B3795aR4kf5u3tDQC1JsoymQwymfIqC0ZGRgpfuJrH1Dg38orwzfF/AAARI7vB2NhYwxFVYz/rD/a1fmA/6w/2tX6Q93Nj+7pBy8MZGhrixRdfxI8//oh//vkHEydORFRUFJydnTFmzBjs27evXvUYGxvD09MTycnJYllVVRWSk5MVRpgfVlxcrJAMA4BUKgUA1BwcT0hIgL29PUaPHv3IWE6dOgUAaNu2bb1ip8fj/T0XUVElYPATdvDtbKvpcIiIiEiPNOpmvtTUVCQkJODbb7+Fvb09QkJCcPPmTTz77LP497//jVWrVj2yjvDwcAQHB6Nfv37w8vJCXFwcioqKxFUwJk+ejHbt2iEmJgYAEBgYiNjYWPTp00ecehEVFYXAwEAxYQaqE+6EhAQEBwfD0FDxMq9cuYJNmzZh1KhRsLGxwR9//IGwsDAMHjwYPXv2bMxbQk3ozM0C7Dh9CwDwnxHcqpqIiIgeL7UT5ezsbHz11VdISEjApUuXEBgYiG+++QYBAQHi3NGQkBCMGDGiXony+PHjkZOTg0WLFiEzMxO9e/dGYmKiOIUjPT1dYQR54cKFkEgkWLhwIW7evAk7OzsEBgZi6dKlCvXu3bsX6enpmDp1qlKbxsbG2Lt3r5iUOzs7Y+zYsVi4cKG6bwc1I/lW1WN6O+FJJysNR0NERET6Ru1EuX379nBzc8PUqVMREhKitGYxAPTs2RNPPfVUvesMDQ1FaGioyudSUlIUjg0NDREdHY3o6Og66/T391eaiiHn7OyMAwcO1Ds+evwOXcrBoUu5MJJK8Lo/R5OJiIjo8VM7UU5OTsagQYPqPMfS0hL79+9vcFCk36qqBHE0eVL/jnC25o6JRERE9PipfTNf+/btcenSJaXyS5cu4fr1600RE+m5n/7MwJmbhbCQGSL06c6aDoeIiIj0lNqJckhICI4cOaJUfuzYMaVNPYjUVVZRhVW/XAAAzBjcCTYWykvyERERET0OaifKJ0+exIABA5TK+/fvLy6xRtRQ36SmI/12MWwtZHh1oKumwyEiIiI9pnaiLJFIcPfuXaXygoICVFZWNklQpJ/ulVbgo33V03rmDe8Cc1mjVi8kIiIiahS1E+XBgwcjJiZGISmurKxETEwMBg4c2KTBkX7536GryL1XBhcbM7z8lLOmwyEiIiI9p/aQ3YoVKzB48GC4u7uLq18cOnQIhYWF9d6Rj6imnLul+OzgVQDAmwFdYSRt0KaRRERERE1G7WzEw8MDf/zxB1566SVkZ2fj7t27mDx5Ms6fP4/u3bs3R4ykBz7edwlFZZXo1d4Ko3o4ajocIiIiooZtYe3k5IRly5Y1dSykp27kFeHrY+kAgP+M7Cru8EhERESkSQ2+W6q4uBjp6ekoKytTKO/Zs2ejgyL9smrPRVRUCRjyhB183Ww1HQ4RERERgAYkyjk5OZgyZQp2796t8nmufEHq+POfAuw8fQsA8NYIblVNRERELYfac5Tnz5+P/Px8HDt2DKampkhMTMQXX3yBLl26YMeOHc0RI+kw+VbVY3o74UknKw1HQ0RERPSA2iPK+/btw48//oh+/frBwMAAHTt2hJ+fHywtLRETE4PRo0c3R5ykgw5dysHhy7kwkkrwuj9Hk4mIiKhlUXtEuaioCPb29gCANm3aICcnBwDQo0cPnDhxommjI51VVSWIo8mT+neEs7WZhiMiIiIiUqR2ouzu7o4LFy4AAHr16oVPPvkEN2/exLp169C2bdsmD5B0009/ZuDMzUJYyAwR+nRnTYdDREREpETtqRfz5s1DRkYGACA6OhojRozA119/DWNjY3z++edNHR/poLKKKqz6pfo/W68N7gQbC5mGIyIiIiJSpnaiPGnSJPHfnp6euHHjBs6fP48OHTrA1pZLe5FqlVUCUq/dRvbdEpxMz0f67WLYWsjw6iBXTYdGREREpJJaiXJ5eTm6du2Kn376Cd26dQMAmJmZoW/fvs0SHOmGxDMZWLLzLDIKShTK/TzsYWbc4KW8iYiIiJqVWnOUjYyMUFJS8ugTif5f4pkMzNp4QilJBoBvU/9G4pkMDURFRERE9Ghq38w3e/ZsrFixAhUVFc0RD+mQyioBS3aehVDHOUt2nkVlVV1nEBEREWmG2n/3Pn78OJKTk7Fnzx706NED5ubmCs9v3bq1yYIj7ZZ67bbKkWQ5AUBGQQlSr92Gj5vN4wuMiIiIqB7UTpRbt26NsWPHNkcspGOy79Zvmk59zyMiIiJ6nNROlBMSEpojDtJB9q1MmvQ8IiIiosdJ7TnKRPXl5WqNtlYmkNTyvARAWysTeLlaP86wiIiIiOpF7RFlV1dXSCS1pT7A1atXGxUQ6Q6pgQTRgR6YtVF5a3P5Jyg60ANSg9o/T0RERESaonaiPH/+fIXj8vJynDx5EomJiXjzzTebKi7SESO6t8XaSX0RufVP3CkuF8sdrUwQHeiBEd257TkRERG1TA3awlqV+Ph4/P77740OiHTPiO5tkXOvFFHb/0J3J0u8PdoDXq7WHEkmIiKiFq3J5iiPHDkSP/zwQ1NVRzomq6AUANCnQxv4uNkwSSYiIqIWr8kS5S1btsDamjdlkWry9ZQdrbjCBREREWkHtade9OnTR+FmPkEQkJmZiZycHKxZs6ZJgyPdkVl4H0D1KhdERERE2kDtRHnMmDEKxwYGBrCzs8PQoUPRtWvXpoqLdAxHlImIiEjbqJ0oR0dHN0ccpMMEQUDm/yfKba1MNRwNERERUf2oPUd5165d+OWXX5TKf/nlF+zevbtJgiLdUlhSgeKySgCAoyVHlImIiEg7qJ0oR0REoLKyUqlcEAREREQ0KIj4+Hi4uLjAxMQE3t7eSE1NrfP8uLg4uLu7w9TUFM7OzggLC0NJSYn4vIuLCyQSidJj9uzZKuMeOXIkJBIJtm/f3qD4qW7y0eTWZkYwNZZqOBoiIiKi+lF76sWlS5fg4eGhVN61a1dcvnxZ7QA2b96M8PBwrFu3Dt7e3oiLi0NAQAAuXLgAe3t7pfM3bdqEiIgIbNiwAb6+vrh48SJCQkIgkUgQGxsLADh+/LhCMn/mzBn4+flh3LhxSvXFxcXVudMgNV5GgfxGPk67ICIiIu2h9oiylZWVym2qL1++DHNzc7UDiI2NxfTp0zFlyhR4eHhg3bp1MDMzw4YNG1Sef+TIEQwYMAATJ06Ei4sL/P39MWHCBIVRaDs7Ozg6OoqPn376CW5ubhgyZIhCXadOncL7779fa1vUNB7MT+a0CyIiItIeao8oP//885g/fz62bdsGNzc3ANVJ8uuvv47nnntOrbrKysqQlpaGyMhIsczAwADDhw/H0aNHVb7G19cXGzduRGpqKry8vHD16lXs2rULQUFBtbaxceNGhIeHK4wcFxcXY+LEiYiPj4ejo+MjYy0tLUVpaal4XFhYCKB6C2/5Q35Mim7eKQIA2Lcy1vr3h/2sP9jX+oH9rD/Y1/qhZj83tr/VTpRXrlyJESNGoGvXrmjfvj0A4J9//sGgQYOwatUqterKzc1FZWUlHBwcFModHBxw/vx5la+ZOHEicnNzMXDgQAiCgIqKCsycORMLFixQef727duRn5+PkJAQhfKwsDD4+vri+eefr1esMTExWLJkiVL5nj17YGZmJh4nJSXVqz59cvyKAQADFGbewK5d1zUdTpNgP+sP9rV+YD/rD/a1fpD3c3FxcaPqUTtRtrKywpEjR5CUlITTp0/D1NQUPXv2xODBgxsVSH2lpKRg2bJlWLNmDby9vXH58mXMmzcP7777LqKiopTOX79+PUaOHAknJyexbMeOHdi3bx9OnjxZ73YjIyMRHh4uHhcWFsLZ2Rn+/v6wtLREeXk5kpKS4OfnByMjo8ZdpI7Z8kUakJ2Hwf16YlTfdpoOp1HYz/qDfa0f2M/6g32tH2r2s3wGQEOpnSgDgEQigb+/P/z9/RvVuK2tLaRSKbKyshTKs7Kyap0OERUVhaCgIEybNg0A0KNHDxQVFWHGjBl4++23YWDwYNr1jRs3sHfvXmzdulWhjn379uHKlSto3bq1QvnYsWMxaNAgpKSkKLUrk8kgk8mUyo2MjBS+cDWPCci6Wz1lpb21hc68N+xn/cG+1g/sZ/3BvtYP8n5ubF+rfTPf3LlzsXr1aqXyjz/+GPPnz1erLmNjY3h6eiI5OVksq6qqQnJyMnx8fFS+pri4WCEZBgCptHrJMUEQFMoTEhJgb2+P0aNHK5RHRETgjz/+wKlTp8QHAHzwwQdISEhQ6xro0bgrHxEREWkjtUeUf/jhB+zYsUOp3NfXF8uXL0dcXJxa9YWHhyM4OBj9+vWDl5cX4uLiUFRUhClTpgAAJk+ejHbt2iEmJgYAEBgYiNjYWPTp00ecehEVFYXAwEAxYQaqE+6EhAQEBwfD0FDxMuWrYdTUoUMHuLq6qhU/1e1eaQXullQAYKJMRERE2kXtRDkvLw9WVlZK5ZaWlsjNzVU7gPHjxyMnJweLFi1CZmYmevfujcTERPEGv/T0dIUR5IULF0IikWDhwoW4efMm7OzsEBgYiKVLlyrUu3fvXqSnp2Pq1Klqx0RNR740XCsTQ1jIGjTTh4iIiEgj1M5cOnfujMTERISGhiqU7969G506dWpQEKGhoUr1ydWcL2xoaIjo6GhER0fXWae/v7/SVIy6qHMu1R/XUCYiIiJtpXaiHB4ejtDQUOTk5OCZZ54BACQnJ+P9999Xe9oF6T75rnyO3JWPiIiItIzaifLUqVNRWlqKpUuX4t133wUAuLi4YO3atZg8eXKTB0jaTRxRtuSIMhEREWmXBk0anTVrFmbNmoWcnByYmprCwsKiqeMiHZFRyBUviIiISDs16u4qOzu7poqDdBTnKBMREZG2alCivGXLFnz33XdIT09HWVmZwnMnTpxoksBIN3ANZSIiItJWam84snr1akyZMgUODg44efIkvLy8YGNjg6tXr2LkyJHNESNpscz/v5mvLW/mIyIiIi2jdqK8Zs0afPrpp/joo49gbGyMt956C0lJSZg7dy4KCgqaI0bSUiXllbhTXA6AI8pERESkfdROlNPT0+Hr6wsAMDU1xd27dwEAQUFB+Oabb5o2OtJq8vnJZsZSWJpwsxEiIiLSLmonyo6Ojrh9+zaA6i2ff/vtNwDAtWvXuGkHKXh4frJEItFwNERERETqUTtRfuaZZ7Bjxw4AwJQpUxAWFgY/Pz+MHz8eL7zwQpMHSNors1A+P5nTLoiIiEj7qP338E8//RRVVVUAgNmzZ8PGxgZHjhzBc889h9dee63JAyTtJY4oW/JGPiIiItI+aifKBgYGMDB4MBD98ssv4+WXX27SoEg3cA1lIiIi0mZqT70gqi+uoUxERETajIkyNRuOKBMREZE2Y6JMzYYjykRERKTNmChTsyirqELuvVIA3JWPiIiItFODlofLz89XKi8sLMQzzzzTFDGRDsgqrB5NNjY0QBszIw1HQ0RERKQ+tRPllJQUlJWVKZWXlJTg0KFDTRIUab/Mwgfzk7nZCBEREWmjei8P98cff4j/Pnv2LDIzM8XjyspKJCYmol27dk0bHWmtB2soc34yERERaad6J8q9e/eGRCKBRCJROcXC1NQUH330UZMGR9ors4C78hEREZF2q3eifO3aNQiCgE6dOiE1NRV2dnbic8bGxrC3t4dUKm2WIEn7PFjxgjfyERERkXaqd6LcsWNHABC3ryaqC9dQJiIiIm2n9s18X3zxBX7++Wfx+K233kLr1q3h6+uLGzduNGlwpL24hjIRERFpO7UT5WXLlsHUtPrP6UePHsXHH3+MlStXwtbWFmFhYU0eIGknjigTERGRtqv31Au5v//+G507dwYAbN++Hf/6178wY8YMDBgwAEOHDm3q+EgLVVRWIfsuR5SJiIhIu6k9omxhYYG8vDwAwJ49e+Dn5wcAMDExwf3795s2OtJKOfdKUSUAhgYS2JrLNB0OERERUYOoPaLs5+eHadOmoU+fPrh48SJGjRoFAPjrr7/g4uLS1PGRFpLPT3awNIGBATcbISIiIu2k9ohyfHw8fHx8kJOTgx9++AE2NjYAgLS0NEyYMKHJAyTtw/nJREREpAvUHlFu3bo1Pv74Y6XyJUuWNElApP244gURERHpArVHlAHg0KFDmDRpEnx9fXHz5k0AwFdffYXDhw83aXCknbgrHxEREekCtRPlH374AQEBATA1NcWJEydQWloKACgoKMCyZcuaPEDSPtyVj4iIiHSB2onye++9h3Xr1uGzzz6DkZGRWD5gwACcOHGiSYMj7cQ5ykRERKQL1E6UL1y4gMGDByuVW1lZIT8/vyliIi3HOcpERESkC9ROlB0dHXH58mWl8sOHD6NTp04NCiI+Ph4uLi4wMTGBt7c3UlNT6zw/Li4O7u7uMDU1hbOzM8LCwlBSUiI+7+LiAolEovSYPXu2eM5rr70GNzc3mJqaws7ODs8//zzOnz/foPjpgaoqAVmFHFEmIiIi7ad2ojx9+nTMmzcPx44dg0Qiwa1bt/D111/jjTfewKxZs9QOYPPmzQgPD0d0dDROnDiBXr16ISAgANnZ2SrP37RpEyIiIhAdHY1z585h/fr12Lx5MxYsWCCec/z4cWRkZIiPpKQkAMC4cePEczw9PZGQkIBz587hl19+gSAI8Pf3R2VlpdrXQA/kFpWiokqAgQSws+BmI0RERKS91F4eLiIiAlVVVRg2bBiKi4sxePBgyGQyvPHGG5gzZ47aAcTGxmL69OmYMmUKAGDdunX4+eefsWHDBkRERCidf+TIEQwYMAATJ04EUD16PGHCBBw7dkw8x87OTuE1y5cvh5ubG4YMGSKWzZgxQ/y3i4sL3nvvPfTq1QvXr1+Hm5ub2tdB1eTzk+1bmcBQ2qBFVYiIiIhaBLUTZYlEgrfffhtvvvkmLl++jHv37sHDwwMWFhZqN15WVoa0tDRERkaKZQYGBhg+fDiOHj2q8jW+vr7YuHEjUlNT4eXlhatXr2LXrl0ICgqqtY2NGzciPDwcEonqXeKKioqQkJAAV1dXODs7qzyntLRUXOEDAAoLCwEA5eXl4kN+rM/+ySsCADhYynTyvWA/6w/2tX5gP+sP9rV+qNnPje1vtRNlOWNjY7Rq1QqtWrVqUJIMALm5uaisrISDg4NCuYODQ63zhSdOnIjc3FwMHDgQgiCgoqICM2fOVJh68bDt27cjPz8fISEhSs+tWbMGb731FoqKiuDu7o6kpCQYGxurrCcmJkblpip79uyBmZmZeCyf5qGvDmZIAEiB4jvYtWuXpsNpNvrez/qEfa0f2M/6g32tH+T9XFxc3Kh61E6UKyoqsGTJEqxevRr37t0DAFhYWGDOnDmIjo5WWDKuOaSkpGDZsmVYs2YNvL29cfnyZcybNw/vvvsuoqKilM5fv349Ro4cCScnJ6XnXnnlFfj5+SEjIwOrVq3CSy+9hF9//RUmJso3oUVGRiI8PFw8LiwshLOzM/z9/WFpaYny8nIkJSXBz8+v2d+DluyvPReB69fR290Fo0Z11XQ4TY79rD/Y1/qB/aw/2Nf6oWY/y2cANJTaifKcOXOwdetWrFy5Ej4+PgCAo0ePYvHixcjLy8PatWvrXZetrS2kUimysrIUyrOysuDo6KjyNVFRUQgKCsK0adMAAD169EBRURFmzJiBt99+GwYGD+bF3rhxA3v37sXWrVtV1mVlZQUrKyt06dIF/fv3R5s2bbBt2zZMmDBB6VyZTAaZTPnmNCMjI4UvXM1jfZN9twwA0K6NmU6/D/rez/qEfa0f2M/6g32tH+T93Ni+VjtR3rRpE7799luMHDlSLOvZsyecnZ0xYcIEtRJlY2NjeHp6Ijk5GWPGjAEAVFVVITk5GaGhoSpfU1xcrJAMA4BUKgUACIKgUJ6QkAB7e3uMHj36kbEIggBBEBTmIZP6uCsfERER6Qq1E2WZTAYXFxelcldX11rn99YlPDwcwcHB6NevH7y8vBAXF4eioiJxFYzJkyejXbt2iImJAQAEBgYiNjYWffr0EadeREVFITAwUEyYgeqEOyEhAcHBwTA0VLzMq1evYvPmzfD394ednR3++ecfLF++HKamphg1apTa10APZHINZSIiItIRaifKoaGhePfdd5GQkCBORSgtLcXSpUtrHQWuy/jx45GTk4NFixYhMzMTvXv3RmJioniDX3p6usII8sKFCyGRSLBw4ULcvHkTdnZ2CAwMxNKlSxXq3bt3L9LT0zF16lSlNk1MTHDo0CHExcXhzp07cHBwwODBg3HkyBHY29urfQ1UTRCEByPKlkyUiYiISLvVK1F+8cUXFY737t2L9u3bo1evXgCA06dPo6ysDMOGDWtQEKGhobUm2SkpKQrHhoaGiI6ORnR0dJ11+vv7K03FkHNyctLpFRk05U5xOcoqqgAADkyUiYiISMvVK1G2srJSOB47dqzCcW1rD5N+ySi4DwCwtZDB2JCbjRAREZF2q1einJCQ0NxxkA6Q78rH+clERESkCzjsR03mwYoXTJSJiIhI+zFRpibDEWUiIiLSJUyUqclwRJmIiIh0CRNlajKZhdU383FEmYiIiHQBE2VqMg/WUOaufERERKT91N5wZPXq1SrLJRIJTExM0LlzZwwePFhhlzzSfYIgcI4yERER6RS1E+UPPvgAOTk5KC4uRps2bQAAd+7cgZmZGSwsLJCdnY1OnTph//79XF9ZjxSWVKC4rBIA5ygTERGRblB76sWyZcvw1FNP4dKlS8jLy0NeXh4uXrwIb29vfPjhh0hPT4ejoyPCwsKaI15qoeSjyW3MjGBixL8mEBERkfZTe0R54cKF+OGHH+Dm5iaWde7cGatWrcLYsWNx9epVrFy5Umn3PtJt8l35HK04P5mIiIh0g9ojyhkZGaioqFAqr6ioQGZmJgDAyckJd+/ebXx0pDU4P5mIiIh0jdqJ8tNPP43XXnsNJ0+eFMtOnjyJWbNm4ZlnngEA/Pnnn3B1dW26KKnF4xrKREREpGvUTpTXr18Pa2treHp6QiaTQSaToV+/frC2tsb69esBABYWFnj//febPFhqucQRZUsmykRERKQb1J6j7OjoiKSkJJw/fx4XL14EALi7u8Pd3V085+mnn266CEkrZBRyRJmIiIh0i9qJslzXrl3RtWvXpoyFtFhmgXxXPt7MR0RERLpB7US5srISn3/+OZKTk5GdnY2qqiqF5/ft29dkwZH24BxlIiIi0jVqJ8rz5s3D559/jtGjR6N79+6QSCTNERdpkXulFbhbUr0SChNlIiIi0hVqJ8rffvstvvvuO4waNao54iEtJL+Rr5WJISxkDZ7NQ0RERNSiqL3qhbGxMTp37twcsZCW4hrKREREpIvUTpRff/11fPjhhxAEoTniIS3EXfmIiIhIF6n9d/LDhw9j//792L17N5588kkYGRkpPL9169YmC460A9dQJiIiIl2kdqLcunVrvPDCC80RC2kprqFMREREukjtRDkhIaE54iAtxjnKREREpIvUnqNMVBPXUCYiIiJdVK8R5b59+yI5ORlt2rRBnz596lw7+cSJE00WHGkH7spHREREuqheifLzzz8PmUwGABgzZkxzxkNapqS8EneKywFwRJmIiIh0S70S5ejoaJX/JpLPTzYzlsLShJuNEBERke5ocGZTVlaG7OxsVFVVKZR36NCh0UGR9nh4fjK3MyciIiJdonaifPHiRbz66qs4cuSIQrkgCJBIJKisrGyy4KjlyyyUz0/mtAsiIiLSLWonylOmTIGhoSF++ukntG3blqOIek4cUbbkjXxERESkW9ROlE+dOoW0tDR07dq1OeIhLcM1lImIiEhXqb2OsoeHB3Jzc5sjFtJCXEOZiIiIdJXaifKKFSvw1ltvISUlBXl5eSgsLFR4NER8fDxcXFxgYmICb29vpKam1nl+XFwc3N3dYWpqCmdnZ4SFhaGkpER83sXFBRKJROkxe/ZsAMDt27cxZ84csY4OHTpg7ty5KCgoaFD8+owjykRERKSr1J56MXz4cADAsGHDFMobejPf5s2bER4ejnXr1sHb2xtxcXEICAjAhQsXYG9vr3T+pk2bEBERgQ0bNsDX1xcXL15ESEgIJBIJYmNjAQDHjx9XiOPMmTPw8/PDuHHjAAC3bt3CrVu3sGrVKnh4eODGjRuYOXMmbt26hS1btqgVv77jiDIRERHpKrUT5f379zdpALGxsZg+fTqmTJkCAFi3bh1+/vlnbNiwAREREUrnHzlyBAMGDMDEiRMBVI8eT5gwAceOHRPPsbOzU3jN8uXL4ebmhiFDhgAAunfvjh9++EF83s3NDUuXLsWkSZNQUVEBQ0Plt6W0tBSlpaXisXz0vLy8XHzIj/VFWUUVcu9Vvye2ZoZ6ce362M/6in2tH9jP+oN9rR9q9nNj+1vtRFmebDaFsrIypKWlITIyUiwzMDDA8OHDcfToUZWv8fX1xcaNG5GamgovLy9cvXoVu3btQlBQUK1tbNy4EeHh4XWu0FFQUABLS0uVSTIAxMTEYMmSJUrle/bsgZmZmXiclJRUaxu6Jq8EAAxhKBFwNGUv9GkBFH3qZ33HvtYP7Gf9wb7WD/J+Li4ublQ9DdpwJD8/H6mpqSo3HJk8eXK968nNzUVlZSUcHBwUyh0cHHD+/HmVr5k4cSJyc3MxcOBACIKAiooKzJw5EwsWLFB5/vbt25Gfn4+QkJA643j33XcxY8aMWs+JjIxEeHi4eFxYWAhnZ2f4+/vD0tIS5eXlSEpKgp+fH4yMjOq4at3x+407wMnjcGpjhtGjB2k6nMdCH/tZX7Gv9QP7WX+wr/VDzX5u6P1zcmonyjt37sQrr7yCe/fuwdLSUmGUViKRqJUoN0RKSgqWLVuGNWvWwNvbG5cvX8a8efPw7rvvIioqSun89evXY+TIkXByclJZX2FhIUaPHg0PDw8sXry41nZlMhlkMplSuZGRkcIXruaxLsspqgAAtLUy1ZtrltOnftZ37Gv9wH7WH+xr/SDv58b2tdqJ8uuvv46pU6di2bJlClMOGsLW1hZSqRRZWVkK5VlZWXB0dFT5mqioKAQFBWHatGkAgB49eqCoqAgzZszA22+/DQODBwt53LhxA3v37sXWrVtV1nX37l2MGDECrVq1wrZt2/jFUVNmAXflIyIiIt2l9vJwN2/exNy5cxudJAOAsbExPD09kZycLJZVVVUhOTkZPj4+Kl9TXFyskAwDgFQqBVC98sbDEhISYG9vj9GjRyvVU1hYCH9/fxgbG2PHjh0wMWGyp64HK15wVz4iIiLSPWqPKAcEBOD3339Hp06dmiSA8PBwBAcHo1+/fvDy8kJcXByKiorEVTAmT56Mdu3aISYmBgAQGBiI2NhY9OnTR5x6ERUVhcDAQDFhBqoT7oSEBAQHByvdoCdPkouLi7Fx40aFNaDt7OwU6qHacQ1lIiIi0mVqJ8qjR4/Gm2++ibNnz6JHjx5K0xWee+45teobP348cnJysGjRImRmZqJ3795ITEwUb/BLT09XGEFeuHAhJBIJFi5ciJs3b8LOzg6BgYFYunSpQr179+5Feno6pk6dqtTmiRMnxOXkOnfurPDctWvX4OLiotY16CuuoUxERES6TO1Eefr06QCAd955R+m5hmw4AgChoaEIDQ1V+VxKSorCsaGhIaKjoxEdHV1nnf7+/kpTMeSGDh1a63NUfxxRJiIiIl2mdqJcczk40k8VlVXIvssRZSIiItJdat/MRwQAOfdKUSUAhgYS2JorL5tHREREpO3UHlFWNeXiYYsWLWpwMKQ95POTHSxNYGCgR1vyERERkd5QO1Hetm2bwnF5eTmuXbsGQ0NDuLm5MVHWE5yfTERERLpO7UT55MmTSmWFhYUICQnBCy+80CRBUcvHFS+IiIhI1zXJHGVLS0ssWbJE5RbSpJsy8rkrHxEREem2JruZr6CgAAUFBU1VHbVwGYXclY+IiIh0m9pTL1avXq1wLAgCMjIy8NVXX2HkyJFNFhi1bJyjTERERLpO7UT5gw8+UDg2MDCAnZ0dgoODERkZ2WSBUcuWyTnKREREpOPUTpSvXbtW63P3799vVDCkHSqrBGQVckSZiIiIdFuTzFEuLS1FbGwsXF1dm6I6auHy7pWiokqAgQSws+BmI0RERKSb6p0ol5aWIjIyEv369YOvry+2b98OANiwYQNcXV3xwQcfICwsrLnipBZEvjScfSsTGEq5uSMRERHppnpPvVi0aBE++eQTDB8+HEeOHMG4ceMwZcoU/Pbbb4iNjcW4ceMglUqbM1ZqIbiGMhEREemDeifK33//Pb788ks899xzOHPmDHr27ImKigqcPn0aEgm3MNYnmQVcQ5mIiIh0X73/bv7PP//A09MTANC9e3fIZDKEhYUxSdZDD9ZQZqJMREREuqveiXJlZSWMjY3FY0NDQ1hYWDRLUNSycQ1lIiIi0gf1nnohCAJCQkIgk1WvclBSUoKZM2fC3Nxc4bytW7c2bYTU4jyYo8xd+YiIiEh31TtRDg4OVjieNGlSkwdD2oEjykRERKQP6p0oJyQkNGccpCUEQXiwK58lE2UiIiLSXVwEl9Ryu6gMZZVVAAAHJspERESkw5gok1rk85NtLWQwNuTHh4iIiHQXMx1SC+cnExERkb5gokxq4RrKREREpC+YKJNauCsfERER6QsmyqSWB2soM1EmIiIi3cZEmdTCOcpERESkL5gok1oerKHMXfmIiIhItzFRpnoTBEGcesERZSIiItJ1TJSp3grvV+B+eSUAzlEmIiIi3cdEmeoto7B6xYs2ZkYwMZJqOBoiIiKi5sVEmertwYoXnJ9MREREuo+JMtUbV7wgIiIifdIiEuX4+Hi4uLjAxMQE3t7eSE1NrfP8uLg4uLu7w9TUFM7OzggLC0NJSYn4vIuLCyQSidJj9uzZ4jmffvophg4dCktLS0gkEuTn5zfX5ekMrqFMRERE+kTjifLmzZsRHh6O6OhonDhxAr169UJAQACys7NVnr9p0yZEREQgOjoa586dw/r167F582YsWLBAPOf48ePIyMgQH0lJSQCAcePGiecUFxdjxIgRCq+juom78lkyUSYiIiLdZ6jpAGJjYzF9+nRMmTIFALBu3Tr8/PPP2LBhAyIiIpTOP3LkCAYMGICJEycCqB49njBhAo4dOyaeY2dnp/Ca5cuXw83NDUOGDBHL5s+fDwBISUlp4ivSXRxRJiIiIn2i0US5rKwMaWlpiIyMFMsMDAwwfPhwHD16VOVrfH19sXHjRqSmpsLLywtXr17Frl27EBQUVGsbGzduRHh4OCQSSYNjLS0tRWlpqXhcWFgIACgvLxcf8mNdlZFfPaJsb2Gk09dZF33oZ6rGvtYP7Gf9wb7WDzX7ubH9rdFEOTc3F5WVlXBwcFAod3BwwPnz51W+ZuLEicjNzcXAgQMhCAIqKiowc+bMWqdQbN++Hfn5+QgJCWlUrDExMViyZIlS+Z49e2BmZiYey6d56KJ/bksBSHDh1DHkX9B0NJqly/1MitjX+oH9rD/Y1/pB3s/FxcWNqkfjUy/UlZKSgmXLlmHNmjXw9vbG5cuXMW/ePLz77ruIiopSOn/9+vUYOXIknJycGtVuZGQkwsPDxePCwkI4OzvD398flpaWKC8vR1JSEvz8/GBkZNSotlqiuyUVKDm6DwDw0rP+MJdp3UenSeh6P9MD7Gv9wH7WH+xr/VCzn+UzABpKo9mOra0tpFIpsrKyFMqzsrLg6Oio8jVRUVEICgrCtGnTAAA9evRAUVERZsyYgbfffhsGBg/uT7xx4wb27t2LrVu3NjpWmUwGmUymVG5kZKTwhat5rCtu36men2xpYojWFlxHWVf7mZSxr/UD+1l/sK/1g7yfG9vXGl31wtjYGJ6enkhOThbLqqqqkJycDB8fH5WvKS4uVkiGAUAqrd4lThAEhfKEhATY29tj9OjRTRy5/skQ11BmkkxERET6QeN/Pw8PD0dwcDD69esHLy8vxMXFoaioSFwFY/LkyWjXrh1iYmIAAIGBgYiNjUWfPn3EqRdRUVEIDAwUE2agOuFOSEhAcHAwDA2VLzMzMxOZmZm4fPkyAODPP/9Eq1at0KFDB1hbWz+GK9cuXPGCiIiI9I3GE+Xx48cjJycHixYtQmZmJnr37o3ExETxBr/09HSFEeSFCxdCIpFg4cKFuHnzJuzs7BAYGIilS5cq1Lt3716kp6dj6tSpKttdt26dws15gwcPBlA9Ct3YG/90EXflIyIiIn2j8UQZAEJDQxEaGqryuZrrHBsaGiI6OhrR0dF11unv7680FeNhixcvxuLFi9UNVW9xRJmIiIj0jcZ35iPtIO7Kx0SZiIiI9AQTZaqXByPKvJmPiIiI9AMTZaqXzELOUSYiIiL9wkSZHul+WSXyi6u3gOQcZSIiItIXTJTpkeSjyebGUrTS0x35iIiISP8wUaZHyvj/G/kcrUwgkUg0HA0RERHR48FEmR4pk7vyERERkR5iokyPxDWUiYiISB8xUaZH4q58REREpI+YKNMjcUSZiIiI9BETZXqkzELuykdERET6h4kyPZJ86oWjJW/mIyIiIv3BRJnqVFpRidx7ZQA4okxERET6hYky1Sm7sBQAIDM0QGszIw1HQ0RERPT4MFGmOmU8tOIFNxshIiIifcJEmer08K58RERERPqEiTLVibvyERERkb5iokx14hrKREREpK+YKFOduCsfERER6SsmylSnjEL5GspMlImIiEi/MFGmOmUWyHfl4xxlIiIi0i9MlKlW5ZVVyL5bvY4y5ygTERGRvmGiTLXKuVsKQQCMpBLYmBtrOhwiIiKix4qJMtVKvuKFg6UJDAy42QgRERHpFybKVCuueEFERET6jIky1erBrny8kY+IiIj0DxNlqhVHlImIiEifMVGmWnENZSIiItJnTJSpVhxRJiIiIn3GRJlqJU+UuYYyERER6SMmyqRSZZWArEL5iDJv5iMiIiL9w0SZVMq7V4qKKgFSAwnsWsk0HQ4RERHRY8dEmVSSbzZi30oGKTcbISIiIj3UIhLl+Ph4uLi4wMTEBN7e3khNTa3z/Li4OLi7u8PU1BTOzs4ICwtDSUmJ+LyLiwskEonSY/bs2eI5JSUlmD17NmxsbGBhYYGxY8ciKyur2a5R22RwfjIRERHpOY0nyps3b0Z4eDiio6Nx4sQJ9OrVCwEBAcjOzlZ5/qZNmxAREYHo6GicO3cO69evx+bNm7FgwQLxnOPHjyMjI0N8JCUlAQDGjRsnnhMWFoadO3fi+++/x4EDB3Dr1i28+OKLzXuxWiTz/zcb4YoXREREpK80nijHxsZi+vTpmDJlCjw8PLBu3TqYmZlhw4YNKs8/cuQIBgwYgIkTJ8LFxQX+/v6YMGGCwii0nZ0dHB0dxcdPP/0ENzc3DBkyBABQUFCA9evXIzY2Fs888ww8PT2RkJCAI0eO4Lfffnss193SPVhDmTfyERERkX4y1GTjZWVlSEtLQ2RkpFhmYGCA4cOH4+jRoypf4+vri40bNyI1NRVeXl64evUqdu3ahaCgoFrb2LhxI8LDwyGRVM+1TUtLQ3l5OYYPHy6e17VrV3To0AFHjx5F//79leopLS1FaWmpeFxYWAgAKC8vFx/yY11w604xAMC+lZHOXFNT0LV+ptqxr/UD+1l/sK/1Q81+bmx/azRRzs3NRWVlJRwcHBTKHRwccP78eZWvmThxInJzczFw4EAIgoCKigrMnDlTYerFw7Zv3478/HyEhISIZZmZmTA2Nkbr1q2V2s3MzFRZT0xMDJYsWaJUvmfPHpiZmYnH8mke2u7sNSkACTKunMOugrOaDqfF0ZV+pkdjX+sH9rP+YF/rB3k/FxcXN6oejSbKDZGSkoJly5ZhzZo18Pb2xuXLlzFv3jy8++67iIqKUjp//fr1GDlyJJycnBrVbmRkJMLDw8XjwsJCODs7w9/fH5aWligvL0dSUhL8/PxgZGTUqLZaglXnDwG4j5FD+sOzYxtNh9Ni6Fo/U+3Y1/qB/aw/2Nf6oWY/y2cANJRGE2VbW1tIpVKl1SaysrLg6Oio8jVRUVEICgrCtGnTAAA9evRAUVERZsyYgbfffhsGBg+mXd+4cQN79+7F1q1bFepwdHREWVkZ8vPzFUaV62pXJpNBJlNeT9jIyEjhC1fzWBsJgoCswuppJu1tLLT+epqDLvQz1Q/7Wj+wn/UH+1o/yPu5sX2t0Zv5jI2N4enpieTkZLGsqqoKycnJ8PHxUfma4uJihWQYAKRSKYDqBO9hCQkJsLe3x+jRoxXKPT09YWRkpNDuhQsXkJ6eXmu7+uR2URnKKqsgkQD2rbjqBREREeknjU+9CA8PR3BwMPr16wcvLy/ExcWhqKgIU6ZMAQBMnjwZ7dq1Q0xMDAAgMDAQsbGx6NOnjzj1IioqCoGBgWLCDFQn3AkJCQgODoahoeJlWllZ4dVXX0V4eDisra1haWmJOXPmwMfHR+WNfPpGvoayrYUMxoYaXxiFiIiISCM0niiPHz8eOTk5WLRoETIzM9G7d28kJiaKN/ilp6crjCAvXLgQEokECxcuxM2bN2FnZ4fAwEAsXbpUod69e/ciPT0dU6dOVdnuBx98AAMDA4wdOxalpaUICAjAmjVrmu9CtUjm/yfKXEOZiIiI9JnGE2UACA0NRWhoqMrnUlJSFI4NDQ0RHR2N6OjoOuv09/dXmorxMBMTE8THxyM+Pl7teHXdgzWUmSgTERGR/uLf1UkJd+UjIiIiYqJMKsjnKDtacVc+IiIi0l9MlEkJ5ygTERERMVEmFTLFEWUmykRERKS/mCiTAkEQxKkXHFEmIiIifcZEmRQU3q/A/fJKAIADV70gIiIiPcZEmRRkFFaveGFtbgwTI+kjziYiIiLSXUyUSYG44gVHk4mIiEjPMVEmBVzxgoiIiKgaE2VSkMEVL4iIiIgAMFGmGrgrHxEREVE1JsqkgLvyEREREVVjokwKOEeZiIiIqBoTZVLAXfmIiIiIqjFRJtHdknLcLa0AwOXhiIiIiJgokyirsHo02dLEEOYyQw1HQ0RERKRZTJRJlCHOT+aNfERERERMlEnENZSJiIiIHmCiTCKueEFERET0ABNlEnFEmYiIiOgBJsok4q58RERERA9waQMtUFklIPXabWTfLYF9KxN4uVpDaiBp8jYuZ98DANwpLkdlldDkbRARERFpEybKLVzimQws2XlWnBYBVI/4Rgd6YET3ts3SxvLd5/HFketN2gYRERGRtuHUixYs8UwGZm08oZAkA9U33c3aeAKJZzK0og0iIiIibcREuYWqrBKwZOdZCCqek5ct2XkWlVWqzmg5bRARERFpK069aKFSr91WGuV9mIDqVSqG/nd/g3fRKyqtqFcbqdduw8fNpkFtEBEREWkrJsotVPbd2hPYh/19534zR1L/WIiIiIh0CRPlFsq+Vf2WaFswqhs82lo2qI2zGYVYtutck8VCREREpEuYKLdQXq7WaGtlgsyCEpVziCWo3hjk1YGuDV7GzcfNBgm/XntkG16u1g2qn4iIiEib8Wa+FkpqIEF0oAeA6oT1YfLj6ECPRq11/DjaICIiItJWTJRbsBHd22LtpL5KW0o7Wplg7aS+TbLG8eNog4iIiEgbcepFCzeie1v4eTg26858j6MNIiIiIm3DRFkLSA0kzb482+Nog4iIiEibaHzqRXx8PFxcXGBiYgJvb2+kpqbWeX5cXBzc3d1hamoKZ2dnhIWFoaREcfmymzdvYtKkSbCxsYGpqSl69OiB33//XXw+KysLISEhcHJygpmZGUaMGIFLly41y/URERERkXbSaKK8efNmhIeHIzo6GidOnECvXr0QEBCA7Oxsledv2rQJERERiI6Oxrlz57B+/Xps3rwZCxYsEM+5c+cOBgwYACMjI+zevRtnz57F+++/jzZt2gAABEHAmDFjcPXqVfz44484efIkOnbsiOHDh6OoqOixXDcRERERtXwanXoRGxuL6dOnY8qUKQCAdevW4eeff8aGDRsQERGhdP6RI0cwYMAATJw4EQDg4uKCCRMm4NixY+I5K1asgLOzMxISEsQyV1dX8d+XLl3Cb7/9hjNnzuDJJ58EAKxduxaOjo745ptvMG3atGa5ViIiIiLSLhpLlMvKypCWlobIyEixzMDAAMOHD8fRo0dVvsbX1xcbN25EamoqvLy8cPXqVezatQtBQUHiOTt27EBAQADGjRuHAwcOoF27dvj3v/+N6dOnAwBKS0sBACYmD1Z5MDAwgEwmw+HDh2tNlEtLS8XXAkBhYSEAoLy8XHzIj0l3sZ/1B/taP7Cf9Qf7Wj/U7OfG9rfGEuXc3FxUVlbCwcFBodzBwQHnz59X+ZqJEyciNzcXAwcOhCAIqKiowMyZMxWmXly9ehVr165FeHg4FixYgOPHj2Pu3LkwNjZGcHAwunbtig4dOiAyMhKffPIJzM3N8cEHH+Cff/5BRkZGrfHGxMRgyZIlSuV79uyBmZmZeJyUlKTuW0FaiP2sP9jX+oH9rD/Y1/pB3s/FxcWNqkerVr1ISUnBsmXLsGbNGnh7e+Py5cuYN28e3n33XURFRQEAqqqq0K9fPyxbtgwA0KdPH5w5cwbr1q1DcHAwjIyMsHXrVrz66quwtraGVCrF8OHDMXLkSAiCqv3pqkVGRiI8PFw8LiwshLOzM/z9/WFpaYny8nIkJSXBz88PRkZGzftGkMawn/UH+1o/sJ/1B/taP9TsZ/kMgIbSWKJsa2sLqVSKrKwshfKsrCw4OjqqfE1UVBSCgoLE6RE9evRAUVERZsyYgbfffhsGBgZo27YtPDw8FF7XrVs3/PDDD+Kxp6cnTp06hYKCApSVlcHOzg7e3t7o169frfHKZDLIZDKlciMjI4UvXM1j0k3sZ/3BvtYP7Gf9wb7WD/J+bmxfa2zVC2NjY3h6eiI5OVksq6qqQnJyMnx8fFS+pri4GAYGiiFLpVIAEEeDBwwYgAsXLiicc/HiRXTs2FGpPisrK9jZ2eHSpUv4/fff8fzzzzfqmoiIiIhId2h06kV4eDiCg4PRr18/eHl5IS4uDkVFReIqGJMnT0a7du0QExMDAAgMDERsbCz69OkjTr2IiopCYGCgmDCHhYXB19cXy5Ytw0svvYTU1FR8+umn+PTTT8V2v//+e9jZ2aFDhw74888/MW/ePIwZMwb+/v6P/00gIiIiohZJo4ny+PHjkZOTg0WLFiEzMxO9e/dGYmKieINfenq6wgjywoULIZFIsHDhQty8eRN2dnYIDAzE0qVLxXOeeuopbNu2DZGRkXjnnXfg6uqKuLg4vPLKK+I5GRkZCA8PR1ZWFtq2bYvJkyeLc5yJiIiIiABAItR1BxvVqqCgAK1bt8bff/8t3sy3Z88e+Pv7c+6TDmM/6w/2tX5gP+sP9rV+qNnP8sUX8vPzYWVlpXZ9WrXqRUty9+5dAICzs7OGIyEiIiKiuty9e7dBiTJHlBuoqqoKt27dQqtWrSCRSMT/schHmEk3sZ/1B/taP7Cf9Qf7Wj/U7GdBEHD37l04OTkpLQhRHxxRbiADAwO0b99eqdzS0pJfQD3AftYf7Gv9wH7WH+xr/fBwPzdkJFlOY8vDERERERG1ZEyUiYiIiIhUYKLcRGQyGaKjo1Xu3ke6g/2sP9jX+oH9rD/Y1/qhqfuZN/MREREREanAEWUiIiIiIhWYKBMRERERqcBEmYiIiIhIBSbKREREREQqMFFuAvHx8XBxcYGJiQm8vb2Rmpqq6ZCoiS1evBgSiUTh0bVrV02HRU3g4MGDCAwMhJOTEyQSCbZv367wvCAIWLRoEdq2bQtTU1MMHz4cly5d0kyw1GCP6ueQkBCl7/iIESM0Eyw1WExMDJ566im0atUK9vb2GDNmDC5cuKBwTklJCWbPng0bGxtYWFhg7NixyMrK0lDE1FD16euhQ4cqfa9nzpypVjtMlBtp8+bNCA8PR3R0NE6cOIFevXohICAA2dnZmg6NmtiTTz6JjIwM8XH48GFNh0RNoKioCL169UJ8fLzK51euXInVq1dj3bp1OHbsGMzNzREQEICSkpLHHCk1xqP6GQBGjBih8B3/5ptvHmOE1BQOHDiA2bNn47fffkNSUhLKy8vh7++PoqIi8ZywsDDs3LkT33//PQ4cOIBbt27hxRdf1GDU1BD16WsAmD59usL3euXKleo1JFCjeHl5CbNnzxaPKysrBScnJyEmJkaDUVFTi46OFnr16qXpMKiZARC2bdsmHldVVQmOjo7Cf//7X7EsPz9fkMlkwjfffKOBCKkp1OxnQRCE4OBg4fnnn9dIPNR8srOzBQDCgQMHBEGo/v4aGRkJ33//vXjOuXPnBADC0aNHNRUmNYGafS0IgjBkyBBh3rx5jaqXI8qNUFZWhrS0NAwfPlwsMzAwwPDhw3H06FENRkbN4dKlS3ByckKnTp3wyiuvID09XdMhUTO7du0aMjMzFb7jVlZW8Pb25ndcB6WkpMDe3h7u7u6YNWsW8vLyNB0SNVJBQQEAwNraGgCQlpaG8vJyhe90165d0aFDB36ntVzNvpb7+uuvYWtri+7duyMyMhLFxcVq1WvYZBHqodzcXFRWVsLBwUGh3MHBAefPn9dQVNQcvL298fnnn8Pd3R0ZGRlYsmQJBg0ahDNnzqBVq1aaDo+aSWZmJgCo/I7LnyPdMGLECLz44otwdXXFlStXsGDBAowcORJHjx6FVCrVdHjUAFVVVZg/fz4GDBiA7t27A6j+ThsbG6N169YK5/I7rd1U9TUATJw4ER07doSTkxP++OMP/Oc//8GFCxewdevWetfNRJmoHkaOHCn+u2fPnvD29kbHjh3x3Xff4dVXX9VgZETUFF5++WXx3z169EDPnj3h5uaGlJQUDBs2TIORUUPNnj0bZ86c4f0keqC2vp4xY4b47x49eqBt27YYNmwYrly5Ajc3t3rVzakXjWBrawupVKp0t2xWVhYcHR01FBU9Dq1bt8YTTzyBy5cvazoUakby7zG/4/qnU6dOsLW15XdcS4WGhuKnn37C/v370b59e7Hc0dERZWVlyM/PVzif32ntVVtfq+Lt7Q0Aan2vmSg3grGxMTw9PZGcnCyWVVVVITk5GT4+PhqMjJrbvXv3cOXKFbRt21bToVAzcnV1haOjo8J3vLCwEMeOHeN3XMf9888/yMvL43dcywiCgNDQUGzbtg379u2Dq6urwvOenp4wMjJS+E5fuHAB6enp/E5rmUf1tSqnTp0CALW+15x60Ujh4eEIDg5Gv3794OXlhbi4OBQVFWHKlCmaDo2a0BtvvIHAwEB07NgRt27dQnR0NKRSKSZMmKDp0KiR7t27pzC6cO3aNZw6dQrW1tbo0KED5s+fj/feew9dunSBq6sroqKi4OTkhDFjxmguaFJbXf1sbW2NJUuWYOzYsXB0dMSVK1fw1ltvoXPnzggICNBg1KSu2bNnY9OmTfjxxx/RqlUrcd6xlZUVTE1NYWVlhVdffRXh4eGwtraGpaUl5syZAx8fH/Tv31/D0ZM6HtXXV65cwaZNmzBq1CjY2Njgjz/+QFhYGAYPHoyePXvWv6FGrZlBgiAIwkcffSR06NBBMDY2Fry8vITffvtN0yFRExs/frzQtm1bwdjYWGjXrp0wfvx44fLly5oOi5rA/v37BQBKj+DgYEEQqpeIi4qKEhwcHASZTCYMGzZMuHDhgmaDJrXV1c/FxcWCv7+/YGdnJxgZGQkdO3YUpk+fLmRmZmo6bFKTqj4GICQkJIjn3L9/X/j3v/8ttGnTRjAzMxNeeOEFISMjQ3NBU4M8qq/T09OFwYMHC9bW1oJMJhM6d+4svPnmm0JBQYFa7Uj+vzEiIiIiInoI5ygTEREREanARJmIiIiISAUmykREREREKjBRJiIiIiJSgYkyEREREZEKTJSJiIiIiFRgokxEREREpAITZSIiIiIiFZgoExFpmevXr0MikeDUqVOaDkV0/vx59O/fHyYmJujdu3ej61u8eLHa9UgkEmzfvr3RbRMRyTFRJiJSU0hICCQSCZYvX65Qvn37dkgkEg1FpVnR0dEwNzfHhQsXkJycrPKcoUOHYv78+fWq74033qi1HiKix4WJMhFRA5iYmGDFihW4c+eOpkNpMmVlZQ1+7ZUrVzBw4EB07NgRNjY2Da5HEARUVFTAwsKiUfUQETUFJspERA0wfPhwODo6IiYmptZzVE0fiIuLg4uLi3gcEhKCMWPGYNmyZXBwcEDr1q3xzjvvoKKiAm+++Sasra3Rvn17JCQkKNV//vx5+Pr6wsTEBN27d8eBAwcUnj9z5gxGjhwJCwsLODg4ICgoCLm5ueLzQ4cORWhoKObPnw9bW1sEBASovI6qqiq88847aN++PWQyGXr37o3ExETxeYlEgrS0NLzzzjuQSCRYvHixUh0hISE4cOAAPvzwQ0gkEkgkEly/fh0pKSmQSCTYvXs3PD09IZPJcPjwYaX37vjx4/Dz84OtrS2srKwwZMgQnDhxotb3vqysDKGhoWjbti1MTEzQsWPHOvuKiEgVJspERA0glUqxbNkyfPTRR/jnn38aVde+fftw69YtHDx4ELGxsYiOjsazzz6LNm3a4NixY5g5cyZee+01pXbefPNNvP766zh58iR8fHwQGBiIvLw8AEB+fj6eeeYZ9OnTB7///jsSExORlZWFl156SaGOL774AsbGxvj111+xbt06lfF9+OGHeP/997Fq1Sr88ccfCAgIwHPPPYdLly4BADIyMvDkk0/i9ddfR0ZGBt544w2Vdfj4+GD69OnIyMhARkYGnJ2dxecjIiKwfPlynDt3Dj179lR6/d27dxEcHIzDhw/jt99+Q5cuXTBq1CjcvXtXZcyrV6/Gjh078N133+HChQv4+uuvFf6DQkRUH4aaDoCISFu98MIL6N27N6Kjo7F+/foG12NtbY3Vq1fDwMAA7u7uWLlyJYqLi7FgwQIAQGRkJJYvX47Dhw/j5ZdfFl8XGhqKsWPHAgDWrl2LxMRErF+/Hm+99RY+/vhj9OnTB8uWLRPP37BhA5ydnXHx4kU88cQTAIAuXbpg5cqVdca3atUq/Oc//xHbXrFiBfbv34+4uDjEx8fD0dERhoaGsLCwgKOjo8o6rKysYGxsDDMzM5XnvPPOO/Dz86s1hmeeeUbh+NNPP0Xr1q1x4MABPPvss0rnp6eno0uXLhg4cCAkEgk6duxY5zUSEanCEWUiokZYsWIFvvjiC5w7d67BdTz55JMwMHjw49jBwQE9evQQj6VSKWxsbJCdna3wOh8fH/HfhoaG6NevnxjH6dOnsX//flhYWIiPrl27AqieTyzn6elZZ2yFhYW4desWBgwYoFA+YMCARl1zTf369avz+aysLEyfPh1dunSBlZUVLC0tce/ePaSnp6s8PyQkBKdOnYK7uzvmzp2LPXv2NFmsRKQ/OKJMRNQIgwcPRkBAACIjIxESEqLwnIGBAQRBUCgrLy9XqsPIyEjhWCKRqCyrqqqqd1z37t1DYGAgVqxYofRc27ZtxX+bm5vXu87m9Kg4goODkZeXhw8//BAdO3aETCaDj49PrTcg9u3bF9euXcPu3buxd+9evPTSSxg+fDi2bNnSHOETkY7iiDIRUSMtX74cO3fuxNGjRxXK7ezskJmZqZAsN+Xax7/99pv474qKCqSlpaFbt24AqhPFv/76Cy4uLujcubPCQ53k2NLSEk5OTvj1118Vyn/99Vd4eHioFa+xsTEqKyvVes3D7c2dOxejRo3Ck08+CZlMpnBjoiqWlpYYP348PvvsM2zevBk//PADbt++3aD2iUg/MVEmImqkHj164JVXXsHq1asVyocOHYqcnBysXLkSV65cQXx8PHbv3t1k7cbHx2Pbtm04f/48Zs+ejTt37mDq1KkAgNmzZ+P27duYMGECjh8/jitXruCXX37BlClT1E5W33zzTaxYsQKbN2/GhQsXEBERgVOnTmHevHlq1ePi4oJjx47h+vXryM3NVWuEvEuXLvjqq69w7tw5HDt2DK+88gpMTU1rPT82NhbffPMNzp8/j4sXL+L777+Ho6MjWrdurVbMRKTfmCgTETWBd955Rynx69atG9asWYP4+Hj06tULqampKleEaKjly5dj+fLl6NWrFw4fPowdO3bA1tYWAMRR4MrKSvj7+6NHjx6YP38+WrdurTAfuj7mzp2L8PBwvP766+jRowcSExOxY8cOdOnSRa163njjDUilUnh4eMDOzq7W+cWqrF+/Hnfu3EHfvn0RFBSEuXPnwt7evtbzW7VqhZUrV6Jfv3546qmncP36dezatUvtayci/SYRak6gIyIiIiIijigTEREREanCRJmIiIiISAUmykREREREKjBRJiIiIiJSgYkyEREREZEKTJSJiIiIiFRgokxEREREpAITZSIiIiIiFZgoExERERGpwESZiIiIiEgFJspERERERCr8H4mBysshY46QAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-05 01:30:55,449]\u001b[0m Using an existing study with name 'tutorial6_prec_integer' instead of creating a new one.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1 best: 0.87724\n",
      "Saved: /workspace/labs/lab3/outputs/tutorial6_task1_integer_layerwise_running_best.png\n",
      "\n",
      "=== Task 2: Compare precision families ===\n",
      "\n",
      "-- Running study for precision: integer\n",
      "[skip] tutorial6_prec_integer: already has 24 COMPLETE trials\n",
      "Best for integer: 0.8771\n",
      "Snapshot: /workspace/labs/lab3/outputs/task2_integer_snapshot.json\n",
      "\n",
      "-- Running study for precision: minifloat_ieee\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-05 01:30:55,507]\u001b[0m Using an existing study with name 'tutorial6_prec_minifloat_ieee' instead of creating a new one.\u001b[0m\n",
      "\u001b[32m[I 2026-02-05 01:30:55,570]\u001b[0m Using an existing study with name 'tutorial6_prec_minifloat_denorm' instead of creating a new one.\u001b[0m\n",
      "\u001b[32m[I 2026-02-05 01:30:55,607]\u001b[0m Using an existing study with name 'tutorial6_prec_log' instead of creating a new one.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[skip] tutorial6_prec_minifloat_ieee: already has 24 COMPLETE trials\n",
      "Best for minifloat_ieee: 0.8773\n",
      "Snapshot: /workspace/labs/lab3/outputs/task2_minifloat_ieee_snapshot.json\n",
      "\n",
      "-- Running study for precision: minifloat_denorm\n",
      "[skip] tutorial6_prec_minifloat_denorm: already has 24 COMPLETE trials\n",
      "Best for minifloat_denorm: 0.8771\n",
      "Snapshot: /workspace/labs/lab3/outputs/task2_minifloat_denorm_snapshot.json\n",
      "\n",
      "-- Running study for precision: log\n",
      "[skip] tutorial6_prec_log: already has 24 COMPLETE trials\n",
      "Best for log: 0.8765\n",
      "Snapshot: /workspace/labs/lab3/outputs/task2_log_snapshot.json\n",
      "\n",
      "-- Running study for precision: blockfp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-05 01:30:55,643]\u001b[0m Using an existing study with name 'tutorial6_prec_blockfp' instead of creating a new one.\u001b[0m\n",
      "\u001b[32m[I 2026-02-05 01:30:55,683]\u001b[0m Using an existing study with name 'tutorial6_prec_blockminifloat' instead of creating a new one.\u001b[0m\n",
      "\u001b[32m[I 2026-02-05 01:30:55,726]\u001b[0m Using an existing study with name 'tutorial6_prec_blocklog' instead of creating a new one.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[skip] tutorial6_prec_blockfp: already has 24 COMPLETE trials\n",
      "Best for blockfp: 0.8762\n",
      "Snapshot: /workspace/labs/lab3/outputs/task2_blockfp_snapshot.json\n",
      "\n",
      "-- Running study for precision: blockminifloat\n",
      "[skip] tutorial6_prec_blockminifloat: already has 12 COMPLETE trials\n",
      "Best for blockminifloat: 0.8434\n",
      "Snapshot: /workspace/labs/lab3/outputs/task2_blockminifloat_snapshot.json\n",
      "\n",
      "-- Running study for precision: blocklog\n",
      "[run]  tutorial6_prec_blocklog: running 12 more trial(s) to reach 12 COMPLETE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 06:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.310500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.303100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.298000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.318100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.307000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.350100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 04:35]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-05 01:41:35,480]\u001b[0m Trial 12 finished with value: 0.87528 and parameters: {'bert.encoder.layer.0.attention.self.query_type': 'blocklog', 'bert.encoder.layer.0.attention.self.key_type': 'fp', 'bert.encoder.layer.0.attention.self.value_type': 'blocklog', 'bert.encoder.layer.0.attention.output.dense_type': 'blocklog', 'bert.encoder.layer.0.intermediate.dense_type': 'fp', 'bert.encoder.layer.0.output.dense_type': 'fp', 'bert.encoder.layer.1.attention.self.query_type': 'blocklog', 'bert.encoder.layer.1.attention.self.key_type': 'blocklog', 'bert.encoder.layer.1.attention.output.dense_type': 'blocklog', 'bert.encoder.layer.1.intermediate.dense_type': 'blocklog', 'bert.encoder.layer.1.output.dense_type': 'fp', 'classifier_type': 'blocklog'}. Best is trial 12 with value: 0.87528.\u001b[0m\n",
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 07:25, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.303700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.318800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.303400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.322200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.312100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.356300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 06:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-05 01:55:10,881]\u001b[0m Trial 13 finished with value: 0.87588 and parameters: {'bert.encoder.layer.0.attention.self.query_type': 'blocklog', 'bert.encoder.layer.0.attention.self.key_type': 'blocklog', 'bert.encoder.layer.0.attention.self.value_type': 'fp', 'bert.encoder.layer.0.attention.output.dense_type': 'blocklog', 'bert.encoder.layer.0.intermediate.dense_type': 'blocklog', 'bert.encoder.layer.0.output.dense_type': 'blocklog', 'bert.encoder.layer.1.attention.self.query_type': 'blocklog', 'bert.encoder.layer.1.attention.self.key_type': 'fp', 'bert.encoder.layer.1.attention.output.dense_type': 'blocklog', 'bert.encoder.layer.1.intermediate.dense_type': 'fp', 'bert.encoder.layer.1.output.dense_type': 'blocklog', 'classifier_type': 'fp'}. Best is trial 13 with value: 0.87588.\u001b[0m\n",
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 03:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.307300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.296700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.309600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.323000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.310500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.357700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:40]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-05 01:59:53,642]\u001b[0m Trial 14 finished with value: 0.87648 and parameters: {'bert.encoder.layer.0.attention.self.query_type': 'blocklog', 'bert.encoder.layer.0.attention.self.key_type': 'fp', 'bert.encoder.layer.0.attention.self.value_type': 'fp', 'bert.encoder.layer.0.attention.output.dense_type': 'fp', 'bert.encoder.layer.0.intermediate.dense_type': 'fp', 'bert.encoder.layer.0.output.dense_type': 'fp', 'bert.encoder.layer.1.attention.self.query_type': 'fp', 'bert.encoder.layer.1.attention.self.key_type': 'fp', 'bert.encoder.layer.1.attention.output.dense_type': 'blocklog', 'bert.encoder.layer.1.intermediate.dense_type': 'fp', 'bert.encoder.layer.1.output.dense_type': 'fp', 'classifier_type': 'fp'}. Best is trial 14 with value: 0.87648.\u001b[0m\n",
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 05:48, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.312100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.301800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.312700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.326000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.307300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.356000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 04:19]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-05 02:10:02,674]\u001b[0m Trial 15 finished with value: 0.876 and parameters: {'bert.encoder.layer.0.attention.self.query_type': 'fp', 'bert.encoder.layer.0.attention.self.key_type': 'fp', 'bert.encoder.layer.0.attention.self.value_type': 'fp', 'bert.encoder.layer.0.attention.output.dense_type': 'fp', 'bert.encoder.layer.0.intermediate.dense_type': 'blocklog', 'bert.encoder.layer.0.output.dense_type': 'blocklog', 'bert.encoder.layer.1.attention.self.query_type': 'fp', 'bert.encoder.layer.1.attention.self.key_type': 'fp', 'bert.encoder.layer.1.attention.output.dense_type': 'blocklog', 'bert.encoder.layer.1.intermediate.dense_type': 'blocklog', 'bert.encoder.layer.1.output.dense_type': 'blocklog', 'classifier_type': 'fp'}. Best is trial 14 with value: 0.87648.\u001b[0m\n",
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 04:09, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.311500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.299300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.309400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.328700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.312900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.358600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 02:58]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-05 02:17:12,157]\u001b[0m Trial 16 finished with value: 0.87468 and parameters: {'bert.encoder.layer.0.attention.self.query_type': 'fp', 'bert.encoder.layer.0.attention.self.key_type': 'fp', 'bert.encoder.layer.0.attention.self.value_type': 'fp', 'bert.encoder.layer.0.attention.output.dense_type': 'blocklog', 'bert.encoder.layer.0.intermediate.dense_type': 'blocklog', 'bert.encoder.layer.0.output.dense_type': 'fp', 'bert.encoder.layer.1.attention.self.query_type': 'blocklog', 'bert.encoder.layer.1.attention.self.key_type': 'blocklog', 'bert.encoder.layer.1.attention.output.dense_type': 'fp', 'bert.encoder.layer.1.intermediate.dense_type': 'fp', 'bert.encoder.layer.1.output.dense_type': 'fp', 'classifier_type': 'fp'}. Best is trial 14 with value: 0.87648.\u001b[0m\n",
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 04:52, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.313100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.298600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.303700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.323800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.300400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.353900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 03:26]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-05 02:25:32,472]\u001b[0m Trial 17 finished with value: 0.87552 and parameters: {'bert.encoder.layer.0.attention.self.query_type': 'fp', 'bert.encoder.layer.0.attention.self.key_type': 'fp', 'bert.encoder.layer.0.attention.self.value_type': 'blocklog', 'bert.encoder.layer.0.attention.output.dense_type': 'blocklog', 'bert.encoder.layer.0.intermediate.dense_type': 'fp', 'bert.encoder.layer.0.output.dense_type': 'fp', 'bert.encoder.layer.1.attention.self.query_type': 'blocklog', 'bert.encoder.layer.1.attention.self.key_type': 'blocklog', 'bert.encoder.layer.1.attention.output.dense_type': 'blocklog', 'bert.encoder.layer.1.intermediate.dense_type': 'fp', 'bert.encoder.layer.1.output.dense_type': 'fp', 'classifier_type': 'blocklog'}. Best is trial 14 with value: 0.87648.\u001b[0m\n",
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 06:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.305500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.292100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.307000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.319400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.302100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.350800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 04:34]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-05 02:36:12,650]\u001b[0m Trial 18 finished with value: 0.8752 and parameters: {'bert.encoder.layer.0.attention.self.query_type': 'fp', 'bert.encoder.layer.0.attention.self.key_type': 'blocklog', 'bert.encoder.layer.0.attention.self.value_type': 'blocklog', 'bert.encoder.layer.0.attention.output.dense_type': 'blocklog', 'bert.encoder.layer.0.intermediate.dense_type': 'blocklog', 'bert.encoder.layer.0.output.dense_type': 'blocklog', 'bert.encoder.layer.1.attention.self.query_type': 'fp', 'bert.encoder.layer.1.attention.self.key_type': 'fp', 'bert.encoder.layer.1.attention.output.dense_type': 'fp', 'bert.encoder.layer.1.intermediate.dense_type': 'blocklog', 'bert.encoder.layer.1.output.dense_type': 'fp', 'classifier_type': 'blocklog'}. Best is trial 14 with value: 0.87648.\u001b[0m\n",
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 03:44, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.314700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.303200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.307900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.330500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.308000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.359800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 02:31]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-05 02:42:30,319]\u001b[0m Trial 19 finished with value: 0.87564 and parameters: {'bert.encoder.layer.0.attention.self.query_type': 'fp', 'bert.encoder.layer.0.attention.self.key_type': 'fp', 'bert.encoder.layer.0.attention.self.value_type': 'fp', 'bert.encoder.layer.0.attention.output.dense_type': 'fp', 'bert.encoder.layer.0.intermediate.dense_type': 'blocklog', 'bert.encoder.layer.0.output.dense_type': 'fp', 'bert.encoder.layer.1.attention.self.query_type': 'blocklog', 'bert.encoder.layer.1.attention.self.key_type': 'fp', 'bert.encoder.layer.1.attention.output.dense_type': 'fp', 'bert.encoder.layer.1.intermediate.dense_type': 'blocklog', 'bert.encoder.layer.1.output.dense_type': 'fp', 'classifier_type': 'fp'}. Best is trial 14 with value: 0.87648.\u001b[0m\n",
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 05:40, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.312900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.298600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.302700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.321400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.301800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.356200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 04:13]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-05 02:52:25,939]\u001b[0m Trial 20 finished with value: 0.87356 and parameters: {'bert.encoder.layer.0.attention.self.query_type': 'blocklog', 'bert.encoder.layer.0.attention.self.key_type': 'fp', 'bert.encoder.layer.0.attention.self.value_type': 'blocklog', 'bert.encoder.layer.0.attention.output.dense_type': 'blocklog', 'bert.encoder.layer.0.intermediate.dense_type': 'blocklog', 'bert.encoder.layer.0.output.dense_type': 'fp', 'bert.encoder.layer.1.attention.self.query_type': 'blocklog', 'bert.encoder.layer.1.attention.self.key_type': 'fp', 'bert.encoder.layer.1.attention.output.dense_type': 'blocklog', 'bert.encoder.layer.1.intermediate.dense_type': 'fp', 'bert.encoder.layer.1.output.dense_type': 'fp', 'classifier_type': 'blocklog'}. Best is trial 14 with value: 0.87648.\u001b[0m\n",
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 06:48, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.304400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.299100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.299700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.315300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.311000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.350300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 05:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-05 03:04:37,666]\u001b[0m Trial 21 finished with value: 0.875 and parameters: {'bert.encoder.layer.0.attention.self.query_type': 'blocklog', 'bert.encoder.layer.0.attention.self.key_type': 'blocklog', 'bert.encoder.layer.0.attention.self.value_type': 'blocklog', 'bert.encoder.layer.0.attention.output.dense_type': 'blocklog', 'bert.encoder.layer.0.intermediate.dense_type': 'blocklog', 'bert.encoder.layer.0.output.dense_type': 'fp', 'bert.encoder.layer.1.attention.self.query_type': 'fp', 'bert.encoder.layer.1.attention.self.key_type': 'fp', 'bert.encoder.layer.1.attention.output.dense_type': 'fp', 'bert.encoder.layer.1.intermediate.dense_type': 'blocklog', 'bert.encoder.layer.1.output.dense_type': 'blocklog', 'classifier_type': 'blocklog'}. Best is trial 14 with value: 0.87648.\u001b[0m\n",
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 06:19, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.306000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.305500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.300500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.326200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.313000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.353800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 04:52]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-05 03:15:59,619]\u001b[0m Trial 22 finished with value: 0.87532 and parameters: {'bert.encoder.layer.0.attention.self.query_type': 'blocklog', 'bert.encoder.layer.0.attention.self.key_type': 'blocklog', 'bert.encoder.layer.0.attention.self.value_type': 'fp', 'bert.encoder.layer.0.attention.output.dense_type': 'fp', 'bert.encoder.layer.0.intermediate.dense_type': 'fp', 'bert.encoder.layer.0.output.dense_type': 'blocklog', 'bert.encoder.layer.1.attention.self.query_type': 'fp', 'bert.encoder.layer.1.attention.self.key_type': 'blocklog', 'bert.encoder.layer.1.attention.output.dense_type': 'blocklog', 'bert.encoder.layer.1.intermediate.dense_type': 'fp', 'bert.encoder.layer.1.output.dense_type': 'blocklog', 'classifier_type': 'fp'}. Best is trial 14 with value: 0.87648.\u001b[0m\n",
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 05:12, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.303600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.297500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.303200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.327600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.305600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.352800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 03:50]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-05 03:25:03,463]\u001b[0m Trial 23 finished with value: 0.875 and parameters: {'bert.encoder.layer.0.attention.self.query_type': 'fp', 'bert.encoder.layer.0.attention.self.key_type': 'fp', 'bert.encoder.layer.0.attention.self.value_type': 'fp', 'bert.encoder.layer.0.attention.output.dense_type': 'fp', 'bert.encoder.layer.0.intermediate.dense_type': 'fp', 'bert.encoder.layer.0.output.dense_type': 'blocklog', 'bert.encoder.layer.1.attention.self.query_type': 'fp', 'bert.encoder.layer.1.attention.self.key_type': 'fp', 'bert.encoder.layer.1.attention.output.dense_type': 'blocklog', 'bert.encoder.layer.1.intermediate.dense_type': 'blocklog', 'bert.encoder.layer.1.output.dense_type': 'blocklog', 'classifier_type': 'fp'}. Best is trial 14 with value: 0.87648.\u001b[0m\n",
      "\u001b[32m[I 2026-02-05 03:25:03,557]\u001b[0m A new study created in RDB with name: tutorial6_prec_binary\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best for blocklog: 0.8765\n",
      "Snapshot: /workspace/labs/lab3/outputs/task2_blocklog_snapshot.json\n",
      "\n",
      "-- Running study for precision: binary\n",
      "[run]  tutorial6_prec_binary: running 12 more trial(s) to reach 12 COMPLETE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:56, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>7.973500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.913900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.513800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.217400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.041900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.990600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:35]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-05 03:27:36,786]\u001b[0m Trial 0 finished with value: 0.75324 and parameters: {'bert.encoder.layer.0.attention.self.query_type': 'binary', 'bert.encoder.layer.0.attention.self.key_type': 'fp', 'bert.encoder.layer.0.attention.self.value_type': 'binary', 'bert.encoder.layer.0.attention.output.dense_type': 'binary', 'bert.encoder.layer.0.intermediate.dense_type': 'fp', 'bert.encoder.layer.0.output.dense_type': 'fp', 'bert.encoder.layer.1.attention.self.query_type': 'binary', 'bert.encoder.layer.1.attention.self.key_type': 'binary', 'bert.encoder.layer.1.attention.output.dense_type': 'binary', 'bert.encoder.layer.1.intermediate.dense_type': 'binary', 'bert.encoder.layer.1.output.dense_type': 'fp', 'classifier_type': 'binary'}. Best is trial 0 with value: 0.75324.\u001b[0m\n",
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:55, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.694300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.540600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.568600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.570200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.535000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.563400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:34]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-05 03:30:08,399]\u001b[0m Trial 1 finished with value: 0.75244 and parameters: {'bert.encoder.layer.0.attention.self.query_type': 'binary', 'bert.encoder.layer.0.attention.self.key_type': 'binary', 'bert.encoder.layer.0.attention.self.value_type': 'fp', 'bert.encoder.layer.0.attention.output.dense_type': 'binary', 'bert.encoder.layer.0.intermediate.dense_type': 'binary', 'bert.encoder.layer.0.output.dense_type': 'binary', 'bert.encoder.layer.1.attention.self.query_type': 'binary', 'bert.encoder.layer.1.attention.self.key_type': 'fp', 'bert.encoder.layer.1.attention.output.dense_type': 'binary', 'bert.encoder.layer.1.intermediate.dense_type': 'fp', 'bert.encoder.layer.1.output.dense_type': 'binary', 'classifier_type': 'fp'}. Best is trial 0 with value: 0.75324.\u001b[0m\n",
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:53, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.468600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.326800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.313000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.321800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.320400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.344800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:33]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-05 03:32:37,197]\u001b[0m Trial 2 finished with value: 0.86888 and parameters: {'bert.encoder.layer.0.attention.self.query_type': 'binary', 'bert.encoder.layer.0.attention.self.key_type': 'fp', 'bert.encoder.layer.0.attention.self.value_type': 'fp', 'bert.encoder.layer.0.attention.output.dense_type': 'fp', 'bert.encoder.layer.0.intermediate.dense_type': 'fp', 'bert.encoder.layer.0.output.dense_type': 'fp', 'bert.encoder.layer.1.attention.self.query_type': 'fp', 'bert.encoder.layer.1.attention.self.key_type': 'fp', 'bert.encoder.layer.1.attention.output.dense_type': 'binary', 'bert.encoder.layer.1.intermediate.dense_type': 'fp', 'bert.encoder.layer.1.output.dense_type': 'fp', 'classifier_type': 'fp'}. Best is trial 2 with value: 0.86888.\u001b[0m\n",
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:54, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.347300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.341200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.322300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.338200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.318100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.370100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:33]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-05 03:35:07,389]\u001b[0m Trial 3 finished with value: 0.8734 and parameters: {'bert.encoder.layer.0.attention.self.query_type': 'fp', 'bert.encoder.layer.0.attention.self.key_type': 'fp', 'bert.encoder.layer.0.attention.self.value_type': 'fp', 'bert.encoder.layer.0.attention.output.dense_type': 'fp', 'bert.encoder.layer.0.intermediate.dense_type': 'binary', 'bert.encoder.layer.0.output.dense_type': 'binary', 'bert.encoder.layer.1.attention.self.query_type': 'fp', 'bert.encoder.layer.1.attention.self.key_type': 'fp', 'bert.encoder.layer.1.attention.output.dense_type': 'binary', 'bert.encoder.layer.1.intermediate.dense_type': 'binary', 'bert.encoder.layer.1.output.dense_type': 'binary', 'classifier_type': 'fp'}. Best is trial 3 with value: 0.8734.\u001b[0m\n",
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:53, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.364700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.342000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.337200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.346200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.322100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.381600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:33]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-05 03:37:36,171]\u001b[0m Trial 4 finished with value: 0.87444 and parameters: {'bert.encoder.layer.0.attention.self.query_type': 'fp', 'bert.encoder.layer.0.attention.self.key_type': 'fp', 'bert.encoder.layer.0.attention.self.value_type': 'fp', 'bert.encoder.layer.0.attention.output.dense_type': 'binary', 'bert.encoder.layer.0.intermediate.dense_type': 'binary', 'bert.encoder.layer.0.output.dense_type': 'fp', 'bert.encoder.layer.1.attention.self.query_type': 'binary', 'bert.encoder.layer.1.attention.self.key_type': 'binary', 'bert.encoder.layer.1.attention.output.dense_type': 'fp', 'bert.encoder.layer.1.intermediate.dense_type': 'fp', 'bert.encoder.layer.1.output.dense_type': 'fp', 'classifier_type': 'fp'}. Best is trial 4 with value: 0.87444.\u001b[0m\n",
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:56, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>4.466900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.945000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.722200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.705000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.575200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.601900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:34]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-05 03:40:08,540]\u001b[0m Trial 5 finished with value: 0.86676 and parameters: {'bert.encoder.layer.0.attention.self.query_type': 'fp', 'bert.encoder.layer.0.attention.self.key_type': 'fp', 'bert.encoder.layer.0.attention.self.value_type': 'binary', 'bert.encoder.layer.0.attention.output.dense_type': 'binary', 'bert.encoder.layer.0.intermediate.dense_type': 'fp', 'bert.encoder.layer.0.output.dense_type': 'fp', 'bert.encoder.layer.1.attention.self.query_type': 'binary', 'bert.encoder.layer.1.attention.self.key_type': 'binary', 'bert.encoder.layer.1.attention.output.dense_type': 'binary', 'bert.encoder.layer.1.intermediate.dense_type': 'fp', 'bert.encoder.layer.1.output.dense_type': 'fp', 'classifier_type': 'binary'}. Best is trial 4 with value: 0.87444.\u001b[0m\n",
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:56, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>5.137100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.075600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.739300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.551800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.458100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.468300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:34]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-05 03:42:41,737]\u001b[0m Trial 6 finished with value: 0.8448 and parameters: {'bert.encoder.layer.0.attention.self.query_type': 'fp', 'bert.encoder.layer.0.attention.self.key_type': 'binary', 'bert.encoder.layer.0.attention.self.value_type': 'binary', 'bert.encoder.layer.0.attention.output.dense_type': 'binary', 'bert.encoder.layer.0.intermediate.dense_type': 'binary', 'bert.encoder.layer.0.output.dense_type': 'binary', 'bert.encoder.layer.1.attention.self.query_type': 'fp', 'bert.encoder.layer.1.attention.self.key_type': 'fp', 'bert.encoder.layer.1.attention.output.dense_type': 'fp', 'bert.encoder.layer.1.intermediate.dense_type': 'binary', 'bert.encoder.layer.1.output.dense_type': 'fp', 'classifier_type': 'binary'}. Best is trial 4 with value: 0.87444.\u001b[0m\n",
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:53, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.428900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.342700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.335300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.348600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.327300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.377000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:33]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-05 03:45:10,442]\u001b[0m Trial 7 finished with value: 0.8732 and parameters: {'bert.encoder.layer.0.attention.self.query_type': 'fp', 'bert.encoder.layer.0.attention.self.key_type': 'fp', 'bert.encoder.layer.0.attention.self.value_type': 'fp', 'bert.encoder.layer.0.attention.output.dense_type': 'fp', 'bert.encoder.layer.0.intermediate.dense_type': 'binary', 'bert.encoder.layer.0.output.dense_type': 'fp', 'bert.encoder.layer.1.attention.self.query_type': 'binary', 'bert.encoder.layer.1.attention.self.key_type': 'fp', 'bert.encoder.layer.1.attention.output.dense_type': 'fp', 'bert.encoder.layer.1.intermediate.dense_type': 'binary', 'bert.encoder.layer.1.output.dense_type': 'fp', 'classifier_type': 'fp'}. Best is trial 4 with value: 0.87444.\u001b[0m\n",
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:56, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>9.614200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.424900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.114000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.957000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.820200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.790300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:35]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-05 03:47:43,285]\u001b[0m Trial 8 finished with value: 0.76576 and parameters: {'bert.encoder.layer.0.attention.self.query_type': 'binary', 'bert.encoder.layer.0.attention.self.key_type': 'fp', 'bert.encoder.layer.0.attention.self.value_type': 'binary', 'bert.encoder.layer.0.attention.output.dense_type': 'binary', 'bert.encoder.layer.0.intermediate.dense_type': 'binary', 'bert.encoder.layer.0.output.dense_type': 'fp', 'bert.encoder.layer.1.attention.self.query_type': 'binary', 'bert.encoder.layer.1.attention.self.key_type': 'fp', 'bert.encoder.layer.1.attention.output.dense_type': 'binary', 'bert.encoder.layer.1.intermediate.dense_type': 'fp', 'bert.encoder.layer.1.output.dense_type': 'fp', 'classifier_type': 'binary'}. Best is trial 4 with value: 0.87444.\u001b[0m\n",
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:56, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>5.137600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.433200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.056400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.869500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.761000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.683100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:35]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-05 03:50:16,643]\u001b[0m Trial 9 finished with value: 0.79128 and parameters: {'bert.encoder.layer.0.attention.self.query_type': 'binary', 'bert.encoder.layer.0.attention.self.key_type': 'binary', 'bert.encoder.layer.0.attention.self.value_type': 'binary', 'bert.encoder.layer.0.attention.output.dense_type': 'binary', 'bert.encoder.layer.0.intermediate.dense_type': 'binary', 'bert.encoder.layer.0.output.dense_type': 'fp', 'bert.encoder.layer.1.attention.self.query_type': 'fp', 'bert.encoder.layer.1.attention.self.key_type': 'fp', 'bert.encoder.layer.1.attention.output.dense_type': 'fp', 'bert.encoder.layer.1.intermediate.dense_type': 'binary', 'bert.encoder.layer.1.output.dense_type': 'binary', 'classifier_type': 'binary'}. Best is trial 4 with value: 0.87444.\u001b[0m\n",
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:54, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.613900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.500100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.523000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.523100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.508700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.513600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:33]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-05 03:52:46,126]\u001b[0m Trial 10 finished with value: 0.78356 and parameters: {'bert.encoder.layer.0.attention.self.query_type': 'fp', 'bert.encoder.layer.0.attention.self.key_type': 'binary', 'bert.encoder.layer.0.attention.self.value_type': 'fp', 'bert.encoder.layer.0.attention.output.dense_type': 'fp', 'bert.encoder.layer.0.intermediate.dense_type': 'fp', 'bert.encoder.layer.0.output.dense_type': 'binary', 'bert.encoder.layer.1.attention.self.query_type': 'binary', 'bert.encoder.layer.1.attention.self.key_type': 'binary', 'bert.encoder.layer.1.attention.output.dense_type': 'fp', 'bert.encoder.layer.1.intermediate.dense_type': 'fp', 'bert.encoder.layer.1.output.dense_type': 'binary', 'classifier_type': 'fp'}. Best is trial 4 with value: 0.87444.\u001b[0m\n",
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:54, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.437900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.341600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.358200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.355200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.331900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.382800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:33]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-05 03:55:16,400]\u001b[0m Trial 11 finished with value: 0.87188 and parameters: {'bert.encoder.layer.0.attention.self.query_type': 'fp', 'bert.encoder.layer.0.attention.self.key_type': 'fp', 'bert.encoder.layer.0.attention.self.value_type': 'fp', 'bert.encoder.layer.0.attention.output.dense_type': 'fp', 'bert.encoder.layer.0.intermediate.dense_type': 'binary', 'bert.encoder.layer.0.output.dense_type': 'binary', 'bert.encoder.layer.1.attention.self.query_type': 'fp', 'bert.encoder.layer.1.attention.self.key_type': 'binary', 'bert.encoder.layer.1.attention.output.dense_type': 'fp', 'bert.encoder.layer.1.intermediate.dense_type': 'binary', 'bert.encoder.layer.1.output.dense_type': 'binary', 'classifier_type': 'fp'}. Best is trial 4 with value: 0.87444.\u001b[0m\n",
      "\u001b[32m[I 2026-02-05 03:55:16,452]\u001b[0m A new study created in RDB with name: tutorial6_prec_binary_scaling\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best for binary: 0.8744\n",
      "Snapshot: /workspace/labs/lab3/outputs/task2_binary_snapshot.json\n",
      "\n",
      "-- Running study for precision: binary_scaling\n",
      "[run]  tutorial6_prec_binary_scaling: running 12 more trial(s) to reach 12 COMPLETE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 02:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>12.276300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>4.683400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>4.641700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>4.300200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>3.551400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>3.568100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:38]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-05 03:57:56,968]\u001b[0m Trial 0 finished with value: 0.75804 and parameters: {'bert.encoder.layer.0.attention.self.query_type': 'binary_scaling', 'bert.encoder.layer.0.attention.self.key_type': 'fp', 'bert.encoder.layer.0.attention.self.value_type': 'binary_scaling', 'bert.encoder.layer.0.attention.output.dense_type': 'binary_scaling', 'bert.encoder.layer.0.intermediate.dense_type': 'fp', 'bert.encoder.layer.0.output.dense_type': 'fp', 'bert.encoder.layer.1.attention.self.query_type': 'binary_scaling', 'bert.encoder.layer.1.attention.self.key_type': 'binary_scaling', 'bert.encoder.layer.1.attention.output.dense_type': 'binary_scaling', 'bert.encoder.layer.1.intermediate.dense_type': 'binary_scaling', 'bert.encoder.layer.1.output.dense_type': 'fp', 'classifier_type': 'binary_scaling'}. Best is trial 0 with value: 0.75804.\u001b[0m\n",
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 02:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.619500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.529000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.561500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.561000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.562900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.576800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:39]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-05 04:00:41,942]\u001b[0m Trial 1 finished with value: 0.73024 and parameters: {'bert.encoder.layer.0.attention.self.query_type': 'binary_scaling', 'bert.encoder.layer.0.attention.self.key_type': 'binary_scaling', 'bert.encoder.layer.0.attention.self.value_type': 'fp', 'bert.encoder.layer.0.attention.output.dense_type': 'binary_scaling', 'bert.encoder.layer.0.intermediate.dense_type': 'binary_scaling', 'bert.encoder.layer.0.output.dense_type': 'binary_scaling', 'bert.encoder.layer.1.attention.self.query_type': 'binary_scaling', 'bert.encoder.layer.1.attention.self.key_type': 'fp', 'bert.encoder.layer.1.attention.output.dense_type': 'binary_scaling', 'bert.encoder.layer.1.intermediate.dense_type': 'fp', 'bert.encoder.layer.1.output.dense_type': 'binary_scaling', 'classifier_type': 'fp'}. Best is trial 0 with value: 0.75804.\u001b[0m\n",
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:54, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.452100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.325100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.302400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.311500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.297500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.324800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:34]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-05 04:03:12,522]\u001b[0m Trial 2 finished with value: 0.86308 and parameters: {'bert.encoder.layer.0.attention.self.query_type': 'binary_scaling', 'bert.encoder.layer.0.attention.self.key_type': 'fp', 'bert.encoder.layer.0.attention.self.value_type': 'fp', 'bert.encoder.layer.0.attention.output.dense_type': 'fp', 'bert.encoder.layer.0.intermediate.dense_type': 'fp', 'bert.encoder.layer.0.output.dense_type': 'fp', 'bert.encoder.layer.1.attention.self.query_type': 'fp', 'bert.encoder.layer.1.attention.self.key_type': 'fp', 'bert.encoder.layer.1.attention.output.dense_type': 'binary_scaling', 'bert.encoder.layer.1.intermediate.dense_type': 'fp', 'bert.encoder.layer.1.output.dense_type': 'fp', 'classifier_type': 'fp'}. Best is trial 2 with value: 0.86308.\u001b[0m\n",
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 02:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.633500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.727700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.711000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.679400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.642000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.655100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:37]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-05 04:06:00,942]\u001b[0m Trial 3 finished with value: 0.81052 and parameters: {'bert.encoder.layer.0.attention.self.query_type': 'fp', 'bert.encoder.layer.0.attention.self.key_type': 'fp', 'bert.encoder.layer.0.attention.self.value_type': 'fp', 'bert.encoder.layer.0.attention.output.dense_type': 'fp', 'bert.encoder.layer.0.intermediate.dense_type': 'binary_scaling', 'bert.encoder.layer.0.output.dense_type': 'binary_scaling', 'bert.encoder.layer.1.attention.self.query_type': 'fp', 'bert.encoder.layer.1.attention.self.key_type': 'fp', 'bert.encoder.layer.1.attention.output.dense_type': 'binary_scaling', 'bert.encoder.layer.1.intermediate.dense_type': 'binary_scaling', 'bert.encoder.layer.1.output.dense_type': 'binary_scaling', 'classifier_type': 'fp'}. Best is trial 2 with value: 0.86308.\u001b[0m\n",
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:56, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.362600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.308300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.291400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.299000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.282400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.320400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:35]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-05 04:08:34,022]\u001b[0m Trial 4 finished with value: 0.87456 and parameters: {'bert.encoder.layer.0.attention.self.query_type': 'fp', 'bert.encoder.layer.0.attention.self.key_type': 'fp', 'bert.encoder.layer.0.attention.self.value_type': 'fp', 'bert.encoder.layer.0.attention.output.dense_type': 'binary_scaling', 'bert.encoder.layer.0.intermediate.dense_type': 'binary_scaling', 'bert.encoder.layer.0.output.dense_type': 'fp', 'bert.encoder.layer.1.attention.self.query_type': 'binary_scaling', 'bert.encoder.layer.1.attention.self.key_type': 'binary_scaling', 'bert.encoder.layer.1.attention.output.dense_type': 'fp', 'bert.encoder.layer.1.intermediate.dense_type': 'fp', 'bert.encoder.layer.1.output.dense_type': 'fp', 'classifier_type': 'fp'}. Best is trial 4 with value: 0.87456.\u001b[0m\n",
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:59, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>7.158700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.367900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>2.226400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.286200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.903300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>2.137700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:36]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-05 04:11:11,480]\u001b[0m Trial 5 finished with value: 0.84024 and parameters: {'bert.encoder.layer.0.attention.self.query_type': 'fp', 'bert.encoder.layer.0.attention.self.key_type': 'fp', 'bert.encoder.layer.0.attention.self.value_type': 'binary_scaling', 'bert.encoder.layer.0.attention.output.dense_type': 'binary_scaling', 'bert.encoder.layer.0.intermediate.dense_type': 'fp', 'bert.encoder.layer.0.output.dense_type': 'fp', 'bert.encoder.layer.1.attention.self.query_type': 'binary_scaling', 'bert.encoder.layer.1.attention.self.key_type': 'binary_scaling', 'bert.encoder.layer.1.attention.output.dense_type': 'binary_scaling', 'bert.encoder.layer.1.intermediate.dense_type': 'fp', 'bert.encoder.layer.1.output.dense_type': 'fp', 'classifier_type': 'binary_scaling'}. Best is trial 4 with value: 0.87456.\u001b[0m\n",
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 02:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>7.655800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.633800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>3.483500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>3.266300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>2.633800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>2.878800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:38]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-05 04:13:54,636]\u001b[0m Trial 6 finished with value: 0.67936 and parameters: {'bert.encoder.layer.0.attention.self.query_type': 'fp', 'bert.encoder.layer.0.attention.self.key_type': 'binary_scaling', 'bert.encoder.layer.0.attention.self.value_type': 'binary_scaling', 'bert.encoder.layer.0.attention.output.dense_type': 'binary_scaling', 'bert.encoder.layer.0.intermediate.dense_type': 'binary_scaling', 'bert.encoder.layer.0.output.dense_type': 'binary_scaling', 'bert.encoder.layer.1.attention.self.query_type': 'fp', 'bert.encoder.layer.1.attention.self.key_type': 'fp', 'bert.encoder.layer.1.attention.output.dense_type': 'fp', 'bert.encoder.layer.1.intermediate.dense_type': 'binary_scaling', 'bert.encoder.layer.1.output.dense_type': 'fp', 'classifier_type': 'binary_scaling'}. Best is trial 4 with value: 0.87456.\u001b[0m\n",
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:55, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.434400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.352600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.342400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.347100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.328200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.371100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:34]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-05 04:16:26,208]\u001b[0m Trial 7 finished with value: 0.8674 and parameters: {'bert.encoder.layer.0.attention.self.query_type': 'fp', 'bert.encoder.layer.0.attention.self.key_type': 'fp', 'bert.encoder.layer.0.attention.self.value_type': 'fp', 'bert.encoder.layer.0.attention.output.dense_type': 'fp', 'bert.encoder.layer.0.intermediate.dense_type': 'binary_scaling', 'bert.encoder.layer.0.output.dense_type': 'fp', 'bert.encoder.layer.1.attention.self.query_type': 'binary_scaling', 'bert.encoder.layer.1.attention.self.key_type': 'fp', 'bert.encoder.layer.1.attention.output.dense_type': 'fp', 'bert.encoder.layer.1.intermediate.dense_type': 'binary_scaling', 'bert.encoder.layer.1.output.dense_type': 'fp', 'classifier_type': 'fp'}. Best is trial 4 with value: 0.87456.\u001b[0m\n",
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 02:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>15.309700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>4.061600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>3.916000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>3.494900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>3.833000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>3.554100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:37]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-05 04:19:05,835]\u001b[0m Trial 8 finished with value: 0.73828 and parameters: {'bert.encoder.layer.0.attention.self.query_type': 'binary_scaling', 'bert.encoder.layer.0.attention.self.key_type': 'fp', 'bert.encoder.layer.0.attention.self.value_type': 'binary_scaling', 'bert.encoder.layer.0.attention.output.dense_type': 'binary_scaling', 'bert.encoder.layer.0.intermediate.dense_type': 'binary_scaling', 'bert.encoder.layer.0.output.dense_type': 'fp', 'bert.encoder.layer.1.attention.self.query_type': 'binary_scaling', 'bert.encoder.layer.1.attention.self.key_type': 'fp', 'bert.encoder.layer.1.attention.output.dense_type': 'binary_scaling', 'bert.encoder.layer.1.intermediate.dense_type': 'fp', 'bert.encoder.layer.1.output.dense_type': 'fp', 'classifier_type': 'binary_scaling'}. Best is trial 4 with value: 0.87456.\u001b[0m\n",
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 02:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>7.933500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>5.810800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>5.285500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>4.952100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>4.761300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>4.677100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:39]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-05 04:21:50,129]\u001b[0m Trial 9 finished with value: 0.75528 and parameters: {'bert.encoder.layer.0.attention.self.query_type': 'binary_scaling', 'bert.encoder.layer.0.attention.self.key_type': 'binary_scaling', 'bert.encoder.layer.0.attention.self.value_type': 'binary_scaling', 'bert.encoder.layer.0.attention.output.dense_type': 'binary_scaling', 'bert.encoder.layer.0.intermediate.dense_type': 'binary_scaling', 'bert.encoder.layer.0.output.dense_type': 'fp', 'bert.encoder.layer.1.attention.self.query_type': 'fp', 'bert.encoder.layer.1.attention.self.key_type': 'fp', 'bert.encoder.layer.1.attention.output.dense_type': 'fp', 'bert.encoder.layer.1.intermediate.dense_type': 'binary_scaling', 'bert.encoder.layer.1.output.dense_type': 'binary_scaling', 'classifier_type': 'binary_scaling'}. Best is trial 4 with value: 0.87456.\u001b[0m\n",
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 02:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.630800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.482100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.499500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.511100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.479000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.501200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:37]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-05 04:24:30,907]\u001b[0m Trial 10 finished with value: 0.77932 and parameters: {'bert.encoder.layer.0.attention.self.query_type': 'fp', 'bert.encoder.layer.0.attention.self.key_type': 'binary_scaling', 'bert.encoder.layer.0.attention.self.value_type': 'fp', 'bert.encoder.layer.0.attention.output.dense_type': 'fp', 'bert.encoder.layer.0.intermediate.dense_type': 'fp', 'bert.encoder.layer.0.output.dense_type': 'binary_scaling', 'bert.encoder.layer.1.attention.self.query_type': 'binary_scaling', 'bert.encoder.layer.1.attention.self.key_type': 'binary_scaling', 'bert.encoder.layer.1.attention.output.dense_type': 'fp', 'bert.encoder.layer.1.intermediate.dense_type': 'fp', 'bert.encoder.layer.1.output.dense_type': 'binary_scaling', 'classifier_type': 'fp'}. Best is trial 4 with value: 0.87456.\u001b[0m\n",
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:55, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.472000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.332600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.346400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.312200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.353300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:35]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-05 04:27:03,689]\u001b[0m Trial 11 finished with value: 0.87072 and parameters: {'bert.encoder.layer.0.attention.self.query_type': 'fp', 'bert.encoder.layer.0.attention.self.key_type': 'fp', 'bert.encoder.layer.0.attention.self.value_type': 'fp', 'bert.encoder.layer.0.attention.output.dense_type': 'fp', 'bert.encoder.layer.0.intermediate.dense_type': 'binary_scaling', 'bert.encoder.layer.0.output.dense_type': 'fp', 'bert.encoder.layer.1.attention.self.query_type': 'binary_scaling', 'bert.encoder.layer.1.attention.self.key_type': 'binary_scaling', 'bert.encoder.layer.1.attention.output.dense_type': 'fp', 'bert.encoder.layer.1.intermediate.dense_type': 'binary_scaling', 'bert.encoder.layer.1.output.dense_type': 'fp', 'classifier_type': 'fp'}. Best is trial 4 with value: 0.87456.\u001b[0m\n",
      "\u001b[32m[I 2026-02-05 04:27:03,752]\u001b[0m A new study created in RDB with name: tutorial6_prec_binary_residual_sign\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best for binary_scaling: 0.8746\n",
      "Snapshot: /workspace/labs/lab3/outputs/task2_binary_scaling_snapshot.json\n",
      "\n",
      "-- Running study for precision: binary_residual_sign\n",
      "[run]  tutorial6_prec_binary_residual_sign: running 12 more trial(s) to reach 12 COMPLETE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-05 04:28:06,217]\u001b[0m Trial 0 finished with value: 0.67952 and parameters: {'bert.encoder.layer.0.attention.self.query_type': 'binary_residual_sign', 'bert.encoder.layer.0.attention.self.key_type': 'fp', 'bert.encoder.layer.0.attention.self.value_type': 'binary_residual_sign', 'bert.encoder.layer.0.attention.output.dense_type': 'binary_residual_sign', 'bert.encoder.layer.0.intermediate.dense_type': 'fp', 'bert.encoder.layer.0.output.dense_type': 'fp', 'bert.encoder.layer.1.attention.self.query_type': 'binary_residual_sign', 'bert.encoder.layer.1.attention.self.key_type': 'binary_residual_sign', 'bert.encoder.layer.1.attention.output.dense_type': 'binary_residual_sign', 'bert.encoder.layer.1.intermediate.dense_type': 'binary_residual_sign', 'bert.encoder.layer.1.output.dense_type': 'fp', 'classifier_type': 'binary_residual_sign'}. Best is trial 0 with value: 0.67952.\u001b[0m\n",
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:34]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-05 04:29:42,182]\u001b[0m Trial 1 finished with value: 0.6664 and parameters: {'bert.encoder.layer.0.attention.self.query_type': 'binary_residual_sign', 'bert.encoder.layer.0.attention.self.key_type': 'binary_residual_sign', 'bert.encoder.layer.0.attention.self.value_type': 'fp', 'bert.encoder.layer.0.attention.output.dense_type': 'binary_residual_sign', 'bert.encoder.layer.0.intermediate.dense_type': 'binary_residual_sign', 'bert.encoder.layer.0.output.dense_type': 'binary_residual_sign', 'bert.encoder.layer.1.attention.self.query_type': 'binary_residual_sign', 'bert.encoder.layer.1.attention.self.key_type': 'fp', 'bert.encoder.layer.1.attention.output.dense_type': 'binary_residual_sign', 'bert.encoder.layer.1.intermediate.dense_type': 'fp', 'bert.encoder.layer.1.output.dense_type': 'binary_residual_sign', 'classifier_type': 'fp'}. Best is trial 0 with value: 0.67952.\u001b[0m\n",
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:40]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-05 04:30:24,242]\u001b[0m Trial 2 finished with value: 0.65624 and parameters: {'bert.encoder.layer.0.attention.self.query_type': 'binary_residual_sign', 'bert.encoder.layer.0.attention.self.key_type': 'fp', 'bert.encoder.layer.0.attention.self.value_type': 'fp', 'bert.encoder.layer.0.attention.output.dense_type': 'fp', 'bert.encoder.layer.0.intermediate.dense_type': 'fp', 'bert.encoder.layer.0.output.dense_type': 'fp', 'bert.encoder.layer.1.attention.self.query_type': 'fp', 'bert.encoder.layer.1.attention.self.key_type': 'fp', 'bert.encoder.layer.1.attention.output.dense_type': 'binary_residual_sign', 'bert.encoder.layer.1.intermediate.dense_type': 'fp', 'bert.encoder.layer.1.output.dense_type': 'fp', 'classifier_type': 'fp'}. Best is trial 0 with value: 0.67952.\u001b[0m\n",
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-05 04:31:48,711]\u001b[0m Trial 3 finished with value: 0.51384 and parameters: {'bert.encoder.layer.0.attention.self.query_type': 'fp', 'bert.encoder.layer.0.attention.self.key_type': 'fp', 'bert.encoder.layer.0.attention.self.value_type': 'fp', 'bert.encoder.layer.0.attention.output.dense_type': 'fp', 'bert.encoder.layer.0.intermediate.dense_type': 'binary_residual_sign', 'bert.encoder.layer.0.output.dense_type': 'binary_residual_sign', 'bert.encoder.layer.1.attention.self.query_type': 'fp', 'bert.encoder.layer.1.attention.self.key_type': 'fp', 'bert.encoder.layer.1.attention.output.dense_type': 'binary_residual_sign', 'bert.encoder.layer.1.intermediate.dense_type': 'binary_residual_sign', 'bert.encoder.layer.1.output.dense_type': 'binary_residual_sign', 'classifier_type': 'fp'}. Best is trial 0 with value: 0.67952.\u001b[0m\n",
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:48]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-05 04:32:38,386]\u001b[0m Trial 4 finished with value: 0.60176 and parameters: {'bert.encoder.layer.0.attention.self.query_type': 'fp', 'bert.encoder.layer.0.attention.self.key_type': 'fp', 'bert.encoder.layer.0.attention.self.value_type': 'fp', 'bert.encoder.layer.0.attention.output.dense_type': 'binary_residual_sign', 'bert.encoder.layer.0.intermediate.dense_type': 'binary_residual_sign', 'bert.encoder.layer.0.output.dense_type': 'fp', 'bert.encoder.layer.1.attention.self.query_type': 'binary_residual_sign', 'bert.encoder.layer.1.attention.self.key_type': 'binary_residual_sign', 'bert.encoder.layer.1.attention.output.dense_type': 'fp', 'bert.encoder.layer.1.intermediate.dense_type': 'fp', 'bert.encoder.layer.1.output.dense_type': 'fp', 'classifier_type': 'fp'}. Best is trial 0 with value: 0.67952.\u001b[0m\n",
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:53]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-05 04:33:33,300]\u001b[0m Trial 5 finished with value: 0.5334 and parameters: {'bert.encoder.layer.0.attention.self.query_type': 'fp', 'bert.encoder.layer.0.attention.self.key_type': 'fp', 'bert.encoder.layer.0.attention.self.value_type': 'binary_residual_sign', 'bert.encoder.layer.0.attention.output.dense_type': 'binary_residual_sign', 'bert.encoder.layer.0.intermediate.dense_type': 'fp', 'bert.encoder.layer.0.output.dense_type': 'fp', 'bert.encoder.layer.1.attention.self.query_type': 'binary_residual_sign', 'bert.encoder.layer.1.attention.self.key_type': 'binary_residual_sign', 'bert.encoder.layer.1.attention.output.dense_type': 'binary_residual_sign', 'bert.encoder.layer.1.intermediate.dense_type': 'fp', 'bert.encoder.layer.1.output.dense_type': 'fp', 'classifier_type': 'binary_residual_sign'}. Best is trial 0 with value: 0.67952.\u001b[0m\n",
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:12]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-05 04:34:47,404]\u001b[0m Trial 6 finished with value: 0.64 and parameters: {'bert.encoder.layer.0.attention.self.query_type': 'fp', 'bert.encoder.layer.0.attention.self.key_type': 'binary_residual_sign', 'bert.encoder.layer.0.attention.self.value_type': 'binary_residual_sign', 'bert.encoder.layer.0.attention.output.dense_type': 'binary_residual_sign', 'bert.encoder.layer.0.intermediate.dense_type': 'binary_residual_sign', 'bert.encoder.layer.0.output.dense_type': 'binary_residual_sign', 'bert.encoder.layer.1.attention.self.query_type': 'fp', 'bert.encoder.layer.1.attention.self.key_type': 'fp', 'bert.encoder.layer.1.attention.output.dense_type': 'fp', 'bert.encoder.layer.1.intermediate.dense_type': 'binary_residual_sign', 'bert.encoder.layer.1.output.dense_type': 'fp', 'classifier_type': 'binary_residual_sign'}. Best is trial 0 with value: 0.67952.\u001b[0m\n",
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:44]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-05 04:35:33,394]\u001b[0m Trial 7 finished with value: 0.21548 and parameters: {'bert.encoder.layer.0.attention.self.query_type': 'fp', 'bert.encoder.layer.0.attention.self.key_type': 'fp', 'bert.encoder.layer.0.attention.self.value_type': 'fp', 'bert.encoder.layer.0.attention.output.dense_type': 'fp', 'bert.encoder.layer.0.intermediate.dense_type': 'binary_residual_sign', 'bert.encoder.layer.0.output.dense_type': 'fp', 'bert.encoder.layer.1.attention.self.query_type': 'binary_residual_sign', 'bert.encoder.layer.1.attention.self.key_type': 'fp', 'bert.encoder.layer.1.attention.output.dense_type': 'fp', 'bert.encoder.layer.1.intermediate.dense_type': 'binary_residual_sign', 'bert.encoder.layer.1.output.dense_type': 'fp', 'classifier_type': 'fp'}. Best is trial 0 with value: 0.67952.\u001b[0m\n",
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:57]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-05 04:36:31,951]\u001b[0m Trial 8 finished with value: 0.68084 and parameters: {'bert.encoder.layer.0.attention.self.query_type': 'binary_residual_sign', 'bert.encoder.layer.0.attention.self.key_type': 'fp', 'bert.encoder.layer.0.attention.self.value_type': 'binary_residual_sign', 'bert.encoder.layer.0.attention.output.dense_type': 'binary_residual_sign', 'bert.encoder.layer.0.intermediate.dense_type': 'binary_residual_sign', 'bert.encoder.layer.0.output.dense_type': 'fp', 'bert.encoder.layer.1.attention.self.query_type': 'binary_residual_sign', 'bert.encoder.layer.1.attention.self.key_type': 'fp', 'bert.encoder.layer.1.attention.output.dense_type': 'binary_residual_sign', 'bert.encoder.layer.1.intermediate.dense_type': 'fp', 'bert.encoder.layer.1.output.dense_type': 'fp', 'classifier_type': 'binary_residual_sign'}. Best is trial 8 with value: 0.68084.\u001b[0m\n",
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:16]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-05 04:37:49,718]\u001b[0m Trial 9 finished with value: 0.6368 and parameters: {'bert.encoder.layer.0.attention.self.query_type': 'binary_residual_sign', 'bert.encoder.layer.0.attention.self.key_type': 'binary_residual_sign', 'bert.encoder.layer.0.attention.self.value_type': 'binary_residual_sign', 'bert.encoder.layer.0.attention.output.dense_type': 'binary_residual_sign', 'bert.encoder.layer.0.intermediate.dense_type': 'binary_residual_sign', 'bert.encoder.layer.0.output.dense_type': 'fp', 'bert.encoder.layer.1.attention.self.query_type': 'fp', 'bert.encoder.layer.1.attention.self.key_type': 'fp', 'bert.encoder.layer.1.attention.output.dense_type': 'fp', 'bert.encoder.layer.1.intermediate.dense_type': 'binary_residual_sign', 'bert.encoder.layer.1.output.dense_type': 'binary_residual_sign', 'classifier_type': 'binary_residual_sign'}. Best is trial 8 with value: 0.68084.\u001b[0m\n",
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:35]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-05 04:39:26,747]\u001b[0m Trial 10 finished with value: 0.66376 and parameters: {'bert.encoder.layer.0.attention.self.query_type': 'binary_residual_sign', 'bert.encoder.layer.0.attention.self.key_type': 'binary_residual_sign', 'bert.encoder.layer.0.attention.self.value_type': 'binary_residual_sign', 'bert.encoder.layer.0.attention.output.dense_type': 'fp', 'bert.encoder.layer.0.intermediate.dense_type': 'fp', 'bert.encoder.layer.0.output.dense_type': 'binary_residual_sign', 'bert.encoder.layer.1.attention.self.query_type': 'binary_residual_sign', 'bert.encoder.layer.1.attention.self.key_type': 'binary_residual_sign', 'bert.encoder.layer.1.attention.output.dense_type': 'binary_residual_sign', 'bert.encoder.layer.1.intermediate.dense_type': 'fp', 'bert.encoder.layer.1.output.dense_type': 'binary_residual_sign', 'classifier_type': 'binary_residual_sign'}. Best is trial 8 with value: 0.68084.\u001b[0m\n",
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-05 04:40:29,299]\u001b[0m Trial 11 finished with value: 0.67952 and parameters: {'bert.encoder.layer.0.attention.self.query_type': 'binary_residual_sign', 'bert.encoder.layer.0.attention.self.key_type': 'fp', 'bert.encoder.layer.0.attention.self.value_type': 'binary_residual_sign', 'bert.encoder.layer.0.attention.output.dense_type': 'binary_residual_sign', 'bert.encoder.layer.0.intermediate.dense_type': 'fp', 'bert.encoder.layer.0.output.dense_type': 'fp', 'bert.encoder.layer.1.attention.self.query_type': 'binary_residual_sign', 'bert.encoder.layer.1.attention.self.key_type': 'binary_residual_sign', 'bert.encoder.layer.1.attention.output.dense_type': 'binary_residual_sign', 'bert.encoder.layer.1.intermediate.dense_type': 'binary_residual_sign', 'bert.encoder.layer.1.output.dense_type': 'fp', 'classifier_type': 'binary_residual_sign'}. Best is trial 8 with value: 0.68084.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best for binary_residual_sign: 0.6808\n",
      "Snapshot: /workspace/labs/lab3/outputs/task2_binary_residual_sign_snapshot.json\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`past_key_values` were not specified as input names, but model.config.use_cache = True. Setting model.config.use_cache = False.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mGetting dummy input for prajjwal1/bert-tiny.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /workspace/labs/lab3/outputs/tutorial6_task2_all_precisions_running_best.png\n",
      "Saved summary JSON: /workspace/labs/lab3/outputs/tutorial6_impl_tasks_summary.json\n",
      "\n",
      "=== Optional: Compression on Task 1 best model ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mGetting dummy input for prajjwal1/bert-tiny.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
      "\n",
      "\n",
      "        [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]])\n",
      "tensor([[[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
      "\n",
      "\n",
      "        [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]])\n",
      "tensor([[[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]])\n",
      "tensor([[[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]])\n",
      "tensor([[[ 0.4399, -0.1289, -0.0193,  ..., -0.7220,  2.1669,  0.2116],\n",
      "         [ 0.4737, -1.2851,  0.7269,  ..., -1.3262, -0.0807,  0.7324],\n",
      "         [-1.0127, -1.2385,  1.0493,  ..., -0.2675,  0.9101,  0.6033],\n",
      "         ...,\n",
      "         [-0.8877,  0.2255, -0.0285,  ..., -0.8598, -1.6034,  0.4798],\n",
      "         [-1.3354, -0.2770, -0.4315,  ...,  0.1540, -0.0039,  0.0438],\n",
      "         [-0.9938, -1.2972,  0.0781,  ..., -2.4799, -0.2318, -0.8143]],\n",
      "\n",
      "        [[ 0.4399, -0.1289, -0.0193,  ..., -0.7220,  2.1669,  0.2116],\n",
      "         [ 0.3325, -2.1907,  0.4309,  ..., -0.4327,  0.8238,  0.6018],\n",
      "         [-2.2631, -0.5424,  1.6860,  ..., -0.1677,  0.0543, -1.1901],\n",
      "         ...,\n",
      "         [-0.6945,  0.7086, -0.0305,  ..., -0.2801, -1.4319,  1.3509],\n",
      "         [-0.9197, -0.5727,  0.8206,  ..., -0.7162,  0.1093,  0.1793],\n",
      "         [-0.9938, -1.2972,  0.0781,  ..., -2.4799, -0.2318, -0.8143]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[ 0.5355, -0.0675, -0.2999,  ...,  1.0623, -1.5882, -0.4372],\n",
      "         [ 0.0714, -0.1049, -0.6291,  ...,  0.3066, -1.2606, -0.1896],\n",
      "         [ 0.4521, -0.2345, -0.2281,  ...,  0.4841, -0.8775, -0.4523],\n",
      "         ...,\n",
      "         [ 0.1751,  0.3563, -0.3652,  ...,  0.5923, -0.7895, -0.6227],\n",
      "         [ 0.2784, -0.2019,  0.0694,  ...,  0.3389, -1.0946, -0.6864],\n",
      "         [ 0.2996, -0.0439, -0.7518,  ...,  0.3756, -0.8931, -0.4892]],\n",
      "\n",
      "        [[ 0.5355, -0.0675, -0.2999,  ...,  1.0623, -1.5882, -0.4372],\n",
      "         [ 0.0419, -0.1495, -0.2300,  ...,  0.4913, -1.2540, -0.3115],\n",
      "         [ 0.6684, -0.1476, -0.5027,  ...,  0.3221, -1.2428, -0.4057],\n",
      "         ...,\n",
      "         [ 0.4988,  0.1559, -0.2923,  ...,  0.6583, -0.7896, -0.5446],\n",
      "         [ 0.0049, -0.3911, -0.1698,  ...,  0.3138, -1.1344, -0.8804],\n",
      "         [ 0.2996, -0.0439, -0.7518,  ...,  0.3756, -0.8931, -0.4892]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.5355, -0.0675, -0.2999,  ...,  1.0623, -1.5882, -0.4372],\n",
      "         [ 0.0714, -0.1049, -0.6291,  ...,  0.3066, -1.2606, -0.1896],\n",
      "         [ 0.4521, -0.2345, -0.2281,  ...,  0.4841, -0.8775, -0.4523],\n",
      "         ...,\n",
      "         [ 0.1751,  0.3563, -0.3652,  ...,  0.5923, -0.7895, -0.6227],\n",
      "         [ 0.2784, -0.2019,  0.0694,  ...,  0.3389, -1.0946, -0.6864],\n",
      "         [ 0.2996, -0.0439, -0.7518,  ...,  0.3756, -0.8931, -0.4892]],\n",
      "\n",
      "        [[ 0.5355, -0.0675, -0.2999,  ...,  1.0623, -1.5882, -0.4372],\n",
      "         [ 0.0419, -0.1495, -0.2300,  ...,  0.4913, -1.2540, -0.3115],\n",
      "         [ 0.6684, -0.1476, -0.5027,  ...,  0.3221, -1.2428, -0.4057],\n",
      "         ...,\n",
      "         [ 0.4988,  0.1559, -0.2923,  ...,  0.6583, -0.7896, -0.5446],\n",
      "         [ 0.0049, -0.3911, -0.1698,  ...,  0.3138, -1.1344, -0.8804],\n",
      "         [ 0.2996, -0.0439, -0.7518,  ...,  0.3756, -0.8931, -0.4892]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 0.5355, -0.0675, -0.2999,  ...,  0.8728, -0.7396, -0.7421],\n",
      "          [ 1.1956, -0.1778, -0.9047,  ...,  1.0623, -1.5882, -0.4372]],\n",
      "\n",
      "         [[ 0.0714, -0.1049, -0.6291,  ...,  0.7638, -0.4328, -0.4335],\n",
      "          [ 0.4737, -0.0795, -0.4281,  ...,  0.3066, -1.2606, -0.1896]],\n",
      "\n",
      "         [[ 0.4521, -0.2345, -0.2281,  ...,  0.5133, -0.1947, -0.6254],\n",
      "          [-0.0835,  0.0678,  0.0493,  ...,  0.4841, -0.8775, -0.4523]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1751,  0.3563, -0.3652,  ...,  0.3062, -0.1877, -0.2744],\n",
      "          [ 0.2485, -0.0350, -0.0193,  ...,  0.5923, -0.7895, -0.6227]],\n",
      "\n",
      "         [[ 0.2784, -0.2019,  0.0694,  ...,  0.3501, -0.2056, -0.5703],\n",
      "          [ 0.3718, -0.0893, -0.2088,  ...,  0.3389, -1.0946, -0.6864]],\n",
      "\n",
      "         [[ 0.2996, -0.0439, -0.7518,  ...,  0.3823, -0.2261, -0.1500],\n",
      "          [ 0.5887, -0.8339, -0.2265,  ...,  0.3756, -0.8931, -0.4892]]],\n",
      "\n",
      "\n",
      "        [[[ 0.5355, -0.0675, -0.2999,  ...,  0.8728, -0.7396, -0.7421],\n",
      "          [ 1.1956, -0.1778, -0.9047,  ...,  1.0623, -1.5882, -0.4372]],\n",
      "\n",
      "         [[ 0.0419, -0.1495, -0.2300,  ...,  1.0737, -0.3505, -0.5324],\n",
      "          [ 0.4068,  0.0290, -0.6251,  ...,  0.4913, -1.2540, -0.3115]],\n",
      "\n",
      "         [[ 0.6684, -0.1476, -0.5027,  ...,  0.4181, -0.5559, -0.3499],\n",
      "          [ 0.0225,  0.0707, -0.2040,  ...,  0.3221, -1.2428, -0.4057]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4988,  0.1559, -0.2923,  ...,  0.3894, -0.2367, -0.1727],\n",
      "          [ 0.1865, -0.0686, -0.0321,  ...,  0.6583, -0.7896, -0.5446]],\n",
      "\n",
      "         [[ 0.0049, -0.3911, -0.1698,  ...,  0.1592, -0.3604, -0.4732],\n",
      "          [ 0.4345, -0.0262, -0.4430,  ...,  0.3138, -1.1344, -0.8804]],\n",
      "\n",
      "         [[ 0.2996, -0.0439, -0.7518,  ...,  0.3823, -0.2261, -0.1500],\n",
      "          [ 0.5887, -0.8339, -0.2265,  ...,  0.3756, -0.8931, -0.4892]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.3411, -0.7532,  0.3818,  ..., -0.4160,  0.1045, -0.4541],\n",
      "         [ 0.0063, -0.1287,  0.4656,  ..., -0.3665,  0.0151, -0.3303],\n",
      "         [ 0.4231,  0.0889, -0.1748,  ..., -0.6287, -0.2605, -0.7964],\n",
      "         ...,\n",
      "         [ 0.0740,  0.2039,  0.5227,  ..., -0.3911,  0.3457, -0.0500],\n",
      "         [ 0.2402, -0.0967,  0.0403,  ..., -0.4263,  0.0623, -0.3743],\n",
      "         [ 0.2773, -0.2832,  0.7327,  ..., -0.3733,  0.1086,  0.1582]],\n",
      "\n",
      "        [[ 0.3411, -0.7532,  0.3818,  ..., -0.4160,  0.1045, -0.4541],\n",
      "         [ 0.0649, -0.2349, -0.0103,  ..., -0.3154,  0.0891,  0.0852],\n",
      "         [ 0.5369,  0.2769,  0.1519,  ..., -0.5449, -0.1785, -0.6726],\n",
      "         ...,\n",
      "         [-0.0540, -0.1838,  0.5757,  ..., -0.1030,  0.3635, -0.2222],\n",
      "         [-0.2446, -0.6213, -0.2209,  ..., -0.5715, -0.1401, -0.2776],\n",
      "         [ 0.2773, -0.2832,  0.7327,  ..., -0.3733,  0.1086,  0.1582]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.3411, -0.7532,  0.3818,  ..., -0.4160,  0.1045, -0.4541],\n",
      "         [ 0.0063, -0.1287,  0.4656,  ..., -0.3665,  0.0151, -0.3303],\n",
      "         [ 0.4231,  0.0889, -0.1748,  ..., -0.6287, -0.2605, -0.7964],\n",
      "         ...,\n",
      "         [ 0.0740,  0.2039,  0.5227,  ..., -0.3911,  0.3457, -0.0500],\n",
      "         [ 0.2402, -0.0967,  0.0403,  ..., -0.4263,  0.0623, -0.3743],\n",
      "         [ 0.2773, -0.2832,  0.7327,  ..., -0.3733,  0.1086,  0.1582]],\n",
      "\n",
      "        [[ 0.3411, -0.7532,  0.3818,  ..., -0.4160,  0.1045, -0.4541],\n",
      "         [ 0.0649, -0.2349, -0.0103,  ..., -0.3154,  0.0891,  0.0852],\n",
      "         [ 0.5369,  0.2769,  0.1519,  ..., -0.5449, -0.1785, -0.6726],\n",
      "         ...,\n",
      "         [-0.0540, -0.1838,  0.5757,  ..., -0.1030,  0.3635, -0.2222],\n",
      "         [-0.2446, -0.6213, -0.2209,  ..., -0.5715, -0.1401, -0.2776],\n",
      "         [ 0.2773, -0.2832,  0.7327,  ..., -0.3733,  0.1086,  0.1582]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 0.3411, -0.7532,  0.3818,  ...,  0.2690,  0.2161,  0.0330],\n",
      "          [-0.2920,  0.2268,  0.5801,  ..., -0.4160,  0.1045, -0.4541]],\n",
      "\n",
      "         [[ 0.0063, -0.1287,  0.4656,  ..., -0.0027,  0.1118,  0.2368],\n",
      "          [ 0.0229,  0.0811,  0.3059,  ..., -0.3665,  0.0151, -0.3303]],\n",
      "\n",
      "         [[ 0.4231,  0.0889, -0.1748,  ...,  0.1443, -0.0530, -0.1326],\n",
      "          [ 0.2280,  0.0405,  0.1187,  ..., -0.6287, -0.2605, -0.7964]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0740,  0.2039,  0.5227,  ..., -0.4241,  0.6389,  0.1987],\n",
      "          [-0.0686,  0.0586,  0.2146,  ..., -0.3911,  0.3457, -0.0500]],\n",
      "\n",
      "         [[ 0.2402, -0.0967,  0.0403,  ...,  0.2317,  0.4075,  0.2734],\n",
      "          [ 0.5015, -0.0139,  0.3928,  ..., -0.4263,  0.0623, -0.3743]],\n",
      "\n",
      "         [[ 0.2773, -0.2832,  0.7327,  ..., -0.4619,  0.6072,  0.3008],\n",
      "          [-0.0837,  0.1545,  0.6450,  ..., -0.3733,  0.1086,  0.1582]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3411, -0.7532,  0.3818,  ...,  0.2690,  0.2161,  0.0330],\n",
      "          [-0.2920,  0.2268,  0.5801,  ..., -0.4160,  0.1045, -0.4541]],\n",
      "\n",
      "         [[ 0.0649, -0.2349, -0.0103,  ...,  0.3474,  0.5938, -0.1704],\n",
      "          [ 0.0828,  0.3909,  0.5522,  ..., -0.3154,  0.0891,  0.0852]],\n",
      "\n",
      "         [[ 0.5369,  0.2769,  0.1519,  ..., -0.2371,  0.2361,  0.1567],\n",
      "          [-0.0264, -0.2820, -0.1599,  ..., -0.5449, -0.1785, -0.6726]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0540, -0.1838,  0.5757,  ...,  0.0928,  1.1794, -0.0686],\n",
      "          [ 0.1348, -0.0950,  0.4700,  ..., -0.1030,  0.3635, -0.2222]],\n",
      "\n",
      "         [[-0.2446, -0.6213, -0.2209,  ...,  0.0220,  0.3821,  0.2678],\n",
      "          [ 0.1187,  0.3833,  0.6152,  ..., -0.5715, -0.1401, -0.2776]],\n",
      "\n",
      "         [[ 0.2773, -0.2832,  0.7327,  ..., -0.4619,  0.6072,  0.3008],\n",
      "          [-0.0837,  0.1545,  0.6450,  ..., -0.3733,  0.1086,  0.1582]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.2848,  0.0133,  0.2944,  ...,  0.1627, -0.2960,  0.0523],\n",
      "         [-0.0516, -0.0073, -0.1727,  ...,  0.0920, -0.6191, -0.3654],\n",
      "         [ 0.6742,  0.1142, -0.0643,  ..., -0.0606, -0.2419, -0.0149],\n",
      "         ...,\n",
      "         [ 0.3567,  0.2127,  0.2474,  ...,  0.1704, -0.1884,  0.1148],\n",
      "         [ 0.6993, -0.1791, -0.0792,  ..., -0.2351, -0.4122,  0.2759],\n",
      "         [-0.2252, -0.3539, -0.3699,  ...,  0.0477, -0.4384, -0.2319]],\n",
      "\n",
      "        [[-0.2848,  0.0133,  0.2944,  ...,  0.1627, -0.2960,  0.0523],\n",
      "         [ 0.1014, -0.1526,  0.2766,  ...,  0.1704, -0.5654, -0.3095],\n",
      "         [ 0.8153,  0.5225, -0.4410,  ...,  0.1153, -0.7423, -0.2427],\n",
      "         ...,\n",
      "         [ 0.1090, -0.1706,  0.1723,  ...,  0.2357, -0.1261, -0.3542],\n",
      "         [ 0.3857,  0.0030,  0.1033,  ...,  0.0958, -0.4121,  0.1341],\n",
      "         [-0.2252, -0.3539, -0.3699,  ...,  0.0477, -0.4384, -0.2319]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.2848,  0.0133,  0.2944,  ...,  0.1627, -0.2960,  0.0523],\n",
      "         [-0.0516, -0.0073, -0.1727,  ...,  0.0920, -0.6191, -0.3654],\n",
      "         [ 0.6742,  0.1142, -0.0643,  ..., -0.0606, -0.2419, -0.0149],\n",
      "         ...,\n",
      "         [ 0.3567,  0.2127,  0.2474,  ...,  0.1704, -0.1884,  0.1148],\n",
      "         [ 0.6993, -0.1791, -0.0792,  ..., -0.2351, -0.4122,  0.2759],\n",
      "         [-0.2252, -0.3539, -0.3699,  ...,  0.0477, -0.4384, -0.2319]],\n",
      "\n",
      "        [[-0.2848,  0.0133,  0.2944,  ...,  0.1627, -0.2960,  0.0523],\n",
      "         [ 0.1014, -0.1526,  0.2766,  ...,  0.1704, -0.5654, -0.3095],\n",
      "         [ 0.8153,  0.5225, -0.4410,  ...,  0.1153, -0.7423, -0.2427],\n",
      "         ...,\n",
      "         [ 0.1090, -0.1706,  0.1723,  ...,  0.2357, -0.1261, -0.3542],\n",
      "         [ 0.3857,  0.0030,  0.1033,  ...,  0.0958, -0.4121,  0.1341],\n",
      "         [-0.2252, -0.3539, -0.3699,  ...,  0.0477, -0.4384, -0.2319]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.2848,  0.0133,  0.2944,  ..., -0.0866,  0.2473,  0.2200],\n",
      "          [ 0.3274, -0.1107, -0.2222,  ...,  0.1627, -0.2960,  0.0523]],\n",
      "\n",
      "         [[-0.0516, -0.0073, -0.1727,  ...,  0.0962,  0.3208,  0.2101],\n",
      "          [-0.3615,  0.0756, -0.5151,  ...,  0.0920, -0.6191, -0.3654]],\n",
      "\n",
      "         [[ 0.6742,  0.1142, -0.0643,  ...,  0.8289, -0.1244, -0.5121],\n",
      "          [ 0.2243,  0.0483, -0.1498,  ..., -0.0606, -0.2419, -0.0149]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3567,  0.2127,  0.2474,  ...,  0.3345, -0.5654,  0.6881],\n",
      "          [-0.0579,  0.2528,  0.4284,  ...,  0.1704, -0.1884,  0.1148]],\n",
      "\n",
      "         [[ 0.6993, -0.1791, -0.0792,  ...,  0.7320,  0.1988,  0.0148],\n",
      "          [ 0.0798, -0.0086, -0.2200,  ..., -0.2351, -0.4122,  0.2759]],\n",
      "\n",
      "         [[-0.2252, -0.3539, -0.3699,  ...,  0.3107, -0.1830,  0.2064],\n",
      "          [-0.1287, -0.2328, -0.7505,  ...,  0.0477, -0.4384, -0.2319]]],\n",
      "\n",
      "\n",
      "        [[[-0.2848,  0.0133,  0.2944,  ..., -0.0866,  0.2473,  0.2200],\n",
      "          [ 0.3274, -0.1107, -0.2222,  ...,  0.1627, -0.2960,  0.0523]],\n",
      "\n",
      "         [[ 0.1014, -0.1526,  0.2766,  ...,  0.1503,  0.4208,  0.2120],\n",
      "          [-0.0164,  0.2578, -0.3759,  ...,  0.1704, -0.5654, -0.3095]],\n",
      "\n",
      "         [[ 0.8153,  0.5225, -0.4410,  ...,  0.7473, -0.0083, -0.1215],\n",
      "          [ 0.2113,  0.2522, -0.5443,  ...,  0.1153, -0.7423, -0.2427]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1090, -0.1706,  0.1723,  ...,  0.1552, -0.0901,  0.5992],\n",
      "          [ 0.0021, -0.2227,  0.0617,  ...,  0.2357, -0.1261, -0.3542]],\n",
      "\n",
      "         [[ 0.3857,  0.0030,  0.1033,  ...,  0.4130,  0.0457, -0.0592],\n",
      "          [ 0.0840, -0.0526, -0.3777,  ...,  0.0958, -0.4121,  0.1341]],\n",
      "\n",
      "         [[-0.2252, -0.3539, -0.3699,  ...,  0.3107, -0.1830,  0.2064],\n",
      "          [-0.1287, -0.2328, -0.7505,  ...,  0.0477, -0.4384, -0.2319]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 0.1888,  0.0703, -0.0939,  ...,  0.4341, -0.0780,  0.0546],\n",
      "          [ 0.1731,  0.0547, -0.0597,  ...,  0.3855, -0.0651,  0.1152],\n",
      "          [ 0.1699,  0.0411, -0.0461,  ...,  0.3645, -0.0604,  0.1491],\n",
      "          ...,\n",
      "          [ 0.1644,  0.0365, -0.0377,  ...,  0.3503, -0.0604,  0.1739],\n",
      "          [ 0.1568,  0.0367, -0.0446,  ...,  0.3490, -0.0542,  0.1628],\n",
      "          [ 0.1580,  0.0424, -0.0425,  ...,  0.3552, -0.0639,  0.1616]],\n",
      "\n",
      "         [[ 0.0919, -0.0055, -0.2216,  ...,  0.2363, -0.3632, -0.1791],\n",
      "          [ 0.0477,  0.0156, -0.2308,  ...,  0.1923, -0.3785, -0.1175],\n",
      "          [ 0.0280,  0.0124, -0.2394,  ...,  0.2182, -0.3893, -0.1299],\n",
      "          ...,\n",
      "          [ 0.0151,  0.0230, -0.2351,  ...,  0.2013, -0.3916, -0.1113],\n",
      "          [ 0.0270,  0.0182, -0.2377,  ...,  0.2042, -0.3903, -0.1129],\n",
      "          [ 0.0268,  0.0155, -0.2381,  ...,  0.2145, -0.3916, -0.1233]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2267,  0.0973,  0.2392,  ...,  0.0629,  0.1635,  0.2638],\n",
      "          [ 0.2166,  0.0858,  0.1707,  ...,  0.1201,  0.1264,  0.2417],\n",
      "          [ 0.2139,  0.0708,  0.1517,  ...,  0.1423,  0.1108,  0.2326],\n",
      "          ...,\n",
      "          [ 0.2170,  0.0778,  0.1218,  ...,  0.1626,  0.0968,  0.2236],\n",
      "          [ 0.2201,  0.0794,  0.1223,  ...,  0.1610,  0.0992,  0.2220],\n",
      "          [ 0.2243,  0.0850,  0.1297,  ...,  0.1575,  0.1013,  0.2262]],\n",
      "\n",
      "         [[ 0.0467, -0.1152, -0.2401,  ...,  0.4170, -0.3111, -0.2295],\n",
      "          [ 0.0352, -0.0908, -0.2657,  ...,  0.3736, -0.3391, -0.2012],\n",
      "          [ 0.0328, -0.0817, -0.2835,  ...,  0.3550, -0.3541, -0.2014],\n",
      "          ...,\n",
      "          [ 0.0304, -0.0727, -0.2836,  ...,  0.3454, -0.3632, -0.2008],\n",
      "          [ 0.0379, -0.0836, -0.2737,  ...,  0.3557, -0.3533, -0.2007],\n",
      "          [ 0.0309, -0.0843, -0.2787,  ...,  0.3537, -0.3493, -0.1970]]]],\n",
      "       grad_fn=<ScaledDotProductFlashAttentionForCpuBackward0>)\n",
      "tensor([[[[ 0.1888,  0.0703, -0.0939,  ...,  0.4341, -0.0780,  0.0546],\n",
      "          [ 0.0919, -0.0055, -0.2216,  ...,  0.2363, -0.3632, -0.1791]],\n",
      "\n",
      "         [[ 0.1731,  0.0547, -0.0597,  ...,  0.3855, -0.0651,  0.1152],\n",
      "          [ 0.0477,  0.0156, -0.2308,  ...,  0.1923, -0.3785, -0.1175]],\n",
      "\n",
      "         [[ 0.1699,  0.0411, -0.0461,  ...,  0.3645, -0.0604,  0.1491],\n",
      "          [ 0.0280,  0.0124, -0.2394,  ...,  0.2182, -0.3893, -0.1299]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1644,  0.0365, -0.0377,  ...,  0.3503, -0.0604,  0.1739],\n",
      "          [ 0.0151,  0.0230, -0.2351,  ...,  0.2013, -0.3916, -0.1113]],\n",
      "\n",
      "         [[ 0.1568,  0.0367, -0.0446,  ...,  0.3490, -0.0542,  0.1628],\n",
      "          [ 0.0270,  0.0182, -0.2377,  ...,  0.2042, -0.3903, -0.1129]],\n",
      "\n",
      "         [[ 0.1580,  0.0424, -0.0425,  ...,  0.3552, -0.0639,  0.1616],\n",
      "          [ 0.0268,  0.0155, -0.2381,  ...,  0.2145, -0.3916, -0.1233]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2267,  0.0973,  0.2392,  ...,  0.0629,  0.1635,  0.2638],\n",
      "          [ 0.0467, -0.1152, -0.2401,  ...,  0.4170, -0.3111, -0.2295]],\n",
      "\n",
      "         [[ 0.2166,  0.0858,  0.1707,  ...,  0.1201,  0.1264,  0.2417],\n",
      "          [ 0.0352, -0.0908, -0.2657,  ...,  0.3736, -0.3391, -0.2012]],\n",
      "\n",
      "         [[ 0.2139,  0.0708,  0.1517,  ...,  0.1423,  0.1108,  0.2326],\n",
      "          [ 0.0328, -0.0817, -0.2835,  ...,  0.3550, -0.3541, -0.2014]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2170,  0.0778,  0.1218,  ...,  0.1626,  0.0968,  0.2236],\n",
      "          [ 0.0304, -0.0727, -0.2836,  ...,  0.3454, -0.3632, -0.2008]],\n",
      "\n",
      "         [[ 0.2201,  0.0794,  0.1223,  ...,  0.1610,  0.0992,  0.2220],\n",
      "          [ 0.0379, -0.0836, -0.2737,  ...,  0.3557, -0.3533, -0.2007]],\n",
      "\n",
      "         [[ 0.2243,  0.0850,  0.1297,  ...,  0.1575,  0.1013,  0.2262],\n",
      "          [ 0.0309, -0.0843, -0.2787,  ...,  0.3537, -0.3493, -0.1970]]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.2965, -0.3144, -0.1336,  ..., -0.5515,  2.1020, -0.0853],\n",
      "         [ 0.3055, -1.4584,  0.5972,  ..., -1.1248, -0.1673,  0.4307],\n",
      "         [-1.1487, -1.3869,  0.9171,  ..., -0.0903,  0.7930,  0.3148],\n",
      "         ...,\n",
      "         [-1.0488,  0.0492, -0.1457,  ..., -0.6695, -1.6687,  0.1821],\n",
      "         [-1.4676, -0.4380, -0.5342,  ...,  0.3276, -0.0951, -0.2500],\n",
      "         [-1.1433, -1.4615, -0.0332,  ..., -2.2869, -0.3153, -1.1242]],\n",
      "\n",
      "        [[ 0.4589, -0.1316,  0.0194,  ..., -0.7212,  2.1792,  0.1995],\n",
      "         [ 0.3273, -2.2635,  0.4489,  ..., -0.4045,  0.8159,  0.5562],\n",
      "         [-2.3148, -0.5869,  1.7037,  ..., -0.1215,  0.0318, -1.3248],\n",
      "         ...,\n",
      "         [-0.7403,  0.6778, -0.0372,  ..., -0.2250, -1.4670,  1.3012],\n",
      "         [-0.9572, -0.6238,  0.8255,  ..., -0.6661,  0.0840,  0.0840],\n",
      "         [-1.0275, -1.3546,  0.0771,  ..., -2.4443, -0.2543, -0.9387]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.2965, -0.3144, -0.1336,  ..., -0.5515,  2.1020, -0.0853],\n",
      "         [ 0.3055, -1.4584,  0.5972,  ..., -1.1248, -0.1673,  0.4307],\n",
      "         [-1.1487, -1.3869,  0.9171,  ..., -0.0903,  0.7930,  0.3148],\n",
      "         ...,\n",
      "         [-1.0488,  0.0492, -0.1457,  ..., -0.6695, -1.6687,  0.1821],\n",
      "         [-1.4676, -0.4380, -0.5342,  ...,  0.3276, -0.0951, -0.2500],\n",
      "         [-1.1433, -1.4615, -0.0332,  ..., -2.2869, -0.3153, -1.1242]],\n",
      "\n",
      "        [[ 0.4589, -0.1316,  0.0194,  ..., -0.7212,  2.1792,  0.1995],\n",
      "         [ 0.3273, -2.2635,  0.4489,  ..., -0.4045,  0.8159,  0.5562],\n",
      "         [-2.3148, -0.5869,  1.7037,  ..., -0.1215,  0.0318, -1.3248],\n",
      "         ...,\n",
      "         [-0.7403,  0.6778, -0.0372,  ..., -0.2250, -1.4670,  1.3012],\n",
      "         [-0.9572, -0.6238,  0.8255,  ..., -0.6661,  0.0840,  0.0840],\n",
      "         [-1.0275, -1.3546,  0.0771,  ..., -2.4443, -0.2543, -0.9387]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[ 0.2965, -0.3144, -0.1336,  ..., -0.5515,  2.1020, -0.0853],\n",
      "         [ 0.3055, -1.4584,  0.5972,  ..., -1.1248, -0.1673,  0.4307],\n",
      "         [-1.1487, -1.3869,  0.9171,  ..., -0.0903,  0.7930,  0.3148],\n",
      "         ...,\n",
      "         [-1.0488,  0.0492, -0.1457,  ..., -0.6695, -1.6687,  0.1821],\n",
      "         [-1.4676, -0.4380, -0.5342,  ...,  0.3276, -0.0951, -0.2500],\n",
      "         [-1.1433, -1.4615, -0.0332,  ..., -2.2869, -0.3153, -1.1242]],\n",
      "\n",
      "        [[ 0.4589, -0.1316,  0.0194,  ..., -0.7212,  2.1792,  0.1995],\n",
      "         [ 0.3273, -2.2635,  0.4489,  ..., -0.4045,  0.8159,  0.5562],\n",
      "         [-2.3148, -0.5869,  1.7037,  ..., -0.1215,  0.0318, -1.3248],\n",
      "         ...,\n",
      "         [-0.7403,  0.6778, -0.0372,  ..., -0.2250, -1.4670,  1.3012],\n",
      "         [-0.9572, -0.6238,  0.8255,  ..., -0.6661,  0.0840,  0.0840],\n",
      "         [-1.0275, -1.3546,  0.0771,  ..., -2.4443, -0.2543, -0.9387]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[[ 0.2965, -0.3144, -0.1336,  ...,  0.3730,  0.4541,  0.5311],\n",
      "          [-0.4796,  0.2522,  1.0154,  ..., -0.5515,  2.1020, -0.0853]],\n",
      "\n",
      "         [[ 0.3055, -1.4584,  0.5972,  ..., -0.4977, -1.4432,  0.2002],\n",
      "          [-0.8983,  0.3068,  0.8379,  ..., -1.1248, -0.1673,  0.4307]],\n",
      "\n",
      "         [[-1.1487, -1.3869,  0.9171,  ..., -0.4039, -0.9157,  1.3295],\n",
      "          [-1.0111,  0.2708,  1.1939,  ..., -0.0903,  0.7930,  0.3148]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.0488,  0.0492, -0.1457,  ..., -0.3619, -0.2865, -0.2105],\n",
      "          [-1.4461,  1.8900,  1.2918,  ..., -0.6695, -1.6687,  0.1821]],\n",
      "\n",
      "         [[-1.4676, -0.4380, -0.5342,  ...,  0.0577, -1.6239,  0.0563],\n",
      "          [-0.3515,  1.2206,  1.5211,  ...,  0.3276, -0.0951, -0.2500]],\n",
      "\n",
      "         [[-1.1433, -1.4615, -0.0332,  ..., -0.5420, -0.6671, -1.4241],\n",
      "          [-1.7851,  0.5569,  0.6397,  ..., -2.2869, -0.3153, -1.1242]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4589, -0.1316,  0.0194,  ...,  0.2662,  0.6550,  0.4453],\n",
      "          [-0.5646,  0.1943,  0.8188,  ..., -0.7212,  2.1792,  0.1995]],\n",
      "\n",
      "         [[ 0.3273, -2.2635,  0.4489,  ..., -0.4586, -1.5076, -0.9967],\n",
      "          [-0.9123,  0.1471, -0.1034,  ..., -0.4045,  0.8159,  0.5562]],\n",
      "\n",
      "         [[-2.3148, -0.5869,  1.7037,  ..., -1.4093, -0.4310,  0.6948],\n",
      "          [ 0.0203, -0.4768,  1.1557,  ..., -0.1215,  0.0318, -1.3248]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.7403,  0.6778, -0.0372,  ...,  0.0411,  0.6922, -0.8735],\n",
      "          [-2.0086,  1.4971,  2.6926,  ..., -0.2250, -1.4670,  1.3012]],\n",
      "\n",
      "         [[-0.9572, -0.6238,  0.8255,  ...,  0.3552, -1.1478,  0.3682],\n",
      "          [-0.7753,  0.8552,  0.7477,  ..., -0.6661,  0.0840,  0.0840]],\n",
      "\n",
      "         [[-1.0275, -1.3546,  0.0771,  ..., -0.6231, -0.5347, -1.4864],\n",
      "          [-1.8713,  0.5198,  0.4933,  ..., -2.4443, -0.2543, -0.9387]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.3306, -0.7109,  0.3804,  ..., -0.0812, -0.8347,  0.1535],\n",
      "          [-0.3306, -0.7109,  0.3804,  ..., -0.0812, -0.8347,  0.1535],\n",
      "          [-0.3306, -0.7109,  0.3804,  ..., -0.0812, -0.8347,  0.1535],\n",
      "          ...,\n",
      "          [-0.3306, -0.7109,  0.3804,  ..., -0.0812, -0.8347,  0.1535],\n",
      "          [-0.3306, -0.7109,  0.3804,  ..., -0.0812, -0.8347,  0.1535],\n",
      "          [-0.3306, -0.7109,  0.3804,  ..., -0.0812, -0.8347,  0.1535]],\n",
      "\n",
      "         [[-0.7417,  0.3805,  0.8759,  ..., -0.7301,  0.2226,  0.0429],\n",
      "          [-0.7417,  0.3805,  0.8759,  ..., -0.7301,  0.2226,  0.0429],\n",
      "          [-0.7417,  0.3805,  0.8759,  ..., -0.7301,  0.2226,  0.0429],\n",
      "          ...,\n",
      "          [-0.7417,  0.3805,  0.8759,  ..., -0.7301,  0.2226,  0.0429],\n",
      "          [-0.7417,  0.3805,  0.8759,  ..., -0.7301,  0.2226,  0.0429],\n",
      "          [-0.7417,  0.3805,  0.8759,  ..., -0.7301,  0.2226,  0.0429]]],\n",
      "\n",
      "\n",
      "        [[[-0.2133, -0.5767,  0.5929,  ..., -0.2661, -0.5832,  0.0088],\n",
      "          [-0.2133, -0.5767,  0.5929,  ..., -0.2661, -0.5832,  0.0088],\n",
      "          [-0.2133, -0.5767,  0.5929,  ..., -0.2661, -0.5832,  0.0088],\n",
      "          ...,\n",
      "          [-0.2133, -0.5767,  0.5929,  ..., -0.2661, -0.5832,  0.0088],\n",
      "          [-0.2133, -0.5767,  0.5929,  ..., -0.2661, -0.5832,  0.0088],\n",
      "          [-0.2133, -0.5767,  0.5929,  ..., -0.2661, -0.5832,  0.0088]],\n",
      "\n",
      "         [[-0.9389,  0.8556,  1.0682,  ..., -0.7085,  0.1527, -0.0298],\n",
      "          [-0.9389,  0.8556,  1.0682,  ..., -0.7085,  0.1527, -0.0298],\n",
      "          [-0.9389,  0.8556,  1.0682,  ..., -0.7085,  0.1527, -0.0298],\n",
      "          ...,\n",
      "          [-0.9389,  0.8556,  1.0682,  ..., -0.7085,  0.1527, -0.0298],\n",
      "          [-0.9389,  0.8556,  1.0682,  ..., -0.7085,  0.1527, -0.0298],\n",
      "          [-0.9389,  0.8556,  1.0682,  ..., -0.7085,  0.1527, -0.0298]]]],\n",
      "       grad_fn=<ScaledDotProductFlashAttentionForCpuBackward0>)\n",
      "tensor([[[[-0.3306, -0.7109,  0.3804,  ..., -0.0812, -0.8347,  0.1535],\n",
      "          [-0.7417,  0.3805,  0.8759,  ..., -0.7301,  0.2226,  0.0429]],\n",
      "\n",
      "         [[-0.3306, -0.7109,  0.3804,  ..., -0.0812, -0.8347,  0.1535],\n",
      "          [-0.7417,  0.3805,  0.8759,  ..., -0.7301,  0.2226,  0.0429]],\n",
      "\n",
      "         [[-0.3306, -0.7109,  0.3804,  ..., -0.0812, -0.8347,  0.1535],\n",
      "          [-0.7417,  0.3805,  0.8759,  ..., -0.7301,  0.2226,  0.0429]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3306, -0.7109,  0.3804,  ..., -0.0812, -0.8347,  0.1535],\n",
      "          [-0.7417,  0.3805,  0.8759,  ..., -0.7301,  0.2226,  0.0429]],\n",
      "\n",
      "         [[-0.3306, -0.7109,  0.3804,  ..., -0.0812, -0.8347,  0.1535],\n",
      "          [-0.7417,  0.3805,  0.8759,  ..., -0.7301,  0.2226,  0.0429]],\n",
      "\n",
      "         [[-0.3306, -0.7109,  0.3804,  ..., -0.0812, -0.8347,  0.1535],\n",
      "          [-0.7417,  0.3805,  0.8759,  ..., -0.7301,  0.2226,  0.0429]]],\n",
      "\n",
      "\n",
      "        [[[-0.2133, -0.5767,  0.5929,  ..., -0.2661, -0.5832,  0.0088],\n",
      "          [-0.9389,  0.8556,  1.0682,  ..., -0.7085,  0.1527, -0.0298]],\n",
      "\n",
      "         [[-0.2133, -0.5767,  0.5929,  ..., -0.2661, -0.5832,  0.0088],\n",
      "          [-0.9389,  0.8556,  1.0682,  ..., -0.7085,  0.1527, -0.0298]],\n",
      "\n",
      "         [[-0.2133, -0.5767,  0.5929,  ..., -0.2661, -0.5832,  0.0088],\n",
      "          [-0.9389,  0.8556,  1.0682,  ..., -0.7085,  0.1527, -0.0298]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2133, -0.5767,  0.5929,  ..., -0.2661, -0.5832,  0.0088],\n",
      "          [-0.9389,  0.8556,  1.0682,  ..., -0.7085,  0.1527, -0.0298]],\n",
      "\n",
      "         [[-0.2133, -0.5767,  0.5929,  ..., -0.2661, -0.5832,  0.0088],\n",
      "          [-0.9389,  0.8556,  1.0682,  ..., -0.7085,  0.1527, -0.0298]],\n",
      "\n",
      "         [[-0.2133, -0.5767,  0.5929,  ..., -0.2661, -0.5832,  0.0088],\n",
      "          [-0.9389,  0.8556,  1.0682,  ..., -0.7085,  0.1527, -0.0298]]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[-1.0854,  0.7831],\n",
      "        [-0.4505,  0.2014]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: classifier\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
      "\n",
      "\n",
      "        [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]])\n",
      "tensor([[[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
      "\n",
      "\n",
      "        [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]])\n",
      "tensor([[[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]])\n",
      "tensor([[[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]])\n",
      "tensor([[[ 0.4399, -0.1289, -0.0193,  ..., -0.7220,  2.1669,  0.2116],\n",
      "         [ 0.4737, -1.2851,  0.7269,  ..., -1.3262, -0.0807,  0.7324],\n",
      "         [-1.0127, -1.2385,  1.0493,  ..., -0.2675,  0.9101,  0.6033],\n",
      "         ...,\n",
      "         [-0.8877,  0.2255, -0.0285,  ..., -0.8598, -1.6034,  0.4798],\n",
      "         [-1.3354, -0.2770, -0.4315,  ...,  0.1540, -0.0039,  0.0438],\n",
      "         [-0.9938, -1.2972,  0.0781,  ..., -2.4799, -0.2318, -0.8143]],\n",
      "\n",
      "        [[ 0.4399, -0.1289, -0.0193,  ..., -0.7220,  2.1669,  0.2116],\n",
      "         [ 0.3325, -2.1907,  0.4309,  ..., -0.4327,  0.8238,  0.6018],\n",
      "         [-2.2631, -0.5424,  1.6860,  ..., -0.1677,  0.0543, -1.1901],\n",
      "         ...,\n",
      "         [-0.6945,  0.7086, -0.0305,  ..., -0.2801, -1.4319,  1.3509],\n",
      "         [-0.9197, -0.5727,  0.8206,  ..., -0.7162,  0.1093,  0.1793],\n",
      "         [-0.9938, -1.2972,  0.0781,  ..., -2.4799, -0.2318, -0.8143]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[ 0.5355, -0.0675, -0.2999,  ...,  1.0623, -1.5882, -0.4372],\n",
      "         [ 0.0714, -0.1049, -0.6291,  ...,  0.3066, -1.2606, -0.1896],\n",
      "         [ 0.4521, -0.2345, -0.2281,  ...,  0.4841, -0.8775, -0.4523],\n",
      "         ...,\n",
      "         [ 0.1751,  0.3563, -0.3652,  ...,  0.5923, -0.7895, -0.6227],\n",
      "         [ 0.2784, -0.2019,  0.0694,  ...,  0.3389, -1.0946, -0.6864],\n",
      "         [ 0.2996, -0.0439, -0.7518,  ...,  0.3756, -0.8931, -0.4892]],\n",
      "\n",
      "        [[ 0.5355, -0.0675, -0.2999,  ...,  1.0623, -1.5882, -0.4372],\n",
      "         [ 0.0419, -0.1495, -0.2300,  ...,  0.4913, -1.2540, -0.3115],\n",
      "         [ 0.6684, -0.1476, -0.5027,  ...,  0.3221, -1.2428, -0.4057],\n",
      "         ...,\n",
      "         [ 0.4988,  0.1559, -0.2923,  ...,  0.6583, -0.7896, -0.5446],\n",
      "         [ 0.0049, -0.3911, -0.1698,  ...,  0.3138, -1.1344, -0.8804],\n",
      "         [ 0.2996, -0.0439, -0.7518,  ...,  0.3756, -0.8931, -0.4892]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.5355, -0.0675, -0.2999,  ...,  1.0623, -1.5882, -0.4372],\n",
      "         [ 0.0714, -0.1049, -0.6291,  ...,  0.3066, -1.2606, -0.1896],\n",
      "         [ 0.4521, -0.2345, -0.2281,  ...,  0.4841, -0.8775, -0.4523],\n",
      "         ...,\n",
      "         [ 0.1751,  0.3563, -0.3652,  ...,  0.5923, -0.7895, -0.6227],\n",
      "         [ 0.2784, -0.2019,  0.0694,  ...,  0.3389, -1.0946, -0.6864],\n",
      "         [ 0.2996, -0.0439, -0.7518,  ...,  0.3756, -0.8931, -0.4892]],\n",
      "\n",
      "        [[ 0.5355, -0.0675, -0.2999,  ...,  1.0623, -1.5882, -0.4372],\n",
      "         [ 0.0419, -0.1495, -0.2300,  ...,  0.4913, -1.2540, -0.3115],\n",
      "         [ 0.6684, -0.1476, -0.5027,  ...,  0.3221, -1.2428, -0.4057],\n",
      "         ...,\n",
      "         [ 0.4988,  0.1559, -0.2923,  ...,  0.6583, -0.7896, -0.5446],\n",
      "         [ 0.0049, -0.3911, -0.1698,  ...,  0.3138, -1.1344, -0.8804],\n",
      "         [ 0.2996, -0.0439, -0.7518,  ...,  0.3756, -0.8931, -0.4892]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 0.5355, -0.0675, -0.2999,  ...,  0.8728, -0.7396, -0.7421],\n",
      "          [ 1.1956, -0.1778, -0.9047,  ...,  1.0623, -1.5882, -0.4372]],\n",
      "\n",
      "         [[ 0.0714, -0.1049, -0.6291,  ...,  0.7638, -0.4328, -0.4335],\n",
      "          [ 0.4737, -0.0795, -0.4281,  ...,  0.3066, -1.2606, -0.1896]],\n",
      "\n",
      "         [[ 0.4521, -0.2345, -0.2281,  ...,  0.5133, -0.1947, -0.6254],\n",
      "          [-0.0835,  0.0678,  0.0493,  ...,  0.4841, -0.8775, -0.4523]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1751,  0.3563, -0.3652,  ...,  0.3062, -0.1877, -0.2744],\n",
      "          [ 0.2485, -0.0350, -0.0193,  ...,  0.5923, -0.7895, -0.6227]],\n",
      "\n",
      "         [[ 0.2784, -0.2019,  0.0694,  ...,  0.3501, -0.2056, -0.5703],\n",
      "          [ 0.3718, -0.0893, -0.2088,  ...,  0.3389, -1.0946, -0.6864]],\n",
      "\n",
      "         [[ 0.2996, -0.0439, -0.7518,  ...,  0.3823, -0.2261, -0.1500],\n",
      "          [ 0.5887, -0.8339, -0.2265,  ...,  0.3756, -0.8931, -0.4892]]],\n",
      "\n",
      "\n",
      "        [[[ 0.5355, -0.0675, -0.2999,  ...,  0.8728, -0.7396, -0.7421],\n",
      "          [ 1.1956, -0.1778, -0.9047,  ...,  1.0623, -1.5882, -0.4372]],\n",
      "\n",
      "         [[ 0.0419, -0.1495, -0.2300,  ...,  1.0737, -0.3505, -0.5324],\n",
      "          [ 0.4068,  0.0290, -0.6251,  ...,  0.4913, -1.2540, -0.3115]],\n",
      "\n",
      "         [[ 0.6684, -0.1476, -0.5027,  ...,  0.4181, -0.5559, -0.3499],\n",
      "          [ 0.0225,  0.0707, -0.2040,  ...,  0.3221, -1.2428, -0.4057]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4988,  0.1559, -0.2923,  ...,  0.3894, -0.2367, -0.1727],\n",
      "          [ 0.1865, -0.0686, -0.0321,  ...,  0.6583, -0.7896, -0.5446]],\n",
      "\n",
      "         [[ 0.0049, -0.3911, -0.1698,  ...,  0.1592, -0.3604, -0.4732],\n",
      "          [ 0.4345, -0.0262, -0.4430,  ...,  0.3138, -1.1344, -0.8804]],\n",
      "\n",
      "         [[ 0.2996, -0.0439, -0.7518,  ...,  0.3823, -0.2261, -0.1500],\n",
      "          [ 0.5887, -0.8339, -0.2265,  ...,  0.3756, -0.8931, -0.4892]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.3411, -0.7532,  0.3818,  ..., -0.4160,  0.1045, -0.4541],\n",
      "         [ 0.0063, -0.1287,  0.4656,  ..., -0.3665,  0.0151, -0.3303],\n",
      "         [ 0.4231,  0.0889, -0.1748,  ..., -0.6287, -0.2605, -0.7964],\n",
      "         ...,\n",
      "         [ 0.0740,  0.2039,  0.5227,  ..., -0.3911,  0.3457, -0.0500],\n",
      "         [ 0.2402, -0.0967,  0.0403,  ..., -0.4263,  0.0623, -0.3743],\n",
      "         [ 0.2773, -0.2832,  0.7327,  ..., -0.3733,  0.1086,  0.1582]],\n",
      "\n",
      "        [[ 0.3411, -0.7532,  0.3818,  ..., -0.4160,  0.1045, -0.4541],\n",
      "         [ 0.0649, -0.2349, -0.0103,  ..., -0.3154,  0.0891,  0.0852],\n",
      "         [ 0.5369,  0.2769,  0.1519,  ..., -0.5449, -0.1785, -0.6726],\n",
      "         ...,\n",
      "         [-0.0540, -0.1838,  0.5757,  ..., -0.1030,  0.3635, -0.2222],\n",
      "         [-0.2446, -0.6213, -0.2209,  ..., -0.5715, -0.1401, -0.2776],\n",
      "         [ 0.2773, -0.2832,  0.7327,  ..., -0.3733,  0.1086,  0.1582]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.3411, -0.7532,  0.3818,  ..., -0.4160,  0.1045, -0.4541],\n",
      "         [ 0.0063, -0.1287,  0.4656,  ..., -0.3665,  0.0151, -0.3303],\n",
      "         [ 0.4231,  0.0889, -0.1748,  ..., -0.6287, -0.2605, -0.7964],\n",
      "         ...,\n",
      "         [ 0.0740,  0.2039,  0.5227,  ..., -0.3911,  0.3457, -0.0500],\n",
      "         [ 0.2402, -0.0967,  0.0403,  ..., -0.4263,  0.0623, -0.3743],\n",
      "         [ 0.2773, -0.2832,  0.7327,  ..., -0.3733,  0.1086,  0.1582]],\n",
      "\n",
      "        [[ 0.3411, -0.7532,  0.3818,  ..., -0.4160,  0.1045, -0.4541],\n",
      "         [ 0.0649, -0.2349, -0.0103,  ..., -0.3154,  0.0891,  0.0852],\n",
      "         [ 0.5369,  0.2769,  0.1519,  ..., -0.5449, -0.1785, -0.6726],\n",
      "         ...,\n",
      "         [-0.0540, -0.1838,  0.5757,  ..., -0.1030,  0.3635, -0.2222],\n",
      "         [-0.2446, -0.6213, -0.2209,  ..., -0.5715, -0.1401, -0.2776],\n",
      "         [ 0.2773, -0.2832,  0.7327,  ..., -0.3733,  0.1086,  0.1582]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 0.3411, -0.7532,  0.3818,  ...,  0.2690,  0.2161,  0.0330],\n",
      "          [-0.2920,  0.2268,  0.5801,  ..., -0.4160,  0.1045, -0.4541]],\n",
      "\n",
      "         [[ 0.0063, -0.1287,  0.4656,  ..., -0.0027,  0.1118,  0.2368],\n",
      "          [ 0.0229,  0.0811,  0.3059,  ..., -0.3665,  0.0151, -0.3303]],\n",
      "\n",
      "         [[ 0.4231,  0.0889, -0.1748,  ...,  0.1443, -0.0530, -0.1326],\n",
      "          [ 0.2280,  0.0405,  0.1187,  ..., -0.6287, -0.2605, -0.7964]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0740,  0.2039,  0.5227,  ..., -0.4241,  0.6389,  0.1987],\n",
      "          [-0.0686,  0.0586,  0.2146,  ..., -0.3911,  0.3457, -0.0500]],\n",
      "\n",
      "         [[ 0.2402, -0.0967,  0.0403,  ...,  0.2317,  0.4075,  0.2734],\n",
      "          [ 0.5015, -0.0139,  0.3928,  ..., -0.4263,  0.0623, -0.3743]],\n",
      "\n",
      "         [[ 0.2773, -0.2832,  0.7327,  ..., -0.4619,  0.6072,  0.3008],\n",
      "          [-0.0837,  0.1545,  0.6450,  ..., -0.3733,  0.1086,  0.1582]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3411, -0.7532,  0.3818,  ...,  0.2690,  0.2161,  0.0330],\n",
      "          [-0.2920,  0.2268,  0.5801,  ..., -0.4160,  0.1045, -0.4541]],\n",
      "\n",
      "         [[ 0.0649, -0.2349, -0.0103,  ...,  0.3474,  0.5938, -0.1704],\n",
      "          [ 0.0828,  0.3909,  0.5522,  ..., -0.3154,  0.0891,  0.0852]],\n",
      "\n",
      "         [[ 0.5369,  0.2769,  0.1519,  ..., -0.2371,  0.2361,  0.1567],\n",
      "          [-0.0264, -0.2820, -0.1599,  ..., -0.5449, -0.1785, -0.6726]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0540, -0.1838,  0.5757,  ...,  0.0928,  1.1794, -0.0686],\n",
      "          [ 0.1348, -0.0950,  0.4700,  ..., -0.1030,  0.3635, -0.2222]],\n",
      "\n",
      "         [[-0.2446, -0.6213, -0.2209,  ...,  0.0220,  0.3821,  0.2678],\n",
      "          [ 0.1187,  0.3833,  0.6152,  ..., -0.5715, -0.1401, -0.2776]],\n",
      "\n",
      "         [[ 0.2773, -0.2832,  0.7327,  ..., -0.4619,  0.6072,  0.3008],\n",
      "          [-0.0837,  0.1545,  0.6450,  ..., -0.3733,  0.1086,  0.1582]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.2848,  0.0133,  0.2944,  ...,  0.1627, -0.2960,  0.0523],\n",
      "         [-0.0516, -0.0073, -0.1727,  ...,  0.0920, -0.6191, -0.3654],\n",
      "         [ 0.6742,  0.1142, -0.0643,  ..., -0.0606, -0.2419, -0.0149],\n",
      "         ...,\n",
      "         [ 0.3567,  0.2127,  0.2474,  ...,  0.1704, -0.1884,  0.1148],\n",
      "         [ 0.6993, -0.1791, -0.0792,  ..., -0.2351, -0.4122,  0.2759],\n",
      "         [-0.2252, -0.3539, -0.3699,  ...,  0.0477, -0.4384, -0.2319]],\n",
      "\n",
      "        [[-0.2848,  0.0133,  0.2944,  ...,  0.1627, -0.2960,  0.0523],\n",
      "         [ 0.1014, -0.1526,  0.2766,  ...,  0.1704, -0.5654, -0.3095],\n",
      "         [ 0.8153,  0.5225, -0.4410,  ...,  0.1153, -0.7423, -0.2427],\n",
      "         ...,\n",
      "         [ 0.1090, -0.1706,  0.1723,  ...,  0.2357, -0.1261, -0.3542],\n",
      "         [ 0.3857,  0.0030,  0.1033,  ...,  0.0958, -0.4121,  0.1341],\n",
      "         [-0.2252, -0.3539, -0.3699,  ...,  0.0477, -0.4384, -0.2319]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.2848,  0.0133,  0.2944,  ...,  0.1627, -0.2960,  0.0523],\n",
      "         [-0.0516, -0.0073, -0.1727,  ...,  0.0920, -0.6191, -0.3654],\n",
      "         [ 0.6742,  0.1142, -0.0643,  ..., -0.0606, -0.2419, -0.0149],\n",
      "         ...,\n",
      "         [ 0.3567,  0.2127,  0.2474,  ...,  0.1704, -0.1884,  0.1148],\n",
      "         [ 0.6993, -0.1791, -0.0792,  ..., -0.2351, -0.4122,  0.2759],\n",
      "         [-0.2252, -0.3539, -0.3699,  ...,  0.0477, -0.4384, -0.2319]],\n",
      "\n",
      "        [[-0.2848,  0.0133,  0.2944,  ...,  0.1627, -0.2960,  0.0523],\n",
      "         [ 0.1014, -0.1526,  0.2766,  ...,  0.1704, -0.5654, -0.3095],\n",
      "         [ 0.8153,  0.5225, -0.4410,  ...,  0.1153, -0.7423, -0.2427],\n",
      "         ...,\n",
      "         [ 0.1090, -0.1706,  0.1723,  ...,  0.2357, -0.1261, -0.3542],\n",
      "         [ 0.3857,  0.0030,  0.1033,  ...,  0.0958, -0.4121,  0.1341],\n",
      "         [-0.2252, -0.3539, -0.3699,  ...,  0.0477, -0.4384, -0.2319]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.2848,  0.0133,  0.2944,  ..., -0.0866,  0.2473,  0.2200],\n",
      "          [ 0.3274, -0.1107, -0.2222,  ...,  0.1627, -0.2960,  0.0523]],\n",
      "\n",
      "         [[-0.0516, -0.0073, -0.1727,  ...,  0.0962,  0.3208,  0.2101],\n",
      "          [-0.3615,  0.0756, -0.5151,  ...,  0.0920, -0.6191, -0.3654]],\n",
      "\n",
      "         [[ 0.6742,  0.1142, -0.0643,  ...,  0.8289, -0.1244, -0.5121],\n",
      "          [ 0.2243,  0.0483, -0.1498,  ..., -0.0606, -0.2419, -0.0149]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3567,  0.2127,  0.2474,  ...,  0.3345, -0.5654,  0.6881],\n",
      "          [-0.0579,  0.2528,  0.4284,  ...,  0.1704, -0.1884,  0.1148]],\n",
      "\n",
      "         [[ 0.6993, -0.1791, -0.0792,  ...,  0.7320,  0.1988,  0.0148],\n",
      "          [ 0.0798, -0.0086, -0.2200,  ..., -0.2351, -0.4122,  0.2759]],\n",
      "\n",
      "         [[-0.2252, -0.3539, -0.3699,  ...,  0.3107, -0.1830,  0.2064],\n",
      "          [-0.1287, -0.2328, -0.7505,  ...,  0.0477, -0.4384, -0.2319]]],\n",
      "\n",
      "\n",
      "        [[[-0.2848,  0.0133,  0.2944,  ..., -0.0866,  0.2473,  0.2200],\n",
      "          [ 0.3274, -0.1107, -0.2222,  ...,  0.1627, -0.2960,  0.0523]],\n",
      "\n",
      "         [[ 0.1014, -0.1526,  0.2766,  ...,  0.1503,  0.4208,  0.2120],\n",
      "          [-0.0164,  0.2578, -0.3759,  ...,  0.1704, -0.5654, -0.3095]],\n",
      "\n",
      "         [[ 0.8153,  0.5225, -0.4410,  ...,  0.7473, -0.0083, -0.1215],\n",
      "          [ 0.2113,  0.2522, -0.5443,  ...,  0.1153, -0.7423, -0.2427]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1090, -0.1706,  0.1723,  ...,  0.1552, -0.0901,  0.5992],\n",
      "          [ 0.0021, -0.2227,  0.0617,  ...,  0.2357, -0.1261, -0.3542]],\n",
      "\n",
      "         [[ 0.3857,  0.0030,  0.1033,  ...,  0.4130,  0.0457, -0.0592],\n",
      "          [ 0.0840, -0.0526, -0.3777,  ...,  0.0958, -0.4121,  0.1341]],\n",
      "\n",
      "         [[-0.2252, -0.3539, -0.3699,  ...,  0.3107, -0.1830,  0.2064],\n",
      "          [-0.1287, -0.2328, -0.7505,  ...,  0.0477, -0.4384, -0.2319]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 0.1888,  0.0703, -0.0939,  ...,  0.4341, -0.0780,  0.0546],\n",
      "          [ 0.1731,  0.0547, -0.0597,  ...,  0.3855, -0.0651,  0.1152],\n",
      "          [ 0.1699,  0.0411, -0.0461,  ...,  0.3645, -0.0604,  0.1491],\n",
      "          ...,\n",
      "          [ 0.1644,  0.0365, -0.0377,  ...,  0.3503, -0.0604,  0.1739],\n",
      "          [ 0.1568,  0.0367, -0.0446,  ...,  0.3490, -0.0542,  0.1628],\n",
      "          [ 0.1580,  0.0424, -0.0425,  ...,  0.3552, -0.0639,  0.1616]],\n",
      "\n",
      "         [[ 0.0919, -0.0055, -0.2216,  ...,  0.2363, -0.3632, -0.1791],\n",
      "          [ 0.0477,  0.0156, -0.2308,  ...,  0.1923, -0.3785, -0.1175],\n",
      "          [ 0.0280,  0.0124, -0.2394,  ...,  0.2182, -0.3893, -0.1299],\n",
      "          ...,\n",
      "          [ 0.0151,  0.0230, -0.2351,  ...,  0.2013, -0.3916, -0.1113],\n",
      "          [ 0.0270,  0.0182, -0.2377,  ...,  0.2042, -0.3903, -0.1129],\n",
      "          [ 0.0268,  0.0155, -0.2381,  ...,  0.2145, -0.3916, -0.1233]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2267,  0.0973,  0.2392,  ...,  0.0629,  0.1635,  0.2638],\n",
      "          [ 0.2166,  0.0858,  0.1707,  ...,  0.1201,  0.1264,  0.2417],\n",
      "          [ 0.2139,  0.0708,  0.1517,  ...,  0.1423,  0.1108,  0.2326],\n",
      "          ...,\n",
      "          [ 0.2170,  0.0778,  0.1218,  ...,  0.1626,  0.0968,  0.2236],\n",
      "          [ 0.2201,  0.0794,  0.1223,  ...,  0.1610,  0.0992,  0.2220],\n",
      "          [ 0.2243,  0.0850,  0.1297,  ...,  0.1575,  0.1013,  0.2262]],\n",
      "\n",
      "         [[ 0.0467, -0.1152, -0.2401,  ...,  0.4170, -0.3111, -0.2295],\n",
      "          [ 0.0352, -0.0908, -0.2657,  ...,  0.3736, -0.3391, -0.2012],\n",
      "          [ 0.0328, -0.0817, -0.2835,  ...,  0.3550, -0.3541, -0.2014],\n",
      "          ...,\n",
      "          [ 0.0304, -0.0727, -0.2836,  ...,  0.3454, -0.3632, -0.2008],\n",
      "          [ 0.0379, -0.0836, -0.2737,  ...,  0.3557, -0.3533, -0.2007],\n",
      "          [ 0.0309, -0.0843, -0.2787,  ...,  0.3537, -0.3493, -0.1970]]]],\n",
      "       grad_fn=<ScaledDotProductFlashAttentionForCpuBackward0>)\n",
      "tensor([[[[ 0.1888,  0.0703, -0.0939,  ...,  0.4341, -0.0780,  0.0546],\n",
      "          [ 0.0919, -0.0055, -0.2216,  ...,  0.2363, -0.3632, -0.1791]],\n",
      "\n",
      "         [[ 0.1731,  0.0547, -0.0597,  ...,  0.3855, -0.0651,  0.1152],\n",
      "          [ 0.0477,  0.0156, -0.2308,  ...,  0.1923, -0.3785, -0.1175]],\n",
      "\n",
      "         [[ 0.1699,  0.0411, -0.0461,  ...,  0.3645, -0.0604,  0.1491],\n",
      "          [ 0.0280,  0.0124, -0.2394,  ...,  0.2182, -0.3893, -0.1299]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1644,  0.0365, -0.0377,  ...,  0.3503, -0.0604,  0.1739],\n",
      "          [ 0.0151,  0.0230, -0.2351,  ...,  0.2013, -0.3916, -0.1113]],\n",
      "\n",
      "         [[ 0.1568,  0.0367, -0.0446,  ...,  0.3490, -0.0542,  0.1628],\n",
      "          [ 0.0270,  0.0182, -0.2377,  ...,  0.2042, -0.3903, -0.1129]],\n",
      "\n",
      "         [[ 0.1580,  0.0424, -0.0425,  ...,  0.3552, -0.0639,  0.1616],\n",
      "          [ 0.0268,  0.0155, -0.2381,  ...,  0.2145, -0.3916, -0.1233]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2267,  0.0973,  0.2392,  ...,  0.0629,  0.1635,  0.2638],\n",
      "          [ 0.0467, -0.1152, -0.2401,  ...,  0.4170, -0.3111, -0.2295]],\n",
      "\n",
      "         [[ 0.2166,  0.0858,  0.1707,  ...,  0.1201,  0.1264,  0.2417],\n",
      "          [ 0.0352, -0.0908, -0.2657,  ...,  0.3736, -0.3391, -0.2012]],\n",
      "\n",
      "         [[ 0.2139,  0.0708,  0.1517,  ...,  0.1423,  0.1108,  0.2326],\n",
      "          [ 0.0328, -0.0817, -0.2835,  ...,  0.3550, -0.3541, -0.2014]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2170,  0.0778,  0.1218,  ...,  0.1626,  0.0968,  0.2236],\n",
      "          [ 0.0304, -0.0727, -0.2836,  ...,  0.3454, -0.3632, -0.2008]],\n",
      "\n",
      "         [[ 0.2201,  0.0794,  0.1223,  ...,  0.1610,  0.0992,  0.2220],\n",
      "          [ 0.0379, -0.0836, -0.2737,  ...,  0.3557, -0.3533, -0.2007]],\n",
      "\n",
      "         [[ 0.2243,  0.0850,  0.1297,  ...,  0.1575,  0.1013,  0.2262],\n",
      "          [ 0.0309, -0.0843, -0.2787,  ...,  0.3537, -0.3493, -0.1970]]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.2965, -0.3144, -0.1336,  ..., -0.5515,  2.1020, -0.0853],\n",
      "         [ 0.3055, -1.4584,  0.5972,  ..., -1.1248, -0.1673,  0.4307],\n",
      "         [-1.1487, -1.3869,  0.9171,  ..., -0.0903,  0.7930,  0.3148],\n",
      "         ...,\n",
      "         [-1.0488,  0.0492, -0.1457,  ..., -0.6695, -1.6687,  0.1821],\n",
      "         [-1.4676, -0.4380, -0.5342,  ...,  0.3276, -0.0951, -0.2500],\n",
      "         [-1.1433, -1.4615, -0.0332,  ..., -2.2869, -0.3153, -1.1242]],\n",
      "\n",
      "        [[ 0.4589, -0.1316,  0.0194,  ..., -0.7212,  2.1792,  0.1995],\n",
      "         [ 0.3273, -2.2635,  0.4489,  ..., -0.4045,  0.8159,  0.5562],\n",
      "         [-2.3148, -0.5869,  1.7037,  ..., -0.1215,  0.0318, -1.3248],\n",
      "         ...,\n",
      "         [-0.7403,  0.6778, -0.0372,  ..., -0.2250, -1.4670,  1.3012],\n",
      "         [-0.9572, -0.6238,  0.8255,  ..., -0.6661,  0.0840,  0.0840],\n",
      "         [-1.0275, -1.3546,  0.0771,  ..., -2.4443, -0.2543, -0.9387]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.2965, -0.3144, -0.1336,  ..., -0.5515,  2.1020, -0.0853],\n",
      "         [ 0.3055, -1.4584,  0.5972,  ..., -1.1248, -0.1673,  0.4307],\n",
      "         [-1.1487, -1.3869,  0.9171,  ..., -0.0903,  0.7930,  0.3148],\n",
      "         ...,\n",
      "         [-1.0488,  0.0492, -0.1457,  ..., -0.6695, -1.6687,  0.1821],\n",
      "         [-1.4676, -0.4380, -0.5342,  ...,  0.3276, -0.0951, -0.2500],\n",
      "         [-1.1433, -1.4615, -0.0332,  ..., -2.2869, -0.3153, -1.1242]],\n",
      "\n",
      "        [[ 0.4589, -0.1316,  0.0194,  ..., -0.7212,  2.1792,  0.1995],\n",
      "         [ 0.3273, -2.2635,  0.4489,  ..., -0.4045,  0.8159,  0.5562],\n",
      "         [-2.3148, -0.5869,  1.7037,  ..., -0.1215,  0.0318, -1.3248],\n",
      "         ...,\n",
      "         [-0.7403,  0.6778, -0.0372,  ..., -0.2250, -1.4670,  1.3012],\n",
      "         [-0.9572, -0.6238,  0.8255,  ..., -0.6661,  0.0840,  0.0840],\n",
      "         [-1.0275, -1.3546,  0.0771,  ..., -2.4443, -0.2543, -0.9387]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[ 0.2965, -0.3144, -0.1336,  ..., -0.5515,  2.1020, -0.0853],\n",
      "         [ 0.3055, -1.4584,  0.5972,  ..., -1.1248, -0.1673,  0.4307],\n",
      "         [-1.1487, -1.3869,  0.9171,  ..., -0.0903,  0.7930,  0.3148],\n",
      "         ...,\n",
      "         [-1.0488,  0.0492, -0.1457,  ..., -0.6695, -1.6687,  0.1821],\n",
      "         [-1.4676, -0.4380, -0.5342,  ...,  0.3276, -0.0951, -0.2500],\n",
      "         [-1.1433, -1.4615, -0.0332,  ..., -2.2869, -0.3153, -1.1242]],\n",
      "\n",
      "        [[ 0.4589, -0.1316,  0.0194,  ..., -0.7212,  2.1792,  0.1995],\n",
      "         [ 0.3273, -2.2635,  0.4489,  ..., -0.4045,  0.8159,  0.5562],\n",
      "         [-2.3148, -0.5869,  1.7037,  ..., -0.1215,  0.0318, -1.3248],\n",
      "         ...,\n",
      "         [-0.7403,  0.6778, -0.0372,  ..., -0.2250, -1.4670,  1.3012],\n",
      "         [-0.9572, -0.6238,  0.8255,  ..., -0.6661,  0.0840,  0.0840],\n",
      "         [-1.0275, -1.3546,  0.0771,  ..., -2.4443, -0.2543, -0.9387]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[[ 0.2965, -0.3144, -0.1336,  ...,  0.3730,  0.4541,  0.5311],\n",
      "          [-0.4796,  0.2522,  1.0154,  ..., -0.5515,  2.1020, -0.0853]],\n",
      "\n",
      "         [[ 0.3055, -1.4584,  0.5972,  ..., -0.4977, -1.4432,  0.2002],\n",
      "          [-0.8983,  0.3068,  0.8379,  ..., -1.1248, -0.1673,  0.4307]],\n",
      "\n",
      "         [[-1.1487, -1.3869,  0.9171,  ..., -0.4039, -0.9157,  1.3295],\n",
      "          [-1.0111,  0.2708,  1.1939,  ..., -0.0903,  0.7930,  0.3148]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.0488,  0.0492, -0.1457,  ..., -0.3619, -0.2865, -0.2105],\n",
      "          [-1.4461,  1.8900,  1.2918,  ..., -0.6695, -1.6687,  0.1821]],\n",
      "\n",
      "         [[-1.4676, -0.4380, -0.5342,  ...,  0.0577, -1.6239,  0.0563],\n",
      "          [-0.3515,  1.2206,  1.5211,  ...,  0.3276, -0.0951, -0.2500]],\n",
      "\n",
      "         [[-1.1433, -1.4615, -0.0332,  ..., -0.5420, -0.6671, -1.4241],\n",
      "          [-1.7851,  0.5569,  0.6397,  ..., -2.2869, -0.3153, -1.1242]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4589, -0.1316,  0.0194,  ...,  0.2662,  0.6550,  0.4453],\n",
      "          [-0.5646,  0.1943,  0.8188,  ..., -0.7212,  2.1792,  0.1995]],\n",
      "\n",
      "         [[ 0.3273, -2.2635,  0.4489,  ..., -0.4586, -1.5076, -0.9967],\n",
      "          [-0.9123,  0.1471, -0.1034,  ..., -0.4045,  0.8159,  0.5562]],\n",
      "\n",
      "         [[-2.3148, -0.5869,  1.7037,  ..., -1.4093, -0.4310,  0.6948],\n",
      "          [ 0.0203, -0.4768,  1.1557,  ..., -0.1215,  0.0318, -1.3248]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.7403,  0.6778, -0.0372,  ...,  0.0411,  0.6922, -0.8735],\n",
      "          [-2.0086,  1.4971,  2.6926,  ..., -0.2250, -1.4670,  1.3012]],\n",
      "\n",
      "         [[-0.9572, -0.6238,  0.8255,  ...,  0.3552, -1.1478,  0.3682],\n",
      "          [-0.7753,  0.8552,  0.7477,  ..., -0.6661,  0.0840,  0.0840]],\n",
      "\n",
      "         [[-1.0275, -1.3546,  0.0771,  ..., -0.6231, -0.5347, -1.4864],\n",
      "          [-1.8713,  0.5198,  0.4933,  ..., -2.4443, -0.2543, -0.9387]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.3306, -0.7109,  0.3804,  ..., -0.0812, -0.8347,  0.1535],\n",
      "          [-0.3306, -0.7109,  0.3804,  ..., -0.0812, -0.8347,  0.1535],\n",
      "          [-0.3306, -0.7109,  0.3804,  ..., -0.0812, -0.8347,  0.1535],\n",
      "          ...,\n",
      "          [-0.3306, -0.7109,  0.3804,  ..., -0.0812, -0.8347,  0.1535],\n",
      "          [-0.3306, -0.7109,  0.3804,  ..., -0.0812, -0.8347,  0.1535],\n",
      "          [-0.3306, -0.7109,  0.3804,  ..., -0.0812, -0.8347,  0.1535]],\n",
      "\n",
      "         [[-0.7417,  0.3805,  0.8759,  ..., -0.7301,  0.2226,  0.0429],\n",
      "          [-0.7417,  0.3805,  0.8759,  ..., -0.7301,  0.2226,  0.0429],\n",
      "          [-0.7417,  0.3805,  0.8759,  ..., -0.7301,  0.2226,  0.0429],\n",
      "          ...,\n",
      "          [-0.7417,  0.3805,  0.8759,  ..., -0.7301,  0.2226,  0.0429],\n",
      "          [-0.7417,  0.3805,  0.8759,  ..., -0.7301,  0.2226,  0.0429],\n",
      "          [-0.7417,  0.3805,  0.8759,  ..., -0.7301,  0.2226,  0.0429]]],\n",
      "\n",
      "\n",
      "        [[[-0.2133, -0.5767,  0.5929,  ..., -0.2661, -0.5832,  0.0088],\n",
      "          [-0.2133, -0.5767,  0.5929,  ..., -0.2661, -0.5832,  0.0088],\n",
      "          [-0.2133, -0.5767,  0.5929,  ..., -0.2661, -0.5832,  0.0088],\n",
      "          ...,\n",
      "          [-0.2133, -0.5767,  0.5929,  ..., -0.2661, -0.5832,  0.0088],\n",
      "          [-0.2133, -0.5767,  0.5929,  ..., -0.2661, -0.5832,  0.0088],\n",
      "          [-0.2133, -0.5767,  0.5929,  ..., -0.2661, -0.5832,  0.0088]],\n",
      "\n",
      "         [[-0.9389,  0.8556,  1.0682,  ..., -0.7085,  0.1527, -0.0298],\n",
      "          [-0.9389,  0.8556,  1.0682,  ..., -0.7085,  0.1527, -0.0298],\n",
      "          [-0.9389,  0.8556,  1.0682,  ..., -0.7085,  0.1527, -0.0298],\n",
      "          ...,\n",
      "          [-0.9389,  0.8556,  1.0682,  ..., -0.7085,  0.1527, -0.0298],\n",
      "          [-0.9389,  0.8556,  1.0682,  ..., -0.7085,  0.1527, -0.0298],\n",
      "          [-0.9389,  0.8556,  1.0682,  ..., -0.7085,  0.1527, -0.0298]]]],\n",
      "       grad_fn=<ScaledDotProductFlashAttentionForCpuBackward0>)\n",
      "tensor([[[[-0.3306, -0.7109,  0.3804,  ..., -0.0812, -0.8347,  0.1535],\n",
      "          [-0.7417,  0.3805,  0.8759,  ..., -0.7301,  0.2226,  0.0429]],\n",
      "\n",
      "         [[-0.3306, -0.7109,  0.3804,  ..., -0.0812, -0.8347,  0.1535],\n",
      "          [-0.7417,  0.3805,  0.8759,  ..., -0.7301,  0.2226,  0.0429]],\n",
      "\n",
      "         [[-0.3306, -0.7109,  0.3804,  ..., -0.0812, -0.8347,  0.1535],\n",
      "          [-0.7417,  0.3805,  0.8759,  ..., -0.7301,  0.2226,  0.0429]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3306, -0.7109,  0.3804,  ..., -0.0812, -0.8347,  0.1535],\n",
      "          [-0.7417,  0.3805,  0.8759,  ..., -0.7301,  0.2226,  0.0429]],\n",
      "\n",
      "         [[-0.3306, -0.7109,  0.3804,  ..., -0.0812, -0.8347,  0.1535],\n",
      "          [-0.7417,  0.3805,  0.8759,  ..., -0.7301,  0.2226,  0.0429]],\n",
      "\n",
      "         [[-0.3306, -0.7109,  0.3804,  ..., -0.0812, -0.8347,  0.1535],\n",
      "          [-0.7417,  0.3805,  0.8759,  ..., -0.7301,  0.2226,  0.0429]]],\n",
      "\n",
      "\n",
      "        [[[-0.2133, -0.5767,  0.5929,  ..., -0.2661, -0.5832,  0.0088],\n",
      "          [-0.9389,  0.8556,  1.0682,  ..., -0.7085,  0.1527, -0.0298]],\n",
      "\n",
      "         [[-0.2133, -0.5767,  0.5929,  ..., -0.2661, -0.5832,  0.0088],\n",
      "          [-0.9389,  0.8556,  1.0682,  ..., -0.7085,  0.1527, -0.0298]],\n",
      "\n",
      "         [[-0.2133, -0.5767,  0.5929,  ..., -0.2661, -0.5832,  0.0088],\n",
      "          [-0.9389,  0.8556,  1.0682,  ..., -0.7085,  0.1527, -0.0298]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2133, -0.5767,  0.5929,  ..., -0.2661, -0.5832,  0.0088],\n",
      "          [-0.9389,  0.8556,  1.0682,  ..., -0.7085,  0.1527, -0.0298]],\n",
      "\n",
      "         [[-0.2133, -0.5767,  0.5929,  ..., -0.2661, -0.5832,  0.0088],\n",
      "          [-0.9389,  0.8556,  1.0682,  ..., -0.7085,  0.1527, -0.0298]],\n",
      "\n",
      "         [[-0.2133, -0.5767,  0.5929,  ..., -0.2661, -0.5832,  0.0088],\n",
      "          [-0.9389,  0.8556,  1.0682,  ..., -0.7085,  0.1527, -0.0298]]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[-1.0854,  0.7831],\n",
      "        [-0.4505,  0.2014]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 02:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`past_key_values` were not specified as input names, but model.config.use_cache = True. Setting model.config.use_cache = False.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mGetting dummy input for prajjwal1/bert-tiny.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressed (no post-train) eval_accuracy: 0.5020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mGetting dummy input for prajjwal1/bert-tiny.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
      "\n",
      "\n",
      "        [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]])\n",
      "tensor([[[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
      "\n",
      "\n",
      "        [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]])\n",
      "tensor([[[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]])\n",
      "tensor([[[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]])\n",
      "tensor([[[ 0.4399, -0.1289, -0.0193,  ..., -0.7220,  2.1669,  0.2116],\n",
      "         [ 0.4737, -1.2851,  0.7269,  ..., -1.3262, -0.0807,  0.7324],\n",
      "         [-1.0127, -1.2385,  1.0493,  ..., -0.2675,  0.9101,  0.6033],\n",
      "         ...,\n",
      "         [-0.8877,  0.2255, -0.0285,  ..., -0.8598, -1.6034,  0.4798],\n",
      "         [-1.3354, -0.2770, -0.4315,  ...,  0.1540, -0.0039,  0.0438],\n",
      "         [-0.9938, -1.2972,  0.0781,  ..., -2.4799, -0.2318, -0.8143]],\n",
      "\n",
      "        [[ 0.4399, -0.1289, -0.0193,  ..., -0.7220,  2.1669,  0.2116],\n",
      "         [ 0.3325, -2.1907,  0.4309,  ..., -0.4327,  0.8238,  0.6018],\n",
      "         [-2.2631, -0.5424,  1.6860,  ..., -0.1677,  0.0543, -1.1901],\n",
      "         ...,\n",
      "         [-0.6945,  0.7086, -0.0305,  ..., -0.2801, -1.4319,  1.3509],\n",
      "         [-0.9197, -0.5727,  0.8206,  ..., -0.7162,  0.1093,  0.1793],\n",
      "         [-0.9938, -1.2972,  0.0781,  ..., -2.4799, -0.2318, -0.8143]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[ 0.5355, -0.0675, -0.2999,  ...,  1.0623, -1.5882, -0.4372],\n",
      "         [ 0.0714, -0.1049, -0.6291,  ...,  0.3066, -1.2606, -0.1896],\n",
      "         [ 0.4521, -0.2345, -0.2281,  ...,  0.4841, -0.8775, -0.4523],\n",
      "         ...,\n",
      "         [ 0.1751,  0.3563, -0.3652,  ...,  0.5923, -0.7895, -0.6227],\n",
      "         [ 0.2784, -0.2019,  0.0694,  ...,  0.3389, -1.0946, -0.6864],\n",
      "         [ 0.2996, -0.0439, -0.7518,  ...,  0.3756, -0.8931, -0.4892]],\n",
      "\n",
      "        [[ 0.5355, -0.0675, -0.2999,  ...,  1.0623, -1.5882, -0.4372],\n",
      "         [ 0.0419, -0.1495, -0.2300,  ...,  0.4913, -1.2540, -0.3115],\n",
      "         [ 0.6684, -0.1476, -0.5027,  ...,  0.3221, -1.2428, -0.4057],\n",
      "         ...,\n",
      "         [ 0.4988,  0.1559, -0.2923,  ...,  0.6583, -0.7896, -0.5446],\n",
      "         [ 0.0049, -0.3911, -0.1698,  ...,  0.3138, -1.1344, -0.8804],\n",
      "         [ 0.2996, -0.0439, -0.7518,  ...,  0.3756, -0.8931, -0.4892]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.5355, -0.0675, -0.2999,  ...,  1.0623, -1.5882, -0.4372],\n",
      "         [ 0.0714, -0.1049, -0.6291,  ...,  0.3066, -1.2606, -0.1896],\n",
      "         [ 0.4521, -0.2345, -0.2281,  ...,  0.4841, -0.8775, -0.4523],\n",
      "         ...,\n",
      "         [ 0.1751,  0.3563, -0.3652,  ...,  0.5923, -0.7895, -0.6227],\n",
      "         [ 0.2784, -0.2019,  0.0694,  ...,  0.3389, -1.0946, -0.6864],\n",
      "         [ 0.2996, -0.0439, -0.7518,  ...,  0.3756, -0.8931, -0.4892]],\n",
      "\n",
      "        [[ 0.5355, -0.0675, -0.2999,  ...,  1.0623, -1.5882, -0.4372],\n",
      "         [ 0.0419, -0.1495, -0.2300,  ...,  0.4913, -1.2540, -0.3115],\n",
      "         [ 0.6684, -0.1476, -0.5027,  ...,  0.3221, -1.2428, -0.4057],\n",
      "         ...,\n",
      "         [ 0.4988,  0.1559, -0.2923,  ...,  0.6583, -0.7896, -0.5446],\n",
      "         [ 0.0049, -0.3911, -0.1698,  ...,  0.3138, -1.1344, -0.8804],\n",
      "         [ 0.2996, -0.0439, -0.7518,  ...,  0.3756, -0.8931, -0.4892]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 0.5355, -0.0675, -0.2999,  ...,  0.8728, -0.7396, -0.7421],\n",
      "          [ 1.1956, -0.1778, -0.9047,  ...,  1.0623, -1.5882, -0.4372]],\n",
      "\n",
      "         [[ 0.0714, -0.1049, -0.6291,  ...,  0.7638, -0.4328, -0.4335],\n",
      "          [ 0.4737, -0.0795, -0.4281,  ...,  0.3066, -1.2606, -0.1896]],\n",
      "\n",
      "         [[ 0.4521, -0.2345, -0.2281,  ...,  0.5133, -0.1947, -0.6254],\n",
      "          [-0.0835,  0.0678,  0.0493,  ...,  0.4841, -0.8775, -0.4523]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1751,  0.3563, -0.3652,  ...,  0.3062, -0.1877, -0.2744],\n",
      "          [ 0.2485, -0.0350, -0.0193,  ...,  0.5923, -0.7895, -0.6227]],\n",
      "\n",
      "         [[ 0.2784, -0.2019,  0.0694,  ...,  0.3501, -0.2056, -0.5703],\n",
      "          [ 0.3718, -0.0893, -0.2088,  ...,  0.3389, -1.0946, -0.6864]],\n",
      "\n",
      "         [[ 0.2996, -0.0439, -0.7518,  ...,  0.3823, -0.2261, -0.1500],\n",
      "          [ 0.5887, -0.8339, -0.2265,  ...,  0.3756, -0.8931, -0.4892]]],\n",
      "\n",
      "\n",
      "        [[[ 0.5355, -0.0675, -0.2999,  ...,  0.8728, -0.7396, -0.7421],\n",
      "          [ 1.1956, -0.1778, -0.9047,  ...,  1.0623, -1.5882, -0.4372]],\n",
      "\n",
      "         [[ 0.0419, -0.1495, -0.2300,  ...,  1.0737, -0.3505, -0.5324],\n",
      "          [ 0.4068,  0.0290, -0.6251,  ...,  0.4913, -1.2540, -0.3115]],\n",
      "\n",
      "         [[ 0.6684, -0.1476, -0.5027,  ...,  0.4181, -0.5559, -0.3499],\n",
      "          [ 0.0225,  0.0707, -0.2040,  ...,  0.3221, -1.2428, -0.4057]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4988,  0.1559, -0.2923,  ...,  0.3894, -0.2367, -0.1727],\n",
      "          [ 0.1865, -0.0686, -0.0321,  ...,  0.6583, -0.7896, -0.5446]],\n",
      "\n",
      "         [[ 0.0049, -0.3911, -0.1698,  ...,  0.1592, -0.3604, -0.4732],\n",
      "          [ 0.4345, -0.0262, -0.4430,  ...,  0.3138, -1.1344, -0.8804]],\n",
      "\n",
      "         [[ 0.2996, -0.0439, -0.7518,  ...,  0.3823, -0.2261, -0.1500],\n",
      "          [ 0.5887, -0.8339, -0.2265,  ...,  0.3756, -0.8931, -0.4892]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.3411, -0.7532,  0.3818,  ..., -0.4160,  0.1045, -0.4541],\n",
      "         [ 0.0063, -0.1287,  0.4656,  ..., -0.3665,  0.0151, -0.3303],\n",
      "         [ 0.4231,  0.0889, -0.1748,  ..., -0.6287, -0.2605, -0.7964],\n",
      "         ...,\n",
      "         [ 0.0740,  0.2039,  0.5227,  ..., -0.3911,  0.3457, -0.0500],\n",
      "         [ 0.2402, -0.0967,  0.0403,  ..., -0.4263,  0.0623, -0.3743],\n",
      "         [ 0.2773, -0.2832,  0.7327,  ..., -0.3733,  0.1086,  0.1582]],\n",
      "\n",
      "        [[ 0.3411, -0.7532,  0.3818,  ..., -0.4160,  0.1045, -0.4541],\n",
      "         [ 0.0649, -0.2349, -0.0103,  ..., -0.3154,  0.0891,  0.0852],\n",
      "         [ 0.5369,  0.2769,  0.1519,  ..., -0.5449, -0.1785, -0.6726],\n",
      "         ...,\n",
      "         [-0.0540, -0.1838,  0.5757,  ..., -0.1030,  0.3635, -0.2222],\n",
      "         [-0.2446, -0.6213, -0.2209,  ..., -0.5715, -0.1401, -0.2776],\n",
      "         [ 0.2773, -0.2832,  0.7327,  ..., -0.3733,  0.1086,  0.1582]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.3411, -0.7532,  0.3818,  ..., -0.4160,  0.1045, -0.4541],\n",
      "         [ 0.0063, -0.1287,  0.4656,  ..., -0.3665,  0.0151, -0.3303],\n",
      "         [ 0.4231,  0.0889, -0.1748,  ..., -0.6287, -0.2605, -0.7964],\n",
      "         ...,\n",
      "         [ 0.0740,  0.2039,  0.5227,  ..., -0.3911,  0.3457, -0.0500],\n",
      "         [ 0.2402, -0.0967,  0.0403,  ..., -0.4263,  0.0623, -0.3743],\n",
      "         [ 0.2773, -0.2832,  0.7327,  ..., -0.3733,  0.1086,  0.1582]],\n",
      "\n",
      "        [[ 0.3411, -0.7532,  0.3818,  ..., -0.4160,  0.1045, -0.4541],\n",
      "         [ 0.0649, -0.2349, -0.0103,  ..., -0.3154,  0.0891,  0.0852],\n",
      "         [ 0.5369,  0.2769,  0.1519,  ..., -0.5449, -0.1785, -0.6726],\n",
      "         ...,\n",
      "         [-0.0540, -0.1838,  0.5757,  ..., -0.1030,  0.3635, -0.2222],\n",
      "         [-0.2446, -0.6213, -0.2209,  ..., -0.5715, -0.1401, -0.2776],\n",
      "         [ 0.2773, -0.2832,  0.7327,  ..., -0.3733,  0.1086,  0.1582]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 0.3411, -0.7532,  0.3818,  ...,  0.2690,  0.2161,  0.0330],\n",
      "          [-0.2920,  0.2268,  0.5801,  ..., -0.4160,  0.1045, -0.4541]],\n",
      "\n",
      "         [[ 0.0063, -0.1287,  0.4656,  ..., -0.0027,  0.1118,  0.2368],\n",
      "          [ 0.0229,  0.0811,  0.3059,  ..., -0.3665,  0.0151, -0.3303]],\n",
      "\n",
      "         [[ 0.4231,  0.0889, -0.1748,  ...,  0.1443, -0.0530, -0.1326],\n",
      "          [ 0.2280,  0.0405,  0.1187,  ..., -0.6287, -0.2605, -0.7964]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0740,  0.2039,  0.5227,  ..., -0.4241,  0.6389,  0.1987],\n",
      "          [-0.0686,  0.0586,  0.2146,  ..., -0.3911,  0.3457, -0.0500]],\n",
      "\n",
      "         [[ 0.2402, -0.0967,  0.0403,  ...,  0.2317,  0.4075,  0.2734],\n",
      "          [ 0.5015, -0.0139,  0.3928,  ..., -0.4263,  0.0623, -0.3743]],\n",
      "\n",
      "         [[ 0.2773, -0.2832,  0.7327,  ..., -0.4619,  0.6072,  0.3008],\n",
      "          [-0.0837,  0.1545,  0.6450,  ..., -0.3733,  0.1086,  0.1582]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3411, -0.7532,  0.3818,  ...,  0.2690,  0.2161,  0.0330],\n",
      "          [-0.2920,  0.2268,  0.5801,  ..., -0.4160,  0.1045, -0.4541]],\n",
      "\n",
      "         [[ 0.0649, -0.2349, -0.0103,  ...,  0.3474,  0.5938, -0.1704],\n",
      "          [ 0.0828,  0.3909,  0.5522,  ..., -0.3154,  0.0891,  0.0852]],\n",
      "\n",
      "         [[ 0.5369,  0.2769,  0.1519,  ..., -0.2371,  0.2361,  0.1567],\n",
      "          [-0.0264, -0.2820, -0.1599,  ..., -0.5449, -0.1785, -0.6726]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0540, -0.1838,  0.5757,  ...,  0.0928,  1.1794, -0.0686],\n",
      "          [ 0.1348, -0.0950,  0.4700,  ..., -0.1030,  0.3635, -0.2222]],\n",
      "\n",
      "         [[-0.2446, -0.6213, -0.2209,  ...,  0.0220,  0.3821,  0.2678],\n",
      "          [ 0.1187,  0.3833,  0.6152,  ..., -0.5715, -0.1401, -0.2776]],\n",
      "\n",
      "         [[ 0.2773, -0.2832,  0.7327,  ..., -0.4619,  0.6072,  0.3008],\n",
      "          [-0.0837,  0.1545,  0.6450,  ..., -0.3733,  0.1086,  0.1582]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.2848,  0.0133,  0.2944,  ...,  0.1627, -0.2960,  0.0523],\n",
      "         [-0.0516, -0.0073, -0.1727,  ...,  0.0920, -0.6191, -0.3654],\n",
      "         [ 0.6742,  0.1142, -0.0643,  ..., -0.0606, -0.2419, -0.0149],\n",
      "         ...,\n",
      "         [ 0.3567,  0.2127,  0.2474,  ...,  0.1704, -0.1884,  0.1148],\n",
      "         [ 0.6993, -0.1791, -0.0792,  ..., -0.2351, -0.4122,  0.2759],\n",
      "         [-0.2252, -0.3539, -0.3699,  ...,  0.0477, -0.4384, -0.2319]],\n",
      "\n",
      "        [[-0.2848,  0.0133,  0.2944,  ...,  0.1627, -0.2960,  0.0523],\n",
      "         [ 0.1014, -0.1526,  0.2766,  ...,  0.1704, -0.5654, -0.3095],\n",
      "         [ 0.8153,  0.5225, -0.4410,  ...,  0.1153, -0.7423, -0.2427],\n",
      "         ...,\n",
      "         [ 0.1090, -0.1706,  0.1723,  ...,  0.2357, -0.1261, -0.3542],\n",
      "         [ 0.3857,  0.0030,  0.1033,  ...,  0.0958, -0.4121,  0.1341],\n",
      "         [-0.2252, -0.3539, -0.3699,  ...,  0.0477, -0.4384, -0.2319]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.2848,  0.0133,  0.2944,  ...,  0.1627, -0.2960,  0.0523],\n",
      "         [-0.0516, -0.0073, -0.1727,  ...,  0.0920, -0.6191, -0.3654],\n",
      "         [ 0.6742,  0.1142, -0.0643,  ..., -0.0606, -0.2419, -0.0149],\n",
      "         ...,\n",
      "         [ 0.3567,  0.2127,  0.2474,  ...,  0.1704, -0.1884,  0.1148],\n",
      "         [ 0.6993, -0.1791, -0.0792,  ..., -0.2351, -0.4122,  0.2759],\n",
      "         [-0.2252, -0.3539, -0.3699,  ...,  0.0477, -0.4384, -0.2319]],\n",
      "\n",
      "        [[-0.2848,  0.0133,  0.2944,  ...,  0.1627, -0.2960,  0.0523],\n",
      "         [ 0.1014, -0.1526,  0.2766,  ...,  0.1704, -0.5654, -0.3095],\n",
      "         [ 0.8153,  0.5225, -0.4410,  ...,  0.1153, -0.7423, -0.2427],\n",
      "         ...,\n",
      "         [ 0.1090, -0.1706,  0.1723,  ...,  0.2357, -0.1261, -0.3542],\n",
      "         [ 0.3857,  0.0030,  0.1033,  ...,  0.0958, -0.4121,  0.1341],\n",
      "         [-0.2252, -0.3539, -0.3699,  ...,  0.0477, -0.4384, -0.2319]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.2848,  0.0133,  0.2944,  ..., -0.0866,  0.2473,  0.2200],\n",
      "          [ 0.3274, -0.1107, -0.2222,  ...,  0.1627, -0.2960,  0.0523]],\n",
      "\n",
      "         [[-0.0516, -0.0073, -0.1727,  ...,  0.0962,  0.3208,  0.2101],\n",
      "          [-0.3615,  0.0756, -0.5151,  ...,  0.0920, -0.6191, -0.3654]],\n",
      "\n",
      "         [[ 0.6742,  0.1142, -0.0643,  ...,  0.8289, -0.1244, -0.5121],\n",
      "          [ 0.2243,  0.0483, -0.1498,  ..., -0.0606, -0.2419, -0.0149]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3567,  0.2127,  0.2474,  ...,  0.3345, -0.5654,  0.6881],\n",
      "          [-0.0579,  0.2528,  0.4284,  ...,  0.1704, -0.1884,  0.1148]],\n",
      "\n",
      "         [[ 0.6993, -0.1791, -0.0792,  ...,  0.7320,  0.1988,  0.0148],\n",
      "          [ 0.0798, -0.0086, -0.2200,  ..., -0.2351, -0.4122,  0.2759]],\n",
      "\n",
      "         [[-0.2252, -0.3539, -0.3699,  ...,  0.3107, -0.1830,  0.2064],\n",
      "          [-0.1287, -0.2328, -0.7505,  ...,  0.0477, -0.4384, -0.2319]]],\n",
      "\n",
      "\n",
      "        [[[-0.2848,  0.0133,  0.2944,  ..., -0.0866,  0.2473,  0.2200],\n",
      "          [ 0.3274, -0.1107, -0.2222,  ...,  0.1627, -0.2960,  0.0523]],\n",
      "\n",
      "         [[ 0.1014, -0.1526,  0.2766,  ...,  0.1503,  0.4208,  0.2120],\n",
      "          [-0.0164,  0.2578, -0.3759,  ...,  0.1704, -0.5654, -0.3095]],\n",
      "\n",
      "         [[ 0.8153,  0.5225, -0.4410,  ...,  0.7473, -0.0083, -0.1215],\n",
      "          [ 0.2113,  0.2522, -0.5443,  ...,  0.1153, -0.7423, -0.2427]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1090, -0.1706,  0.1723,  ...,  0.1552, -0.0901,  0.5992],\n",
      "          [ 0.0021, -0.2227,  0.0617,  ...,  0.2357, -0.1261, -0.3542]],\n",
      "\n",
      "         [[ 0.3857,  0.0030,  0.1033,  ...,  0.4130,  0.0457, -0.0592],\n",
      "          [ 0.0840, -0.0526, -0.3777,  ...,  0.0958, -0.4121,  0.1341]],\n",
      "\n",
      "         [[-0.2252, -0.3539, -0.3699,  ...,  0.3107, -0.1830,  0.2064],\n",
      "          [-0.1287, -0.2328, -0.7505,  ...,  0.0477, -0.4384, -0.2319]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 0.1888,  0.0703, -0.0939,  ...,  0.4341, -0.0780,  0.0546],\n",
      "          [ 0.1731,  0.0547, -0.0597,  ...,  0.3855, -0.0651,  0.1152],\n",
      "          [ 0.1699,  0.0411, -0.0461,  ...,  0.3645, -0.0604,  0.1491],\n",
      "          ...,\n",
      "          [ 0.1644,  0.0365, -0.0377,  ...,  0.3503, -0.0604,  0.1739],\n",
      "          [ 0.1568,  0.0367, -0.0446,  ...,  0.3490, -0.0542,  0.1628],\n",
      "          [ 0.1580,  0.0424, -0.0425,  ...,  0.3552, -0.0639,  0.1616]],\n",
      "\n",
      "         [[ 0.0919, -0.0055, -0.2216,  ...,  0.2363, -0.3632, -0.1791],\n",
      "          [ 0.0477,  0.0156, -0.2308,  ...,  0.1923, -0.3785, -0.1175],\n",
      "          [ 0.0280,  0.0124, -0.2394,  ...,  0.2182, -0.3893, -0.1299],\n",
      "          ...,\n",
      "          [ 0.0151,  0.0230, -0.2351,  ...,  0.2013, -0.3916, -0.1113],\n",
      "          [ 0.0270,  0.0182, -0.2377,  ...,  0.2042, -0.3903, -0.1129],\n",
      "          [ 0.0268,  0.0155, -0.2381,  ...,  0.2145, -0.3916, -0.1233]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2267,  0.0973,  0.2392,  ...,  0.0629,  0.1635,  0.2638],\n",
      "          [ 0.2166,  0.0858,  0.1707,  ...,  0.1201,  0.1264,  0.2417],\n",
      "          [ 0.2139,  0.0708,  0.1517,  ...,  0.1423,  0.1108,  0.2326],\n",
      "          ...,\n",
      "          [ 0.2170,  0.0778,  0.1218,  ...,  0.1626,  0.0968,  0.2236],\n",
      "          [ 0.2201,  0.0794,  0.1223,  ...,  0.1610,  0.0992,  0.2220],\n",
      "          [ 0.2243,  0.0850,  0.1297,  ...,  0.1575,  0.1013,  0.2262]],\n",
      "\n",
      "         [[ 0.0467, -0.1152, -0.2401,  ...,  0.4170, -0.3111, -0.2295],\n",
      "          [ 0.0352, -0.0908, -0.2657,  ...,  0.3736, -0.3391, -0.2012],\n",
      "          [ 0.0328, -0.0817, -0.2835,  ...,  0.3550, -0.3541, -0.2014],\n",
      "          ...,\n",
      "          [ 0.0304, -0.0727, -0.2836,  ...,  0.3454, -0.3632, -0.2008],\n",
      "          [ 0.0379, -0.0836, -0.2737,  ...,  0.3557, -0.3533, -0.2007],\n",
      "          [ 0.0309, -0.0843, -0.2787,  ...,  0.3537, -0.3493, -0.1970]]]],\n",
      "       grad_fn=<ScaledDotProductFlashAttentionForCpuBackward0>)\n",
      "tensor([[[[ 0.1888,  0.0703, -0.0939,  ...,  0.4341, -0.0780,  0.0546],\n",
      "          [ 0.0919, -0.0055, -0.2216,  ...,  0.2363, -0.3632, -0.1791]],\n",
      "\n",
      "         [[ 0.1731,  0.0547, -0.0597,  ...,  0.3855, -0.0651,  0.1152],\n",
      "          [ 0.0477,  0.0156, -0.2308,  ...,  0.1923, -0.3785, -0.1175]],\n",
      "\n",
      "         [[ 0.1699,  0.0411, -0.0461,  ...,  0.3645, -0.0604,  0.1491],\n",
      "          [ 0.0280,  0.0124, -0.2394,  ...,  0.2182, -0.3893, -0.1299]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1644,  0.0365, -0.0377,  ...,  0.3503, -0.0604,  0.1739],\n",
      "          [ 0.0151,  0.0230, -0.2351,  ...,  0.2013, -0.3916, -0.1113]],\n",
      "\n",
      "         [[ 0.1568,  0.0367, -0.0446,  ...,  0.3490, -0.0542,  0.1628],\n",
      "          [ 0.0270,  0.0182, -0.2377,  ...,  0.2042, -0.3903, -0.1129]],\n",
      "\n",
      "         [[ 0.1580,  0.0424, -0.0425,  ...,  0.3552, -0.0639,  0.1616],\n",
      "          [ 0.0268,  0.0155, -0.2381,  ...,  0.2145, -0.3916, -0.1233]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2267,  0.0973,  0.2392,  ...,  0.0629,  0.1635,  0.2638],\n",
      "          [ 0.0467, -0.1152, -0.2401,  ...,  0.4170, -0.3111, -0.2295]],\n",
      "\n",
      "         [[ 0.2166,  0.0858,  0.1707,  ...,  0.1201,  0.1264,  0.2417],\n",
      "          [ 0.0352, -0.0908, -0.2657,  ...,  0.3736, -0.3391, -0.2012]],\n",
      "\n",
      "         [[ 0.2139,  0.0708,  0.1517,  ...,  0.1423,  0.1108,  0.2326],\n",
      "          [ 0.0328, -0.0817, -0.2835,  ...,  0.3550, -0.3541, -0.2014]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2170,  0.0778,  0.1218,  ...,  0.1626,  0.0968,  0.2236],\n",
      "          [ 0.0304, -0.0727, -0.2836,  ...,  0.3454, -0.3632, -0.2008]],\n",
      "\n",
      "         [[ 0.2201,  0.0794,  0.1223,  ...,  0.1610,  0.0992,  0.2220],\n",
      "          [ 0.0379, -0.0836, -0.2737,  ...,  0.3557, -0.3533, -0.2007]],\n",
      "\n",
      "         [[ 0.2243,  0.0850,  0.1297,  ...,  0.1575,  0.1013,  0.2262],\n",
      "          [ 0.0309, -0.0843, -0.2787,  ...,  0.3537, -0.3493, -0.1970]]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.2965, -0.3144, -0.1336,  ..., -0.5515,  2.1020, -0.0853],\n",
      "         [ 0.3055, -1.4584,  0.5972,  ..., -1.1248, -0.1673,  0.4307],\n",
      "         [-1.1487, -1.3869,  0.9171,  ..., -0.0903,  0.7930,  0.3148],\n",
      "         ...,\n",
      "         [-1.0488,  0.0492, -0.1457,  ..., -0.6695, -1.6687,  0.1821],\n",
      "         [-1.4676, -0.4380, -0.5342,  ...,  0.3276, -0.0951, -0.2500],\n",
      "         [-1.1433, -1.4615, -0.0332,  ..., -2.2869, -0.3153, -1.1242]],\n",
      "\n",
      "        [[ 0.4589, -0.1316,  0.0194,  ..., -0.7212,  2.1792,  0.1995],\n",
      "         [ 0.3273, -2.2635,  0.4489,  ..., -0.4045,  0.8159,  0.5562],\n",
      "         [-2.3148, -0.5869,  1.7037,  ..., -0.1215,  0.0318, -1.3248],\n",
      "         ...,\n",
      "         [-0.7403,  0.6778, -0.0372,  ..., -0.2250, -1.4670,  1.3012],\n",
      "         [-0.9572, -0.6238,  0.8255,  ..., -0.6661,  0.0840,  0.0840],\n",
      "         [-1.0275, -1.3546,  0.0771,  ..., -2.4443, -0.2543, -0.9387]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.2965, -0.3144, -0.1336,  ..., -0.5515,  2.1020, -0.0853],\n",
      "         [ 0.3055, -1.4584,  0.5972,  ..., -1.1248, -0.1673,  0.4307],\n",
      "         [-1.1487, -1.3869,  0.9171,  ..., -0.0903,  0.7930,  0.3148],\n",
      "         ...,\n",
      "         [-1.0488,  0.0492, -0.1457,  ..., -0.6695, -1.6687,  0.1821],\n",
      "         [-1.4676, -0.4380, -0.5342,  ...,  0.3276, -0.0951, -0.2500],\n",
      "         [-1.1433, -1.4615, -0.0332,  ..., -2.2869, -0.3153, -1.1242]],\n",
      "\n",
      "        [[ 0.4589, -0.1316,  0.0194,  ..., -0.7212,  2.1792,  0.1995],\n",
      "         [ 0.3273, -2.2635,  0.4489,  ..., -0.4045,  0.8159,  0.5562],\n",
      "         [-2.3148, -0.5869,  1.7037,  ..., -0.1215,  0.0318, -1.3248],\n",
      "         ...,\n",
      "         [-0.7403,  0.6778, -0.0372,  ..., -0.2250, -1.4670,  1.3012],\n",
      "         [-0.9572, -0.6238,  0.8255,  ..., -0.6661,  0.0840,  0.0840],\n",
      "         [-1.0275, -1.3546,  0.0771,  ..., -2.4443, -0.2543, -0.9387]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[ 0.2965, -0.3144, -0.1336,  ..., -0.5515,  2.1020, -0.0853],\n",
      "         [ 0.3055, -1.4584,  0.5972,  ..., -1.1248, -0.1673,  0.4307],\n",
      "         [-1.1487, -1.3869,  0.9171,  ..., -0.0903,  0.7930,  0.3148],\n",
      "         ...,\n",
      "         [-1.0488,  0.0492, -0.1457,  ..., -0.6695, -1.6687,  0.1821],\n",
      "         [-1.4676, -0.4380, -0.5342,  ...,  0.3276, -0.0951, -0.2500],\n",
      "         [-1.1433, -1.4615, -0.0332,  ..., -2.2869, -0.3153, -1.1242]],\n",
      "\n",
      "        [[ 0.4589, -0.1316,  0.0194,  ..., -0.7212,  2.1792,  0.1995],\n",
      "         [ 0.3273, -2.2635,  0.4489,  ..., -0.4045,  0.8159,  0.5562],\n",
      "         [-2.3148, -0.5869,  1.7037,  ..., -0.1215,  0.0318, -1.3248],\n",
      "         ...,\n",
      "         [-0.7403,  0.6778, -0.0372,  ..., -0.2250, -1.4670,  1.3012],\n",
      "         [-0.9572, -0.6238,  0.8255,  ..., -0.6661,  0.0840,  0.0840],\n",
      "         [-1.0275, -1.3546,  0.0771,  ..., -2.4443, -0.2543, -0.9387]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[[ 0.2965, -0.3144, -0.1336,  ...,  0.3730,  0.4541,  0.5311],\n",
      "          [-0.4796,  0.2522,  1.0154,  ..., -0.5515,  2.1020, -0.0853]],\n",
      "\n",
      "         [[ 0.3055, -1.4584,  0.5972,  ..., -0.4977, -1.4432,  0.2002],\n",
      "          [-0.8983,  0.3068,  0.8379,  ..., -1.1248, -0.1673,  0.4307]],\n",
      "\n",
      "         [[-1.1487, -1.3869,  0.9171,  ..., -0.4039, -0.9157,  1.3295],\n",
      "          [-1.0111,  0.2708,  1.1939,  ..., -0.0903,  0.7930,  0.3148]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.0488,  0.0492, -0.1457,  ..., -0.3619, -0.2865, -0.2105],\n",
      "          [-1.4461,  1.8900,  1.2918,  ..., -0.6695, -1.6687,  0.1821]],\n",
      "\n",
      "         [[-1.4676, -0.4380, -0.5342,  ...,  0.0577, -1.6239,  0.0563],\n",
      "          [-0.3515,  1.2206,  1.5211,  ...,  0.3276, -0.0951, -0.2500]],\n",
      "\n",
      "         [[-1.1433, -1.4615, -0.0332,  ..., -0.5420, -0.6671, -1.4241],\n",
      "          [-1.7851,  0.5569,  0.6397,  ..., -2.2869, -0.3153, -1.1242]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4589, -0.1316,  0.0194,  ...,  0.2662,  0.6550,  0.4453],\n",
      "          [-0.5646,  0.1943,  0.8188,  ..., -0.7212,  2.1792,  0.1995]],\n",
      "\n",
      "         [[ 0.3273, -2.2635,  0.4489,  ..., -0.4586, -1.5076, -0.9967],\n",
      "          [-0.9123,  0.1471, -0.1034,  ..., -0.4045,  0.8159,  0.5562]],\n",
      "\n",
      "         [[-2.3148, -0.5869,  1.7037,  ..., -1.4093, -0.4310,  0.6948],\n",
      "          [ 0.0203, -0.4768,  1.1557,  ..., -0.1215,  0.0318, -1.3248]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.7403,  0.6778, -0.0372,  ...,  0.0411,  0.6922, -0.8735],\n",
      "          [-2.0086,  1.4971,  2.6926,  ..., -0.2250, -1.4670,  1.3012]],\n",
      "\n",
      "         [[-0.9572, -0.6238,  0.8255,  ...,  0.3552, -1.1478,  0.3682],\n",
      "          [-0.7753,  0.8552,  0.7477,  ..., -0.6661,  0.0840,  0.0840]],\n",
      "\n",
      "         [[-1.0275, -1.3546,  0.0771,  ..., -0.6231, -0.5347, -1.4864],\n",
      "          [-1.8713,  0.5198,  0.4933,  ..., -2.4443, -0.2543, -0.9387]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.3306, -0.7109,  0.3804,  ..., -0.0812, -0.8347,  0.1535],\n",
      "          [-0.3306, -0.7109,  0.3804,  ..., -0.0812, -0.8347,  0.1535],\n",
      "          [-0.3306, -0.7109,  0.3804,  ..., -0.0812, -0.8347,  0.1535],\n",
      "          ...,\n",
      "          [-0.3306, -0.7109,  0.3804,  ..., -0.0812, -0.8347,  0.1535],\n",
      "          [-0.3306, -0.7109,  0.3804,  ..., -0.0812, -0.8347,  0.1535],\n",
      "          [-0.3306, -0.7109,  0.3804,  ..., -0.0812, -0.8347,  0.1535]],\n",
      "\n",
      "         [[-0.7417,  0.3805,  0.8759,  ..., -0.7301,  0.2226,  0.0429],\n",
      "          [-0.7417,  0.3805,  0.8759,  ..., -0.7301,  0.2226,  0.0429],\n",
      "          [-0.7417,  0.3805,  0.8759,  ..., -0.7301,  0.2226,  0.0429],\n",
      "          ...,\n",
      "          [-0.7417,  0.3805,  0.8759,  ..., -0.7301,  0.2226,  0.0429],\n",
      "          [-0.7417,  0.3805,  0.8759,  ..., -0.7301,  0.2226,  0.0429],\n",
      "          [-0.7417,  0.3805,  0.8759,  ..., -0.7301,  0.2226,  0.0429]]],\n",
      "\n",
      "\n",
      "        [[[-0.2133, -0.5767,  0.5929,  ..., -0.2661, -0.5832,  0.0088],\n",
      "          [-0.2133, -0.5767,  0.5929,  ..., -0.2661, -0.5832,  0.0088],\n",
      "          [-0.2133, -0.5767,  0.5929,  ..., -0.2661, -0.5832,  0.0088],\n",
      "          ...,\n",
      "          [-0.2133, -0.5767,  0.5929,  ..., -0.2661, -0.5832,  0.0088],\n",
      "          [-0.2133, -0.5767,  0.5929,  ..., -0.2661, -0.5832,  0.0088],\n",
      "          [-0.2133, -0.5767,  0.5929,  ..., -0.2661, -0.5832,  0.0088]],\n",
      "\n",
      "         [[-0.9389,  0.8556,  1.0682,  ..., -0.7085,  0.1527, -0.0298],\n",
      "          [-0.9389,  0.8556,  1.0682,  ..., -0.7085,  0.1527, -0.0298],\n",
      "          [-0.9389,  0.8556,  1.0682,  ..., -0.7085,  0.1527, -0.0298],\n",
      "          ...,\n",
      "          [-0.9389,  0.8556,  1.0682,  ..., -0.7085,  0.1527, -0.0298],\n",
      "          [-0.9389,  0.8556,  1.0682,  ..., -0.7085,  0.1527, -0.0298],\n",
      "          [-0.9389,  0.8556,  1.0682,  ..., -0.7085,  0.1527, -0.0298]]]],\n",
      "       grad_fn=<ScaledDotProductFlashAttentionForCpuBackward0>)\n",
      "tensor([[[[-0.3306, -0.7109,  0.3804,  ..., -0.0812, -0.8347,  0.1535],\n",
      "          [-0.7417,  0.3805,  0.8759,  ..., -0.7301,  0.2226,  0.0429]],\n",
      "\n",
      "         [[-0.3306, -0.7109,  0.3804,  ..., -0.0812, -0.8347,  0.1535],\n",
      "          [-0.7417,  0.3805,  0.8759,  ..., -0.7301,  0.2226,  0.0429]],\n",
      "\n",
      "         [[-0.3306, -0.7109,  0.3804,  ..., -0.0812, -0.8347,  0.1535],\n",
      "          [-0.7417,  0.3805,  0.8759,  ..., -0.7301,  0.2226,  0.0429]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3306, -0.7109,  0.3804,  ..., -0.0812, -0.8347,  0.1535],\n",
      "          [-0.7417,  0.3805,  0.8759,  ..., -0.7301,  0.2226,  0.0429]],\n",
      "\n",
      "         [[-0.3306, -0.7109,  0.3804,  ..., -0.0812, -0.8347,  0.1535],\n",
      "          [-0.7417,  0.3805,  0.8759,  ..., -0.7301,  0.2226,  0.0429]],\n",
      "\n",
      "         [[-0.3306, -0.7109,  0.3804,  ..., -0.0812, -0.8347,  0.1535],\n",
      "          [-0.7417,  0.3805,  0.8759,  ..., -0.7301,  0.2226,  0.0429]]],\n",
      "\n",
      "\n",
      "        [[[-0.2133, -0.5767,  0.5929,  ..., -0.2661, -0.5832,  0.0088],\n",
      "          [-0.9389,  0.8556,  1.0682,  ..., -0.7085,  0.1527, -0.0298]],\n",
      "\n",
      "         [[-0.2133, -0.5767,  0.5929,  ..., -0.2661, -0.5832,  0.0088],\n",
      "          [-0.9389,  0.8556,  1.0682,  ..., -0.7085,  0.1527, -0.0298]],\n",
      "\n",
      "         [[-0.2133, -0.5767,  0.5929,  ..., -0.2661, -0.5832,  0.0088],\n",
      "          [-0.9389,  0.8556,  1.0682,  ..., -0.7085,  0.1527, -0.0298]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2133, -0.5767,  0.5929,  ..., -0.2661, -0.5832,  0.0088],\n",
      "          [-0.9389,  0.8556,  1.0682,  ..., -0.7085,  0.1527, -0.0298]],\n",
      "\n",
      "         [[-0.2133, -0.5767,  0.5929,  ..., -0.2661, -0.5832,  0.0088],\n",
      "          [-0.9389,  0.8556,  1.0682,  ..., -0.7085,  0.1527, -0.0298]],\n",
      "\n",
      "         [[-0.2133, -0.5767,  0.5929,  ..., -0.2661, -0.5832,  0.0088],\n",
      "          [-0.9389,  0.8556,  1.0682,  ..., -0.7085,  0.1527, -0.0298]]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[-1.0854,  0.7831],\n",
      "        [-0.4505,  0.2014]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: classifier\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
      "\n",
      "\n",
      "        [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]])\n",
      "tensor([[[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
      "\n",
      "\n",
      "        [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]])\n",
      "tensor([[[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]])\n",
      "tensor([[[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]])\n",
      "tensor([[[ 0.4399, -0.1289, -0.0193,  ..., -0.7220,  2.1669,  0.2116],\n",
      "         [ 0.4737, -1.2851,  0.7269,  ..., -1.3262, -0.0807,  0.7324],\n",
      "         [-1.0127, -1.2385,  1.0493,  ..., -0.2675,  0.9101,  0.6033],\n",
      "         ...,\n",
      "         [-0.8877,  0.2255, -0.0285,  ..., -0.8598, -1.6034,  0.4798],\n",
      "         [-1.3354, -0.2770, -0.4315,  ...,  0.1540, -0.0039,  0.0438],\n",
      "         [-0.9938, -1.2972,  0.0781,  ..., -2.4799, -0.2318, -0.8143]],\n",
      "\n",
      "        [[ 0.4399, -0.1289, -0.0193,  ..., -0.7220,  2.1669,  0.2116],\n",
      "         [ 0.3325, -2.1907,  0.4309,  ..., -0.4327,  0.8238,  0.6018],\n",
      "         [-2.2631, -0.5424,  1.6860,  ..., -0.1677,  0.0543, -1.1901],\n",
      "         ...,\n",
      "         [-0.6945,  0.7086, -0.0305,  ..., -0.2801, -1.4319,  1.3509],\n",
      "         [-0.9197, -0.5727,  0.8206,  ..., -0.7162,  0.1093,  0.1793],\n",
      "         [-0.9938, -1.2972,  0.0781,  ..., -2.4799, -0.2318, -0.8143]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[ 0.5355, -0.0675, -0.2999,  ...,  1.0623, -1.5882, -0.4372],\n",
      "         [ 0.0714, -0.1049, -0.6291,  ...,  0.3066, -1.2606, -0.1896],\n",
      "         [ 0.4521, -0.2345, -0.2281,  ...,  0.4841, -0.8775, -0.4523],\n",
      "         ...,\n",
      "         [ 0.1751,  0.3563, -0.3652,  ...,  0.5923, -0.7895, -0.6227],\n",
      "         [ 0.2784, -0.2019,  0.0694,  ...,  0.3389, -1.0946, -0.6864],\n",
      "         [ 0.2996, -0.0439, -0.7518,  ...,  0.3756, -0.8931, -0.4892]],\n",
      "\n",
      "        [[ 0.5355, -0.0675, -0.2999,  ...,  1.0623, -1.5882, -0.4372],\n",
      "         [ 0.0419, -0.1495, -0.2300,  ...,  0.4913, -1.2540, -0.3115],\n",
      "         [ 0.6684, -0.1476, -0.5027,  ...,  0.3221, -1.2428, -0.4057],\n",
      "         ...,\n",
      "         [ 0.4988,  0.1559, -0.2923,  ...,  0.6583, -0.7896, -0.5446],\n",
      "         [ 0.0049, -0.3911, -0.1698,  ...,  0.3138, -1.1344, -0.8804],\n",
      "         [ 0.2996, -0.0439, -0.7518,  ...,  0.3756, -0.8931, -0.4892]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.5355, -0.0675, -0.2999,  ...,  1.0623, -1.5882, -0.4372],\n",
      "         [ 0.0714, -0.1049, -0.6291,  ...,  0.3066, -1.2606, -0.1896],\n",
      "         [ 0.4521, -0.2345, -0.2281,  ...,  0.4841, -0.8775, -0.4523],\n",
      "         ...,\n",
      "         [ 0.1751,  0.3563, -0.3652,  ...,  0.5923, -0.7895, -0.6227],\n",
      "         [ 0.2784, -0.2019,  0.0694,  ...,  0.3389, -1.0946, -0.6864],\n",
      "         [ 0.2996, -0.0439, -0.7518,  ...,  0.3756, -0.8931, -0.4892]],\n",
      "\n",
      "        [[ 0.5355, -0.0675, -0.2999,  ...,  1.0623, -1.5882, -0.4372],\n",
      "         [ 0.0419, -0.1495, -0.2300,  ...,  0.4913, -1.2540, -0.3115],\n",
      "         [ 0.6684, -0.1476, -0.5027,  ...,  0.3221, -1.2428, -0.4057],\n",
      "         ...,\n",
      "         [ 0.4988,  0.1559, -0.2923,  ...,  0.6583, -0.7896, -0.5446],\n",
      "         [ 0.0049, -0.3911, -0.1698,  ...,  0.3138, -1.1344, -0.8804],\n",
      "         [ 0.2996, -0.0439, -0.7518,  ...,  0.3756, -0.8931, -0.4892]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 0.5355, -0.0675, -0.2999,  ...,  0.8728, -0.7396, -0.7421],\n",
      "          [ 1.1956, -0.1778, -0.9047,  ...,  1.0623, -1.5882, -0.4372]],\n",
      "\n",
      "         [[ 0.0714, -0.1049, -0.6291,  ...,  0.7638, -0.4328, -0.4335],\n",
      "          [ 0.4737, -0.0795, -0.4281,  ...,  0.3066, -1.2606, -0.1896]],\n",
      "\n",
      "         [[ 0.4521, -0.2345, -0.2281,  ...,  0.5133, -0.1947, -0.6254],\n",
      "          [-0.0835,  0.0678,  0.0493,  ...,  0.4841, -0.8775, -0.4523]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1751,  0.3563, -0.3652,  ...,  0.3062, -0.1877, -0.2744],\n",
      "          [ 0.2485, -0.0350, -0.0193,  ...,  0.5923, -0.7895, -0.6227]],\n",
      "\n",
      "         [[ 0.2784, -0.2019,  0.0694,  ...,  0.3501, -0.2056, -0.5703],\n",
      "          [ 0.3718, -0.0893, -0.2088,  ...,  0.3389, -1.0946, -0.6864]],\n",
      "\n",
      "         [[ 0.2996, -0.0439, -0.7518,  ...,  0.3823, -0.2261, -0.1500],\n",
      "          [ 0.5887, -0.8339, -0.2265,  ...,  0.3756, -0.8931, -0.4892]]],\n",
      "\n",
      "\n",
      "        [[[ 0.5355, -0.0675, -0.2999,  ...,  0.8728, -0.7396, -0.7421],\n",
      "          [ 1.1956, -0.1778, -0.9047,  ...,  1.0623, -1.5882, -0.4372]],\n",
      "\n",
      "         [[ 0.0419, -0.1495, -0.2300,  ...,  1.0737, -0.3505, -0.5324],\n",
      "          [ 0.4068,  0.0290, -0.6251,  ...,  0.4913, -1.2540, -0.3115]],\n",
      "\n",
      "         [[ 0.6684, -0.1476, -0.5027,  ...,  0.4181, -0.5559, -0.3499],\n",
      "          [ 0.0225,  0.0707, -0.2040,  ...,  0.3221, -1.2428, -0.4057]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4988,  0.1559, -0.2923,  ...,  0.3894, -0.2367, -0.1727],\n",
      "          [ 0.1865, -0.0686, -0.0321,  ...,  0.6583, -0.7896, -0.5446]],\n",
      "\n",
      "         [[ 0.0049, -0.3911, -0.1698,  ...,  0.1592, -0.3604, -0.4732],\n",
      "          [ 0.4345, -0.0262, -0.4430,  ...,  0.3138, -1.1344, -0.8804]],\n",
      "\n",
      "         [[ 0.2996, -0.0439, -0.7518,  ...,  0.3823, -0.2261, -0.1500],\n",
      "          [ 0.5887, -0.8339, -0.2265,  ...,  0.3756, -0.8931, -0.4892]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.3411, -0.7532,  0.3818,  ..., -0.4160,  0.1045, -0.4541],\n",
      "         [ 0.0063, -0.1287,  0.4656,  ..., -0.3665,  0.0151, -0.3303],\n",
      "         [ 0.4231,  0.0889, -0.1748,  ..., -0.6287, -0.2605, -0.7964],\n",
      "         ...,\n",
      "         [ 0.0740,  0.2039,  0.5227,  ..., -0.3911,  0.3457, -0.0500],\n",
      "         [ 0.2402, -0.0967,  0.0403,  ..., -0.4263,  0.0623, -0.3743],\n",
      "         [ 0.2773, -0.2832,  0.7327,  ..., -0.3733,  0.1086,  0.1582]],\n",
      "\n",
      "        [[ 0.3411, -0.7532,  0.3818,  ..., -0.4160,  0.1045, -0.4541],\n",
      "         [ 0.0649, -0.2349, -0.0103,  ..., -0.3154,  0.0891,  0.0852],\n",
      "         [ 0.5369,  0.2769,  0.1519,  ..., -0.5449, -0.1785, -0.6726],\n",
      "         ...,\n",
      "         [-0.0540, -0.1838,  0.5757,  ..., -0.1030,  0.3635, -0.2222],\n",
      "         [-0.2446, -0.6213, -0.2209,  ..., -0.5715, -0.1401, -0.2776],\n",
      "         [ 0.2773, -0.2832,  0.7327,  ..., -0.3733,  0.1086,  0.1582]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.3411, -0.7532,  0.3818,  ..., -0.4160,  0.1045, -0.4541],\n",
      "         [ 0.0063, -0.1287,  0.4656,  ..., -0.3665,  0.0151, -0.3303],\n",
      "         [ 0.4231,  0.0889, -0.1748,  ..., -0.6287, -0.2605, -0.7964],\n",
      "         ...,\n",
      "         [ 0.0740,  0.2039,  0.5227,  ..., -0.3911,  0.3457, -0.0500],\n",
      "         [ 0.2402, -0.0967,  0.0403,  ..., -0.4263,  0.0623, -0.3743],\n",
      "         [ 0.2773, -0.2832,  0.7327,  ..., -0.3733,  0.1086,  0.1582]],\n",
      "\n",
      "        [[ 0.3411, -0.7532,  0.3818,  ..., -0.4160,  0.1045, -0.4541],\n",
      "         [ 0.0649, -0.2349, -0.0103,  ..., -0.3154,  0.0891,  0.0852],\n",
      "         [ 0.5369,  0.2769,  0.1519,  ..., -0.5449, -0.1785, -0.6726],\n",
      "         ...,\n",
      "         [-0.0540, -0.1838,  0.5757,  ..., -0.1030,  0.3635, -0.2222],\n",
      "         [-0.2446, -0.6213, -0.2209,  ..., -0.5715, -0.1401, -0.2776],\n",
      "         [ 0.2773, -0.2832,  0.7327,  ..., -0.3733,  0.1086,  0.1582]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 0.3411, -0.7532,  0.3818,  ...,  0.2690,  0.2161,  0.0330],\n",
      "          [-0.2920,  0.2268,  0.5801,  ..., -0.4160,  0.1045, -0.4541]],\n",
      "\n",
      "         [[ 0.0063, -0.1287,  0.4656,  ..., -0.0027,  0.1118,  0.2368],\n",
      "          [ 0.0229,  0.0811,  0.3059,  ..., -0.3665,  0.0151, -0.3303]],\n",
      "\n",
      "         [[ 0.4231,  0.0889, -0.1748,  ...,  0.1443, -0.0530, -0.1326],\n",
      "          [ 0.2280,  0.0405,  0.1187,  ..., -0.6287, -0.2605, -0.7964]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0740,  0.2039,  0.5227,  ..., -0.4241,  0.6389,  0.1987],\n",
      "          [-0.0686,  0.0586,  0.2146,  ..., -0.3911,  0.3457, -0.0500]],\n",
      "\n",
      "         [[ 0.2402, -0.0967,  0.0403,  ...,  0.2317,  0.4075,  0.2734],\n",
      "          [ 0.5015, -0.0139,  0.3928,  ..., -0.4263,  0.0623, -0.3743]],\n",
      "\n",
      "         [[ 0.2773, -0.2832,  0.7327,  ..., -0.4619,  0.6072,  0.3008],\n",
      "          [-0.0837,  0.1545,  0.6450,  ..., -0.3733,  0.1086,  0.1582]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3411, -0.7532,  0.3818,  ...,  0.2690,  0.2161,  0.0330],\n",
      "          [-0.2920,  0.2268,  0.5801,  ..., -0.4160,  0.1045, -0.4541]],\n",
      "\n",
      "         [[ 0.0649, -0.2349, -0.0103,  ...,  0.3474,  0.5938, -0.1704],\n",
      "          [ 0.0828,  0.3909,  0.5522,  ..., -0.3154,  0.0891,  0.0852]],\n",
      "\n",
      "         [[ 0.5369,  0.2769,  0.1519,  ..., -0.2371,  0.2361,  0.1567],\n",
      "          [-0.0264, -0.2820, -0.1599,  ..., -0.5449, -0.1785, -0.6726]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0540, -0.1838,  0.5757,  ...,  0.0928,  1.1794, -0.0686],\n",
      "          [ 0.1348, -0.0950,  0.4700,  ..., -0.1030,  0.3635, -0.2222]],\n",
      "\n",
      "         [[-0.2446, -0.6213, -0.2209,  ...,  0.0220,  0.3821,  0.2678],\n",
      "          [ 0.1187,  0.3833,  0.6152,  ..., -0.5715, -0.1401, -0.2776]],\n",
      "\n",
      "         [[ 0.2773, -0.2832,  0.7327,  ..., -0.4619,  0.6072,  0.3008],\n",
      "          [-0.0837,  0.1545,  0.6450,  ..., -0.3733,  0.1086,  0.1582]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.2848,  0.0133,  0.2944,  ...,  0.1627, -0.2960,  0.0523],\n",
      "         [-0.0516, -0.0073, -0.1727,  ...,  0.0920, -0.6191, -0.3654],\n",
      "         [ 0.6742,  0.1142, -0.0643,  ..., -0.0606, -0.2419, -0.0149],\n",
      "         ...,\n",
      "         [ 0.3567,  0.2127,  0.2474,  ...,  0.1704, -0.1884,  0.1148],\n",
      "         [ 0.6993, -0.1791, -0.0792,  ..., -0.2351, -0.4122,  0.2759],\n",
      "         [-0.2252, -0.3539, -0.3699,  ...,  0.0477, -0.4384, -0.2319]],\n",
      "\n",
      "        [[-0.2848,  0.0133,  0.2944,  ...,  0.1627, -0.2960,  0.0523],\n",
      "         [ 0.1014, -0.1526,  0.2766,  ...,  0.1704, -0.5654, -0.3095],\n",
      "         [ 0.8153,  0.5225, -0.4410,  ...,  0.1153, -0.7423, -0.2427],\n",
      "         ...,\n",
      "         [ 0.1090, -0.1706,  0.1723,  ...,  0.2357, -0.1261, -0.3542],\n",
      "         [ 0.3857,  0.0030,  0.1033,  ...,  0.0958, -0.4121,  0.1341],\n",
      "         [-0.2252, -0.3539, -0.3699,  ...,  0.0477, -0.4384, -0.2319]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.2848,  0.0133,  0.2944,  ...,  0.1627, -0.2960,  0.0523],\n",
      "         [-0.0516, -0.0073, -0.1727,  ...,  0.0920, -0.6191, -0.3654],\n",
      "         [ 0.6742,  0.1142, -0.0643,  ..., -0.0606, -0.2419, -0.0149],\n",
      "         ...,\n",
      "         [ 0.3567,  0.2127,  0.2474,  ...,  0.1704, -0.1884,  0.1148],\n",
      "         [ 0.6993, -0.1791, -0.0792,  ..., -0.2351, -0.4122,  0.2759],\n",
      "         [-0.2252, -0.3539, -0.3699,  ...,  0.0477, -0.4384, -0.2319]],\n",
      "\n",
      "        [[-0.2848,  0.0133,  0.2944,  ...,  0.1627, -0.2960,  0.0523],\n",
      "         [ 0.1014, -0.1526,  0.2766,  ...,  0.1704, -0.5654, -0.3095],\n",
      "         [ 0.8153,  0.5225, -0.4410,  ...,  0.1153, -0.7423, -0.2427],\n",
      "         ...,\n",
      "         [ 0.1090, -0.1706,  0.1723,  ...,  0.2357, -0.1261, -0.3542],\n",
      "         [ 0.3857,  0.0030,  0.1033,  ...,  0.0958, -0.4121,  0.1341],\n",
      "         [-0.2252, -0.3539, -0.3699,  ...,  0.0477, -0.4384, -0.2319]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.2848,  0.0133,  0.2944,  ..., -0.0866,  0.2473,  0.2200],\n",
      "          [ 0.3274, -0.1107, -0.2222,  ...,  0.1627, -0.2960,  0.0523]],\n",
      "\n",
      "         [[-0.0516, -0.0073, -0.1727,  ...,  0.0962,  0.3208,  0.2101],\n",
      "          [-0.3615,  0.0756, -0.5151,  ...,  0.0920, -0.6191, -0.3654]],\n",
      "\n",
      "         [[ 0.6742,  0.1142, -0.0643,  ...,  0.8289, -0.1244, -0.5121],\n",
      "          [ 0.2243,  0.0483, -0.1498,  ..., -0.0606, -0.2419, -0.0149]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3567,  0.2127,  0.2474,  ...,  0.3345, -0.5654,  0.6881],\n",
      "          [-0.0579,  0.2528,  0.4284,  ...,  0.1704, -0.1884,  0.1148]],\n",
      "\n",
      "         [[ 0.6993, -0.1791, -0.0792,  ...,  0.7320,  0.1988,  0.0148],\n",
      "          [ 0.0798, -0.0086, -0.2200,  ..., -0.2351, -0.4122,  0.2759]],\n",
      "\n",
      "         [[-0.2252, -0.3539, -0.3699,  ...,  0.3107, -0.1830,  0.2064],\n",
      "          [-0.1287, -0.2328, -0.7505,  ...,  0.0477, -0.4384, -0.2319]]],\n",
      "\n",
      "\n",
      "        [[[-0.2848,  0.0133,  0.2944,  ..., -0.0866,  0.2473,  0.2200],\n",
      "          [ 0.3274, -0.1107, -0.2222,  ...,  0.1627, -0.2960,  0.0523]],\n",
      "\n",
      "         [[ 0.1014, -0.1526,  0.2766,  ...,  0.1503,  0.4208,  0.2120],\n",
      "          [-0.0164,  0.2578, -0.3759,  ...,  0.1704, -0.5654, -0.3095]],\n",
      "\n",
      "         [[ 0.8153,  0.5225, -0.4410,  ...,  0.7473, -0.0083, -0.1215],\n",
      "          [ 0.2113,  0.2522, -0.5443,  ...,  0.1153, -0.7423, -0.2427]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1090, -0.1706,  0.1723,  ...,  0.1552, -0.0901,  0.5992],\n",
      "          [ 0.0021, -0.2227,  0.0617,  ...,  0.2357, -0.1261, -0.3542]],\n",
      "\n",
      "         [[ 0.3857,  0.0030,  0.1033,  ...,  0.4130,  0.0457, -0.0592],\n",
      "          [ 0.0840, -0.0526, -0.3777,  ...,  0.0958, -0.4121,  0.1341]],\n",
      "\n",
      "         [[-0.2252, -0.3539, -0.3699,  ...,  0.3107, -0.1830,  0.2064],\n",
      "          [-0.1287, -0.2328, -0.7505,  ...,  0.0477, -0.4384, -0.2319]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 0.1888,  0.0703, -0.0939,  ...,  0.4341, -0.0780,  0.0546],\n",
      "          [ 0.1731,  0.0547, -0.0597,  ...,  0.3855, -0.0651,  0.1152],\n",
      "          [ 0.1699,  0.0411, -0.0461,  ...,  0.3645, -0.0604,  0.1491],\n",
      "          ...,\n",
      "          [ 0.1644,  0.0365, -0.0377,  ...,  0.3503, -0.0604,  0.1739],\n",
      "          [ 0.1568,  0.0367, -0.0446,  ...,  0.3490, -0.0542,  0.1628],\n",
      "          [ 0.1580,  0.0424, -0.0425,  ...,  0.3552, -0.0639,  0.1616]],\n",
      "\n",
      "         [[ 0.0919, -0.0055, -0.2216,  ...,  0.2363, -0.3632, -0.1791],\n",
      "          [ 0.0477,  0.0156, -0.2308,  ...,  0.1923, -0.3785, -0.1175],\n",
      "          [ 0.0280,  0.0124, -0.2394,  ...,  0.2182, -0.3893, -0.1299],\n",
      "          ...,\n",
      "          [ 0.0151,  0.0230, -0.2351,  ...,  0.2013, -0.3916, -0.1113],\n",
      "          [ 0.0270,  0.0182, -0.2377,  ...,  0.2042, -0.3903, -0.1129],\n",
      "          [ 0.0268,  0.0155, -0.2381,  ...,  0.2145, -0.3916, -0.1233]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2267,  0.0973,  0.2392,  ...,  0.0629,  0.1635,  0.2638],\n",
      "          [ 0.2166,  0.0858,  0.1707,  ...,  0.1201,  0.1264,  0.2417],\n",
      "          [ 0.2139,  0.0708,  0.1517,  ...,  0.1423,  0.1108,  0.2326],\n",
      "          ...,\n",
      "          [ 0.2170,  0.0778,  0.1218,  ...,  0.1626,  0.0968,  0.2236],\n",
      "          [ 0.2201,  0.0794,  0.1223,  ...,  0.1610,  0.0992,  0.2220],\n",
      "          [ 0.2243,  0.0850,  0.1297,  ...,  0.1575,  0.1013,  0.2262]],\n",
      "\n",
      "         [[ 0.0467, -0.1152, -0.2401,  ...,  0.4170, -0.3111, -0.2295],\n",
      "          [ 0.0352, -0.0908, -0.2657,  ...,  0.3736, -0.3391, -0.2012],\n",
      "          [ 0.0328, -0.0817, -0.2835,  ...,  0.3550, -0.3541, -0.2014],\n",
      "          ...,\n",
      "          [ 0.0304, -0.0727, -0.2836,  ...,  0.3454, -0.3632, -0.2008],\n",
      "          [ 0.0379, -0.0836, -0.2737,  ...,  0.3557, -0.3533, -0.2007],\n",
      "          [ 0.0309, -0.0843, -0.2787,  ...,  0.3537, -0.3493, -0.1970]]]],\n",
      "       grad_fn=<ScaledDotProductFlashAttentionForCpuBackward0>)\n",
      "tensor([[[[ 0.1888,  0.0703, -0.0939,  ...,  0.4341, -0.0780,  0.0546],\n",
      "          [ 0.0919, -0.0055, -0.2216,  ...,  0.2363, -0.3632, -0.1791]],\n",
      "\n",
      "         [[ 0.1731,  0.0547, -0.0597,  ...,  0.3855, -0.0651,  0.1152],\n",
      "          [ 0.0477,  0.0156, -0.2308,  ...,  0.1923, -0.3785, -0.1175]],\n",
      "\n",
      "         [[ 0.1699,  0.0411, -0.0461,  ...,  0.3645, -0.0604,  0.1491],\n",
      "          [ 0.0280,  0.0124, -0.2394,  ...,  0.2182, -0.3893, -0.1299]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1644,  0.0365, -0.0377,  ...,  0.3503, -0.0604,  0.1739],\n",
      "          [ 0.0151,  0.0230, -0.2351,  ...,  0.2013, -0.3916, -0.1113]],\n",
      "\n",
      "         [[ 0.1568,  0.0367, -0.0446,  ...,  0.3490, -0.0542,  0.1628],\n",
      "          [ 0.0270,  0.0182, -0.2377,  ...,  0.2042, -0.3903, -0.1129]],\n",
      "\n",
      "         [[ 0.1580,  0.0424, -0.0425,  ...,  0.3552, -0.0639,  0.1616],\n",
      "          [ 0.0268,  0.0155, -0.2381,  ...,  0.2145, -0.3916, -0.1233]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2267,  0.0973,  0.2392,  ...,  0.0629,  0.1635,  0.2638],\n",
      "          [ 0.0467, -0.1152, -0.2401,  ...,  0.4170, -0.3111, -0.2295]],\n",
      "\n",
      "         [[ 0.2166,  0.0858,  0.1707,  ...,  0.1201,  0.1264,  0.2417],\n",
      "          [ 0.0352, -0.0908, -0.2657,  ...,  0.3736, -0.3391, -0.2012]],\n",
      "\n",
      "         [[ 0.2139,  0.0708,  0.1517,  ...,  0.1423,  0.1108,  0.2326],\n",
      "          [ 0.0328, -0.0817, -0.2835,  ...,  0.3550, -0.3541, -0.2014]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2170,  0.0778,  0.1218,  ...,  0.1626,  0.0968,  0.2236],\n",
      "          [ 0.0304, -0.0727, -0.2836,  ...,  0.3454, -0.3632, -0.2008]],\n",
      "\n",
      "         [[ 0.2201,  0.0794,  0.1223,  ...,  0.1610,  0.0992,  0.2220],\n",
      "          [ 0.0379, -0.0836, -0.2737,  ...,  0.3557, -0.3533, -0.2007]],\n",
      "\n",
      "         [[ 0.2243,  0.0850,  0.1297,  ...,  0.1575,  0.1013,  0.2262],\n",
      "          [ 0.0309, -0.0843, -0.2787,  ...,  0.3537, -0.3493, -0.1970]]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.2965, -0.3144, -0.1336,  ..., -0.5515,  2.1020, -0.0853],\n",
      "         [ 0.3055, -1.4584,  0.5972,  ..., -1.1248, -0.1673,  0.4307],\n",
      "         [-1.1487, -1.3869,  0.9171,  ..., -0.0903,  0.7930,  0.3148],\n",
      "         ...,\n",
      "         [-1.0488,  0.0492, -0.1457,  ..., -0.6695, -1.6687,  0.1821],\n",
      "         [-1.4676, -0.4380, -0.5342,  ...,  0.3276, -0.0951, -0.2500],\n",
      "         [-1.1433, -1.4615, -0.0332,  ..., -2.2869, -0.3153, -1.1242]],\n",
      "\n",
      "        [[ 0.4589, -0.1316,  0.0194,  ..., -0.7212,  2.1792,  0.1995],\n",
      "         [ 0.3273, -2.2635,  0.4489,  ..., -0.4045,  0.8159,  0.5562],\n",
      "         [-2.3148, -0.5869,  1.7037,  ..., -0.1215,  0.0318, -1.3248],\n",
      "         ...,\n",
      "         [-0.7403,  0.6778, -0.0372,  ..., -0.2250, -1.4670,  1.3012],\n",
      "         [-0.9572, -0.6238,  0.8255,  ..., -0.6661,  0.0840,  0.0840],\n",
      "         [-1.0275, -1.3546,  0.0771,  ..., -2.4443, -0.2543, -0.9387]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.2965, -0.3144, -0.1336,  ..., -0.5515,  2.1020, -0.0853],\n",
      "         [ 0.3055, -1.4584,  0.5972,  ..., -1.1248, -0.1673,  0.4307],\n",
      "         [-1.1487, -1.3869,  0.9171,  ..., -0.0903,  0.7930,  0.3148],\n",
      "         ...,\n",
      "         [-1.0488,  0.0492, -0.1457,  ..., -0.6695, -1.6687,  0.1821],\n",
      "         [-1.4676, -0.4380, -0.5342,  ...,  0.3276, -0.0951, -0.2500],\n",
      "         [-1.1433, -1.4615, -0.0332,  ..., -2.2869, -0.3153, -1.1242]],\n",
      "\n",
      "        [[ 0.4589, -0.1316,  0.0194,  ..., -0.7212,  2.1792,  0.1995],\n",
      "         [ 0.3273, -2.2635,  0.4489,  ..., -0.4045,  0.8159,  0.5562],\n",
      "         [-2.3148, -0.5869,  1.7037,  ..., -0.1215,  0.0318, -1.3248],\n",
      "         ...,\n",
      "         [-0.7403,  0.6778, -0.0372,  ..., -0.2250, -1.4670,  1.3012],\n",
      "         [-0.9572, -0.6238,  0.8255,  ..., -0.6661,  0.0840,  0.0840],\n",
      "         [-1.0275, -1.3546,  0.0771,  ..., -2.4443, -0.2543, -0.9387]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[ 0.2965, -0.3144, -0.1336,  ..., -0.5515,  2.1020, -0.0853],\n",
      "         [ 0.3055, -1.4584,  0.5972,  ..., -1.1248, -0.1673,  0.4307],\n",
      "         [-1.1487, -1.3869,  0.9171,  ..., -0.0903,  0.7930,  0.3148],\n",
      "         ...,\n",
      "         [-1.0488,  0.0492, -0.1457,  ..., -0.6695, -1.6687,  0.1821],\n",
      "         [-1.4676, -0.4380, -0.5342,  ...,  0.3276, -0.0951, -0.2500],\n",
      "         [-1.1433, -1.4615, -0.0332,  ..., -2.2869, -0.3153, -1.1242]],\n",
      "\n",
      "        [[ 0.4589, -0.1316,  0.0194,  ..., -0.7212,  2.1792,  0.1995],\n",
      "         [ 0.3273, -2.2635,  0.4489,  ..., -0.4045,  0.8159,  0.5562],\n",
      "         [-2.3148, -0.5869,  1.7037,  ..., -0.1215,  0.0318, -1.3248],\n",
      "         ...,\n",
      "         [-0.7403,  0.6778, -0.0372,  ..., -0.2250, -1.4670,  1.3012],\n",
      "         [-0.9572, -0.6238,  0.8255,  ..., -0.6661,  0.0840,  0.0840],\n",
      "         [-1.0275, -1.3546,  0.0771,  ..., -2.4443, -0.2543, -0.9387]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[[ 0.2965, -0.3144, -0.1336,  ...,  0.3730,  0.4541,  0.5311],\n",
      "          [-0.4796,  0.2522,  1.0154,  ..., -0.5515,  2.1020, -0.0853]],\n",
      "\n",
      "         [[ 0.3055, -1.4584,  0.5972,  ..., -0.4977, -1.4432,  0.2002],\n",
      "          [-0.8983,  0.3068,  0.8379,  ..., -1.1248, -0.1673,  0.4307]],\n",
      "\n",
      "         [[-1.1487, -1.3869,  0.9171,  ..., -0.4039, -0.9157,  1.3295],\n",
      "          [-1.0111,  0.2708,  1.1939,  ..., -0.0903,  0.7930,  0.3148]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.0488,  0.0492, -0.1457,  ..., -0.3619, -0.2865, -0.2105],\n",
      "          [-1.4461,  1.8900,  1.2918,  ..., -0.6695, -1.6687,  0.1821]],\n",
      "\n",
      "         [[-1.4676, -0.4380, -0.5342,  ...,  0.0577, -1.6239,  0.0563],\n",
      "          [-0.3515,  1.2206,  1.5211,  ...,  0.3276, -0.0951, -0.2500]],\n",
      "\n",
      "         [[-1.1433, -1.4615, -0.0332,  ..., -0.5420, -0.6671, -1.4241],\n",
      "          [-1.7851,  0.5569,  0.6397,  ..., -2.2869, -0.3153, -1.1242]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4589, -0.1316,  0.0194,  ...,  0.2662,  0.6550,  0.4453],\n",
      "          [-0.5646,  0.1943,  0.8188,  ..., -0.7212,  2.1792,  0.1995]],\n",
      "\n",
      "         [[ 0.3273, -2.2635,  0.4489,  ..., -0.4586, -1.5076, -0.9967],\n",
      "          [-0.9123,  0.1471, -0.1034,  ..., -0.4045,  0.8159,  0.5562]],\n",
      "\n",
      "         [[-2.3148, -0.5869,  1.7037,  ..., -1.4093, -0.4310,  0.6948],\n",
      "          [ 0.0203, -0.4768,  1.1557,  ..., -0.1215,  0.0318, -1.3248]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.7403,  0.6778, -0.0372,  ...,  0.0411,  0.6922, -0.8735],\n",
      "          [-2.0086,  1.4971,  2.6926,  ..., -0.2250, -1.4670,  1.3012]],\n",
      "\n",
      "         [[-0.9572, -0.6238,  0.8255,  ...,  0.3552, -1.1478,  0.3682],\n",
      "          [-0.7753,  0.8552,  0.7477,  ..., -0.6661,  0.0840,  0.0840]],\n",
      "\n",
      "         [[-1.0275, -1.3546,  0.0771,  ..., -0.6231, -0.5347, -1.4864],\n",
      "          [-1.8713,  0.5198,  0.4933,  ..., -2.4443, -0.2543, -0.9387]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.3306, -0.7109,  0.3804,  ..., -0.0812, -0.8347,  0.1535],\n",
      "          [-0.3306, -0.7109,  0.3804,  ..., -0.0812, -0.8347,  0.1535],\n",
      "          [-0.3306, -0.7109,  0.3804,  ..., -0.0812, -0.8347,  0.1535],\n",
      "          ...,\n",
      "          [-0.3306, -0.7109,  0.3804,  ..., -0.0812, -0.8347,  0.1535],\n",
      "          [-0.3306, -0.7109,  0.3804,  ..., -0.0812, -0.8347,  0.1535],\n",
      "          [-0.3306, -0.7109,  0.3804,  ..., -0.0812, -0.8347,  0.1535]],\n",
      "\n",
      "         [[-0.7417,  0.3805,  0.8759,  ..., -0.7301,  0.2226,  0.0429],\n",
      "          [-0.7417,  0.3805,  0.8759,  ..., -0.7301,  0.2226,  0.0429],\n",
      "          [-0.7417,  0.3805,  0.8759,  ..., -0.7301,  0.2226,  0.0429],\n",
      "          ...,\n",
      "          [-0.7417,  0.3805,  0.8759,  ..., -0.7301,  0.2226,  0.0429],\n",
      "          [-0.7417,  0.3805,  0.8759,  ..., -0.7301,  0.2226,  0.0429],\n",
      "          [-0.7417,  0.3805,  0.8759,  ..., -0.7301,  0.2226,  0.0429]]],\n",
      "\n",
      "\n",
      "        [[[-0.2133, -0.5767,  0.5929,  ..., -0.2661, -0.5832,  0.0088],\n",
      "          [-0.2133, -0.5767,  0.5929,  ..., -0.2661, -0.5832,  0.0088],\n",
      "          [-0.2133, -0.5767,  0.5929,  ..., -0.2661, -0.5832,  0.0088],\n",
      "          ...,\n",
      "          [-0.2133, -0.5767,  0.5929,  ..., -0.2661, -0.5832,  0.0088],\n",
      "          [-0.2133, -0.5767,  0.5929,  ..., -0.2661, -0.5832,  0.0088],\n",
      "          [-0.2133, -0.5767,  0.5929,  ..., -0.2661, -0.5832,  0.0088]],\n",
      "\n",
      "         [[-0.9389,  0.8556,  1.0682,  ..., -0.7085,  0.1527, -0.0298],\n",
      "          [-0.9389,  0.8556,  1.0682,  ..., -0.7085,  0.1527, -0.0298],\n",
      "          [-0.9389,  0.8556,  1.0682,  ..., -0.7085,  0.1527, -0.0298],\n",
      "          ...,\n",
      "          [-0.9389,  0.8556,  1.0682,  ..., -0.7085,  0.1527, -0.0298],\n",
      "          [-0.9389,  0.8556,  1.0682,  ..., -0.7085,  0.1527, -0.0298],\n",
      "          [-0.9389,  0.8556,  1.0682,  ..., -0.7085,  0.1527, -0.0298]]]],\n",
      "       grad_fn=<ScaledDotProductFlashAttentionForCpuBackward0>)\n",
      "tensor([[[[-0.3306, -0.7109,  0.3804,  ..., -0.0812, -0.8347,  0.1535],\n",
      "          [-0.7417,  0.3805,  0.8759,  ..., -0.7301,  0.2226,  0.0429]],\n",
      "\n",
      "         [[-0.3306, -0.7109,  0.3804,  ..., -0.0812, -0.8347,  0.1535],\n",
      "          [-0.7417,  0.3805,  0.8759,  ..., -0.7301,  0.2226,  0.0429]],\n",
      "\n",
      "         [[-0.3306, -0.7109,  0.3804,  ..., -0.0812, -0.8347,  0.1535],\n",
      "          [-0.7417,  0.3805,  0.8759,  ..., -0.7301,  0.2226,  0.0429]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3306, -0.7109,  0.3804,  ..., -0.0812, -0.8347,  0.1535],\n",
      "          [-0.7417,  0.3805,  0.8759,  ..., -0.7301,  0.2226,  0.0429]],\n",
      "\n",
      "         [[-0.3306, -0.7109,  0.3804,  ..., -0.0812, -0.8347,  0.1535],\n",
      "          [-0.7417,  0.3805,  0.8759,  ..., -0.7301,  0.2226,  0.0429]],\n",
      "\n",
      "         [[-0.3306, -0.7109,  0.3804,  ..., -0.0812, -0.8347,  0.1535],\n",
      "          [-0.7417,  0.3805,  0.8759,  ..., -0.7301,  0.2226,  0.0429]]],\n",
      "\n",
      "\n",
      "        [[[-0.2133, -0.5767,  0.5929,  ..., -0.2661, -0.5832,  0.0088],\n",
      "          [-0.9389,  0.8556,  1.0682,  ..., -0.7085,  0.1527, -0.0298]],\n",
      "\n",
      "         [[-0.2133, -0.5767,  0.5929,  ..., -0.2661, -0.5832,  0.0088],\n",
      "          [-0.9389,  0.8556,  1.0682,  ..., -0.7085,  0.1527, -0.0298]],\n",
      "\n",
      "         [[-0.2133, -0.5767,  0.5929,  ..., -0.2661, -0.5832,  0.0088],\n",
      "          [-0.9389,  0.8556,  1.0682,  ..., -0.7085,  0.1527, -0.0298]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2133, -0.5767,  0.5929,  ..., -0.2661, -0.5832,  0.0088],\n",
      "          [-0.9389,  0.8556,  1.0682,  ..., -0.7085,  0.1527, -0.0298]],\n",
      "\n",
      "         [[-0.2133, -0.5767,  0.5929,  ..., -0.2661, -0.5832,  0.0088],\n",
      "          [-0.9389,  0.8556,  1.0682,  ..., -0.7085,  0.1527, -0.0298]],\n",
      "\n",
      "         [[-0.2133, -0.5767,  0.5929,  ..., -0.2661, -0.5832,  0.0088],\n",
      "          [-0.9389,  0.8556,  1.0682,  ..., -0.7085,  0.1527, -0.0298]]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[-1.0854,  0.7831],\n",
      "        [-0.4505,  0.2014]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 03:29, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.339200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.288100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.286100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.287200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.272400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.314200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 02:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressed (+ post-train 1 epoch) eval_accuracy: 0.8601\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import json\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "from chop.tools import get_tokenized_dataset, get_trainer\n",
    "from chop.tools.utils import deepsetattr\n",
    "import chop.passes as passes\n",
    "from chop import MaseGraph\n",
    "from chop.pipelines import CompressionPipeline\n",
    "\n",
    "from chop.nn.quantized.modules.linear import (\n",
    "    LinearInteger,\n",
    "    LinearMinifloatDenorm,\n",
    "    LinearMinifloatIEEE,\n",
    "    LinearLog,\n",
    "    LinearBlockFP,\n",
    "    LinearBlockMinifloat,\n",
    "    LinearBlockLog,\n",
    "    LinearBinary,\n",
    "    LinearBinaryScaling,\n",
    "    LinearBinaryResidualSign,\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# User config\n",
    "# -----------------------------\n",
    "checkpoint = \"prajjwal1/bert-tiny\"\n",
    "tokenizer_checkpoint = \"bert-base-uncased\"\n",
    "dataset_name = \"imdb\"\n",
    "\n",
    "lab3_out_dir = Path(\"/workspace/labs/lab3/outputs\")\n",
    "lab3_out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "lab2_out_dir = Path(\"/workspace/labs/lab2/outputs\")\n",
    "\n",
    "TOTAL_TRIALS = 12           # cap TOTAL COMPLETE trials per study\n",
    "search_epochs = 1\n",
    "\n",
    "pruning_sparsity = 0.5\n",
    "post_compress_epochs = 1\n",
    "\n",
    "HF_INPUT_NAMES = [\"input_ids\", \"attention_mask\", \"labels\"]\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# -----------------------------\n",
    "# Optuna persistence (IMPORTANT)\n",
    "# -----------------------------\n",
    "OPTUNA_DB = lab3_out_dir / \"optuna_tutorial6.db\"\n",
    "OPTUNA_STORAGE = f\"sqlite:///{OPTUNA_DB.as_posix()}\"\n",
    "\n",
    "# -----------------------------\n",
    "# Helpers\n",
    "# -----------------------------\n",
    "def cleanup(*objs):\n",
    "    for o in objs:\n",
    "        try:\n",
    "            del o\n",
    "        except Exception:\n",
    "            pass\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "def running_best(study: optuna.Study):\n",
    "    best = float(\"-inf\")\n",
    "    xs, ys = [], []\n",
    "    for t in sorted(study.trials, key=lambda x: x.number):\n",
    "        if t.value is None:\n",
    "            continue\n",
    "        best = max(best, float(t.value))\n",
    "        xs.append(len(xs) + 1)\n",
    "        ys.append(best)\n",
    "    return xs, ys\n",
    "\n",
    "\n",
    "def json_safe(obj):\n",
    "    if isinstance(obj, type):\n",
    "        return f\"{obj.__module__}.{obj.__qualname__}\"\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: json_safe(v) for k, v in obj.items()}\n",
    "    if isinstance(obj, (list, tuple)):\n",
    "        return [json_safe(v) for v in obj]\n",
    "    return obj\n",
    "\n",
    "\n",
    "def copy_linear_params(src: nn.Linear, dst: nn.Module):\n",
    "    \"\"\"Copy weights/bias if tensor shapes match.\"\"\"\n",
    "    with torch.no_grad():\n",
    "        try:\n",
    "            if hasattr(dst, \"weight\") and hasattr(src, \"weight\"):\n",
    "                if getattr(dst.weight, \"shape\", None) == src.weight.shape:\n",
    "                    dst.weight.copy_(src.weight)\n",
    "        except Exception:\n",
    "            pass\n",
    "        try:\n",
    "            if getattr(src, \"bias\", None) is not None and hasattr(dst, \"bias\"):\n",
    "                if getattr(dst.bias, \"shape\", None) == src.bias.shape:\n",
    "                    dst.bias.copy_(src.bias)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "\n",
    "def safe_best(study: optuna.Study):\n",
    "    trials = study.get_trials(deepcopy=False)\n",
    "    complete = [\n",
    "        t for t in trials\n",
    "        if t.state == optuna.trial.TrialState.COMPLETE and t.value is not None\n",
    "    ]\n",
    "    if not complete:\n",
    "        return None, None\n",
    "    best_t = max(complete, key=lambda t: float(t.value))\n",
    "    return float(best_t.value), json_safe(best_t.params)\n",
    "\n",
    "\n",
    "def n_complete(study: optuna.Study) -> int:\n",
    "    trials = study.get_trials(deepcopy=False)\n",
    "    return sum(t.state == optuna.trial.TrialState.COMPLETE for t in trials)\n",
    "\n",
    "\n",
    "def save_study_snapshot(study: optuna.Study, out_path: Path):\n",
    "    trials = study.get_trials(deepcopy=False)\n",
    "\n",
    "    complete = [\n",
    "        t for t in trials\n",
    "        if t.state == optuna.trial.TrialState.COMPLETE and t.value is not None\n",
    "    ]\n",
    "    if complete:\n",
    "        best_t = max(complete, key=lambda t: float(t.value))\n",
    "        best_value = float(best_t.value)\n",
    "        best_params = json_safe(best_t.params)\n",
    "        best_number = best_t.number\n",
    "    else:\n",
    "        best_value = None\n",
    "        best_params = None\n",
    "        best_number = None\n",
    "\n",
    "    snap = {\n",
    "        \"study_name\": study.study_name,\n",
    "        \"storage\": OPTUNA_STORAGE,\n",
    "        \"best_value\": best_value,\n",
    "        \"best_trial_number\": best_number,\n",
    "        \"best_params\": best_params,\n",
    "        \"n_trials\": len(trials),\n",
    "        \"n_complete\": sum(t.state == optuna.trial.TrialState.COMPLETE for t in trials),\n",
    "        \"n_fail\": sum(t.state == optuna.trial.TrialState.FAIL for t in trials),\n",
    "        \"n_pruned\": sum(t.state == optuna.trial.TrialState.PRUNED for t in trials),\n",
    "    }\n",
    "    out_path.write_text(json.dumps(snap, indent=2))\n",
    "\n",
    "\n",
    "def make_snapshot_callback(out_path: Path):\n",
    "    def _cb(study: optuna.Study, trial: optuna.Trial):\n",
    "        save_study_snapshot(study, out_path)\n",
    "    return _cb\n",
    "\n",
    "\n",
    "def optimize_to_total_complete(\n",
    "    study: optuna.Study,\n",
    "    objective,\n",
    "    total_complete_target: int,\n",
    "    **optimize_kwargs,\n",
    "):\n",
    "    remaining = max(0, total_complete_target - n_complete(study))\n",
    "    if remaining == 0:\n",
    "        print(f\"[skip] {study.study_name}: already has {n_complete(study)} COMPLETE trials\")\n",
    "        return\n",
    "    print(f\"[run]  {study.study_name}: running {remaining} more trial(s) to reach {total_complete_target} COMPLETE\")\n",
    "    study.optimize(objective, n_trials=remaining, **optimize_kwargs)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Dataset / tokenizer\n",
    "# -----------------------------\n",
    "dataset, tokenizer = get_tokenized_dataset(\n",
    "    dataset=dataset_name,\n",
    "    checkpoint=tokenizer_checkpoint,\n",
    "    return_tokenizer=True,\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Base model loading\n",
    "# -----------------------------\n",
    "base_model_path = lab2_out_dir / \"tutorial_5_best_model.pkl\"\n",
    "if base_model_path.exists():\n",
    "    import dill\n",
    "    with open(base_model_path, \"rb\") as f:\n",
    "        base_model = dill.load(f)\n",
    "else:\n",
    "    base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        checkpoint, num_labels=2\n",
    "    )\n",
    "\n",
    "try:\n",
    "    base_model.config.problem_type = \"single_label_classification\"\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# -----------------------------\n",
    "# Precision configs\n",
    "# -----------------------------\n",
    "INT_WIDTH_CHOICES = [8, 16, 32]\n",
    "INT_FRAC_CHOICES = [2, 4, 8]\n",
    "\n",
    "\n",
    "def make_integer_config_for_layer(trial: optuna.Trial, layer_name: str):\n",
    "    din_w = trial.suggest_categorical(f\"{layer_name}.data_in_width\", INT_WIDTH_CHOICES)\n",
    "    din_fw = trial.suggest_categorical(f\"{layer_name}.data_in_frac_width\", INT_FRAC_CHOICES)\n",
    "    w_w = trial.suggest_categorical(f\"{layer_name}.weight_width\", INT_WIDTH_CHOICES)\n",
    "    w_fw = trial.suggest_categorical(f\"{layer_name}.weight_frac_width\", INT_FRAC_CHOICES)\n",
    "    b_w = trial.suggest_categorical(f\"{layer_name}.bias_width\", INT_WIDTH_CHOICES)\n",
    "    b_fw = trial.suggest_categorical(f\"{layer_name}.bias_frac_width\", INT_FRAC_CHOICES)\n",
    "    return {\n",
    "        \"data_in_width\": din_w,\n",
    "        \"data_in_frac_width\": din_fw,\n",
    "        \"weight_width\": w_w,\n",
    "        \"weight_frac_width\": w_fw,\n",
    "        \"bias_width\": b_w,\n",
    "        \"bias_frac_width\": b_fw,\n",
    "        \"bypass\": False,\n",
    "    }\n",
    "\n",
    "\n",
    "def make_minifloat_config():\n",
    "    return {\n",
    "        \"data_in_width\": 8,\n",
    "        \"data_in_exponent_width\": 5,\n",
    "        \"data_in_exponent_bias\": 15,\n",
    "        \"weight_width\": 8,\n",
    "        \"weight_exponent_width\": 5,\n",
    "        \"weight_exponent_bias\": 15,\n",
    "        \"bias_width\": 8,\n",
    "        \"bias_exponent_width\": 5,\n",
    "        \"bias_exponent_bias\": 15,\n",
    "        \"bypass\": False,\n",
    "    }\n",
    "\n",
    "\n",
    "def make_log_config():\n",
    "    # for LinearLog (NOT blocklog)\n",
    "    return {\n",
    "        \"data_in_width\": 8,\n",
    "        \"data_in_exponent_bias\": 15,\n",
    "        \"weight_width\": 8,\n",
    "        \"weight_exponent_bias\": 15,\n",
    "        \"bias_width\": 8,\n",
    "        \"bias_exponent_bias\": 15,\n",
    "        \"bypass\": False,\n",
    "    }\n",
    "\n",
    "\n",
    "def make_blockfp_config(block_size: int = 32):\n",
    "    # block_fp_quantizer accepts list[int]; keep consistent.\n",
    "    return {\n",
    "        \"data_in_width\": 12,\n",
    "        \"data_in_exponent_width\": 8,\n",
    "        \"data_in_exponent_bias\": None,\n",
    "        \"data_in_block_size\": [int(block_size)],\n",
    "        \"data_in_skip_first_dim\": True,\n",
    "\n",
    "        \"weight_width\": 12,\n",
    "        \"weight_exponent_width\": 8,\n",
    "        \"weight_exponent_bias\": None,\n",
    "        \"weight_block_size\": [int(block_size)],\n",
    "\n",
    "        \"bias_width\": 12,\n",
    "        \"bias_exponent_width\": 8,\n",
    "        \"bias_exponent_bias\": None,\n",
    "        \"bias_block_size\": [int(block_size)],\n",
    "\n",
    "        \"bypass\": False,\n",
    "    }\n",
    "\n",
    "\n",
    "def make_blockminifloat_config(block_size: int = 32):\n",
    "    # block_minifloat quantizer expects *_block_size to be a sequence (list is safest)\n",
    "    return {\n",
    "        \"data_in_width\": 8,\n",
    "        \"data_in_exponent_width\": 5,\n",
    "        \"data_in_exponent_bias_width\": 4,\n",
    "        \"data_in_block_size\": [int(block_size)],\n",
    "        \"data_in_skip_first_dim\": True,\n",
    "\n",
    "        \"weight_width\": 8,\n",
    "        \"weight_exponent_width\": 5,\n",
    "        \"weight_exponent_bias_width\": 4,\n",
    "        \"weight_block_size\": [int(block_size)],\n",
    "\n",
    "        \"bias_width\": 8,\n",
    "        \"bias_exponent_width\": 5,\n",
    "        \"bias_exponent_bias_width\": 4,\n",
    "        \"bias_block_size\": [int(block_size)],\n",
    "\n",
    "        \"bypass\": False,\n",
    "    }\n",
    "\n",
    "\n",
    "def make_blocklog_config(block_size: int = 32, exponent_bias_width: int = 4):\n",
    "    # required by linearBlockLog: *_exponent_bias_width and *_block_size\n",
    "    return {\n",
    "        \"data_in_width\": 8,\n",
    "        \"data_in_exponent_bias_width\": int(exponent_bias_width),\n",
    "        \"data_in_block_size\": [int(block_size)],\n",
    "        \"data_in_skip_first_dim\": True,\n",
    "\n",
    "        \"weight_width\": 8,\n",
    "        \"weight_exponent_bias_width\": int(exponent_bias_width),\n",
    "        \"weight_block_size\": [int(block_size)],\n",
    "\n",
    "        \"bias_width\": 8,\n",
    "        \"bias_exponent_bias_width\": int(exponent_bias_width),\n",
    "        \"bias_block_size\": [int(block_size)],\n",
    "\n",
    "        \"bypass\": False,\n",
    "    }\n",
    "\n",
    "\n",
    "def make_binary_common_config(levels: int = 2):\n",
    "    return {\n",
    "        \"data_in_levels\": int(levels),\n",
    "        \"weight_levels\": int(levels),\n",
    "        \"bias_levels\": int(levels),\n",
    "        \"data_in_stochastic\": False,\n",
    "        \"weight_stochastic\": False,\n",
    "        \"bias_stochastic\": False,\n",
    "        \"data_in_bipolar\": True,\n",
    "        \"weight_bipolar\": True,\n",
    "        \"bias_bipolar\": True,\n",
    "        \"binary_training\": True,\n",
    "        \"data_in_residual_sign\": True,\n",
    "        \"bypass\": False,\n",
    "    }\n",
    "\n",
    "\n",
    "def config_for_precision(prec_name: str, trial: optuna.Trial | None, layer_name: str):\n",
    "    if prec_name == \"integer\":\n",
    "        assert trial is not None\n",
    "        return make_integer_config_for_layer(trial, layer_name)\n",
    "\n",
    "    if prec_name in (\"minifloat_ieee\", \"minifloat_denorm\"):\n",
    "        return make_minifloat_config()\n",
    "\n",
    "    if prec_name == \"log\":\n",
    "        return make_log_config()\n",
    "\n",
    "    if prec_name == \"blockfp\":\n",
    "        return make_blockfp_config(block_size=32)\n",
    "\n",
    "    if prec_name == \"blockminifloat\":\n",
    "        return make_blockminifloat_config(block_size=32)\n",
    "\n",
    "    if prec_name == \"blocklog\":\n",
    "        return make_blocklog_config(block_size=32, exponent_bias_width=4)\n",
    "\n",
    "    if prec_name in (\"binary\", \"binary_scaling\", \"binary_residual_sign\"):\n",
    "        return make_binary_common_config(levels=2)\n",
    "\n",
    "    return {\n",
    "        \"data_in_width\": 8,\n",
    "        \"weight_width\": 8,\n",
    "        \"bias_width\": 8,\n",
    "        \"bypass\": False,\n",
    "    }\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Precision families\n",
    "# -----------------------------\n",
    "PRECISIONS = [\n",
    "    (\"integer\", LinearInteger),\n",
    "    (\"minifloat_ieee\", LinearMinifloatIEEE),\n",
    "    (\"minifloat_denorm\", LinearMinifloatDenorm),\n",
    "    (\"log\", LinearLog),\n",
    "    (\"blockfp\", LinearBlockFP),\n",
    "    (\"blockminifloat\", LinearBlockMinifloat),\n",
    "    (\"blocklog\", LinearBlockLog),\n",
    "    (\"binary\", LinearBinary),\n",
    "    (\"binary_scaling\", LinearBinaryScaling),\n",
    "    (\"binary_residual_sign\", LinearBinaryResidualSign),\n",
    "]\n",
    "PREC_BY_NAME = {n: c for n, c in PRECISIONS}\n",
    "\n",
    "\n",
    "def construct_model_for_precision(trial: optuna.Trial, prec_name: str):\n",
    "    prec_cls = PREC_BY_NAME[prec_name]\n",
    "    trial_model = deepcopy(base_model)\n",
    "\n",
    "    for name, layer in trial_model.named_modules():\n",
    "        if not isinstance(layer, nn.Linear):\n",
    "            continue\n",
    "\n",
    "        choice = trial.suggest_categorical(f\"{name}_type\", (\"fp\", prec_name))\n",
    "        if choice == \"fp\":\n",
    "            continue\n",
    "\n",
    "        cfg = config_for_precision(prec_name, trial, name)\n",
    "        kwargs = {\n",
    "            \"in_features\": layer.in_features,\n",
    "            \"out_features\": layer.out_features,\n",
    "            \"bias\": (layer.bias is not None),\n",
    "            \"config\": cfg,\n",
    "        }\n",
    "\n",
    "        new_layer = prec_cls(**kwargs)\n",
    "        copy_linear_params(layer, new_layer)\n",
    "        deepsetattr(trial_model, name, new_layer)\n",
    "\n",
    "    try:\n",
    "        trial_model.config.problem_type = \"single_label_classification\"\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    return trial_model\n",
    "\n",
    "\n",
    "# Some precisions fail in backward (or are meant as forward-only). We evaluate only.\n",
    "EVAL_ONLY_PRECS = {\"blockminifloat\", \"binary_residual_sign\"}\n",
    "\n",
    "\n",
    "def make_objective_for_precision(prec_name: str):\n",
    "    def objective(trial: optuna.Trial):\n",
    "        trainer = None\n",
    "        model = None\n",
    "        try:\n",
    "            model = construct_model_for_precision(trial, prec_name).to(device)\n",
    "            trainer = get_trainer(\n",
    "                model=model,\n",
    "                tokenized_dataset=dataset,\n",
    "                tokenizer=tokenizer,\n",
    "                evaluate_metric=\"accuracy\",\n",
    "                num_train_epochs=(0 if prec_name in EVAL_ONLY_PRECS else search_epochs),\n",
    "            )\n",
    "            if prec_name not in EVAL_ONLY_PRECS:\n",
    "                trainer.train()\n",
    "            ev = trainer.evaluate()\n",
    "            return float(ev[\"eval_accuracy\"])\n",
    "        finally:\n",
    "            cleanup(trainer, model)\n",
    "    return objective\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Task 1: Integer search (CAP at 12 COMPLETE, otherwise skip)\n",
    "# -----------------------------\n",
    "print(\"=== Task 1: Integer per-layer width/frac search ===\")\n",
    "sampler = optuna.samplers.TPESampler(seed=0)\n",
    "study_int = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    sampler=sampler,\n",
    "    study_name=\"tutorial6_integer_layerwise_widthfrac\",\n",
    "    storage=OPTUNA_STORAGE,\n",
    "    load_if_exists=True,\n",
    ")\n",
    "\n",
    "optimize_to_total_complete(\n",
    "    study_int,\n",
    "    make_objective_for_precision(\"integer\"),\n",
    "    total_complete_target=TOTAL_TRIALS,\n",
    "    callbacks=[make_snapshot_callback(lab3_out_dir / \"task1_integer_snapshot.json\")],\n",
    "    catch=(Exception,),\n",
    ")\n",
    "\n",
    "x1, y1 = running_best(study_int)\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(x1, y1, marker=\"o\")\n",
    "plt.xlabel(\"Number of trials\")\n",
    "plt.ylabel(\"Running best accuracy\")\n",
    "plt.title(\"Task 1: Integer layer-wise widths (Running Best)\")\n",
    "plt.grid(True)\n",
    "task1_plot = lab3_out_dir / \"tutorial6_task1_integer_layerwise_running_best.png\"\n",
    "plt.savefig(task1_plot)\n",
    "plt.show()\n",
    "\n",
    "bv, bp = safe_best(study_int)\n",
    "print(\"Task 1 best:\", bv)\n",
    "print(\"Saved:\", task1_plot)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Task 2: Compare precision families (CAP each at 12 COMPLETE, otherwise skip)\n",
    "# -----------------------------\n",
    "print(\"\\n=== Task 2: Compare precision families ===\")\n",
    "studies = {}\n",
    "\n",
    "for prec_name, _ in PRECISIONS:\n",
    "    print(f\"\\n-- Running study for precision: {prec_name}\")\n",
    "    sampler = optuna.samplers.TPESampler(seed=0)\n",
    "    st = optuna.create_study(\n",
    "        direction=\"maximize\",\n",
    "        sampler=sampler,\n",
    "        study_name=f\"tutorial6_prec_{prec_name}\",\n",
    "        storage=OPTUNA_STORAGE,\n",
    "        load_if_exists=True,\n",
    "    )\n",
    "\n",
    "    snap_path = lab3_out_dir / f\"task2_{prec_name}_snapshot.json\"\n",
    "\n",
    "    optimize_to_total_complete(\n",
    "        st,\n",
    "        make_objective_for_precision(prec_name),\n",
    "        total_complete_target=TOTAL_TRIALS,\n",
    "        catch=(Exception,),\n",
    "        callbacks=[make_snapshot_callback(snap_path)],\n",
    "    )\n",
    "\n",
    "    studies[prec_name] = st\n",
    "\n",
    "    bv2, _ = safe_best(st)\n",
    "    if bv2 is not None:\n",
    "        print(f\"Best for {prec_name}: {bv2:.4f}\")\n",
    "    else:\n",
    "        print(f\"Best for {prec_name}: None (no COMPLETE trials)\")\n",
    "    print(\"Snapshot:\", snap_path)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "for prec_name, st in studies.items():\n",
    "    xs, ys = running_best(st)\n",
    "    if xs:\n",
    "        plt.plot(xs, ys, label=prec_name)\n",
    "plt.xlabel(\"Number of trials\")\n",
    "plt.ylabel(\"Running best accuracy\")\n",
    "plt.title(\"Task 2: Running Best Accuracy per Precision\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "task2_plot = lab3_out_dir / \"tutorial6_task2_all_precisions_running_best.png\"\n",
    "plt.savefig(task2_plot)\n",
    "plt.show()\n",
    "\n",
    "print(\"Saved:\", task2_plot)\n",
    "\n",
    "summary = {\n",
    "    \"optuna_storage\": OPTUNA_STORAGE,\n",
    "    \"task1_integer_layerwise\": {\n",
    "        \"best_value\": (bv),\n",
    "        \"best_params\": (bp),\n",
    "        \"n_trials_total\": len(study_int.trials),\n",
    "        \"n_complete\": n_complete(study_int),\n",
    "        \"search_epochs\": search_epochs,\n",
    "        \"sampler\": \"TPESampler\",\n",
    "        \"plot\": str(task1_plot),\n",
    "    },\n",
    "    \"task2_all_precisions\": {\n",
    "        \"target_complete_each\": TOTAL_TRIALS,\n",
    "        \"search_epochs\": search_epochs,\n",
    "        \"sampler\": \"TPESampler\",\n",
    "        \"plot\": str(task2_plot),\n",
    "        \"best_by_precision\": {\n",
    "            name: {\n",
    "                \"best_value\": safe_best(st)[0],\n",
    "                \"best_params\": safe_best(st)[1],\n",
    "                \"n_trials_total\": len(st.trials),\n",
    "                \"n_complete\": n_complete(st),\n",
    "            }\n",
    "            for name, st in studies.items()\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "summary_path = lab3_out_dir / \"tutorial6_impl_tasks_summary.json\"\n",
    "summary_path.write_text(json.dumps(summary, indent=2))\n",
    "print(\"Saved summary JSON:\", summary_path)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Optional: Compression pass\n",
    "# -----------------------------\n",
    "BASE_QUANTIZATION_CONFIG = {\n",
    "    \"by\": \"type\",\n",
    "    \"default\": {\"config\": {\"name\": None}},\n",
    "    \"linear\": {\n",
    "        \"config\": {\n",
    "            \"name\": \"integer\",\n",
    "            \"data_in_width\": 8,\n",
    "            \"data_in_frac_width\": 4,\n",
    "            \"weight_width\": 8,\n",
    "            \"weight_frac_width\": 4,\n",
    "            \"bias_width\": 8,\n",
    "            \"bias_frac_width\": 4,\n",
    "        }\n",
    "    },\n",
    "}\n",
    "BASE_PRUNING_CONFIG = {\n",
    "    \"weight\": {\"sparsity\": pruning_sparsity, \"method\": \"l1-norm\", \"scope\": \"local\"},\n",
    "    \"activation\": {\"sparsity\": pruning_sparsity, \"method\": \"l1-norm\", \"scope\": \"local\"},\n",
    "}\n",
    "\n",
    "\n",
    "def compress_with_mase(model_cpu: nn.Module):\n",
    "    mg = MaseGraph(model_cpu, hf_input_names=HF_INPUT_NAMES)\n",
    "    mg, _ = passes.init_metadata_analysis_pass(mg)\n",
    "    mg, _ = passes.add_common_metadata_analysis_pass(mg)\n",
    "\n",
    "    qcfg = deepcopy(BASE_QUANTIZATION_CONFIG)\n",
    "    pcfg = deepcopy(BASE_PRUNING_CONFIG)\n",
    "\n",
    "    pipe = CompressionPipeline()\n",
    "    mg, _ = pipe(\n",
    "        mg,\n",
    "        pass_args={\n",
    "            \"quantize_transform_pass\": qcfg,\n",
    "            \"prune_transform_pass\": pcfg,\n",
    "        },\n",
    "    )\n",
    "    return mg\n",
    "\n",
    "\n",
    "print(\"\\n=== Optional: Compression on Task 1 best model ===\")\n",
    "if bp is None:\n",
    "    print(\"Skipping compression: Task 1 has no COMPLETE trials / no best params.\")\n",
    "else:\n",
    "    fixed_trial = optuna.trial.FixedTrial(bp)\n",
    "    best_model_task1 = construct_model_for_precision(fixed_trial, \"integer\")\n",
    "\n",
    "    mg_a = None\n",
    "    trainer_a = None\n",
    "    try:\n",
    "        mg_a = compress_with_mase(deepcopy(best_model_task1).to(\"cpu\"))\n",
    "        model_a = mg_a.model.to(device)\n",
    "        trainer_a = get_trainer(\n",
    "            model=model_a,\n",
    "            tokenized_dataset=dataset,\n",
    "            tokenizer=tokenizer,\n",
    "            evaluate_metric=\"accuracy\",\n",
    "            num_train_epochs=0,\n",
    "        )\n",
    "        ev_a = trainer_a.evaluate()\n",
    "        acc_a = float(ev_a[\"eval_accuracy\"])\n",
    "        print(f\"Compressed (no post-train) eval_accuracy: {acc_a:.4f}\")\n",
    "    finally:\n",
    "        cleanup(trainer_a, mg_a)\n",
    "\n",
    "    mg_b = None\n",
    "    trainer_b = None\n",
    "    try:\n",
    "        mg_b = compress_with_mase(deepcopy(best_model_task1).to(\"cpu\"))\n",
    "        model_b = mg_b.model.to(device)\n",
    "        trainer_b = get_trainer(\n",
    "            model=model_b,\n",
    "            tokenized_dataset=dataset,\n",
    "            tokenizer=tokenizer,\n",
    "            evaluate_metric=\"accuracy\",\n",
    "            num_train_epochs=post_compress_epochs,\n",
    "        )\n",
    "        trainer_b.train()\n",
    "        ev_b = trainer_b.evaluate()\n",
    "        acc_b = float(ev_b[\"eval_accuracy\"])\n",
    "        print(f\"Compressed (+ post-train {post_compress_epochs} epoch) eval_accuracy: {acc_b:.4f}\")\n",
    "    finally:\n",
    "        cleanup(trainer_b, mg_b)\n",
    "\n",
    "print(\"\\nDone.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mase-dev)",
   "language": "python",
   "name": "mase-dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
