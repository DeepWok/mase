{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 4: Unstructured Pruning on Bert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pruning is a technique used to reduce the size and complexity of neural networks by removing unnecessary parameters (weights and connections) or structural components (neurons, filters, or layers). The goal is to create a smaller, more efficient model that maintains most of the original model's performance. The following benefits can be seen from pruning neural networks:\n",
    "\n",
    "- **Reduce model size**: Deep neural networks often have millions of parameters, leading to large storage requirements.\n",
    "\n",
    "- **Decrease inference time**: Fewer parameters mean fewer computations, resulting in faster predictions.\n",
    "\n",
    "- **Improve generalization**: Removing unnecessary connections can help prevent overfitting.\n",
    "\n",
    "- **Energy efficiency**: Smaller models require less energy to run, which is crucial for edge devices and mobile applications.\n",
    "\n",
    "Structured pruning removes entire structures (e.g., channels, filters, or layers) from the network, while unstructured pruning removes individual weights or connections from the network, regardless of their location. In this tutorial, we'll build on top of Tutorial 3 by taking the quantized Bert model and running Mase's unstructured pruning pass. After pruning, we'll run further fine tuning iterations to retain sequence classification accuracy in the pruned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"prajjwal1/bert-tiny\"\n",
    "tokenizer_checkpoint = \"bert-base-uncased\"\n",
    "dataset_name = \"imdb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are starting from scratch, you can create a MaseGraph for Bert by running the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "`past_key_values` were not specified as input names, but model.config.use_cache = True. Setting model.config.use_cache = False.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mGetting dummy input for prajjwal1/bert-tiny.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
      "\n",
      "\n",
      "        [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]])\n",
      "tensor([[[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
      "\n",
      "\n",
      "        [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]])\n",
      "tensor([[[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]])\n",
      "tensor([[[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]])\n",
      "tensor([[[ 0.7973,  0.0109, -8.8405,  ...,  1.4170,  0.1046, -0.1551],\n",
      "         [-1.1766,  1.2879, -1.0986,  ...,  0.4749, -0.5899,  0.8746],\n",
      "         [-2.0560,  0.7748, -0.8909,  ..., -0.4034,  0.5352, -1.3657],\n",
      "         ...,\n",
      "         [ 0.2317, -0.7896,  0.9634,  ..., -0.8037,  0.4834, -0.5868],\n",
      "         [ 0.0243, -1.0235, -1.2771,  ..., -2.2378,  1.8530,  0.1558],\n",
      "         [-1.3637,  0.7055, -0.2177,  ...,  0.3557, -0.3971, -0.3107]],\n",
      "\n",
      "        [[ 0.7973,  0.0109, -8.8405,  ...,  1.4170,  0.1046, -0.1551],\n",
      "         [-2.6940,  0.6198, -0.4564,  ..., -1.4367, -1.5705, -3.1260],\n",
      "         [-1.7524,  0.8535, -0.2155,  ..., -0.5222, -1.2430, -1.7199],\n",
      "         ...,\n",
      "         [-0.0347,  0.7446,  1.4462,  ..., -1.1578, -2.6197,  0.2612],\n",
      "         [ 2.4334, -0.3068,  0.8250,  ...,  0.1475,  0.1790,  2.2907],\n",
      "         [-1.3637,  0.7055, -0.2177,  ...,  0.3557, -0.3971, -0.3107]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[ 9.7740e-01,  2.5482e-03, -5.2921e-01,  ...,  1.4757e-01,\n",
      "           1.8900e-01,  2.8282e-01],\n",
      "         [-3.5020e-02, -6.1047e-02, -1.0465e-01,  ..., -8.1892e-01,\n",
      "           1.1978e+00,  2.1808e+00],\n",
      "         [ 4.3982e-01, -1.9602e+00, -6.8830e-01,  ..., -6.3025e-01,\n",
      "          -1.5967e-01,  1.3284e+00],\n",
      "         ...,\n",
      "         [ 1.4783e+00,  1.0907e-01, -1.5222e+00,  ..., -3.0983e-01,\n",
      "          -1.2971e-01,  1.1265e+00],\n",
      "         [ 1.5890e+00, -1.6859e+00,  7.8703e-01,  ..., -1.3174e+00,\n",
      "           2.2258e-01,  8.8157e-01],\n",
      "         [-3.7517e-01,  1.5191e+00, -2.6796e-01,  ..., -1.6159e+00,\n",
      "           7.2677e-02,  1.1724e-01]],\n",
      "\n",
      "        [[ 9.7740e-01,  2.5482e-03, -5.2921e-01,  ...,  1.4757e-01,\n",
      "           1.8900e-01,  2.8282e-01],\n",
      "         [-4.4781e-01, -7.9224e-01, -2.1741e+00,  ..., -5.9181e-01,\n",
      "           1.4373e+00,  2.4267e+00],\n",
      "         [-2.5942e-01,  9.7163e-01, -3.2928e+00,  ..., -5.9773e-01,\n",
      "          -3.0482e-01,  1.4038e+00],\n",
      "         ...,\n",
      "         [ 5.1575e-02,  3.5218e-01, -3.8926e-01,  ..., -1.1508e+00,\n",
      "           7.5490e-01,  8.2911e-01],\n",
      "         [ 1.6107e+00,  6.8170e-02,  9.2537e-01,  ..., -1.5233e+00,\n",
      "          -6.0733e-01,  3.3097e-01],\n",
      "         [-3.7517e-01,  1.5191e+00, -2.6796e-01,  ..., -1.6159e+00,\n",
      "           7.2677e-02,  1.1724e-01]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 9.7740e-01,  2.5482e-03, -5.2921e-01,  ...,  1.4757e-01,\n",
      "           1.8900e-01,  2.8282e-01],\n",
      "         [-3.5020e-02, -6.1047e-02, -1.0465e-01,  ..., -8.1892e-01,\n",
      "           1.1978e+00,  2.1808e+00],\n",
      "         [ 4.3982e-01, -1.9602e+00, -6.8830e-01,  ..., -6.3025e-01,\n",
      "          -1.5967e-01,  1.3284e+00],\n",
      "         ...,\n",
      "         [ 1.4783e+00,  1.0907e-01, -1.5222e+00,  ..., -3.0983e-01,\n",
      "          -1.2971e-01,  1.1265e+00],\n",
      "         [ 1.5890e+00, -1.6859e+00,  7.8703e-01,  ..., -1.3174e+00,\n",
      "           2.2258e-01,  8.8157e-01],\n",
      "         [-3.7517e-01,  1.5191e+00, -2.6796e-01,  ..., -1.6159e+00,\n",
      "           7.2677e-02,  1.1724e-01]],\n",
      "\n",
      "        [[ 9.7740e-01,  2.5482e-03, -5.2921e-01,  ...,  1.4757e-01,\n",
      "           1.8900e-01,  2.8282e-01],\n",
      "         [-4.4781e-01, -7.9224e-01, -2.1741e+00,  ..., -5.9181e-01,\n",
      "           1.4373e+00,  2.4267e+00],\n",
      "         [-2.5942e-01,  9.7163e-01, -3.2928e+00,  ..., -5.9773e-01,\n",
      "          -3.0482e-01,  1.4038e+00],\n",
      "         ...,\n",
      "         [ 5.1575e-02,  3.5218e-01, -3.8926e-01,  ..., -1.1508e+00,\n",
      "           7.5490e-01,  8.2911e-01],\n",
      "         [ 1.6107e+00,  6.8170e-02,  9.2537e-01,  ..., -1.5233e+00,\n",
      "          -6.0733e-01,  3.3097e-01],\n",
      "         [-3.7517e-01,  1.5191e+00, -2.6796e-01,  ..., -1.6159e+00,\n",
      "           7.2677e-02,  1.1724e-01]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 9.7740e-01,  2.5482e-03, -5.2921e-01,  ..., -5.2614e-01,\n",
      "           -3.5687e-01, -2.6793e-01],\n",
      "          [ 2.0335e-01, -5.4534e-01,  3.0686e-01,  ...,  1.4757e-01,\n",
      "            1.8900e-01,  2.8282e-01]],\n",
      "\n",
      "         [[-3.5020e-02, -6.1047e-02, -1.0465e-01,  ..., -2.0138e+00,\n",
      "            4.5529e-01, -7.8171e-01],\n",
      "          [ 1.1969e+00,  1.6337e+00,  2.5047e-01,  ..., -8.1892e-01,\n",
      "            1.1978e+00,  2.1808e+00]],\n",
      "\n",
      "         [[ 4.3982e-01, -1.9602e+00, -6.8830e-01,  ..., -2.2501e-01,\n",
      "            7.2290e-02, -1.8290e+00],\n",
      "          [ 8.9952e-01,  1.0029e+00,  7.4536e-04,  ..., -6.3025e-01,\n",
      "           -1.5967e-01,  1.3284e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4783e+00,  1.0907e-01, -1.5222e+00,  ...,  1.1867e+00,\n",
      "           -1.3561e+00,  6.5158e-01],\n",
      "          [ 9.5466e-01,  4.5887e-01,  7.8078e-01,  ..., -3.0983e-01,\n",
      "           -1.2971e-01,  1.1265e+00]],\n",
      "\n",
      "         [[ 1.5890e+00, -1.6859e+00,  7.8703e-01,  ...,  6.5467e-01,\n",
      "           -6.8451e-01,  6.5081e-01],\n",
      "          [ 7.0729e-01,  1.4499e+00, -1.5089e-01,  ..., -1.3174e+00,\n",
      "            2.2258e-01,  8.8157e-01]],\n",
      "\n",
      "         [[-3.7517e-01,  1.5191e+00, -2.6796e-01,  ...,  3.3130e-01,\n",
      "           -3.2756e-01, -6.3130e-01],\n",
      "          [ 8.6773e-01,  2.0996e-01, -3.4332e-01,  ..., -1.6159e+00,\n",
      "            7.2677e-02,  1.1724e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 9.7740e-01,  2.5482e-03, -5.2921e-01,  ..., -5.2614e-01,\n",
      "           -3.5687e-01, -2.6793e-01],\n",
      "          [ 2.0335e-01, -5.4534e-01,  3.0686e-01,  ...,  1.4757e-01,\n",
      "            1.8900e-01,  2.8282e-01]],\n",
      "\n",
      "         [[-4.4781e-01, -7.9224e-01, -2.1741e+00,  ...,  1.7508e+00,\n",
      "           -3.6708e-01, -1.3251e+00],\n",
      "          [ 7.9208e-01, -1.3537e-01,  2.3756e-01,  ..., -5.9181e-01,\n",
      "            1.4373e+00,  2.4267e+00]],\n",
      "\n",
      "         [[-2.5942e-01,  9.7163e-01, -3.2928e+00,  ..., -9.6646e-01,\n",
      "           -4.8876e-01, -1.4426e+00],\n",
      "          [ 1.0250e+00, -6.9093e-01, -1.2734e+00,  ..., -5.9773e-01,\n",
      "           -3.0482e-01,  1.4038e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.1575e-02,  3.5218e-01, -3.8926e-01,  ..., -1.2252e-02,\n",
      "            1.0394e+00,  4.2402e-01],\n",
      "          [-4.7386e-01,  2.6401e+00,  1.7024e+00,  ..., -1.1508e+00,\n",
      "            7.5490e-01,  8.2911e-01]],\n",
      "\n",
      "         [[ 1.6107e+00,  6.8170e-02,  9.2537e-01,  ..., -6.1665e-01,\n",
      "            2.7627e-01, -1.2083e+00],\n",
      "          [ 9.3395e-01, -9.7541e-01, -2.5442e-02,  ..., -1.5233e+00,\n",
      "           -6.0733e-01,  3.3097e-01]],\n",
      "\n",
      "         [[-3.7517e-01,  1.5191e+00, -2.6796e-01,  ...,  3.3130e-01,\n",
      "           -3.2756e-01, -6.3130e-01],\n",
      "          [ 8.6773e-01,  2.0996e-01, -3.4332e-01,  ..., -1.6159e+00,\n",
      "            7.2677e-02,  1.1724e-01]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.1709,  0.5230, -0.8713,  ..., -1.3382,  0.5892,  0.4026],\n",
      "         [-0.5842,  0.9588,  1.5642,  ..., -1.0731, -0.7330,  0.3132],\n",
      "         [-0.8601, -1.3756,  0.5042,  ..., -0.0476,  0.2650,  1.2150],\n",
      "         ...,\n",
      "         [ 0.0520,  1.1719, -1.5471,  ..., -0.7894,  0.1419,  1.6964],\n",
      "         [ 0.7654, -1.5053, -0.4142,  ..., -1.4622, -0.8975,  1.4576],\n",
      "         [-1.2008, -0.6008, -1.4608,  ..., -1.2105, -0.4289,  0.3827]],\n",
      "\n",
      "        [[-0.1709,  0.5230, -0.8713,  ..., -1.3382,  0.5892,  0.4026],\n",
      "         [-1.3806,  0.2626, -0.5207,  ..., -1.6714, -0.0554,  1.0225],\n",
      "         [-1.7116,  1.8788, -2.5695,  ..., -0.6958,  0.5728,  0.5461],\n",
      "         ...,\n",
      "         [-1.3246,  1.2196, -0.3034,  ..., -1.1955, -0.6708,  0.5128],\n",
      "         [ 0.9854,  0.8260,  0.2892,  ..., -0.6428,  0.3637,  0.4339],\n",
      "         [-1.2008, -0.6008, -1.4608,  ..., -1.2105, -0.4289,  0.3827]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.1709,  0.5230, -0.8713,  ..., -1.3382,  0.5892,  0.4026],\n",
      "         [-0.5842,  0.9588,  1.5642,  ..., -1.0731, -0.7330,  0.3132],\n",
      "         [-0.8601, -1.3756,  0.5042,  ..., -0.0476,  0.2650,  1.2150],\n",
      "         ...,\n",
      "         [ 0.0520,  1.1719, -1.5471,  ..., -0.7894,  0.1419,  1.6964],\n",
      "         [ 0.7654, -1.5053, -0.4142,  ..., -1.4622, -0.8975,  1.4576],\n",
      "         [-1.2008, -0.6008, -1.4608,  ..., -1.2105, -0.4289,  0.3827]],\n",
      "\n",
      "        [[-0.1709,  0.5230, -0.8713,  ..., -1.3382,  0.5892,  0.4026],\n",
      "         [-1.3806,  0.2626, -0.5207,  ..., -1.6714, -0.0554,  1.0225],\n",
      "         [-1.7116,  1.8788, -2.5695,  ..., -0.6958,  0.5728,  0.5461],\n",
      "         ...,\n",
      "         [-1.3246,  1.2196, -0.3034,  ..., -1.1955, -0.6708,  0.5128],\n",
      "         [ 0.9854,  0.8260,  0.2892,  ..., -0.6428,  0.3637,  0.4339],\n",
      "         [-1.2008, -0.6008, -1.4608,  ..., -1.2105, -0.4289,  0.3827]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.1709,  0.5230, -0.8713,  ...,  0.4365,  0.6238, -0.9414],\n",
      "          [-1.3731,  1.1521,  0.1321,  ..., -1.3382,  0.5892,  0.4026]],\n",
      "\n",
      "         [[-0.5842,  0.9588,  1.5642,  ..., -1.5431,  0.4999, -1.1350],\n",
      "          [ 0.9615,  0.8694,  0.0998,  ..., -1.0731, -0.7330,  0.3132]],\n",
      "\n",
      "         [[-0.8601, -1.3756,  0.5042,  ...,  0.9764, -0.8321, -1.0204],\n",
      "          [ 1.5175,  1.1454,  0.7791,  ..., -0.0476,  0.2650,  1.2150]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0520,  1.1719, -1.5471,  ...,  1.9402, -1.1294,  0.4793],\n",
      "          [ 1.0053,  0.8099,  1.6415,  ..., -0.7894,  0.1419,  1.6964]],\n",
      "\n",
      "         [[ 0.7654, -1.5053, -0.4142,  ...,  1.7455, -0.7326,  1.5248],\n",
      "          [ 1.0806,  1.1457,  2.2163,  ..., -1.4622, -0.8975,  1.4576]],\n",
      "\n",
      "         [[-1.2008, -0.6008, -1.4608,  ...,  2.0905,  1.8849, -1.5708],\n",
      "          [ 1.9999,  0.3493, -0.8524,  ..., -1.2105, -0.4289,  0.3827]]],\n",
      "\n",
      "\n",
      "        [[[-0.1709,  0.5230, -0.8713,  ...,  0.4365,  0.6238, -0.9414],\n",
      "          [-1.3731,  1.1521,  0.1321,  ..., -1.3382,  0.5892,  0.4026]],\n",
      "\n",
      "         [[-1.3806,  0.2626, -0.5207,  ...,  1.6517, -0.2316, -1.3171],\n",
      "          [ 0.6812, -0.0090,  0.3803,  ..., -1.6714, -0.0554,  1.0225]],\n",
      "\n",
      "         [[-1.7116,  1.8788, -2.5695,  ...,  0.4927, -0.4850, -1.0645],\n",
      "          [ 1.2646,  1.6481,  0.9055,  ..., -0.6958,  0.5728,  0.5461]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.3246,  1.2196, -0.3034,  ...,  1.2747,  1.2353,  0.2825],\n",
      "          [ 1.5373,  0.8648,  0.6062,  ..., -1.1955, -0.6708,  0.5128]],\n",
      "\n",
      "         [[ 0.9854,  0.8260,  0.2892,  ...,  1.3848, -0.0103, -1.0700],\n",
      "          [ 1.3827,  2.9809,  0.0276,  ..., -0.6428,  0.3637,  0.4339]],\n",
      "\n",
      "         [[-1.2008, -0.6008, -1.4608,  ...,  2.0905,  1.8849, -1.5708],\n",
      "          [ 1.9999,  0.3493, -0.8524,  ..., -1.2105, -0.4289,  0.3827]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.0123,  0.5761,  0.2209,  ..., -0.1027,  1.1061, -2.5200],\n",
      "         [-1.1465, -1.5578, -0.6984,  ...,  1.0310,  0.4824, -0.2291],\n",
      "         [-1.0361, -1.8192, -2.3055,  ...,  1.5286, -1.5941,  1.1762],\n",
      "         ...,\n",
      "         [-0.7992,  0.0886,  0.4887,  ..., -1.7941,  0.4835,  1.3780],\n",
      "         [-1.4692, -0.9135, -0.2802,  ..., -0.9691,  0.3500,  1.8863],\n",
      "         [-0.5760, -0.0452,  0.4230,  ..., -0.7179, -0.7858,  1.6879]],\n",
      "\n",
      "        [[-0.0123,  0.5761,  0.2209,  ..., -0.1027,  1.1061, -2.5200],\n",
      "         [-0.3700, -1.9754, -0.7315,  ...,  0.2293,  0.6996,  3.1299],\n",
      "         [-0.6252,  0.2879, -1.4036,  ..., -2.0560, -2.4623, -0.9584],\n",
      "         ...,\n",
      "         [-1.1306, -1.4343, -1.4422,  ..., -1.6115, -0.0475,  1.3975],\n",
      "         [-0.9816, -1.4909, -1.0086,  ..., -0.9284,  0.5260,  1.5330],\n",
      "         [-0.5760, -0.0452,  0.4230,  ..., -0.7179, -0.7858,  1.6879]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.0123,  0.5761,  0.2209,  ..., -0.1027,  1.1061, -2.5200],\n",
      "         [-1.1465, -1.5578, -0.6984,  ...,  1.0310,  0.4824, -0.2291],\n",
      "         [-1.0361, -1.8192, -2.3055,  ...,  1.5286, -1.5941,  1.1762],\n",
      "         ...,\n",
      "         [-0.7992,  0.0886,  0.4887,  ..., -1.7941,  0.4835,  1.3780],\n",
      "         [-1.4692, -0.9135, -0.2802,  ..., -0.9691,  0.3500,  1.8863],\n",
      "         [-0.5760, -0.0452,  0.4230,  ..., -0.7179, -0.7858,  1.6879]],\n",
      "\n",
      "        [[-0.0123,  0.5761,  0.2209,  ..., -0.1027,  1.1061, -2.5200],\n",
      "         [-0.3700, -1.9754, -0.7315,  ...,  0.2293,  0.6996,  3.1299],\n",
      "         [-0.6252,  0.2879, -1.4036,  ..., -2.0560, -2.4623, -0.9584],\n",
      "         ...,\n",
      "         [-1.1306, -1.4343, -1.4422,  ..., -1.6115, -0.0475,  1.3975],\n",
      "         [-0.9816, -1.4909, -1.0086,  ..., -0.9284,  0.5260,  1.5330],\n",
      "         [-0.5760, -0.0452,  0.4230,  ..., -0.7179, -0.7858,  1.6879]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.0123,  0.5761,  0.2209,  ..., -0.1457, -0.7538,  0.1761],\n",
      "          [-0.0705,  0.9215,  0.7990,  ..., -0.1027,  1.1061, -2.5200]],\n",
      "\n",
      "         [[-1.1465, -1.5578, -0.6984,  ...,  0.0289, -2.1112, -0.8728],\n",
      "          [ 0.6506, -1.6966,  1.4463,  ...,  1.0310,  0.4824, -0.2291]],\n",
      "\n",
      "         [[-1.0361, -1.8192, -2.3055,  ..., -0.2195, -1.1732,  0.3182],\n",
      "          [-0.5841, -0.0227,  3.0901,  ...,  1.5286, -1.5941,  1.1762]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.7992,  0.0886,  0.4887,  ...,  0.7859, -1.0127, -0.2676],\n",
      "          [-0.3055,  0.6270, -3.0705,  ..., -1.7941,  0.4835,  1.3780]],\n",
      "\n",
      "         [[-1.4692, -0.9135, -0.2802,  ...,  0.1197, -0.7532,  0.0731],\n",
      "          [ 0.6096, -1.0893, -0.6959,  ..., -0.9691,  0.3500,  1.8863]],\n",
      "\n",
      "         [[-0.5760, -0.0452,  0.4230,  ...,  0.8851,  0.3078,  0.8106],\n",
      "          [-1.1804,  0.9512,  0.3169,  ..., -0.7179, -0.7858,  1.6879]]],\n",
      "\n",
      "\n",
      "        [[[-0.0123,  0.5761,  0.2209,  ..., -0.1457, -0.7538,  0.1761],\n",
      "          [-0.0705,  0.9215,  0.7990,  ..., -0.1027,  1.1061, -2.5200]],\n",
      "\n",
      "         [[-0.3700, -1.9754, -0.7315,  ...,  0.5756, -1.5559,  0.0326],\n",
      "          [ 1.4229,  2.3970, -0.4516,  ...,  0.2293,  0.6996,  3.1299]],\n",
      "\n",
      "         [[-0.6252,  0.2879, -1.4036,  ...,  0.5306, -0.5608,  1.1861],\n",
      "          [-2.5980,  0.2673,  3.3016,  ..., -2.0560, -2.4623, -0.9584]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1306, -1.4343, -1.4422,  ...,  0.3918, -1.5336, -0.5026],\n",
      "          [ 1.8587,  0.8501, -1.2402,  ..., -1.6115, -0.0475,  1.3975]],\n",
      "\n",
      "         [[-0.9816, -1.4909, -1.0086,  ...,  0.2956,  0.0351, -1.0685],\n",
      "          [-0.6594, -0.0133, -1.1863,  ..., -0.9284,  0.5260,  1.5330]],\n",
      "\n",
      "         [[-0.5760, -0.0452,  0.4230,  ...,  0.8851,  0.3078,  0.8106],\n",
      "          [-1.1804,  0.9512,  0.3169,  ..., -0.7179, -0.7858,  1.6879]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.5911, -0.4682, -0.4314,  ...,  0.0366, -1.0405, -0.0579],\n",
      "          [-1.1141, -1.4785, -0.6477,  ...,  0.0631, -1.9950, -0.7912],\n",
      "          [-0.7059, -0.9954, -1.3923,  ..., -0.1557, -0.9998,  0.2774],\n",
      "          ...,\n",
      "          [-0.6300,  0.1252,  0.3486,  ...,  0.5692, -0.9417, -0.1399],\n",
      "          [-1.0593, -0.6395, -0.3343,  ...,  0.0571, -0.7842,  0.1042],\n",
      "          [-0.2081,  0.2785,  0.0613,  ..., -0.0353, -0.8389, -0.0026]],\n",
      "\n",
      "         [[-0.3266,  0.6360,  0.0214,  ...,  0.1677,  0.3883,  0.4382],\n",
      "          [-0.6299,  0.6012,  0.7379,  ...,  0.2989, -0.1569,  0.9508],\n",
      "          [-0.4097,  0.6374, -0.1589,  ...,  0.0258, -0.0364,  0.9990],\n",
      "          ...,\n",
      "          [-0.0088,  0.1378, -0.4819,  ..., -0.1261,  0.2908,  1.0980],\n",
      "          [-0.5584,  0.9932, -0.1105,  ...,  0.2486,  0.4005,  0.6046],\n",
      "          [-0.4516,  0.8092, -0.0513,  ...,  0.1182,  0.4294,  0.4781]]],\n",
      "\n",
      "\n",
      "        [[[-0.6850, -0.2168, -0.6087,  ...,  0.1402, -0.7267, -0.1502],\n",
      "          [-0.2084, -0.1325, -0.1151,  ...,  0.0938, -0.8963,  0.1296],\n",
      "          [-0.3665,  0.3408, -0.6133,  ...,  0.1938, -0.6681,  0.5929],\n",
      "          ...,\n",
      "          [-1.0985, -1.2861, -1.2531,  ...,  0.3609, -1.4022, -0.4444],\n",
      "          [-0.9787, -1.4207, -0.9908,  ...,  0.2989, -0.0159, -1.0060],\n",
      "          [-0.1970,  0.2371, -0.0115,  ...,  0.0049, -0.8135,  0.1201]],\n",
      "\n",
      "         [[ 0.0907,  0.7927, -0.0524,  ..., -0.4610, -0.4295,  0.4391],\n",
      "          [-0.2352,  1.0586, -0.1117,  ..., -0.4943, -0.6546,  0.6617],\n",
      "          [ 0.8269,  1.7861, -1.1207,  ..., -0.0885,  0.2791,  1.4721],\n",
      "          ...,\n",
      "          [-0.1038,  0.9623, -0.7062,  ..., -0.3340, -0.3050,  0.8792],\n",
      "          [ 0.0507,  0.6634, -0.2642,  ..., -0.4959, -0.7944,  0.7687],\n",
      "          [ 0.3364,  0.9047, -0.2037,  ..., -0.3705, -0.2893,  0.6787]]]],\n",
      "       grad_fn=<ScaledDotProductFlashAttentionForCpuBackward0>)\n",
      "tensor([[[[-0.5911, -0.4682, -0.4314,  ...,  0.0366, -1.0405, -0.0579],\n",
      "          [-0.3266,  0.6360,  0.0214,  ...,  0.1677,  0.3883,  0.4382]],\n",
      "\n",
      "         [[-1.1141, -1.4785, -0.6477,  ...,  0.0631, -1.9950, -0.7912],\n",
      "          [-0.6299,  0.6012,  0.7379,  ...,  0.2989, -0.1569,  0.9508]],\n",
      "\n",
      "         [[-0.7059, -0.9954, -1.3923,  ..., -0.1557, -0.9998,  0.2774],\n",
      "          [-0.4097,  0.6374, -0.1589,  ...,  0.0258, -0.0364,  0.9990]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6300,  0.1252,  0.3486,  ...,  0.5692, -0.9417, -0.1399],\n",
      "          [-0.0088,  0.1378, -0.4819,  ..., -0.1261,  0.2908,  1.0980]],\n",
      "\n",
      "         [[-1.0593, -0.6395, -0.3343,  ...,  0.0571, -0.7842,  0.1042],\n",
      "          [-0.5584,  0.9932, -0.1105,  ...,  0.2486,  0.4005,  0.6046]],\n",
      "\n",
      "         [[-0.2081,  0.2785,  0.0613,  ..., -0.0353, -0.8389, -0.0026],\n",
      "          [-0.4516,  0.8092, -0.0513,  ...,  0.1182,  0.4294,  0.4781]]],\n",
      "\n",
      "\n",
      "        [[[-0.6850, -0.2168, -0.6087,  ...,  0.1402, -0.7267, -0.1502],\n",
      "          [ 0.0907,  0.7927, -0.0524,  ..., -0.4610, -0.4295,  0.4391]],\n",
      "\n",
      "         [[-0.2084, -0.1325, -0.1151,  ...,  0.0938, -0.8963,  0.1296],\n",
      "          [-0.2352,  1.0586, -0.1117,  ..., -0.4943, -0.6546,  0.6617]],\n",
      "\n",
      "         [[-0.3665,  0.3408, -0.6133,  ...,  0.1938, -0.6681,  0.5929],\n",
      "          [ 0.8269,  1.7861, -1.1207,  ..., -0.0885,  0.2791,  1.4721]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.0985, -1.2861, -1.2531,  ...,  0.3609, -1.4022, -0.4444],\n",
      "          [-0.1038,  0.9623, -0.7062,  ..., -0.3340, -0.3050,  0.8792]],\n",
      "\n",
      "         [[-0.9787, -1.4207, -0.9908,  ...,  0.2989, -0.0159, -1.0060],\n",
      "          [ 0.0507,  0.6634, -0.2642,  ..., -0.4959, -0.7944,  0.7687]],\n",
      "\n",
      "         [[-0.1970,  0.2371, -0.0115,  ...,  0.0049, -0.8135,  0.1201],\n",
      "          [ 0.3364,  0.9047, -0.2037,  ..., -0.3705, -0.2893,  0.6787]]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[-0.9552,  0.6594, -6.5403,  ..., -0.7144,  0.0906,  0.3369],\n",
      "         [-2.5251,  1.3955, -0.8914,  ..., -2.1363,  0.0271,  1.1132],\n",
      "         [-3.7148,  0.6796, -0.8710,  ..., -2.6492,  0.5694, -0.1085],\n",
      "         ...,\n",
      "         [-2.2403, -0.7594,  0.5414,  ..., -3.0426,  0.8895, -0.0546],\n",
      "         [-1.6945, -0.6326, -0.8632,  ..., -4.0678,  1.7219,  0.6481],\n",
      "         [-2.9625,  0.7451, -0.8037,  ..., -2.5048,  0.3125,  0.5537]],\n",
      "\n",
      "        [[-0.5150,  0.8150, -6.5015,  ..., -0.5377, -0.4171,  0.1350],\n",
      "         [-2.9979,  1.0930, -0.2619,  ..., -3.1811, -1.0048, -1.8349],\n",
      "         [-2.8788,  0.5405, -0.0789,  ..., -2.3969, -0.7016, -0.7332],\n",
      "         ...,\n",
      "         [-1.7194,  1.5158,  1.0070,  ..., -2.8931, -2.3309,  1.1685],\n",
      "         [ 0.0717, -0.1039,  0.5084,  ..., -2.1932,  0.0751,  2.8236],\n",
      "         [-2.4774,  0.7563, -0.7502,  ..., -2.1312, -0.0685,  0.8700]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[-0.0455,  0.6529,  0.6297,  ...,  0.4139, -0.9381,  0.6769],\n",
      "         [-3.1104, -3.7282, -2.3953,  ..., -0.9155, -0.8280, -1.7070],\n",
      "         [-0.9324, -2.9333, -2.3249,  ..., -0.8455, -0.0326, -0.6998],\n",
      "         ...,\n",
      "         [-1.9000, -1.1028, -1.1281,  ..., -0.2809,  2.0206, -1.0802],\n",
      "         [-1.1088, -1.0420, -2.4026,  ..., -0.4478,  0.7391, -0.0354],\n",
      "         [ 0.7349,  0.6742, -2.6697,  ..., -0.5114,  1.5155,  2.0246]],\n",
      "\n",
      "        [[-0.0799,  0.7813,  0.4918,  ...,  0.6888, -0.7680,  0.9805],\n",
      "         [-2.8720, -1.0602, -2.3610,  ..., -2.1143,  0.9664, -1.1212],\n",
      "         [-1.4705, -2.1384, -1.9955,  ..., -0.9722,  1.5909, -0.1668],\n",
      "         ...,\n",
      "         [-2.9884, -1.1566, -2.5215,  ...,  1.1460,  0.7120, -0.6320],\n",
      "         [-3.3666, -0.7966, -3.3154,  ...,  0.5316,  1.7058,  2.1950],\n",
      "         [ 0.6626,  0.8537, -2.7251,  ..., -0.0901,  1.5883,  2.3840]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.0455,  0.6529,  0.6297,  ...,  0.4139, -0.9381,  0.6769],\n",
      "         [-3.1104, -3.7282, -2.3953,  ..., -0.9155, -0.8280, -1.7070],\n",
      "         [-0.9324, -2.9333, -2.3249,  ..., -0.8455, -0.0326, -0.6998],\n",
      "         ...,\n",
      "         [-1.9000, -1.1028, -1.1281,  ..., -0.2809,  2.0206, -1.0802],\n",
      "         [-1.1088, -1.0420, -2.4026,  ..., -0.4478,  0.7391, -0.0354],\n",
      "         [ 0.7349,  0.6742, -2.6697,  ..., -0.5114,  1.5155,  2.0246]],\n",
      "\n",
      "        [[-0.0799,  0.7813,  0.4918,  ...,  0.6888, -0.7680,  0.9805],\n",
      "         [-2.8720, -1.0602, -2.3610,  ..., -2.1143,  0.9664, -1.1212],\n",
      "         [-1.4705, -2.1384, -1.9955,  ..., -0.9722,  1.5909, -0.1668],\n",
      "         ...,\n",
      "         [-2.9884, -1.1566, -2.5215,  ...,  1.1460,  0.7120, -0.6320],\n",
      "         [-3.3666, -0.7966, -3.3154,  ...,  0.5316,  1.7058,  2.1950],\n",
      "         [ 0.6626,  0.8537, -2.7251,  ..., -0.0901,  1.5883,  2.3840]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.0455,  0.6529,  0.6297,  ...,  1.0165, -1.6055,  0.0557],\n",
      "          [-0.9141, -1.5101, -0.8415,  ...,  0.4139, -0.9381,  0.6769]],\n",
      "\n",
      "         [[-3.1104, -3.7282, -2.3953,  ..., -1.6195,  0.7426, -3.2794],\n",
      "          [-1.2694,  0.3821, -0.5687,  ..., -0.9155, -0.8280, -1.7070]],\n",
      "\n",
      "         [[-0.9324, -2.9333, -2.3249,  ..., -1.0254,  1.8158, -1.8835],\n",
      "          [-1.5265, -0.3901,  0.2734,  ..., -0.8455, -0.0326, -0.6998]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.9000, -1.1028, -1.1281,  ..., -1.2688, -0.0851, -2.3190],\n",
      "          [-2.4374,  0.0718, -2.7276,  ..., -0.2809,  2.0206, -1.0802]],\n",
      "\n",
      "         [[-1.1088, -1.0420, -2.4026,  ..., -1.0658,  0.1932, -1.7012],\n",
      "          [-2.3622, -0.5291, -1.9931,  ..., -0.4478,  0.7391, -0.0354]],\n",
      "\n",
      "         [[ 0.7349,  0.6742, -2.6697,  ..., -1.4630, -0.1686, -2.5682],\n",
      "          [-0.1401, -0.9712, -2.3801,  ..., -0.5114,  1.5155,  2.0246]]],\n",
      "\n",
      "\n",
      "        [[[-0.0799,  0.7813,  0.4918,  ...,  1.2364, -1.9500, -0.1275],\n",
      "          [-0.4080, -1.5069, -0.8504,  ...,  0.6888, -0.7680,  0.9805]],\n",
      "\n",
      "         [[-2.8720, -1.0602, -2.3610,  ..., -2.3225, -0.0351, -2.7432],\n",
      "          [-0.2305, -0.5940, -1.1570,  ..., -2.1143,  0.9664, -1.1212]],\n",
      "\n",
      "         [[-1.4705, -2.1384, -1.9955,  ..., -0.6524, -1.8025, -1.8321],\n",
      "          [-1.7742, -0.6800, -0.2172,  ..., -0.9722,  1.5909, -0.1668]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.9884, -1.1566, -2.5215,  ..., -0.5054, -1.0314, -3.4883],\n",
      "          [-1.9535,  0.5573, -2.1564,  ...,  1.1460,  0.7120, -0.6320]],\n",
      "\n",
      "         [[-3.3666, -0.7966, -3.3154,  ...,  0.7587, -0.6289, -3.4848],\n",
      "          [-1.4099, -2.0919, -1.5870,  ...,  0.5316,  1.7058,  2.1950]],\n",
      "\n",
      "         [[ 0.6626,  0.8537, -2.7251,  ..., -1.1831, -0.7083, -2.7717],\n",
      "          [ 0.4486, -1.1639, -2.1203,  ..., -0.0901,  1.5883,  2.3840]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.8947,  0.0412, -1.2359,  ...,  0.4410, -0.3965,  0.0106],\n",
      "         [-1.9196,  0.3326,  0.8482,  ..., -1.5790, -1.1817, -1.0156],\n",
      "         [-2.1664,  0.3959,  0.7476,  ..., -2.1767, -0.6488,  0.1889],\n",
      "         ...,\n",
      "         [-1.6009,  0.4887, -0.4818,  ..., -1.1268,  0.4111,  0.7892],\n",
      "         [-0.1528,  1.1728, -0.5164,  ..., -0.4340,  0.1499,  1.6704],\n",
      "         [ 1.0253,  1.4222, -0.1805,  ..., -0.6130, -0.5380,  1.6164]],\n",
      "\n",
      "        [[-0.6736, -0.0718, -1.1724,  ...,  0.2001, -0.5481,  0.0232],\n",
      "         [-1.8698, -1.2184,  0.2913,  ..., -1.1398, -1.3523, -0.7851],\n",
      "         [-1.3725, -0.8212,  0.1984,  ..., -1.8218, -1.4800, -0.2956],\n",
      "         ...,\n",
      "         [-0.5946,  0.5680,  0.8938,  ..., -1.6653,  0.8218,  1.1902],\n",
      "         [ 1.2800,  1.9566,  0.2540,  ..., -1.2290,  0.5257,  1.2667],\n",
      "         [ 1.3511,  1.3329, -0.0782,  ..., -0.8454, -0.7400,  1.5966]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.8947,  0.0412, -1.2359,  ...,  0.4410, -0.3965,  0.0106],\n",
      "         [-1.9196,  0.3326,  0.8482,  ..., -1.5790, -1.1817, -1.0156],\n",
      "         [-2.1664,  0.3959,  0.7476,  ..., -2.1767, -0.6488,  0.1889],\n",
      "         ...,\n",
      "         [-1.6009,  0.4887, -0.4818,  ..., -1.1268,  0.4111,  0.7892],\n",
      "         [-0.1528,  1.1728, -0.5164,  ..., -0.4340,  0.1499,  1.6704],\n",
      "         [ 1.0253,  1.4222, -0.1805,  ..., -0.6130, -0.5380,  1.6164]],\n",
      "\n",
      "        [[-0.6736, -0.0718, -1.1724,  ...,  0.2001, -0.5481,  0.0232],\n",
      "         [-1.8698, -1.2184,  0.2913,  ..., -1.1398, -1.3523, -0.7851],\n",
      "         [-1.3725, -0.8212,  0.1984,  ..., -1.8218, -1.4800, -0.2956],\n",
      "         ...,\n",
      "         [-0.5946,  0.5680,  0.8938,  ..., -1.6653,  0.8218,  1.1902],\n",
      "         [ 1.2800,  1.9566,  0.2540,  ..., -1.2290,  0.5257,  1.2667],\n",
      "         [ 1.3511,  1.3329, -0.0782,  ..., -0.8454, -0.7400,  1.5966]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.8947,  0.0412, -1.2359,  ...,  1.5140, -1.9812, -2.5532],\n",
      "          [-0.2951, -1.6086, -0.6381,  ...,  0.4410, -0.3965,  0.0106]],\n",
      "\n",
      "         [[-1.9196,  0.3326,  0.8482,  ..., -2.3348,  1.3935,  1.1452],\n",
      "          [-0.5277,  0.1234,  0.7865,  ..., -1.5790, -1.1817, -1.0156]],\n",
      "\n",
      "         [[-2.1664,  0.3959,  0.7476,  ..., -2.0817,  0.2852,  0.8173],\n",
      "          [-0.8414,  0.5154, -0.4553,  ..., -2.1767, -0.6488,  0.1889]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.6009,  0.4887, -0.4818,  ..., -1.8165,  1.4764,  0.5091],\n",
      "          [-0.6869,  0.4007, -1.5818,  ..., -1.1268,  0.4111,  0.7892]],\n",
      "\n",
      "         [[-0.1528,  1.1728, -0.5164,  ..., -1.3611,  1.0621,  1.1810],\n",
      "          [-0.7595, -0.1699, -1.5305,  ..., -0.4340,  0.1499,  1.6704]],\n",
      "\n",
      "         [[ 1.0253,  1.4222, -0.1805,  ..., -0.6989,  0.4721,  2.6129],\n",
      "          [-1.2381, -0.4573, -1.7561,  ..., -0.6130, -0.5380,  1.6164]]],\n",
      "\n",
      "\n",
      "        [[[-0.6736, -0.0718, -1.1724,  ...,  1.4816, -1.7920, -2.5177],\n",
      "          [-0.3929, -1.5120, -0.5353,  ...,  0.2001, -0.5481,  0.0232]],\n",
      "\n",
      "         [[-1.8698, -1.2184,  0.2913,  ..., -1.5227,  1.9764,  0.6389],\n",
      "          [-0.4202,  0.4572, -1.0780,  ..., -1.1398, -1.3523, -0.7851]],\n",
      "\n",
      "         [[-1.3725, -0.8212,  0.1984,  ..., -2.1553,  1.7041,  0.7166],\n",
      "          [-1.0124,  0.9351, -0.0954,  ..., -1.8218, -1.4800, -0.2956]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.5946,  0.5680,  0.8938,  ..., -2.1904,  1.7986,  1.0902],\n",
      "          [-1.3820,  1.0268, -1.0041,  ..., -1.6653,  0.8218,  1.1902]],\n",
      "\n",
      "         [[ 1.2800,  1.9566,  0.2540,  ..., -1.6180,  1.6176,  2.5636],\n",
      "          [-2.0592,  0.7059, -1.3359,  ..., -1.2290,  0.5257,  1.2667]],\n",
      "\n",
      "         [[ 1.3511,  1.3329, -0.0782,  ..., -0.5836,  0.6491,  2.6554],\n",
      "          [-1.3686, -0.2348, -1.7438,  ..., -0.8454, -0.7400,  1.5966]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 3.8307e-01,  1.8836e-02, -1.0314e+00,  ...,  6.4335e-01,\n",
      "          -3.1830e-01, -1.7296e+00],\n",
      "         [ 1.5897e+00,  1.3689e-01, -6.8915e-01,  ...,  1.5973e+00,\n",
      "           1.1907e+00, -9.0454e-01],\n",
      "         [-5.8138e-01,  6.7943e-01, -1.3203e+00,  ..., -5.3627e-01,\n",
      "          -1.0456e+00, -1.6301e+00],\n",
      "         ...,\n",
      "         [-1.7466e-01,  3.0707e-02,  7.5225e-01,  ..., -1.3217e+00,\n",
      "          -1.3415e+00, -3.8328e-01],\n",
      "         [ 1.5170e-01,  5.1089e-01,  1.3993e-01,  ..., -1.6600e-01,\n",
      "          -6.5011e-01,  2.1798e-02],\n",
      "         [-2.4311e-01,  1.6726e+00,  1.6682e-01,  ...,  1.3441e-03,\n",
      "          -1.6754e+00,  3.1771e-01]],\n",
      "\n",
      "        [[ 4.7844e-01, -3.1772e-01, -1.0617e+00,  ...,  6.4928e-01,\n",
      "          -3.2944e-01, -2.4185e+00],\n",
      "         [ 5.9122e-01, -2.2648e-01,  1.7474e-01,  ..., -1.8623e+00,\n",
      "          -1.1230e+00,  3.5013e-01],\n",
      "         [ 1.1642e-01,  1.2460e+00,  7.7942e-02,  ...,  6.4975e-01,\n",
      "          -7.3862e-01, -2.1510e+00],\n",
      "         ...,\n",
      "         [ 1.1291e+00, -1.3637e+00, -1.5779e+00,  ...,  1.7637e+00,\n",
      "           9.1331e-01, -1.7033e+00],\n",
      "         [ 1.5909e+00, -1.4922e+00,  1.0060e+00,  ...,  9.8096e-01,\n",
      "           8.6736e-01, -2.3894e+00],\n",
      "         [ 1.8451e-01,  1.2740e+00,  4.2857e-01,  ...,  6.2708e-01,\n",
      "          -1.3601e+00, -3.9984e-01]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 3.8307e-01,  1.8836e-02, -1.0314e+00,  ...,  6.4335e-01,\n",
      "          -3.1830e-01, -1.7296e+00],\n",
      "         [ 1.5897e+00,  1.3689e-01, -6.8915e-01,  ...,  1.5973e+00,\n",
      "           1.1907e+00, -9.0454e-01],\n",
      "         [-5.8138e-01,  6.7943e-01, -1.3203e+00,  ..., -5.3627e-01,\n",
      "          -1.0456e+00, -1.6301e+00],\n",
      "         ...,\n",
      "         [-1.7466e-01,  3.0707e-02,  7.5225e-01,  ..., -1.3217e+00,\n",
      "          -1.3415e+00, -3.8328e-01],\n",
      "         [ 1.5170e-01,  5.1089e-01,  1.3993e-01,  ..., -1.6600e-01,\n",
      "          -6.5011e-01,  2.1798e-02],\n",
      "         [-2.4311e-01,  1.6726e+00,  1.6682e-01,  ...,  1.3441e-03,\n",
      "          -1.6754e+00,  3.1771e-01]],\n",
      "\n",
      "        [[ 4.7844e-01, -3.1772e-01, -1.0617e+00,  ...,  6.4928e-01,\n",
      "          -3.2944e-01, -2.4185e+00],\n",
      "         [ 5.9122e-01, -2.2648e-01,  1.7474e-01,  ..., -1.8623e+00,\n",
      "          -1.1230e+00,  3.5013e-01],\n",
      "         [ 1.1642e-01,  1.2460e+00,  7.7942e-02,  ...,  6.4975e-01,\n",
      "          -7.3862e-01, -2.1510e+00],\n",
      "         ...,\n",
      "         [ 1.1291e+00, -1.3637e+00, -1.5779e+00,  ...,  1.7637e+00,\n",
      "           9.1331e-01, -1.7033e+00],\n",
      "         [ 1.5909e+00, -1.4922e+00,  1.0060e+00,  ...,  9.8096e-01,\n",
      "           8.6736e-01, -2.3894e+00],\n",
      "         [ 1.8451e-01,  1.2740e+00,  4.2857e-01,  ...,  6.2708e-01,\n",
      "          -1.3601e+00, -3.9984e-01]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 3.8307e-01,  1.8836e-02, -1.0314e+00,  ..., -8.0955e-01,\n",
      "           -2.8557e-01, -2.3318e-01],\n",
      "          [-9.9661e-02,  3.1722e-01, -3.0517e-01,  ...,  6.4335e-01,\n",
      "           -3.1830e-01, -1.7296e+00]],\n",
      "\n",
      "         [[ 1.5897e+00,  1.3689e-01, -6.8915e-01,  ..., -7.9549e-01,\n",
      "           -6.9279e-01, -1.8082e-01],\n",
      "          [-9.9201e-01,  9.4938e-01,  4.4198e-02,  ...,  1.5973e+00,\n",
      "            1.1907e+00, -9.0454e-01]],\n",
      "\n",
      "         [[-5.8138e-01,  6.7943e-01, -1.3203e+00,  ..., -1.8905e+00,\n",
      "            1.6226e-01, -1.2953e+00],\n",
      "          [-7.0312e-01, -6.4926e-01, -5.0913e-01,  ..., -5.3627e-01,\n",
      "           -1.0456e+00, -1.6301e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.7466e-01,  3.0707e-02,  7.5225e-01,  ..., -1.9281e+00,\n",
      "            1.1489e+00, -2.4530e-01],\n",
      "          [-7.6226e-02,  8.5814e-01, -1.5467e+00,  ..., -1.3217e+00,\n",
      "           -1.3415e+00, -3.8328e-01]],\n",
      "\n",
      "         [[ 1.5170e-01,  5.1089e-01,  1.3993e-01,  ..., -2.4168e+00,\n",
      "            3.3385e-01, -6.2115e-02],\n",
      "          [-1.6390e+00, -1.6085e-01, -1.9118e+00,  ..., -1.6600e-01,\n",
      "           -6.5011e-01,  2.1798e-02]],\n",
      "\n",
      "         [[-2.4311e-01,  1.6726e+00,  1.6682e-01,  ..., -1.0481e+00,\n",
      "           -2.7634e+00,  2.2741e-01],\n",
      "          [-1.4603e+00,  3.1239e-02,  3.8892e-01,  ...,  1.3441e-03,\n",
      "           -1.6754e+00,  3.1771e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.7844e-01, -3.1772e-01, -1.0617e+00,  ..., -7.8511e-01,\n",
      "           -3.2510e-01, -2.1300e-01],\n",
      "          [-3.9893e-01,  6.1469e-01, -3.9206e-01,  ...,  6.4928e-01,\n",
      "           -3.2944e-01, -2.4185e+00]],\n",
      "\n",
      "         [[ 5.9122e-01, -2.2648e-01,  1.7474e-01,  ..., -1.6488e+00,\n",
      "           -8.6854e-01, -8.0783e-01],\n",
      "          [-2.1516e+00, -2.4247e-01, -8.1713e-01,  ..., -1.8623e+00,\n",
      "           -1.1230e+00,  3.5013e-01]],\n",
      "\n",
      "         [[ 1.1642e-01,  1.2460e+00,  7.7942e-02,  ..., -1.3121e+00,\n",
      "           -6.7044e-01, -1.1324e+00],\n",
      "          [ 4.3930e-01,  3.4082e-01, -1.2243e+00,  ...,  6.4975e-01,\n",
      "           -7.3862e-01, -2.1510e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1291e+00, -1.3637e+00, -1.5779e+00,  ...,  8.5980e-01,\n",
      "            3.2796e-01, -1.9442e+00],\n",
      "          [-8.9502e-01,  9.7357e-01,  8.5447e-01,  ...,  1.7637e+00,\n",
      "            9.1331e-01, -1.7033e+00]],\n",
      "\n",
      "         [[ 1.5909e+00, -1.4922e+00,  1.0060e+00,  ..., -1.5965e+00,\n",
      "           -3.9380e-01, -4.3585e-01],\n",
      "          [-2.2103e+00,  4.4127e-01,  1.1554e+00,  ...,  9.8096e-01,\n",
      "            8.6736e-01, -2.3894e+00]],\n",
      "\n",
      "         [[ 1.8451e-01,  1.2740e+00,  4.2857e-01,  ..., -1.1366e+00,\n",
      "           -2.8409e+00,  4.6711e-01],\n",
      "          [-1.9576e+00,  2.0176e-01, -4.1035e-02,  ...,  6.2708e-01,\n",
      "           -1.3601e+00, -3.9984e-01]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 3.7393e-01,  3.7078e-01, -7.5553e-01,  ..., -9.4280e-01,\n",
      "           -6.5765e-01, -1.4711e-01],\n",
      "          [ 3.9396e-01,  4.7658e-02, -1.0277e+00,  ..., -8.4926e-01,\n",
      "           -2.7815e-01, -2.6628e-01],\n",
      "          [ 9.9586e-01,  2.4414e-01, -8.3459e-01,  ..., -8.5795e-01,\n",
      "           -4.3860e-01, -2.1582e-01],\n",
      "          ...,\n",
      "          [ 1.4504e+00, -1.2077e-01, -4.8160e-01,  ..., -1.6701e+00,\n",
      "            6.3807e-01, -8.3788e-02],\n",
      "          [ 3.8821e-01,  1.4150e-01, -1.5051e-01,  ..., -1.5785e+00,\n",
      "            4.1589e-01, -1.8024e-01],\n",
      "          [ 1.0467e-01,  5.5196e-01,  1.0818e-01,  ..., -2.0373e+00,\n",
      "            8.4396e-02, -6.9033e-02]],\n",
      "\n",
      "         [[-7.7230e-01, -1.1852e-01, -8.0275e-02,  ..., -1.3792e-03,\n",
      "           -5.2249e-01, -4.2095e-01],\n",
      "          [-4.6209e-01, -1.2680e-01, -2.5711e-01,  ...,  1.3235e-01,\n",
      "           -4.1385e-01, -1.3744e+00],\n",
      "          [-1.7985e-01, -2.6037e-01,  3.5677e-01,  ...,  2.4736e-01,\n",
      "           -1.6626e-01, -7.0940e-01],\n",
      "          ...,\n",
      "          [-6.2069e-01,  2.5298e-01, -7.8416e-01,  ...,  8.6186e-02,\n",
      "           -6.9561e-01, -8.5675e-01],\n",
      "          [-9.1553e-01,  1.4648e-01, -5.5621e-02,  ...,  1.8643e-01,\n",
      "           -1.0965e+00, -4.8097e-01],\n",
      "          [-1.0678e+00,  9.0884e-02, -4.5400e-02,  ...,  1.5424e-01,\n",
      "           -1.1762e+00, -2.9385e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.9445e-01,  9.6669e-03, -5.7118e-01,  ..., -9.7640e-01,\n",
      "           -9.0948e-01, -1.3761e-01],\n",
      "          [ 4.7672e-01, -2.3672e-01, -8.9246e-01,  ..., -8.9927e-01,\n",
      "           -3.9088e-01, -3.1635e-01],\n",
      "          [ 4.5120e-01, -5.8034e-02, -6.8736e-01,  ..., -1.0352e+00,\n",
      "           -4.7996e-01, -4.5624e-01],\n",
      "          ...,\n",
      "          [ 3.3362e-01,  1.5919e-03, -1.0108e+00,  ..., -1.5704e+00,\n",
      "           -3.9079e-01, -2.1742e-01],\n",
      "          [ 1.0123e+00, -1.1147e+00, -1.3032e+00,  ...,  3.4082e-01,\n",
      "            1.3298e-01, -1.5481e+00],\n",
      "          [ 1.4273e+00, -1.2951e+00,  5.7719e-01,  ..., -1.2490e+00,\n",
      "           -4.1355e-01, -5.8558e-01]],\n",
      "\n",
      "         [[-1.0884e+00,  2.0838e-01, -5.0948e-01,  ...,  2.2845e-01,\n",
      "           -8.2075e-01, -1.1496e+00],\n",
      "          [-3.4296e-01,  5.0833e-01, -8.6644e-01,  ...,  3.3008e-01,\n",
      "           -5.5070e-01, -1.8440e+00],\n",
      "          [-3.2602e-01,  6.0671e-01, -7.5711e-01,  ...,  4.7493e-01,\n",
      "           -4.6589e-01, -2.0454e+00],\n",
      "          ...,\n",
      "          [-1.7399e+00,  4.6359e-01,  6.5213e-01,  ...,  9.0025e-01,\n",
      "            3.1642e-01, -2.0784e+00],\n",
      "          [-1.8375e+00,  2.6226e-01,  3.7727e-02,  ...,  6.6286e-01,\n",
      "           -1.0588e+00, -7.6781e-01],\n",
      "          [-1.6402e+00,  3.1250e-01, -6.6174e-04,  ...,  6.6493e-01,\n",
      "           -9.1110e-01, -1.0382e+00]]]],\n",
      "       grad_fn=<ScaledDotProductFlashAttentionForCpuBackward0>)\n",
      "tensor([[[[ 3.7393e-01,  3.7078e-01, -7.5553e-01,  ..., -9.4280e-01,\n",
      "           -6.5765e-01, -1.4711e-01],\n",
      "          [-7.7230e-01, -1.1852e-01, -8.0275e-02,  ..., -1.3792e-03,\n",
      "           -5.2249e-01, -4.2095e-01]],\n",
      "\n",
      "         [[ 3.9396e-01,  4.7658e-02, -1.0277e+00,  ..., -8.4926e-01,\n",
      "           -2.7815e-01, -2.6628e-01],\n",
      "          [-4.6209e-01, -1.2680e-01, -2.5711e-01,  ...,  1.3235e-01,\n",
      "           -4.1385e-01, -1.3744e+00]],\n",
      "\n",
      "         [[ 9.9586e-01,  2.4414e-01, -8.3459e-01,  ..., -8.5795e-01,\n",
      "           -4.3860e-01, -2.1582e-01],\n",
      "          [-1.7985e-01, -2.6037e-01,  3.5677e-01,  ...,  2.4736e-01,\n",
      "           -1.6626e-01, -7.0940e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4504e+00, -1.2077e-01, -4.8160e-01,  ..., -1.6701e+00,\n",
      "            6.3807e-01, -8.3788e-02],\n",
      "          [-6.2069e-01,  2.5298e-01, -7.8416e-01,  ...,  8.6186e-02,\n",
      "           -6.9561e-01, -8.5675e-01]],\n",
      "\n",
      "         [[ 3.8821e-01,  1.4150e-01, -1.5051e-01,  ..., -1.5785e+00,\n",
      "            4.1589e-01, -1.8024e-01],\n",
      "          [-9.1553e-01,  1.4648e-01, -5.5621e-02,  ...,  1.8643e-01,\n",
      "           -1.0965e+00, -4.8097e-01]],\n",
      "\n",
      "         [[ 1.0467e-01,  5.5196e-01,  1.0818e-01,  ..., -2.0373e+00,\n",
      "            8.4396e-02, -6.9033e-02],\n",
      "          [-1.0678e+00,  9.0884e-02, -4.5400e-02,  ...,  1.5424e-01,\n",
      "           -1.1762e+00, -2.9385e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.9445e-01,  9.6669e-03, -5.7118e-01,  ..., -9.7640e-01,\n",
      "           -9.0948e-01, -1.3761e-01],\n",
      "          [-1.0884e+00,  2.0838e-01, -5.0948e-01,  ...,  2.2845e-01,\n",
      "           -8.2075e-01, -1.1496e+00]],\n",
      "\n",
      "         [[ 4.7672e-01, -2.3672e-01, -8.9246e-01,  ..., -8.9927e-01,\n",
      "           -3.9088e-01, -3.1635e-01],\n",
      "          [-3.4296e-01,  5.0833e-01, -8.6644e-01,  ...,  3.3008e-01,\n",
      "           -5.5070e-01, -1.8440e+00]],\n",
      "\n",
      "         [[ 4.5120e-01, -5.8034e-02, -6.8736e-01,  ..., -1.0352e+00,\n",
      "           -4.7996e-01, -4.5624e-01],\n",
      "          [-3.2602e-01,  6.0671e-01, -7.5711e-01,  ...,  4.7493e-01,\n",
      "           -4.6589e-01, -2.0454e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.3362e-01,  1.5919e-03, -1.0108e+00,  ..., -1.5704e+00,\n",
      "           -3.9079e-01, -2.1742e-01],\n",
      "          [-1.7399e+00,  4.6359e-01,  6.5213e-01,  ...,  9.0025e-01,\n",
      "            3.1642e-01, -2.0784e+00]],\n",
      "\n",
      "         [[ 1.0123e+00, -1.1147e+00, -1.3032e+00,  ...,  3.4082e-01,\n",
      "            1.3298e-01, -1.5481e+00],\n",
      "          [-1.8375e+00,  2.6226e-01,  3.7727e-02,  ...,  6.6286e-01,\n",
      "           -1.0588e+00, -7.6781e-01]],\n",
      "\n",
      "         [[ 1.4273e+00, -1.2951e+00,  5.7719e-01,  ..., -1.2490e+00,\n",
      "           -4.1355e-01, -5.8558e-01],\n",
      "          [-1.6402e+00,  3.1250e-01, -6.6174e-04,  ...,  6.6493e-01,\n",
      "           -9.1110e-01, -1.0382e+00]]]], grad_fn=<TransposeBackward0>)\n",
      "tensor([[ 0.3425, -0.0361],\n",
      "        [ 0.3986, -0.0110]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1, 0])\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "from chop import MaseGraph\n",
    "import chop.passes as passes\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
    "model.config.problem_type = \"single_label_classification\"\n",
    "\n",
    "mg = MaseGraph(\n",
    "    model,\n",
    "    hf_input_names=[\n",
    "        \"input_ids\",\n",
    "        \"attention_mask\",\n",
    "        \"labels\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "mg, _ = passes.init_metadata_analysis_pass(mg)\n",
    "mg, _ = passes.add_common_metadata_analysis_pass(mg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have previously ran the tutorial on Quantization-Aware Training (QAT), run the following cell to import the fine tuned checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from chop import MaseGraph\n",
    "\n",
    "lab1_out_dir = Path(\"/workspace/labs/lab1/outputs\")\n",
    "lab1_out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "mg = MaseGraph.from_checkpoint(f\"{lab1_out_dir}/tutorial_3_qat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unstructured Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running pruning, let's evaluate the model accuracy on the IMDb dataset. If you're coming from Tutorial, this would be the same as the accuracy after Quantization Aware Training (QAT). If you've just initialized the model, this will likely be a random guess (i.e. around 50%), in which case pruning wouldn't have a significant effect on the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mTokenizing dataset imdb with AutoTokenizer for bert-base-uncased.\u001b[0m\n",
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:33]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation accuracy: 0.83856\n"
     ]
    }
   ],
   "source": [
    "from chop.tools import get_tokenized_dataset, get_trainer\n",
    "\n",
    "dataset, tokenizer = get_tokenized_dataset(\n",
    "    dataset=dataset_name,\n",
    "    checkpoint=tokenizer_checkpoint,\n",
    "    return_tokenizer=True,\n",
    ")\n",
    "\n",
    "trainer = get_trainer(\n",
    "    model=mg.model,\n",
    "    tokenized_dataset=dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    evaluate_metric=\"accuracy\",\n",
    ")\n",
    "\n",
    "# Evaluate accuracy\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Evaluation accuracy: {eval_results['eval_accuracy']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the pruning pass, we pass the following pruning configuration dictionary, which defines the following parameters.\n",
    "\n",
    "- **Sparsity**: a value between 0 and 1, expressing the proportion of elements in the model that should be pruned (i.e. set to 0).\n",
    "\n",
    "- **Method**: several pruning methods are supported, including ``Random`` and ``L1-Norm``.\n",
    "\n",
    "- **Scope**: defines whether to consider each weight/activation tensor individually (``local``) or all tensors in the model (``global``) when obtaining statistics for pruning (e.g. absolute value threshold for pruning)\n",
    "\n",
    "We'll start by running random pruning with local scope, at a fixed sparsity. This may be suboptimal, but in future tutorials we'll see how to find optimal pruning and quantization configurations for a given model on a specified dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_pooler_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: classifier\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import chop.passes as passes\n",
    "\n",
    "pruning_config = {\n",
    "    \"weight\": {\n",
    "        \"sparsity\": 0.5,\n",
    "        \"method\": \"l1-norm\",\n",
    "        \"scope\": \"local\",\n",
    "    },\n",
    "    \"activation\": {\n",
    "        \"sparsity\": 0.5,\n",
    "        \"method\": \"l1-norm\",\n",
    "        \"scope\": \"local\",\n",
    "    },\n",
    "}\n",
    "\n",
    "mg, _ = passes.prune_transform_pass(mg, pass_args=pruning_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate the effect of pruning on accuracy. It's likely to observe drops of around 10% or more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6250' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 13:35]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation accuracy: 0.72932\n"
     ]
    }
   ],
   "source": [
    "trainer = get_trainer(\n",
    "    model=mg.model,\n",
    "    tokenized_dataset=dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    evaluate_metric=\"accuracy\",\n",
    "    num_train_epochs=5,\n",
    ")\n",
    "\n",
    "# Evaluate accuracy\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Evaluation accuracy: {eval_results['eval_accuracy']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To overcome the drop in accuracy, we'll run a few finetuning epochs. This allows the model to adapt to the new pruning mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15625' max='15625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15625/15625 10:06, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.441800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.414200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.428600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.404800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.413100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.414300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.425700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.405300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.399100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.394200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.401000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.404800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.389100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.394800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.399300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.387000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.419600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.393600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.402400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.383900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.386000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.393600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.379400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.397300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.381900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.369000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.391700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.384400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.386700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.389400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.394600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=15625, training_loss=0.3987020075683594, metrics={'train_runtime': 606.3085, 'train_samples_per_second': 206.166, 'train_steps_per_second': 25.771, 'total_flos': 0.0, 'train_loss': 0.3987020075683594, 'epoch': 5.0})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate the model accuracy after finetuning. We should see that the accuracy is reverted back to the original level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation accuracy: 0.83188\n"
     ]
    }
   ],
   "source": [
    "eval_results = trainer.evaluate()\n",
    "print(f\"Evaluation accuracy: {eval_results['eval_accuracy']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genereate_pruning_config(sparsity, method=\"l1-norm\"):\n",
    "    return {\n",
    "        \"weight\": {\n",
    "            \"sparsity\": sparsity,\n",
    "            \"method\": method,\n",
    "            \"scope\": \"local\",\n",
    "        },\n",
    "        \"activation\": {\n",
    "            \"sparsity\": sparsity,\n",
    "            \"method\": method,\n",
    "            \"scope\": \"local\",\n",
    "        },\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity_levels = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mTokenizing dataset imdb with AutoTokenizer for bert-base-uncased.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from chop.tools import get_logger\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "logger = get_logger('mase_logger')\n",
    "logger.setLevel('INFO')\n",
    "\n",
    "dataset, tokenizer = get_tokenized_dataset(\n",
    "    dataset=dataset_name,\n",
    "    checkpoint=tokenizer_checkpoint,\n",
    "    return_tokenizer=True,\n",
    ")\n",
    "\n",
    "lab1_out_dir = Path(\"/workspace/labs/lab1/outputs\")\n",
    "lab1_out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "RESULTS_PATH = lab1_out_dir / \"pruning_results.jsonl\"\n",
    "\n",
    "def load_existing_results(path: Path):\n",
    "    done = {}  # (method, sparsity) -> eval_accuracy\n",
    "    if not path.exists():\n",
    "        return done\n",
    "    with path.open(\"r\") as f:\n",
    "        for line in f:\n",
    "            row = json.loads(line)\n",
    "            done[(row[\"method\"], row[\"sparsity\"])] = row\n",
    "    return done\n",
    "\n",
    "def append_result(path: Path, row: dict):\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with path.open(\"a\") as f:\n",
    "        f.write(json.dumps(row) + \"\\n\")\n",
    "        f.flush()  # make sure its on disk immediately\n",
    "\n",
    "def run_pruning(\n",
    "    sparsity_levels,\n",
    "    method=\"l1-norm\",\n",
    "    cooldown_seconds=120,   # sleep 2 mins between runs\n",
    "    results_path: Path = RESULTS_PATH,\n",
    "):\n",
    "    done = load_existing_results(results_path)\n",
    "    results = {}\n",
    "\n",
    "    for sparsity in sparsity_levels:\n",
    "        key = (method, float(sparsity))\n",
    "\n",
    "        # Skip if already computed\n",
    "        if key in done:\n",
    "            logger.info(f\"Skipping {method=} {sparsity=}, already in results file.\")\n",
    "            results[sparsity] = done[key][\"eval\"]\n",
    "            continue\n",
    "\n",
    "        logger.info(f\"Running pruning with {method=} at sparsity={sparsity}\")\n",
    "\n",
    "        mg = MaseGraph.from_checkpoint(f\"{lab1_out_dir}/tutorial_3_qat\")\n",
    "        mg_pruned, _ = passes.prune_transform_pass(\n",
    "            mg, pass_args=genereate_pruning_config(sparsity, method=method)\n",
    "        )\n",
    "\n",
    "        trainer_pruned = get_trainer(\n",
    "            model=mg_pruned.model,\n",
    "            tokenized_dataset=dataset,\n",
    "            tokenizer=tokenizer,\n",
    "            evaluate_metric=\"accuracy\",\n",
    "            num_train_epochs=1,\n",
    "        )\n",
    "\n",
    "        train_start = time.time()\n",
    "        trainer_pruned.train()\n",
    "        train_time_s = time.time() - train_start\n",
    "\n",
    "        eval_results_pruned = trainer_pruned.evaluate()\n",
    "        results[sparsity] = eval_results_pruned\n",
    "\n",
    "        row = {\n",
    "            \"method\": method,\n",
    "            \"sparsity\": float(sparsity),\n",
    "            \"train_time_s\": train_time_s,\n",
    "            \"eval\": eval_results_pruned,\n",
    "        }\n",
    "        append_result(results_path, row)\n",
    "\n",
    "        logger.info(\n",
    "            f\"Saved result. {method=} {sparsity=}, \"\n",
    "            f\"eval_accuracy={eval_results_pruned.get('eval_accuracy')}, \"\n",
    "            f\"train_time_s={train_time_s:.1f}\"\n",
    "        )\n",
    "\n",
    "        # Cleanup to reduce lingering allocations\n",
    "        del trainer_pruned\n",
    "        del mg_pruned\n",
    "        del mg\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        # Cooldown\n",
    "        if cooldown_seconds and cooldown_seconds > 0:\n",
    "            logger.info(f\"Cooling down for {cooldown_seconds}s...\")\n",
    "            time.sleep(cooldown_seconds)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pruning_results(random_results, l1norm_results):\n",
    "\n",
    "    sparsity_levels = list(random_results.keys())\n",
    "    random_accuracies = [random_results[s][\"eval_accuracy\"] for s in sparsity_levels]\n",
    "    l1norm_accuracies = [l1norm_results[s][\"eval_accuracy\"] for s in sparsity_levels]\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(sparsity_levels, random_accuracies, marker='o', label='Random Pruning')\n",
    "    plt.plot(sparsity_levels, l1norm_accuracies, marker='s', label='L1-Norm Pruning')\n",
    "    plt.title('Pruning Sparsity vs Evaluation Accuracy')\n",
    "    plt.xlabel('Sparsity Level')\n",
    "    plt.ylabel('Evaluation Accuracy')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.savefig(lab1_out_dir / \"pruning_results.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mRunning pruning with method='random' at sparsity=0.1\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_pooler_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: classifier\u001b[0m\n",
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 05:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.469500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.436400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.441500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.418700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.415600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.428700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 03:27]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mSaved result. method='random' sparsity=0.1, eval_accuracy=0.8186, train_time_s=305.3\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mCooling down for 180s...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRunning pruning with method='random' at sparsity=0.2\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_pooler_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: classifier\u001b[0m\n",
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 05:22, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.586400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.490600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.481900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.463400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.457400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.461600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 03:58]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mSaved result. method='random' sparsity=0.2, eval_accuracy=0.79724, train_time_s=323.3\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mCooling down for 180s...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRunning pruning with method='random' at sparsity=0.3\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_pooler_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: classifier\u001b[0m\n",
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 06:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.680600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.642000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.571200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.522200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.524000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.510200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 04:31]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mSaved result. method='random' sparsity=0.3, eval_accuracy=0.76516, train_time_s=362.0\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mCooling down for 180s...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRunning pruning with method='random' at sparsity=0.4\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_pooler_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: classifier\u001b[0m\n",
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 04:36, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.692800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.691900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.686800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.687000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.685300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.679900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 04:33]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mSaved result. method='random' sparsity=0.4, eval_accuracy=0.58448, train_time_s=276.7\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mCooling down for 180s...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRunning pruning with method='random' at sparsity=0.5\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_pooler_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: classifier\u001b[0m\n",
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 04:55, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.693800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.694000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.692000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.692700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.694100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.692600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 05:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mSaved result. method='random' sparsity=0.5, eval_accuracy=0.51492, train_time_s=295.4\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mCooling down for 180s...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRunning pruning with method='random' at sparsity=0.6\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_pooler_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: classifier\u001b[0m\n",
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 04:56, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.693400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.693400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.692900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.693300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.693600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 04:55]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mSaved result. method='random' sparsity=0.6, eval_accuracy=0.5016, train_time_s=297.0\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mCooling down for 180s...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRunning pruning with method='random' at sparsity=0.7\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_pooler_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: classifier\u001b[0m\n",
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 05:51, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.693200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.693000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.693500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.693400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.693200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 05:29]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mSaved result. method='random' sparsity=0.7, eval_accuracy=0.50152, train_time_s=352.2\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mCooling down for 180s...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRunning pruning with method='random' at sparsity=0.8\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_pooler_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: classifier\u001b[0m\n",
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 07:45, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.693200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.693200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.693200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.693200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 07:13]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mSaved result. method='random' sparsity=0.8, eval_accuracy=0.49844, train_time_s=465.9\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mCooling down for 180s...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRunning pruning with method='random' at sparsity=0.9\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_pooler_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: classifier\u001b[0m\n",
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 08:53, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.693200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.693200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 06:26]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mSaved result. method='random' sparsity=0.9, eval_accuracy=0.50072, train_time_s=534.1\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mCooling down for 180s...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRunning pruning with method='l1-norm' at sparsity=0.1\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_pooler_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: classifier\u001b[0m\n",
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:56, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.369500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.376700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.384500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.366600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.377600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.382100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:19]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mSaved result. method='l1-norm' sparsity=0.1, eval_accuracy=0.84332, train_time_s=117.4\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mCooling down for 180s...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRunning pruning with method='l1-norm' at sparsity=0.2\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_pooler_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: classifier\u001b[0m\n",
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 02:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.368900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.374800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.383700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.362200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.380600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.383700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:18]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mSaved result. method='l1-norm' sparsity=0.2, eval_accuracy=0.8424, train_time_s=121.7\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mCooling down for 180s...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRunning pruning with method='l1-norm' at sparsity=0.3\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_pooler_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: classifier\u001b[0m\n",
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:57, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.370700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.370500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.386800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.367400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.374700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.380600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:17]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mSaved result. method='l1-norm' sparsity=0.3, eval_accuracy=0.83796, train_time_s=117.8\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mCooling down for 180s...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRunning pruning with method='l1-norm' at sparsity=0.4\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_pooler_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: classifier\u001b[0m\n",
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:56, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.393900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.388000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.406800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.383700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.389900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.397400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:19]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mSaved result. method='l1-norm' sparsity=0.4, eval_accuracy=0.82708, train_time_s=116.7\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mCooling down for 180s...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRunning pruning with method='l1-norm' at sparsity=0.5\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_pooler_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: classifier\u001b[0m\n",
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:56, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.443500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.412800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.429800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.407000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.419200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.417600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:19]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mSaved result. method='l1-norm' sparsity=0.5, eval_accuracy=0.81584, train_time_s=116.9\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mCooling down for 180s...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRunning pruning with method='l1-norm' at sparsity=0.6\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_pooler_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: classifier\u001b[0m\n",
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:57, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.532700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.459900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.454100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.440800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.432400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.439900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:19]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mSaved result. method='l1-norm' sparsity=0.6, eval_accuracy=0.80648, train_time_s=117.8\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mCooling down for 180s...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRunning pruning with method='l1-norm' at sparsity=0.7\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_pooler_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: classifier\u001b[0m\n",
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:57, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.650100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.610100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.587400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.562300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.551400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.544200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:26]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mSaved result. method='l1-norm' sparsity=0.7, eval_accuracy=0.76624, train_time_s=118.0\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mCooling down for 180s...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRunning pruning with method='l1-norm' at sparsity=0.8\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_pooler_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: classifier\u001b[0m\n",
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 02:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.690100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.686300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.683900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.682700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.678200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.680000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:27]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mSaved result. method='l1-norm' sparsity=0.8, eval_accuracy=0.61684, train_time_s=125.5\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mCooling down for 180s...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRunning pruning with method='l1-norm' at sparsity=0.9\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_pooler_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: classifier\u001b[0m\n",
      "/workspace/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:53, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.693000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.691700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.692600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.691700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.691500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.691500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:16]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mSaved result. method='l1-norm' sparsity=0.9, eval_accuracy=0.54956, train_time_s=114.0\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mCooling down for 180s...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_results = run_pruning(sparsity_levels, method=\"random\", cooldown_seconds=180)\n",
    "l1norm_results = run_pruning(sparsity_levels, method=\"l1-norm\", cooldown_seconds=180)\n",
    "plot_pruning_results(random_results, l1norm_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mase-dev)",
   "language": "python",
   "name": "mase-dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
