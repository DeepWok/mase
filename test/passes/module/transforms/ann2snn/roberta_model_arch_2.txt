: RobertaForSequenceClassification(
  (roberta): RobertaModel(
    (embeddings): RobertaEmbeddings(
      (word_embeddings): Embedding(50265, 768, padding_idx=1)
      (position_embeddings): Embedding(514, 768, padding_idx=1)
      (token_type_embeddings): Embedding(1, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): RobertaEncoder(
      (layer): ModuleList(
        (0-11): 12 x RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSdpaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): ReLU()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
  (classifier): RobertaClassificationHead(
    (dense): Linear(in_features=768, out_features=768, bias=True)
    (dropout): Dropout(p=0.1, inplace=False)
    (out_proj): Linear(in_features=768, out_features=2, bias=True)
  )
)
roberta: RobertaModel(
  (embeddings): RobertaEmbeddings(
    (word_embeddings): Embedding(50265, 768, padding_idx=1)
    (position_embeddings): Embedding(514, 768, padding_idx=1)
    (token_type_embeddings): Embedding(1, 768)
    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (encoder): RobertaEncoder(
    (layer): ModuleList(
      (0-11): 12 x RobertaLayer(
        (attention): RobertaAttention(
          (self): RobertaSdpaSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): RobertaSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): RobertaIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
          (intermediate_act_fn): ReLU()
        )
        (output): RobertaOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
)
roberta.embeddings: RobertaEmbeddings(
  (word_embeddings): Embedding(50265, 768, padding_idx=1)
  (position_embeddings): Embedding(514, 768, padding_idx=1)
  (token_type_embeddings): Embedding(1, 768)
  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  (dropout): Dropout(p=0.1, inplace=False)
)
roberta.embeddings.word_embeddings: Embedding(50265, 768, padding_idx=1)
roberta.embeddings.position_embeddings: Embedding(514, 768, padding_idx=1)
roberta.embeddings.token_type_embeddings: Embedding(1, 768)
roberta.embeddings.LayerNorm: LayerNorm((768,), eps=1e-05, elementwise_affine=True)
roberta.embeddings.dropout: Dropout(p=0.1, inplace=False)
roberta.encoder: RobertaEncoder(
  (layer): ModuleList(
    (0-11): 12 x RobertaLayer(
      (attention): RobertaAttention(
        (self): RobertaSdpaSelfAttention(
          (query): Linear(in_features=768, out_features=768, bias=True)
          (key): Linear(in_features=768, out_features=768, bias=True)
          (value): Linear(in_features=768, out_features=768, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (output): RobertaSelfOutput(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (intermediate): RobertaIntermediate(
        (dense): Linear(in_features=768, out_features=3072, bias=True)
        (intermediate_act_fn): ReLU()
      )
      (output): RobertaOutput(
        (dense): Linear(in_features=3072, out_features=768, bias=True)
        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
)
roberta.encoder.layer: ModuleList(
  (0-11): 12 x RobertaLayer(
    (attention): RobertaAttention(
      (self): RobertaSdpaSelfAttention(
        (query): Linear(in_features=768, out_features=768, bias=True)
        (key): Linear(in_features=768, out_features=768, bias=True)
        (value): Linear(in_features=768, out_features=768, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (output): RobertaSelfOutput(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (intermediate): RobertaIntermediate(
      (dense): Linear(in_features=768, out_features=3072, bias=True)
      (intermediate_act_fn): ReLU()
    )
    (output): RobertaOutput(
      (dense): Linear(in_features=3072, out_features=768, bias=True)
      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
)
roberta.encoder.layer.0: RobertaLayer(
  (attention): RobertaAttention(
    (self): RobertaSdpaSelfAttention(
      (query): Linear(in_features=768, out_features=768, bias=True)
      (key): Linear(in_features=768, out_features=768, bias=True)
      (value): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (output): RobertaSelfOutput(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (intermediate): RobertaIntermediate(
    (dense): Linear(in_features=768, out_features=3072, bias=True)
    (intermediate_act_fn): ReLU()
  )
  (output): RobertaOutput(
    (dense): Linear(in_features=3072, out_features=768, bias=True)
    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (dropout): Dropout(p=0.1, inplace=False)
  )
)
roberta.encoder.layer.0.attention: RobertaAttention(
  (self): RobertaSdpaSelfAttention(
    (query): Linear(in_features=768, out_features=768, bias=True)
    (key): Linear(in_features=768, out_features=768, bias=True)
    (value): Linear(in_features=768, out_features=768, bias=True)
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (output): RobertaSelfOutput(
    (dense): Linear(in_features=768, out_features=768, bias=True)
    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (dropout): Dropout(p=0.1, inplace=False)
  )
)
roberta.encoder.layer.0.attention.self: RobertaSdpaSelfAttention(
  (query): Linear(in_features=768, out_features=768, bias=True)
  (key): Linear(in_features=768, out_features=768, bias=True)
  (value): Linear(in_features=768, out_features=768, bias=True)
  (dropout): Dropout(p=0.1, inplace=False)
)
roberta.encoder.layer.0.attention.self.query: Linear(in_features=768, out_features=768, bias=True)
roberta.encoder.layer.0.attention.self.key: Linear(in_features=768, out_features=768, bias=True)
roberta.encoder.layer.0.attention.self.value: Linear(in_features=768, out_features=768, bias=True)
roberta.encoder.layer.0.attention.self.dropout: Dropout(p=0.1, inplace=False)
roberta.encoder.layer.0.attention.output: RobertaSelfOutput(
  (dense): Linear(in_features=768, out_features=768, bias=True)
  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  (dropout): Dropout(p=0.1, inplace=False)
)
roberta.encoder.layer.0.attention.output.dense: Linear(in_features=768, out_features=768, bias=True)
roberta.encoder.layer.0.attention.output.LayerNorm: LayerNorm((768,), eps=1e-05, elementwise_affine=True)
roberta.encoder.layer.0.attention.output.dropout: Dropout(p=0.1, inplace=False)
roberta.encoder.layer.0.intermediate: RobertaIntermediate(
  (dense): Linear(in_features=768, out_features=3072, bias=True)
  (intermediate_act_fn): ReLU()
)
roberta.encoder.layer.0.intermediate.dense: Linear(in_features=768, out_features=3072, bias=True)
roberta.encoder.layer.0.intermediate.intermediate_act_fn: ReLU()
roberta.encoder.layer.0.output: RobertaOutput(
  (dense): Linear(in_features=3072, out_features=768, bias=True)
  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  (dropout): Dropout(p=0.1, inplace=False)
)
roberta.encoder.layer.0.output.dense: Linear(in_features=3072, out_features=768, bias=True)
roberta.encoder.layer.0.output.LayerNorm: LayerNorm((768,), eps=1e-05, elementwise_affine=True)
roberta.encoder.layer.0.output.dropout: Dropout(p=0.1, inplace=False)
roberta.encoder.layer.1: RobertaLayer(
  (attention): RobertaAttention(
    (self): RobertaSdpaSelfAttention(
      (query): Linear(in_features=768, out_features=768, bias=True)
      (key): Linear(in_features=768, out_features=768, bias=True)
      (value): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (output): RobertaSelfOutput(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (intermediate): RobertaIntermediate(
    (dense): Linear(in_features=768, out_features=3072, bias=True)
    (intermediate_act_fn): ReLU()
  )
  (output): RobertaOutput(
    (dense): Linear(in_features=3072, out_features=768, bias=True)
    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (dropout): Dropout(p=0.1, inplace=False)
  )
)
roberta.encoder.layer.1.attention: RobertaAttention(
  (self): RobertaSdpaSelfAttention(
    (query): Linear(in_features=768, out_features=768, bias=True)
    (key): Linear(in_features=768, out_features=768, bias=True)
    (value): Linear(in_features=768, out_features=768, bias=True)
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (output): RobertaSelfOutput(
    (dense): Linear(in_features=768, out_features=768, bias=True)
    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (dropout): Dropout(p=0.1, inplace=False)
  )
)
roberta.encoder.layer.1.attention.self: RobertaSdpaSelfAttention(
  (query): Linear(in_features=768, out_features=768, bias=True)
  (key): Linear(in_features=768, out_features=768, bias=True)
  (value): Linear(in_features=768, out_features=768, bias=True)
  (dropout): Dropout(p=0.1, inplace=False)
)
roberta.encoder.layer.1.attention.self.query: Linear(in_features=768, out_features=768, bias=True)
roberta.encoder.layer.1.attention.self.key: Linear(in_features=768, out_features=768, bias=True)
roberta.encoder.layer.1.attention.self.value: Linear(in_features=768, out_features=768, bias=True)
roberta.encoder.layer.1.attention.self.dropout: Dropout(p=0.1, inplace=False)
roberta.encoder.layer.1.attention.output: RobertaSelfOutput(
  (dense): Linear(in_features=768, out_features=768, bias=True)
  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  (dropout): Dropout(p=0.1, inplace=False)
)
roberta.encoder.layer.1.attention.output.dense: Linear(in_features=768, out_features=768, bias=True)
roberta.encoder.layer.1.attention.output.LayerNorm: LayerNorm((768,), eps=1e-05, elementwise_affine=True)
roberta.encoder.layer.1.attention.output.dropout: Dropout(p=0.1, inplace=False)
roberta.encoder.layer.1.intermediate: RobertaIntermediate(
  (dense): Linear(in_features=768, out_features=3072, bias=True)
  (intermediate_act_fn): ReLU()
)
roberta.encoder.layer.1.intermediate.dense: Linear(in_features=768, out_features=3072, bias=True)
roberta.encoder.layer.1.intermediate.intermediate_act_fn: ReLU()
roberta.encoder.layer.1.output: RobertaOutput(
  (dense): Linear(in_features=3072, out_features=768, bias=True)
  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  (dropout): Dropout(p=0.1, inplace=False)
)
roberta.encoder.layer.1.output.dense: Linear(in_features=3072, out_features=768, bias=True)
roberta.encoder.layer.1.output.LayerNorm: LayerNorm((768,), eps=1e-05, elementwise_affine=True)
roberta.encoder.layer.1.output.dropout: Dropout(p=0.1, inplace=False)
roberta.encoder.layer.2: RobertaLayer(
  (attention): RobertaAttention(
    (self): RobertaSdpaSelfAttention(
      (query): Linear(in_features=768, out_features=768, bias=True)
      (key): Linear(in_features=768, out_features=768, bias=True)
      (value): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (output): RobertaSelfOutput(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (intermediate): RobertaIntermediate(
    (dense): Linear(in_features=768, out_features=3072, bias=True)
    (intermediate_act_fn): ReLU()
  )
  (output): RobertaOutput(
    (dense): Linear(in_features=3072, out_features=768, bias=True)
    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (dropout): Dropout(p=0.1, inplace=False)
  )
)
roberta.encoder.layer.2.attention: RobertaAttention(
  (self): RobertaSdpaSelfAttention(
    (query): Linear(in_features=768, out_features=768, bias=True)
    (key): Linear(in_features=768, out_features=768, bias=True)
    (value): Linear(in_features=768, out_features=768, bias=True)
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (output): RobertaSelfOutput(
    (dense): Linear(in_features=768, out_features=768, bias=True)
    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (dropout): Dropout(p=0.1, inplace=False)
  )
)
roberta.encoder.layer.2.attention.self: RobertaSdpaSelfAttention(
  (query): Linear(in_features=768, out_features=768, bias=True)
  (key): Linear(in_features=768, out_features=768, bias=True)
  (value): Linear(in_features=768, out_features=768, bias=True)
  (dropout): Dropout(p=0.1, inplace=False)
)
roberta.encoder.layer.2.attention.self.query: Linear(in_features=768, out_features=768, bias=True)
roberta.encoder.layer.2.attention.self.key: Linear(in_features=768, out_features=768, bias=True)
roberta.encoder.layer.2.attention.self.value: Linear(in_features=768, out_features=768, bias=True)
roberta.encoder.layer.2.attention.self.dropout: Dropout(p=0.1, inplace=False)
roberta.encoder.layer.2.attention.output: RobertaSelfOutput(
  (dense): Linear(in_features=768, out_features=768, bias=True)
  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  (dropout): Dropout(p=0.1, inplace=False)
)
roberta.encoder.layer.2.attention.output.dense: Linear(in_features=768, out_features=768, bias=True)
roberta.encoder.layer.2.attention.output.LayerNorm: LayerNorm((768,), eps=1e-05, elementwise_affine=True)
roberta.encoder.layer.2.attention.output.dropout: Dropout(p=0.1, inplace=False)
roberta.encoder.layer.2.intermediate: RobertaIntermediate(
  (dense): Linear(in_features=768, out_features=3072, bias=True)
  (intermediate_act_fn): ReLU()
)
roberta.encoder.layer.2.intermediate.dense: Linear(in_features=768, out_features=3072, bias=True)
roberta.encoder.layer.2.intermediate.intermediate_act_fn: ReLU()
roberta.encoder.layer.2.output: RobertaOutput(
  (dense): Linear(in_features=3072, out_features=768, bias=True)
  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  (dropout): Dropout(p=0.1, inplace=False)
)
roberta.encoder.layer.2.output.dense: Linear(in_features=3072, out_features=768, bias=True)
roberta.encoder.layer.2.output.LayerNorm: LayerNorm((768,), eps=1e-05, elementwise_affine=True)
roberta.encoder.layer.2.output.dropout: Dropout(p=0.1, inplace=False)
roberta.encoder.layer.3: RobertaLayer(
  (attention): RobertaAttention(
    (self): RobertaSdpaSelfAttention(
      (query): Linear(in_features=768, out_features=768, bias=True)
      (key): Linear(in_features=768, out_features=768, bias=True)
      (value): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (output): RobertaSelfOutput(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (intermediate): RobertaIntermediate(
    (dense): Linear(in_features=768, out_features=3072, bias=True)
    (intermediate_act_fn): ReLU()
  )
  (output): RobertaOutput(
    (dense): Linear(in_features=3072, out_features=768, bias=True)
    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (dropout): Dropout(p=0.1, inplace=False)
  )
)
roberta.encoder.layer.3.attention: RobertaAttention(
  (self): RobertaSdpaSelfAttention(
    (query): Linear(in_features=768, out_features=768, bias=True)
    (key): Linear(in_features=768, out_features=768, bias=True)
    (value): Linear(in_features=768, out_features=768, bias=True)
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (output): RobertaSelfOutput(
    (dense): Linear(in_features=768, out_features=768, bias=True)
    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (dropout): Dropout(p=0.1, inplace=False)
  )
)
roberta.encoder.layer.3.attention.self: RobertaSdpaSelfAttention(
  (query): Linear(in_features=768, out_features=768, bias=True)
  (key): Linear(in_features=768, out_features=768, bias=True)
  (value): Linear(in_features=768, out_features=768, bias=True)
  (dropout): Dropout(p=0.1, inplace=False)
)
roberta.encoder.layer.3.attention.self.query: Linear(in_features=768, out_features=768, bias=True)
roberta.encoder.layer.3.attention.self.key: Linear(in_features=768, out_features=768, bias=True)
roberta.encoder.layer.3.attention.self.value: Linear(in_features=768, out_features=768, bias=True)
roberta.encoder.layer.3.attention.self.dropout: Dropout(p=0.1, inplace=False)
roberta.encoder.layer.3.attention.output: RobertaSelfOutput(
  (dense): Linear(in_features=768, out_features=768, bias=True)
  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  (dropout): Dropout(p=0.1, inplace=False)
)
roberta.encoder.layer.3.attention.output.dense: Linear(in_features=768, out_features=768, bias=True)
roberta.encoder.layer.3.attention.output.LayerNorm: LayerNorm((768,), eps=1e-05, elementwise_affine=True)
roberta.encoder.layer.3.attention.output.dropout: Dropout(p=0.1, inplace=False)
roberta.encoder.layer.3.intermediate: RobertaIntermediate(
  (dense): Linear(in_features=768, out_features=3072, bias=True)
  (intermediate_act_fn): ReLU()
)
roberta.encoder.layer.3.intermediate.dense: Linear(in_features=768, out_features=3072, bias=True)
roberta.encoder.layer.3.intermediate.intermediate_act_fn: ReLU()
roberta.encoder.layer.3.output: RobertaOutput(
  (dense): Linear(in_features=3072, out_features=768, bias=True)
  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  (dropout): Dropout(p=0.1, inplace=False)
)
roberta.encoder.layer.3.output.dense: Linear(in_features=3072, out_features=768, bias=True)
roberta.encoder.layer.3.output.LayerNorm: LayerNorm((768,), eps=1e-05, elementwise_affine=True)
roberta.encoder.layer.3.output.dropout: Dropout(p=0.1, inplace=False)
roberta.encoder.layer.4: RobertaLayer(
  (attention): RobertaAttention(
    (self): RobertaSdpaSelfAttention(
      (query): Linear(in_features=768, out_features=768, bias=True)
      (key): Linear(in_features=768, out_features=768, bias=True)
      (value): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (output): RobertaSelfOutput(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (intermediate): RobertaIntermediate(
    (dense): Linear(in_features=768, out_features=3072, bias=True)
    (intermediate_act_fn): ReLU()
  )
  (output): RobertaOutput(
    (dense): Linear(in_features=3072, out_features=768, bias=True)
    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (dropout): Dropout(p=0.1, inplace=False)
  )
)
roberta.encoder.layer.4.attention: RobertaAttention(
  (self): RobertaSdpaSelfAttention(
    (query): Linear(in_features=768, out_features=768, bias=True)
    (key): Linear(in_features=768, out_features=768, bias=True)
    (value): Linear(in_features=768, out_features=768, bias=True)
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (output): RobertaSelfOutput(
    (dense): Linear(in_features=768, out_features=768, bias=True)
    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (dropout): Dropout(p=0.1, inplace=False)
  )
)
roberta.encoder.layer.4.attention.self: RobertaSdpaSelfAttention(
  (query): Linear(in_features=768, out_features=768, bias=True)
  (key): Linear(in_features=768, out_features=768, bias=True)
  (value): Linear(in_features=768, out_features=768, bias=True)
  (dropout): Dropout(p=0.1, inplace=False)
)
roberta.encoder.layer.4.attention.self.query: Linear(in_features=768, out_features=768, bias=True)
roberta.encoder.layer.4.attention.self.key: Linear(in_features=768, out_features=768, bias=True)
roberta.encoder.layer.4.attention.self.value: Linear(in_features=768, out_features=768, bias=True)
roberta.encoder.layer.4.attention.self.dropout: Dropout(p=0.1, inplace=False)
roberta.encoder.layer.4.attention.output: RobertaSelfOutput(
  (dense): Linear(in_features=768, out_features=768, bias=True)
  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  (dropout): Dropout(p=0.1, inplace=False)
)
roberta.encoder.layer.4.attention.output.dense: Linear(in_features=768, out_features=768, bias=True)
roberta.encoder.layer.4.attention.output.LayerNorm: LayerNorm((768,), eps=1e-05, elementwise_affine=True)
roberta.encoder.layer.4.attention.output.dropout: Dropout(p=0.1, inplace=False)
roberta.encoder.layer.4.intermediate: RobertaIntermediate(
  (dense): Linear(in_features=768, out_features=3072, bias=True)
  (intermediate_act_fn): ReLU()
)
roberta.encoder.layer.4.intermediate.dense: Linear(in_features=768, out_features=3072, bias=True)
roberta.encoder.layer.4.intermediate.intermediate_act_fn: ReLU()
roberta.encoder.layer.4.output: RobertaOutput(
  (dense): Linear(in_features=3072, out_features=768, bias=True)
  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  (dropout): Dropout(p=0.1, inplace=False)
)
roberta.encoder.layer.4.output.dense: Linear(in_features=3072, out_features=768, bias=True)
roberta.encoder.layer.4.output.LayerNorm: LayerNorm((768,), eps=1e-05, elementwise_affine=True)
roberta.encoder.layer.4.output.dropout: Dropout(p=0.1, inplace=False)
roberta.encoder.layer.5: RobertaLayer(
  (attention): RobertaAttention(
    (self): RobertaSdpaSelfAttention(
      (query): Linear(in_features=768, out_features=768, bias=True)
      (key): Linear(in_features=768, out_features=768, bias=True)
      (value): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (output): RobertaSelfOutput(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (intermediate): RobertaIntermediate(
    (dense): Linear(in_features=768, out_features=3072, bias=True)
    (intermediate_act_fn): ReLU()
  )
  (output): RobertaOutput(
    (dense): Linear(in_features=3072, out_features=768, bias=True)
    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (dropout): Dropout(p=0.1, inplace=False)
  )
)
roberta.encoder.layer.5.attention: RobertaAttention(
  (self): RobertaSdpaSelfAttention(
    (query): Linear(in_features=768, out_features=768, bias=True)
    (key): Linear(in_features=768, out_features=768, bias=True)
    (value): Linear(in_features=768, out_features=768, bias=True)
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (output): RobertaSelfOutput(
    (dense): Linear(in_features=768, out_features=768, bias=True)
    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (dropout): Dropout(p=0.1, inplace=False)
  )
)
roberta.encoder.layer.5.attention.self: RobertaSdpaSelfAttention(
  (query): Linear(in_features=768, out_features=768, bias=True)
  (key): Linear(in_features=768, out_features=768, bias=True)
  (value): Linear(in_features=768, out_features=768, bias=True)
  (dropout): Dropout(p=0.1, inplace=False)
)
roberta.encoder.layer.5.attention.self.query: Linear(in_features=768, out_features=768, bias=True)
roberta.encoder.layer.5.attention.self.key: Linear(in_features=768, out_features=768, bias=True)
roberta.encoder.layer.5.attention.self.value: Linear(in_features=768, out_features=768, bias=True)
roberta.encoder.layer.5.attention.self.dropout: Dropout(p=0.1, inplace=False)
roberta.encoder.layer.5.attention.output: RobertaSelfOutput(
  (dense): Linear(in_features=768, out_features=768, bias=True)
  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  (dropout): Dropout(p=0.1, inplace=False)
)
roberta.encoder.layer.5.attention.output.dense: Linear(in_features=768, out_features=768, bias=True)
roberta.encoder.layer.5.attention.output.LayerNorm: LayerNorm((768,), eps=1e-05, elementwise_affine=True)
roberta.encoder.layer.5.attention.output.dropout: Dropout(p=0.1, inplace=False)
roberta.encoder.layer.5.intermediate: RobertaIntermediate(
  (dense): Linear(in_features=768, out_features=3072, bias=True)
  (intermediate_act_fn): ReLU()
)
roberta.encoder.layer.5.intermediate.dense: Linear(in_features=768, out_features=3072, bias=True)
roberta.encoder.layer.5.intermediate.intermediate_act_fn: ReLU()
roberta.encoder.layer.5.output: RobertaOutput(
  (dense): Linear(in_features=3072, out_features=768, bias=True)
  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  (dropout): Dropout(p=0.1, inplace=False)
)
roberta.encoder.layer.5.output.dense: Linear(in_features=3072, out_features=768, bias=True)
roberta.encoder.layer.5.output.LayerNorm: LayerNorm((768,), eps=1e-05, elementwise_affine=True)
roberta.encoder.layer.5.output.dropout: Dropout(p=0.1, inplace=False)
roberta.encoder.layer.6: RobertaLayer(
  (attention): RobertaAttention(
    (self): RobertaSdpaSelfAttention(
      (query): Linear(in_features=768, out_features=768, bias=True)
      (key): Linear(in_features=768, out_features=768, bias=True)
      (value): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (output): RobertaSelfOutput(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (intermediate): RobertaIntermediate(
    (dense): Linear(in_features=768, out_features=3072, bias=True)
    (intermediate_act_fn): ReLU()
  )
  (output): RobertaOutput(
    (dense): Linear(in_features=3072, out_features=768, bias=True)
    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (dropout): Dropout(p=0.1, inplace=False)
  )
)
roberta.encoder.layer.6.attention: RobertaAttention(
  (self): RobertaSdpaSelfAttention(
    (query): Linear(in_features=768, out_features=768, bias=True)
    (key): Linear(in_features=768, out_features=768, bias=True)
    (value): Linear(in_features=768, out_features=768, bias=True)
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (output): RobertaSelfOutput(
    (dense): Linear(in_features=768, out_features=768, bias=True)
    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (dropout): Dropout(p=0.1, inplace=False)
  )
)
roberta.encoder.layer.6.attention.self: RobertaSdpaSelfAttention(
  (query): Linear(in_features=768, out_features=768, bias=True)
  (key): Linear(in_features=768, out_features=768, bias=True)
  (value): Linear(in_features=768, out_features=768, bias=True)
  (dropout): Dropout(p=0.1, inplace=False)
)
roberta.encoder.layer.6.attention.self.query: Linear(in_features=768, out_features=768, bias=True)
roberta.encoder.layer.6.attention.self.key: Linear(in_features=768, out_features=768, bias=True)
roberta.encoder.layer.6.attention.self.value: Linear(in_features=768, out_features=768, bias=True)
roberta.encoder.layer.6.attention.self.dropout: Dropout(p=0.1, inplace=False)
roberta.encoder.layer.6.attention.output: RobertaSelfOutput(
  (dense): Linear(in_features=768, out_features=768, bias=True)
  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  (dropout): Dropout(p=0.1, inplace=False)
)
roberta.encoder.layer.6.attention.output.dense: Linear(in_features=768, out_features=768, bias=True)
roberta.encoder.layer.6.attention.output.LayerNorm: LayerNorm((768,), eps=1e-05, elementwise_affine=True)
roberta.encoder.layer.6.attention.output.dropout: Dropout(p=0.1, inplace=False)
roberta.encoder.layer.6.intermediate: RobertaIntermediate(
  (dense): Linear(in_features=768, out_features=3072, bias=True)
  (intermediate_act_fn): ReLU()
)
roberta.encoder.layer.6.intermediate.dense: Linear(in_features=768, out_features=3072, bias=True)
roberta.encoder.layer.6.intermediate.intermediate_act_fn: ReLU()
roberta.encoder.layer.6.output: RobertaOutput(
  (dense): Linear(in_features=3072, out_features=768, bias=True)
  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  (dropout): Dropout(p=0.1, inplace=False)
)
roberta.encoder.layer.6.output.dense: Linear(in_features=3072, out_features=768, bias=True)
roberta.encoder.layer.6.output.LayerNorm: LayerNorm((768,), eps=1e-05, elementwise_affine=True)
roberta.encoder.layer.6.output.dropout: Dropout(p=0.1, inplace=False)
roberta.encoder.layer.7: RobertaLayer(
  (attention): RobertaAttention(
    (self): RobertaSdpaSelfAttention(
      (query): Linear(in_features=768, out_features=768, bias=True)
      (key): Linear(in_features=768, out_features=768, bias=True)
      (value): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (output): RobertaSelfOutput(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (intermediate): RobertaIntermediate(
    (dense): Linear(in_features=768, out_features=3072, bias=True)
    (intermediate_act_fn): ReLU()
  )
  (output): RobertaOutput(
    (dense): Linear(in_features=3072, out_features=768, bias=True)
    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (dropout): Dropout(p=0.1, inplace=False)
  )
)
roberta.encoder.layer.7.attention: RobertaAttention(
  (self): RobertaSdpaSelfAttention(
    (query): Linear(in_features=768, out_features=768, bias=True)
    (key): Linear(in_features=768, out_features=768, bias=True)
    (value): Linear(in_features=768, out_features=768, bias=True)
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (output): RobertaSelfOutput(
    (dense): Linear(in_features=768, out_features=768, bias=True)
    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (dropout): Dropout(p=0.1, inplace=False)
  )
)
roberta.encoder.layer.7.attention.self: RobertaSdpaSelfAttention(
  (query): Linear(in_features=768, out_features=768, bias=True)
  (key): Linear(in_features=768, out_features=768, bias=True)
  (value): Linear(in_features=768, out_features=768, bias=True)
  (dropout): Dropout(p=0.1, inplace=False)
)
roberta.encoder.layer.7.attention.self.query: Linear(in_features=768, out_features=768, bias=True)
roberta.encoder.layer.7.attention.self.key: Linear(in_features=768, out_features=768, bias=True)
roberta.encoder.layer.7.attention.self.value: Linear(in_features=768, out_features=768, bias=True)
roberta.encoder.layer.7.attention.self.dropout: Dropout(p=0.1, inplace=False)
roberta.encoder.layer.7.attention.output: RobertaSelfOutput(
  (dense): Linear(in_features=768, out_features=768, bias=True)
  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  (dropout): Dropout(p=0.1, inplace=False)
)
roberta.encoder.layer.7.attention.output.dense: Linear(in_features=768, out_features=768, bias=True)
roberta.encoder.layer.7.attention.output.LayerNorm: LayerNorm((768,), eps=1e-05, elementwise_affine=True)
roberta.encoder.layer.7.attention.output.dropout: Dropout(p=0.1, inplace=False)
roberta.encoder.layer.7.intermediate: RobertaIntermediate(
  (dense): Linear(in_features=768, out_features=3072, bias=True)
  (intermediate_act_fn): ReLU()
)
roberta.encoder.layer.7.intermediate.dense: Linear(in_features=768, out_features=3072, bias=True)
roberta.encoder.layer.7.intermediate.intermediate_act_fn: ReLU()
roberta.encoder.layer.7.output: RobertaOutput(
  (dense): Linear(in_features=3072, out_features=768, bias=True)
  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  (dropout): Dropout(p=0.1, inplace=False)
)
roberta.encoder.layer.7.output.dense: Linear(in_features=3072, out_features=768, bias=True)
roberta.encoder.layer.7.output.LayerNorm: LayerNorm((768,), eps=1e-05, elementwise_affine=True)
roberta.encoder.layer.7.output.dropout: Dropout(p=0.1, inplace=False)
roberta.encoder.layer.8: RobertaLayer(
  (attention): RobertaAttention(
    (self): RobertaSdpaSelfAttention(
      (query): Linear(in_features=768, out_features=768, bias=True)
      (key): Linear(in_features=768, out_features=768, bias=True)
      (value): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (output): RobertaSelfOutput(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (intermediate): RobertaIntermediate(
    (dense): Linear(in_features=768, out_features=3072, bias=True)
    (intermediate_act_fn): ReLU()
  )
  (output): RobertaOutput(
    (dense): Linear(in_features=3072, out_features=768, bias=True)
    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (dropout): Dropout(p=0.1, inplace=False)
  )
)
roberta.encoder.layer.8.attention: RobertaAttention(
  (self): RobertaSdpaSelfAttention(
    (query): Linear(in_features=768, out_features=768, bias=True)
    (key): Linear(in_features=768, out_features=768, bias=True)
    (value): Linear(in_features=768, out_features=768, bias=True)
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (output): RobertaSelfOutput(
    (dense): Linear(in_features=768, out_features=768, bias=True)
    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (dropout): Dropout(p=0.1, inplace=False)
  )
)
roberta.encoder.layer.8.attention.self: RobertaSdpaSelfAttention(
  (query): Linear(in_features=768, out_features=768, bias=True)
  (key): Linear(in_features=768, out_features=768, bias=True)
  (value): Linear(in_features=768, out_features=768, bias=True)
  (dropout): Dropout(p=0.1, inplace=False)
)
roberta.encoder.layer.8.attention.self.query: Linear(in_features=768, out_features=768, bias=True)
roberta.encoder.layer.8.attention.self.key: Linear(in_features=768, out_features=768, bias=True)
roberta.encoder.layer.8.attention.self.value: Linear(in_features=768, out_features=768, bias=True)
roberta.encoder.layer.8.attention.self.dropout: Dropout(p=0.1, inplace=False)
roberta.encoder.layer.8.attention.output: RobertaSelfOutput(
  (dense): Linear(in_features=768, out_features=768, bias=True)
  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  (dropout): Dropout(p=0.1, inplace=False)
)
roberta.encoder.layer.8.attention.output.dense: Linear(in_features=768, out_features=768, bias=True)
roberta.encoder.layer.8.attention.output.LayerNorm: LayerNorm((768,), eps=1e-05, elementwise_affine=True)
roberta.encoder.layer.8.attention.output.dropout: Dropout(p=0.1, inplace=False)
roberta.encoder.layer.8.intermediate: RobertaIntermediate(
  (dense): Linear(in_features=768, out_features=3072, bias=True)
  (intermediate_act_fn): ReLU()
)
roberta.encoder.layer.8.intermediate.dense: Linear(in_features=768, out_features=3072, bias=True)
roberta.encoder.layer.8.intermediate.intermediate_act_fn: ReLU()
roberta.encoder.layer.8.output: RobertaOutput(
  (dense): Linear(in_features=3072, out_features=768, bias=True)
  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  (dropout): Dropout(p=0.1, inplace=False)
)
roberta.encoder.layer.8.output.dense: Linear(in_features=3072, out_features=768, bias=True)
roberta.encoder.layer.8.output.LayerNorm: LayerNorm((768,), eps=1e-05, elementwise_affine=True)
roberta.encoder.layer.8.output.dropout: Dropout(p=0.1, inplace=False)
roberta.encoder.layer.9: RobertaLayer(
  (attention): RobertaAttention(
    (self): RobertaSdpaSelfAttention(
      (query): Linear(in_features=768, out_features=768, bias=True)
      (key): Linear(in_features=768, out_features=768, bias=True)
      (value): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (output): RobertaSelfOutput(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (intermediate): RobertaIntermediate(
    (dense): Linear(in_features=768, out_features=3072, bias=True)
    (intermediate_act_fn): ReLU()
  )
  (output): RobertaOutput(
    (dense): Linear(in_features=3072, out_features=768, bias=True)
    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (dropout): Dropout(p=0.1, inplace=False)
  )
)
roberta.encoder.layer.9.attention: RobertaAttention(
  (self): RobertaSdpaSelfAttention(
    (query): Linear(in_features=768, out_features=768, bias=True)
    (key): Linear(in_features=768, out_features=768, bias=True)
    (value): Linear(in_features=768, out_features=768, bias=True)
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (output): RobertaSelfOutput(
    (dense): Linear(in_features=768, out_features=768, bias=True)
    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (dropout): Dropout(p=0.1, inplace=False)
  )
)
roberta.encoder.layer.9.attention.self: RobertaSdpaSelfAttention(
  (query): Linear(in_features=768, out_features=768, bias=True)
  (key): Linear(in_features=768, out_features=768, bias=True)
  (value): Linear(in_features=768, out_features=768, bias=True)
  (dropout): Dropout(p=0.1, inplace=False)
)
roberta.encoder.layer.9.attention.self.query: Linear(in_features=768, out_features=768, bias=True)
roberta.encoder.layer.9.attention.self.key: Linear(in_features=768, out_features=768, bias=True)
roberta.encoder.layer.9.attention.self.value: Linear(in_features=768, out_features=768, bias=True)
roberta.encoder.layer.9.attention.self.dropout: Dropout(p=0.1, inplace=False)
roberta.encoder.layer.9.attention.output: RobertaSelfOutput(
  (dense): Linear(in_features=768, out_features=768, bias=True)
  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  (dropout): Dropout(p=0.1, inplace=False)
)
roberta.encoder.layer.9.attention.output.dense: Linear(in_features=768, out_features=768, bias=True)
roberta.encoder.layer.9.attention.output.LayerNorm: LayerNorm((768,), eps=1e-05, elementwise_affine=True)
roberta.encoder.layer.9.attention.output.dropout: Dropout(p=0.1, inplace=False)
roberta.encoder.layer.9.intermediate: RobertaIntermediate(
  (dense): Linear(in_features=768, out_features=3072, bias=True)
  (intermediate_act_fn): ReLU()
)
roberta.encoder.layer.9.intermediate.dense: Linear(in_features=768, out_features=3072, bias=True)
roberta.encoder.layer.9.intermediate.intermediate_act_fn: ReLU()
roberta.encoder.layer.9.output: RobertaOutput(
  (dense): Linear(in_features=3072, out_features=768, bias=True)
  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  (dropout): Dropout(p=0.1, inplace=False)
)
roberta.encoder.layer.9.output.dense: Linear(in_features=3072, out_features=768, bias=True)
roberta.encoder.layer.9.output.LayerNorm: LayerNorm((768,), eps=1e-05, elementwise_affine=True)
roberta.encoder.layer.9.output.dropout: Dropout(p=0.1, inplace=False)
roberta.encoder.layer.10: RobertaLayer(
  (attention): RobertaAttention(
    (self): RobertaSdpaSelfAttention(
      (query): Linear(in_features=768, out_features=768, bias=True)
      (key): Linear(in_features=768, out_features=768, bias=True)
      (value): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (output): RobertaSelfOutput(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (intermediate): RobertaIntermediate(
    (dense): Linear(in_features=768, out_features=3072, bias=True)
    (intermediate_act_fn): ReLU()
  )
  (output): RobertaOutput(
    (dense): Linear(in_features=3072, out_features=768, bias=True)
    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (dropout): Dropout(p=0.1, inplace=False)
  )
)
roberta.encoder.layer.10.attention: RobertaAttention(
  (self): RobertaSdpaSelfAttention(
    (query): Linear(in_features=768, out_features=768, bias=True)
    (key): Linear(in_features=768, out_features=768, bias=True)
    (value): Linear(in_features=768, out_features=768, bias=True)
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (output): RobertaSelfOutput(
    (dense): Linear(in_features=768, out_features=768, bias=True)
    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (dropout): Dropout(p=0.1, inplace=False)
  )
)
roberta.encoder.layer.10.attention.self: RobertaSdpaSelfAttention(
  (query): Linear(in_features=768, out_features=768, bias=True)
  (key): Linear(in_features=768, out_features=768, bias=True)
  (value): Linear(in_features=768, out_features=768, bias=True)
  (dropout): Dropout(p=0.1, inplace=False)
)
roberta.encoder.layer.10.attention.self.query: Linear(in_features=768, out_features=768, bias=True)
roberta.encoder.layer.10.attention.self.key: Linear(in_features=768, out_features=768, bias=True)
roberta.encoder.layer.10.attention.self.value: Linear(in_features=768, out_features=768, bias=True)
roberta.encoder.layer.10.attention.self.dropout: Dropout(p=0.1, inplace=False)
roberta.encoder.layer.10.attention.output: RobertaSelfOutput(
  (dense): Linear(in_features=768, out_features=768, bias=True)
  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  (dropout): Dropout(p=0.1, inplace=False)
)
roberta.encoder.layer.10.attention.output.dense: Linear(in_features=768, out_features=768, bias=True)
roberta.encoder.layer.10.attention.output.LayerNorm: LayerNorm((768,), eps=1e-05, elementwise_affine=True)
roberta.encoder.layer.10.attention.output.dropout: Dropout(p=0.1, inplace=False)
roberta.encoder.layer.10.intermediate: RobertaIntermediate(
  (dense): Linear(in_features=768, out_features=3072, bias=True)
  (intermediate_act_fn): ReLU()
)
roberta.encoder.layer.10.intermediate.dense: Linear(in_features=768, out_features=3072, bias=True)
roberta.encoder.layer.10.intermediate.intermediate_act_fn: ReLU()
roberta.encoder.layer.10.output: RobertaOutput(
  (dense): Linear(in_features=3072, out_features=768, bias=True)
  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  (dropout): Dropout(p=0.1, inplace=False)
)
roberta.encoder.layer.10.output.dense: Linear(in_features=3072, out_features=768, bias=True)
roberta.encoder.layer.10.output.LayerNorm: LayerNorm((768,), eps=1e-05, elementwise_affine=True)
roberta.encoder.layer.10.output.dropout: Dropout(p=0.1, inplace=False)
roberta.encoder.layer.11: RobertaLayer(
  (attention): RobertaAttention(
    (self): RobertaSdpaSelfAttention(
      (query): Linear(in_features=768, out_features=768, bias=True)
      (key): Linear(in_features=768, out_features=768, bias=True)
      (value): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (output): RobertaSelfOutput(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (intermediate): RobertaIntermediate(
    (dense): Linear(in_features=768, out_features=3072, bias=True)
    (intermediate_act_fn): ReLU()
  )
  (output): RobertaOutput(
    (dense): Linear(in_features=3072, out_features=768, bias=True)
    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (dropout): Dropout(p=0.1, inplace=False)
  )
)
roberta.encoder.layer.11.attention: RobertaAttention(
  (self): RobertaSdpaSelfAttention(
    (query): Linear(in_features=768, out_features=768, bias=True)
    (key): Linear(in_features=768, out_features=768, bias=True)
    (value): Linear(in_features=768, out_features=768, bias=True)
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (output): RobertaSelfOutput(
    (dense): Linear(in_features=768, out_features=768, bias=True)
    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (dropout): Dropout(p=0.1, inplace=False)
  )
)
roberta.encoder.layer.11.attention.self: RobertaSdpaSelfAttention(
  (query): Linear(in_features=768, out_features=768, bias=True)
  (key): Linear(in_features=768, out_features=768, bias=True)
  (value): Linear(in_features=768, out_features=768, bias=True)
  (dropout): Dropout(p=0.1, inplace=False)
)
roberta.encoder.layer.11.attention.self.query: Linear(in_features=768, out_features=768, bias=True)
roberta.encoder.layer.11.attention.self.key: Linear(in_features=768, out_features=768, bias=True)
roberta.encoder.layer.11.attention.self.value: Linear(in_features=768, out_features=768, bias=True)
roberta.encoder.layer.11.attention.self.dropout: Dropout(p=0.1, inplace=False)
roberta.encoder.layer.11.attention.output: RobertaSelfOutput(
  (dense): Linear(in_features=768, out_features=768, bias=True)
  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  (dropout): Dropout(p=0.1, inplace=False)
)
roberta.encoder.layer.11.attention.output.dense: Linear(in_features=768, out_features=768, bias=True)
roberta.encoder.layer.11.attention.output.LayerNorm: LayerNorm((768,), eps=1e-05, elementwise_affine=True)
roberta.encoder.layer.11.attention.output.dropout: Dropout(p=0.1, inplace=False)
roberta.encoder.layer.11.intermediate: RobertaIntermediate(
  (dense): Linear(in_features=768, out_features=3072, bias=True)
  (intermediate_act_fn): ReLU()
)
roberta.encoder.layer.11.intermediate.dense: Linear(in_features=768, out_features=3072, bias=True)
roberta.encoder.layer.11.intermediate.intermediate_act_fn: ReLU()
roberta.encoder.layer.11.output: RobertaOutput(
  (dense): Linear(in_features=3072, out_features=768, bias=True)
  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  (dropout): Dropout(p=0.1, inplace=False)
)
roberta.encoder.layer.11.output.dense: Linear(in_features=3072, out_features=768, bias=True)
roberta.encoder.layer.11.output.LayerNorm: LayerNorm((768,), eps=1e-05, elementwise_affine=True)
roberta.encoder.layer.11.output.dropout: Dropout(p=0.1, inplace=False)
classifier: RobertaClassificationHead(
  (dense): Linear(in_features=768, out_features=768, bias=True)
  (dropout): Dropout(p=0.1, inplace=False)
  (out_proj): Linear(in_features=768, out_features=2, bias=True)
)
classifier.dense: Linear(in_features=768, out_features=768, bias=True)
classifier.dropout: Dropout(p=0.1, inplace=False)
classifier.out_proj: Linear(in_features=768, out_features=2, bias=True)
