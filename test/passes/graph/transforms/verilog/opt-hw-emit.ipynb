{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "ROOT = os.path.join(\n",
    "        os.getcwd(),\n",
    "        \"..\",\n",
    "        \"..\",\n",
    "        \"..\",\n",
    "        \"..\",\n",
    "        \"..\",\n",
    "    )\n",
    "\n",
    "sys.path.append(ROOT + \"/machop\")\n",
    "\n",
    "from chop.passes.graph.mase_graph import MaseGraph\n",
    "from chop.models import get_model, get_model_info, get_tokenizer\n",
    "from chop.tools.get_input import get_cf_args, get_dummy_input\n",
    "from chop.dataset import get_dataset_info, MaseDataModule\n",
    "import chop.passes as passes\n",
    "\n",
    "from chop.passes.transforms import (\n",
    "    emit_verilog_top_transform_pass,\n",
    "    emit_mlir_hls_transform_pass,\n",
    "    emit_internal_rtl_transform_pass,\n",
    "    emit_bram_transform_pass,\n",
    "    emit_verilog_tb_transform_pass,\n",
    "    quantize_transform_pass,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reload modules after changing code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikitext_info = get_dataset_info(\"wikitext2\")\n",
    "\n",
    "opt = get_model(\n",
    "    \"facebook/opt-125m:patched\",\n",
    "    task=\"lm\",\n",
    "    dataset_info=wikitext_info,\n",
    "    pretrained=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_tokenizer = get_tokenizer(\"facebook/opt-125m:patched\")\n",
    "\n",
    "data_module = MaseDataModule(\n",
    "    name=\"wikitext2\",\n",
    "    batch_size=1,\n",
    "    num_workers=os.cpu_count(),\n",
    "    max_token_len=128,\n",
    "    tokenizer=opt_tokenizer,\n",
    "    load_from_cache_file=True,\n",
    "    model_name=\"facebook/opt-125m@patched\",\n",
    ")\n",
    "data_module.prepare_data()\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate graph, initialize metadata and draw diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADD COMMON METADATA\n",
      "ADD HW METADATA\n",
      "before removal [model_decoder_layers_0_self_attn, model_decoder_layers_1_self_attn, model_decoder_layers_2_self_attn, model_decoder_layers_3_self_attn, model_decoder_layers_4_self_attn, model_decoder_layers_5_self_attn, model_decoder_layers_6_self_attn, model_decoder_layers_7_self_attn, model_decoder_layers_8_self_attn, model_decoder_layers_9_self_attn, model_decoder_layers_10_self_attn, model_decoder_layers_11_self_attn, add_1, add, output]\n",
      "after removal [model_decoder_layers_0_self_attn, model_decoder_layers_1_self_attn, model_decoder_layers_2_self_attn, model_decoder_layers_3_self_attn, model_decoder_layers_4_self_attn, model_decoder_layers_5_self_attn, model_decoder_layers_6_self_attn, model_decoder_layers_7_self_attn, model_decoder_layers_8_self_attn, model_decoder_layers_9_self_attn, model_decoder_layers_10_self_attn, model_decoder_layers_11_self_attn]\n",
      "UPDATE ATTENTION ARGS\n"
     ]
    }
   ],
   "source": [
    "# Generate graph and initialize metadata\n",
    "model_info = get_model_info(\"facebook/opt-125m:patched\")\n",
    "cf_args = get_cf_args(model_info=model_info, task=\"lm\", model=opt)\n",
    "graph = MaseGraph(model=opt, cf_args=cf_args)\n",
    "graph = passes.PASSES[\"init_metadata\"](graph, pass_args=None)\n",
    "\n",
    "# Generate dummy input\n",
    "dummy_in = get_dummy_input(model_info, data_module=data_module, task=\"lm\")\n",
    "if len(graph.model.additional_inputs) > 0:\n",
    "    dummy_in = dummy_in | graph.model.additional_inputs\n",
    "\n",
    "# Add common metadata - infer input and output shape for each node\n",
    "print(f\"ADD COMMON METADATA\")\n",
    "graph = passes.PASSES[\"add_common_metadata\"](graph, pass_args=dummy_in)\n",
    "# graph = passes.PASSES[\"verify_common_metadata\"](graph)\n",
    "\n",
    "config_file = ROOT + \"/machop/configs/tests/quantize/fixed.toml\"\n",
    "with open(config_file, \"r\") as f:\n",
    "    import toml\n",
    "    quan_args = toml.load(f)[\"passes\"][\"quantize\"]\n",
    "graph = quantize_transform_pass(graph, quan_args)\n",
    "\n",
    "print(f\"ADD HW METADATA\")\n",
    "graph = passes.PASSES[\"add_hardware_metadata\"](graph, pass_args=None)\n",
    "\n",
    "# Remove add/add_1/output as input nodes\n",
    "# TO DO: temporary solution\n",
    "print(f\"before removal {graph.nodes_in}\")\n",
    "graph.nodes_in = graph.nodes_in[:-3]\n",
    "print(f\"after removal {graph.nodes_in}\")\n",
    "\n",
    "print(f\"UPDATE ATTENTION ARGS\")\n",
    "# Rename attention node inputs etc\n",
    "for node in graph.fx_graph.nodes:\n",
    "    if (\"self_attn\" in node.name and \"layer_norm\" not in node.name):\n",
    "        node.meta[\"mase\"].parameters[\"common\"][\"args\"][\"bias_q\"] = node.meta[\"mase\"].parameters[\"common\"][\"args\"].pop(\"q_proj.bias\")\n",
    "        node.meta[\"mase\"].parameters[\"common\"][\"args\"][\"bias_k\"] = node.meta[\"mase\"].parameters[\"common\"][\"args\"].pop(\"k_proj.bias\")\n",
    "        node.meta[\"mase\"].parameters[\"common\"][\"args\"][\"bias_v\"] = node.meta[\"mase\"].parameters[\"common\"][\"args\"].pop(\"v_proj.bias\")\n",
    "        \n",
    "        node.meta[\"mase\"].parameters[\"common\"][\"args\"][\"weight_q\"] = node.meta[\"mase\"].parameters[\"common\"][\"args\"].pop(\"q_proj.weight\")\n",
    "        node.meta[\"mase\"].parameters[\"common\"][\"args\"][\"weight_k\"] = node.meta[\"mase\"].parameters[\"common\"][\"args\"].pop(\"k_proj.weight\")\n",
    "        node.meta[\"mase\"].parameters[\"common\"][\"args\"][\"weight_v\"] = node.meta[\"mase\"].parameters[\"common\"][\"args\"].pop(\"v_proj.weight\")\n",
    "\n",
    "        # Pop out attention_mask and output_attentions\n",
    "        node.meta[\"mase\"].parameters[\"common\"][\"args\"].pop(\"data_in_2\")\n",
    "        node.meta[\"mase\"].parameters[\"common\"][\"args\"].pop(\"data_in_4\")\n",
    "\n",
    "        # Pop output projection weight/bias\n",
    "        node.meta[\"mase\"].parameters[\"common\"][\"args\"].pop(\"out_proj.weight\")\n",
    "        node.meta[\"mase\"].parameters[\"common\"][\"args\"].pop(\"out_proj.bias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<chop.passes.graph.mase_graph.MaseGraph at 0x7fe17bb41de0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# graph.fx_graph.print_tabular()\n",
    "\n",
    "from chop.passes.analysis.report.report_node import report_node_type_analysis_pass\n",
    "report_node_type_analysis_pass(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = emit_verilog_top_transform_pass(graph)\n",
    "# graph = emit_bram_transform_pass(graph)\n",
    "# graph = emit_internal_rtl_transform_pass(graph)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
