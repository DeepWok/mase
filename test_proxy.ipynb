{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from naslib.predictors.utils.pruners.predictive import find_measures "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ansonhon/mase_project/machop\n"
     ]
    }
   ],
   "source": [
    "%cd machop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define a simple neural network\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, 1)\n",
    "        self.fc1 = nn.Linear(32 * 5 * 5, 128)  # Corrected size\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 32 * 5 * 5)  # Corrected size\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Initialize the network\n",
    "net = SimpleNet()\n",
    "\n",
    "# Create some random input data and targets\n",
    "inputs = torch.randn(64, 1, 28, 28)  # Assuming MNIST-like data\n",
    "targets = torch.randint(0, 10, (64,))  # 10 classes\n",
    "\n",
    "# Define a loss function\n",
    "loss_fn = nn.NLLLoss()\n",
    "\n",
    "# Call the function with the provided code\n",
    "result = compute_epe_score(net, inputs, targets, loss_fn, split_data=1)\n",
    "# print(\"length of result: \", len(result))\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import types\n",
    "\n",
    "# Define a simple neural network\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Function to generate some dummy data\n",
    "def get_some_data(trainloader, num_batches, device):\n",
    "    dataiter = iter(trainloader)\n",
    "    images, labels = dataiter.next()\n",
    "    return images.to(device), labels.to(device)\n",
    "\n",
    "# Function to simulate a data loader\n",
    "class DummyDataLoader:\n",
    "    def __init__(self, data_shape):\n",
    "        self.data_shape = data_shape\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        # Simulate loading data\n",
    "        return torch.randn(*self.data_shape), torch.randint(0, 10, (self.data_shape[0],))\n",
    "\n",
    "# Define dummy parameters for the test case\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "trainloader = DummyDataLoader((4, 3, 32, 32))  # Dummy data loader with batch size 4 and 3-channel images\n",
    "dataload_info = (\"random\", 1, 10)  # Random data, 1 batch, 10 classes\n",
    "\n",
    "# Call the function with the provided code\n",
    "measure_values = find_measures_arrays(SimpleNet(), trainloader, dataload_info, device)\n",
    "\n",
    "# Print the results\n",
    "print(measure_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define a simple neural network\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def forward_before_global_avg_pool(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        return x\n",
    "\n",
    "# Call the function with the provided code\n",
    "measure_values = find_measures(SimpleNet(), trainloader, dataload_info, device)\n",
    "\n",
    "# Print the results\n",
    "print(measure_values.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epe_nas': 5.910644394585874, 'fisher': 0.004558369982987642, 'grad_norm': 0.5958195328712463, 'grasp': -0.36751067638397217, 'jacov': -4.02287100674039, 'l2_norm': 17.101762771606445, 'nwot': -inf, 'plain': 0.07703622430562973, 'snip': 0.9100861549377441, 'synflow': 324971.8274572004, 'zen': 5.3224263191223145}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define a simple neural network\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def forward_before_global_avg_pool(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        return x\n",
    "\n",
    "# Dummy data loader class\n",
    "class DummyDataLoader:\n",
    "    def __init__(self, data_shape):\n",
    "        self.data_shape = data_shape\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        # Simulate loading data\n",
    "        return torch.randn(*self.data_shape), torch.randint(0, 10, (self.data_shape[0],))\n",
    "\n",
    "# Dummy loss function\n",
    "def dummy_loss_fn(output, target):\n",
    "    # Assuming output has shape [batch_size, num_classes] and target has shape [batch_size]\n",
    "    # Convert target to one-hot encoding to match the shape of output\n",
    "    target_one_hot = F.one_hot(target, num_classes=output.shape[1])\n",
    "    # Calculate mean squared error\n",
    "    return F.mse_loss(output, target_one_hot.float())\n",
    "\n",
    "# Define dummy parameters for the test case\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dataloader = DummyDataLoader((4, 3, 32, 32))  # Dummy data loader with batch size 4 and 3-channel images\n",
    "dataload_info = (\"random\", 1, 10)  # Random data, 1 batch, 10 classes\n",
    "measure_names = ['params']  # Only compute parameters count for this test\n",
    "\n",
    "# Call the function with the provided code\n",
    "measure_values = find_measures(SimpleNet(), dataloader, dataload_info, device, dummy_loss_fn, measure_names = ['epe_nas', 'fisher', 'grad_norm', 'grasp', 'jacov', 'l2_norm', 'nwot', 'plain', 'snip', 'synflow', 'zen'])\n",
    "\n",
    "# Print the results\n",
    "print(measure_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ansonhon/mase_project/machop\n"
     ]
    }
   ],
   "source": [
    "%cd machop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from naslib.predictors.utils.pruners.measures.epe_nas import compute_epe_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
