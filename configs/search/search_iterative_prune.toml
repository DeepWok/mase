# basics
model = "vgg7"
dataset = "cifar10"
task = "cls"

max_epochs = 5
batch_size = 256
learning_rate = 1e-3
accelerator = "cpu"
project = "vgg7-pruning-search"
seed = 42
log_every_n_steps = 5
# load_name = ""
# load_type = "pl"

[search.search_space]
name = "prune/iterative"

[search.search_space.config.model_config]
model = "vgg7"
dataset = "cifar10"
task = "cls"
batch_size = 256

# [search.search_space.config.search_config.iterative_prune]
# num_iterations = [1, 3, 5]
# scope = ["global", "local"]
# granularity = ["elementwise"]
# method = ["l1-norm", "random"]
# sparsity = [0.3, 0.5, 0.7, 0.9]

[search.search_space.config.search_config.iterative_prune]
num_iterations = [5]
scope = ["global"]
granularity = ["elementwise"]
method = ["l1-norm"]
sparsity = [0.5, 0.7]

[search.search_space.config.search_config.train]
max_epochs = [5]
optimizer = ["adam"]
learning_rate = [1e-3]

[search.strategy]
name = "optuna"
eval_mode = true

[search.strategy.sw_runner.basic_evaluation]
name = "accuracy"
data_loader = "val_dataloader"
num_samples = 512

[search.strategy.sw_runner.basic_sparsity]
name = "weight_sparsity"

[search.strategy.hw_runner.hw_dummy]
name = "hw_dummy"

[search.strategy.setup]
n_jobs = 1
n_trials = 2
timeout = 20000
sampler = "tpe"
# sum_scaled_metrics = true # single objective
# direction = "maximize"
sum_scaled_metrics = false # multi objective

[search.strategy.metrics]
loss.scale = 1.0
loss.direction = "minimize"
accuracy.scale = 1.0
accuracy.direction = "maximize"
# average_bitwidth.scale = 0.2
# average_bitwidth.direction = "minimize"