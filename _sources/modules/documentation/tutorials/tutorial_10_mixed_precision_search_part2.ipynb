{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 6: Mixed Precision Quantization Search with Mase and Optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we'll see how Mase can be integrated with Optuna to search on more applications, such as finding out the best mixed-precision configuration.\n",
    "\n",
    "As we'll see, this would be very similar to running NAS, involving the following setups: **Define the search space**, **Write the model constructor** and **Write the objective function**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The difference caused different precisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by importing the necessary libraries and defining the model constructor. We'll use the same model as in the previous tutorial.\n",
    "\n",
    "However, we instantiate a function `get_accuracy` that will be used to evaluate the model's accuracy. This function will be used to evaluate the model's accuracy in the objective function too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chop.passes as passes\n",
    "\n",
    "from chop import MaseGraph\n",
    "\n",
    "from chop.tools import get_tokenized_dataset, get_trainer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from pathlib import Path\n",
    "\n",
    "import copy\n",
    "\n",
    "\n",
    "checkpoint = \"prajjwal1/bert-tiny\"\n",
    "tokenizer_checkpoint = \"bert-base-uncased\"\n",
    "dataset_name = \"imdb\"\n",
    "\n",
    "\n",
    "def get_accuracy(mg, dataset, tokenizer):\n",
    "    t = get_trainer(\n",
    "        model=mg.model,\n",
    "        tokenized_dataset=dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        evaluate_metric=\"accuracy\")\n",
    "    e = t.evaluate()\n",
    "    return e[\"eval_accuracy\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the pretrianed model and then transform the model to the MASE graph format and also instantiate the dataset and tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "`past_key_values` were not specified as input names, but model.config.use_cache = True. Setting model.config.use_cache = False.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mGetting dummy input for prajjwal1/bert-tiny.\u001b[0m\n",
      "/Users/yz10513/anaconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/Users/yz10513/Projects/mase/src/chop/ir/graph/mase_graph.py:374: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  loaded_model = torch.load(f)\n",
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode finfo not found in loaded metadata.\u001b[0m\n",
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode getattr_2 not found in loaded metadata.\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTokenizing dataset imdb with AutoTokenizer for bert-base-uncased.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
      "\n",
      "\n",
      "        [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]])\n",
      "tensor([[[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
      "\n",
      "\n",
      "        [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]])\n",
      "tensor([[[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]])\n",
      "tensor([[[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]])\n",
      "tensor([[[ 0.7973,  0.0109, -8.8405,  ...,  1.4170,  0.1046, -0.1551],\n",
      "         [-1.1766,  1.2879, -1.0986,  ...,  0.4749, -0.5899,  0.8746],\n",
      "         [-2.0560,  0.7748, -0.8909,  ..., -0.4034,  0.5352, -1.3657],\n",
      "         ...,\n",
      "         [ 0.2317, -0.7896,  0.9634,  ..., -0.8037,  0.4834, -0.5868],\n",
      "         [ 0.0243, -1.0235, -1.2771,  ..., -2.2378,  1.8530,  0.1558],\n",
      "         [-1.3637,  0.7055, -0.2177,  ...,  0.3557, -0.3971, -0.3107]],\n",
      "\n",
      "        [[ 0.7973,  0.0109, -8.8405,  ...,  1.4170,  0.1046, -0.1551],\n",
      "         [-2.6940,  0.6198, -0.4564,  ..., -1.4367, -1.5705, -3.1260],\n",
      "         [-1.7524,  0.8535, -0.2155,  ..., -0.5222, -1.2430, -1.7199],\n",
      "         ...,\n",
      "         [-0.0347,  0.7446,  1.4462,  ..., -1.1578, -2.6197,  0.2612],\n",
      "         [ 2.4334, -0.3068,  0.8250,  ...,  0.1475,  0.1790,  2.2907],\n",
      "         [-1.3637,  0.7055, -0.2177,  ...,  0.3557, -0.3971, -0.3107]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[ 9.7740e-01,  2.5481e-03, -5.2921e-01,  ...,  1.4757e-01,\n",
      "           1.8900e-01,  2.8282e-01],\n",
      "         [-3.5020e-02, -6.1047e-02, -1.0465e-01,  ..., -8.1892e-01,\n",
      "           1.1978e+00,  2.1808e+00],\n",
      "         [ 4.3982e-01, -1.9602e+00, -6.8830e-01,  ..., -6.3025e-01,\n",
      "          -1.5967e-01,  1.3284e+00],\n",
      "         ...,\n",
      "         [ 1.4783e+00,  1.0907e-01, -1.5222e+00,  ..., -3.0983e-01,\n",
      "          -1.2971e-01,  1.1265e+00],\n",
      "         [ 1.5890e+00, -1.6859e+00,  7.8703e-01,  ..., -1.3173e+00,\n",
      "           2.2258e-01,  8.8157e-01],\n",
      "         [-3.7517e-01,  1.5191e+00, -2.6796e-01,  ..., -1.6159e+00,\n",
      "           7.2677e-02,  1.1724e-01]],\n",
      "\n",
      "        [[ 9.7740e-01,  2.5481e-03, -5.2921e-01,  ...,  1.4757e-01,\n",
      "           1.8900e-01,  2.8282e-01],\n",
      "         [-4.4781e-01, -7.9224e-01, -2.1741e+00,  ..., -5.9181e-01,\n",
      "           1.4373e+00,  2.4267e+00],\n",
      "         [-2.5942e-01,  9.7163e-01, -3.2928e+00,  ..., -5.9773e-01,\n",
      "          -3.0482e-01,  1.4038e+00],\n",
      "         ...,\n",
      "         [ 5.1574e-02,  3.5218e-01, -3.8926e-01,  ..., -1.1508e+00,\n",
      "           7.5490e-01,  8.2911e-01],\n",
      "         [ 1.6107e+00,  6.8170e-02,  9.2537e-01,  ..., -1.5233e+00,\n",
      "          -6.0733e-01,  3.3097e-01],\n",
      "         [-3.7517e-01,  1.5191e+00, -2.6796e-01,  ..., -1.6159e+00,\n",
      "           7.2677e-02,  1.1724e-01]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 9.7740e-01,  2.5481e-03, -5.2921e-01,  ...,  1.4757e-01,\n",
      "           1.8900e-01,  2.8282e-01],\n",
      "         [-3.5020e-02, -6.1047e-02, -1.0465e-01,  ..., -8.1892e-01,\n",
      "           1.1978e+00,  2.1808e+00],\n",
      "         [ 4.3982e-01, -1.9602e+00, -6.8830e-01,  ..., -6.3025e-01,\n",
      "          -1.5967e-01,  1.3284e+00],\n",
      "         ...,\n",
      "         [ 1.4783e+00,  1.0907e-01, -1.5222e+00,  ..., -3.0983e-01,\n",
      "          -1.2971e-01,  1.1265e+00],\n",
      "         [ 1.5890e+00, -1.6859e+00,  7.8703e-01,  ..., -1.3173e+00,\n",
      "           2.2258e-01,  8.8157e-01],\n",
      "         [-3.7517e-01,  1.5191e+00, -2.6796e-01,  ..., -1.6159e+00,\n",
      "           7.2677e-02,  1.1724e-01]],\n",
      "\n",
      "        [[ 9.7740e-01,  2.5481e-03, -5.2921e-01,  ...,  1.4757e-01,\n",
      "           1.8900e-01,  2.8282e-01],\n",
      "         [-4.4781e-01, -7.9224e-01, -2.1741e+00,  ..., -5.9181e-01,\n",
      "           1.4373e+00,  2.4267e+00],\n",
      "         [-2.5942e-01,  9.7163e-01, -3.2928e+00,  ..., -5.9773e-01,\n",
      "          -3.0482e-01,  1.4038e+00],\n",
      "         ...,\n",
      "         [ 5.1574e-02,  3.5218e-01, -3.8926e-01,  ..., -1.1508e+00,\n",
      "           7.5490e-01,  8.2911e-01],\n",
      "         [ 1.6107e+00,  6.8170e-02,  9.2537e-01,  ..., -1.5233e+00,\n",
      "          -6.0733e-01,  3.3097e-01],\n",
      "         [-3.7517e-01,  1.5191e+00, -2.6796e-01,  ..., -1.6159e+00,\n",
      "           7.2677e-02,  1.1724e-01]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 9.7740e-01,  2.5481e-03, -5.2921e-01,  ..., -5.2614e-01,\n",
      "           -3.5687e-01, -2.6793e-01],\n",
      "          [ 2.0335e-01, -5.4534e-01,  3.0686e-01,  ...,  1.4757e-01,\n",
      "            1.8900e-01,  2.8282e-01]],\n",
      "\n",
      "         [[-3.5020e-02, -6.1047e-02, -1.0465e-01,  ..., -2.0138e+00,\n",
      "            4.5529e-01, -7.8171e-01],\n",
      "          [ 1.1969e+00,  1.6337e+00,  2.5047e-01,  ..., -8.1892e-01,\n",
      "            1.1978e+00,  2.1808e+00]],\n",
      "\n",
      "         [[ 4.3982e-01, -1.9602e+00, -6.8830e-01,  ..., -2.2501e-01,\n",
      "            7.2290e-02, -1.8290e+00],\n",
      "          [ 8.9952e-01,  1.0029e+00,  7.4520e-04,  ..., -6.3025e-01,\n",
      "           -1.5967e-01,  1.3284e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4783e+00,  1.0907e-01, -1.5222e+00,  ...,  1.1867e+00,\n",
      "           -1.3561e+00,  6.5158e-01],\n",
      "          [ 9.5466e-01,  4.5887e-01,  7.8078e-01,  ..., -3.0983e-01,\n",
      "           -1.2971e-01,  1.1265e+00]],\n",
      "\n",
      "         [[ 1.5890e+00, -1.6859e+00,  7.8703e-01,  ...,  6.5467e-01,\n",
      "           -6.8451e-01,  6.5081e-01],\n",
      "          [ 7.0729e-01,  1.4499e+00, -1.5089e-01,  ..., -1.3173e+00,\n",
      "            2.2258e-01,  8.8157e-01]],\n",
      "\n",
      "         [[-3.7517e-01,  1.5191e+00, -2.6796e-01,  ...,  3.3130e-01,\n",
      "           -3.2756e-01, -6.3130e-01],\n",
      "          [ 8.6773e-01,  2.0996e-01, -3.4332e-01,  ..., -1.6159e+00,\n",
      "            7.2677e-02,  1.1724e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 9.7740e-01,  2.5481e-03, -5.2921e-01,  ..., -5.2614e-01,\n",
      "           -3.5687e-01, -2.6793e-01],\n",
      "          [ 2.0335e-01, -5.4534e-01,  3.0686e-01,  ...,  1.4757e-01,\n",
      "            1.8900e-01,  2.8282e-01]],\n",
      "\n",
      "         [[-4.4781e-01, -7.9224e-01, -2.1741e+00,  ...,  1.7508e+00,\n",
      "           -3.6708e-01, -1.3251e+00],\n",
      "          [ 7.9208e-01, -1.3537e-01,  2.3756e-01,  ..., -5.9181e-01,\n",
      "            1.4373e+00,  2.4267e+00]],\n",
      "\n",
      "         [[-2.5942e-01,  9.7163e-01, -3.2928e+00,  ..., -9.6646e-01,\n",
      "           -4.8876e-01, -1.4426e+00],\n",
      "          [ 1.0250e+00, -6.9093e-01, -1.2734e+00,  ..., -5.9773e-01,\n",
      "           -3.0482e-01,  1.4038e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.1574e-02,  3.5218e-01, -3.8926e-01,  ..., -1.2252e-02,\n",
      "            1.0394e+00,  4.2402e-01],\n",
      "          [-4.7386e-01,  2.6401e+00,  1.7024e+00,  ..., -1.1508e+00,\n",
      "            7.5490e-01,  8.2911e-01]],\n",
      "\n",
      "         [[ 1.6107e+00,  6.8170e-02,  9.2537e-01,  ..., -6.1665e-01,\n",
      "            2.7627e-01, -1.2083e+00],\n",
      "          [ 9.3395e-01, -9.7541e-01, -2.5442e-02,  ..., -1.5233e+00,\n",
      "           -6.0733e-01,  3.3097e-01]],\n",
      "\n",
      "         [[-3.7517e-01,  1.5191e+00, -2.6796e-01,  ...,  3.3130e-01,\n",
      "           -3.2756e-01, -6.3130e-01],\n",
      "          [ 8.6773e-01,  2.0996e-01, -3.4332e-01,  ..., -1.6159e+00,\n",
      "            7.2677e-02,  1.1724e-01]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.1709,  0.5230, -0.8713,  ..., -1.3382,  0.5892,  0.4026],\n",
      "         [-0.5842,  0.9588,  1.5642,  ..., -1.0731, -0.7330,  0.3132],\n",
      "         [-0.8601, -1.3756,  0.5042,  ..., -0.0476,  0.2650,  1.2150],\n",
      "         ...,\n",
      "         [ 0.0520,  1.1719, -1.5471,  ..., -0.7894,  0.1419,  1.6964],\n",
      "         [ 0.7654, -1.5053, -0.4142,  ..., -1.4622, -0.8975,  1.4576],\n",
      "         [-1.2008, -0.6008, -1.4608,  ..., -1.2105, -0.4289,  0.3827]],\n",
      "\n",
      "        [[-0.1709,  0.5230, -0.8713,  ..., -1.3382,  0.5892,  0.4026],\n",
      "         [-1.3806,  0.2626, -0.5207,  ..., -1.6714, -0.0554,  1.0225],\n",
      "         [-1.7116,  1.8788, -2.5695,  ..., -0.6958,  0.5728,  0.5461],\n",
      "         ...,\n",
      "         [-1.3246,  1.2196, -0.3034,  ..., -1.1955, -0.6708,  0.5128],\n",
      "         [ 0.9854,  0.8260,  0.2892,  ..., -0.6428,  0.3637,  0.4339],\n",
      "         [-1.2008, -0.6008, -1.4608,  ..., -1.2105, -0.4289,  0.3827]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.1709,  0.5230, -0.8713,  ..., -1.3382,  0.5892,  0.4026],\n",
      "         [-0.5842,  0.9588,  1.5642,  ..., -1.0731, -0.7330,  0.3132],\n",
      "         [-0.8601, -1.3756,  0.5042,  ..., -0.0476,  0.2650,  1.2150],\n",
      "         ...,\n",
      "         [ 0.0520,  1.1719, -1.5471,  ..., -0.7894,  0.1419,  1.6964],\n",
      "         [ 0.7654, -1.5053, -0.4142,  ..., -1.4622, -0.8975,  1.4576],\n",
      "         [-1.2008, -0.6008, -1.4608,  ..., -1.2105, -0.4289,  0.3827]],\n",
      "\n",
      "        [[-0.1709,  0.5230, -0.8713,  ..., -1.3382,  0.5892,  0.4026],\n",
      "         [-1.3806,  0.2626, -0.5207,  ..., -1.6714, -0.0554,  1.0225],\n",
      "         [-1.7116,  1.8788, -2.5695,  ..., -0.6958,  0.5728,  0.5461],\n",
      "         ...,\n",
      "         [-1.3246,  1.2196, -0.3034,  ..., -1.1955, -0.6708,  0.5128],\n",
      "         [ 0.9854,  0.8260,  0.2892,  ..., -0.6428,  0.3637,  0.4339],\n",
      "         [-1.2008, -0.6008, -1.4608,  ..., -1.2105, -0.4289,  0.3827]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.1709,  0.5230, -0.8713,  ...,  0.4365,  0.6238, -0.9414],\n",
      "          [-1.3731,  1.1521,  0.1321,  ..., -1.3382,  0.5892,  0.4026]],\n",
      "\n",
      "         [[-0.5842,  0.9588,  1.5642,  ..., -1.5431,  0.4999, -1.1350],\n",
      "          [ 0.9615,  0.8694,  0.0998,  ..., -1.0731, -0.7330,  0.3132]],\n",
      "\n",
      "         [[-0.8601, -1.3756,  0.5042,  ...,  0.9764, -0.8321, -1.0204],\n",
      "          [ 1.5175,  1.1454,  0.7791,  ..., -0.0476,  0.2650,  1.2150]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0520,  1.1719, -1.5471,  ...,  1.9402, -1.1294,  0.4793],\n",
      "          [ 1.0053,  0.8099,  1.6415,  ..., -0.7894,  0.1419,  1.6964]],\n",
      "\n",
      "         [[ 0.7654, -1.5053, -0.4142,  ...,  1.7455, -0.7326,  1.5248],\n",
      "          [ 1.0806,  1.1457,  2.2163,  ..., -1.4622, -0.8975,  1.4576]],\n",
      "\n",
      "         [[-1.2008, -0.6008, -1.4608,  ...,  2.0905,  1.8849, -1.5708],\n",
      "          [ 1.9999,  0.3493, -0.8524,  ..., -1.2105, -0.4289,  0.3827]]],\n",
      "\n",
      "\n",
      "        [[[-0.1709,  0.5230, -0.8713,  ...,  0.4365,  0.6238, -0.9414],\n",
      "          [-1.3731,  1.1521,  0.1321,  ..., -1.3382,  0.5892,  0.4026]],\n",
      "\n",
      "         [[-1.3806,  0.2626, -0.5207,  ...,  1.6517, -0.2316, -1.3171],\n",
      "          [ 0.6812, -0.0090,  0.3803,  ..., -1.6714, -0.0554,  1.0225]],\n",
      "\n",
      "         [[-1.7116,  1.8788, -2.5695,  ...,  0.4927, -0.4850, -1.0645],\n",
      "          [ 1.2646,  1.6481,  0.9055,  ..., -0.6958,  0.5728,  0.5461]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.3246,  1.2196, -0.3034,  ...,  1.2747,  1.2353,  0.2825],\n",
      "          [ 1.5373,  0.8648,  0.6062,  ..., -1.1955, -0.6708,  0.5128]],\n",
      "\n",
      "         [[ 0.9854,  0.8260,  0.2892,  ...,  1.3848, -0.0103, -1.0700],\n",
      "          [ 1.3827,  2.9809,  0.0276,  ..., -0.6428,  0.3637,  0.4339]],\n",
      "\n",
      "         [[-1.2008, -0.6008, -1.4608,  ...,  2.0905,  1.8849, -1.5708],\n",
      "          [ 1.9999,  0.3493, -0.8524,  ..., -1.2105, -0.4289,  0.3827]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.0123,  0.5761,  0.2209,  ..., -0.1027,  1.1061, -2.5200],\n",
      "         [-1.1465, -1.5578, -0.6984,  ...,  1.0310,  0.4824, -0.2291],\n",
      "         [-1.0361, -1.8192, -2.3055,  ...,  1.5286, -1.5941,  1.1762],\n",
      "         ...,\n",
      "         [-0.7992,  0.0886,  0.4887,  ..., -1.7941,  0.4835,  1.3780],\n",
      "         [-1.4692, -0.9135, -0.2802,  ..., -0.9691,  0.3500,  1.8863],\n",
      "         [-0.5760, -0.0452,  0.4230,  ..., -0.7179, -0.7858,  1.6879]],\n",
      "\n",
      "        [[-0.0123,  0.5761,  0.2209,  ..., -0.1027,  1.1061, -2.5200],\n",
      "         [-0.3700, -1.9754, -0.7315,  ...,  0.2293,  0.6996,  3.1299],\n",
      "         [-0.6252,  0.2879, -1.4036,  ..., -2.0560, -2.4623, -0.9584],\n",
      "         ...,\n",
      "         [-1.1306, -1.4343, -1.4422,  ..., -1.6115, -0.0475,  1.3975],\n",
      "         [-0.9816, -1.4909, -1.0086,  ..., -0.9284,  0.5260,  1.5330],\n",
      "         [-0.5760, -0.0452,  0.4230,  ..., -0.7179, -0.7858,  1.6879]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.0123,  0.5761,  0.2209,  ..., -0.1027,  1.1061, -2.5200],\n",
      "         [-1.1465, -1.5578, -0.6984,  ...,  1.0310,  0.4824, -0.2291],\n",
      "         [-1.0361, -1.8192, -2.3055,  ...,  1.5286, -1.5941,  1.1762],\n",
      "         ...,\n",
      "         [-0.7992,  0.0886,  0.4887,  ..., -1.7941,  0.4835,  1.3780],\n",
      "         [-1.4692, -0.9135, -0.2802,  ..., -0.9691,  0.3500,  1.8863],\n",
      "         [-0.5760, -0.0452,  0.4230,  ..., -0.7179, -0.7858,  1.6879]],\n",
      "\n",
      "        [[-0.0123,  0.5761,  0.2209,  ..., -0.1027,  1.1061, -2.5200],\n",
      "         [-0.3700, -1.9754, -0.7315,  ...,  0.2293,  0.6996,  3.1299],\n",
      "         [-0.6252,  0.2879, -1.4036,  ..., -2.0560, -2.4623, -0.9584],\n",
      "         ...,\n",
      "         [-1.1306, -1.4343, -1.4422,  ..., -1.6115, -0.0475,  1.3975],\n",
      "         [-0.9816, -1.4909, -1.0086,  ..., -0.9284,  0.5260,  1.5330],\n",
      "         [-0.5760, -0.0452,  0.4230,  ..., -0.7179, -0.7858,  1.6879]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.0123,  0.5761,  0.2209,  ..., -0.1457, -0.7538,  0.1761],\n",
      "          [-0.0705,  0.9215,  0.7990,  ..., -0.1027,  1.1061, -2.5200]],\n",
      "\n",
      "         [[-1.1465, -1.5578, -0.6984,  ...,  0.0289, -2.1112, -0.8728],\n",
      "          [ 0.6506, -1.6966,  1.4463,  ...,  1.0310,  0.4824, -0.2291]],\n",
      "\n",
      "         [[-1.0361, -1.8192, -2.3055,  ..., -0.2195, -1.1732,  0.3182],\n",
      "          [-0.5841, -0.0227,  3.0901,  ...,  1.5286, -1.5941,  1.1762]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.7992,  0.0886,  0.4887,  ...,  0.7859, -1.0127, -0.2676],\n",
      "          [-0.3055,  0.6270, -3.0705,  ..., -1.7941,  0.4835,  1.3780]],\n",
      "\n",
      "         [[-1.4692, -0.9135, -0.2802,  ...,  0.1197, -0.7532,  0.0731],\n",
      "          [ 0.6096, -1.0893, -0.6959,  ..., -0.9691,  0.3500,  1.8863]],\n",
      "\n",
      "         [[-0.5760, -0.0452,  0.4230,  ...,  0.8851,  0.3078,  0.8106],\n",
      "          [-1.1804,  0.9512,  0.3169,  ..., -0.7179, -0.7858,  1.6879]]],\n",
      "\n",
      "\n",
      "        [[[-0.0123,  0.5761,  0.2209,  ..., -0.1457, -0.7538,  0.1761],\n",
      "          [-0.0705,  0.9215,  0.7990,  ..., -0.1027,  1.1061, -2.5200]],\n",
      "\n",
      "         [[-0.3700, -1.9754, -0.7315,  ...,  0.5756, -1.5559,  0.0326],\n",
      "          [ 1.4229,  2.3970, -0.4516,  ...,  0.2293,  0.6996,  3.1299]],\n",
      "\n",
      "         [[-0.6252,  0.2879, -1.4036,  ...,  0.5306, -0.5608,  1.1861],\n",
      "          [-2.5980,  0.2673,  3.3016,  ..., -2.0560, -2.4623, -0.9584]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1306, -1.4343, -1.4422,  ...,  0.3918, -1.5336, -0.5026],\n",
      "          [ 1.8587,  0.8501, -1.2402,  ..., -1.6115, -0.0475,  1.3975]],\n",
      "\n",
      "         [[-0.9816, -1.4909, -1.0086,  ...,  0.2956,  0.0351, -1.0685],\n",
      "          [-0.6594, -0.0133, -1.1863,  ..., -0.9284,  0.5260,  1.5330]],\n",
      "\n",
      "         [[-0.5760, -0.0452,  0.4230,  ...,  0.8851,  0.3078,  0.8106],\n",
      "          [-1.1804,  0.9512,  0.3169,  ..., -0.7179, -0.7858,  1.6879]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.5911, -0.4682, -0.4314,  ...,  0.0366, -1.0405, -0.0579],\n",
      "          [-1.1141, -1.4785, -0.6477,  ...,  0.0631, -1.9950, -0.7912],\n",
      "          [-0.7059, -0.9954, -1.3923,  ..., -0.1557, -0.9998,  0.2774],\n",
      "          ...,\n",
      "          [-0.6300,  0.1252,  0.3486,  ...,  0.5692, -0.9417, -0.1399],\n",
      "          [-1.0593, -0.6395, -0.3343,  ...,  0.0571, -0.7842,  0.1042],\n",
      "          [-0.2081,  0.2785,  0.0613,  ..., -0.0353, -0.8389, -0.0026]],\n",
      "\n",
      "         [[-0.3266,  0.6360,  0.0214,  ...,  0.1677,  0.3883,  0.4382],\n",
      "          [-0.6299,  0.6012,  0.7379,  ...,  0.2989, -0.1569,  0.9508],\n",
      "          [-0.4097,  0.6374, -0.1589,  ...,  0.0258, -0.0364,  0.9990],\n",
      "          ...,\n",
      "          [-0.0088,  0.1378, -0.4819,  ..., -0.1261,  0.2908,  1.0980],\n",
      "          [-0.5584,  0.9932, -0.1105,  ...,  0.2486,  0.4005,  0.6046],\n",
      "          [-0.4516,  0.8092, -0.0513,  ...,  0.1182,  0.4294,  0.4781]]],\n",
      "\n",
      "\n",
      "        [[[-0.6850, -0.2168, -0.6087,  ...,  0.1402, -0.7267, -0.1502],\n",
      "          [-0.2084, -0.1325, -0.1151,  ...,  0.0938, -0.8963,  0.1296],\n",
      "          [-0.3665,  0.3408, -0.6133,  ...,  0.1938, -0.6681,  0.5929],\n",
      "          ...,\n",
      "          [-1.0985, -1.2861, -1.2531,  ...,  0.3609, -1.4022, -0.4444],\n",
      "          [-0.9787, -1.4207, -0.9908,  ...,  0.2989, -0.0159, -1.0060],\n",
      "          [-0.1970,  0.2371, -0.0115,  ...,  0.0049, -0.8135,  0.1201]],\n",
      "\n",
      "         [[ 0.0907,  0.7927, -0.0524,  ..., -0.4610, -0.4295,  0.4391],\n",
      "          [-0.2352,  1.0586, -0.1117,  ..., -0.4943, -0.6546,  0.6617],\n",
      "          [ 0.8269,  1.7861, -1.1207,  ..., -0.0885,  0.2791,  1.4721],\n",
      "          ...,\n",
      "          [-0.1038,  0.9623, -0.7062,  ..., -0.3340, -0.3050,  0.8792],\n",
      "          [ 0.0507,  0.6634, -0.2642,  ..., -0.4959, -0.7944,  0.7687],\n",
      "          [ 0.3364,  0.9047, -0.2037,  ..., -0.3705, -0.2893,  0.6787]]]],\n",
      "       grad_fn=<ScaledDotProductFlashAttentionForCpuBackward0>)\n",
      "tensor([[[[-0.5911, -0.4682, -0.4314,  ...,  0.0366, -1.0405, -0.0579],\n",
      "          [-0.3266,  0.6360,  0.0214,  ...,  0.1677,  0.3883,  0.4382]],\n",
      "\n",
      "         [[-1.1141, -1.4785, -0.6477,  ...,  0.0631, -1.9950, -0.7912],\n",
      "          [-0.6299,  0.6012,  0.7379,  ...,  0.2989, -0.1569,  0.9508]],\n",
      "\n",
      "         [[-0.7059, -0.9954, -1.3923,  ..., -0.1557, -0.9998,  0.2774],\n",
      "          [-0.4097,  0.6374, -0.1589,  ...,  0.0258, -0.0364,  0.9990]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6300,  0.1252,  0.3486,  ...,  0.5692, -0.9417, -0.1399],\n",
      "          [-0.0088,  0.1378, -0.4819,  ..., -0.1261,  0.2908,  1.0980]],\n",
      "\n",
      "         [[-1.0593, -0.6395, -0.3343,  ...,  0.0571, -0.7842,  0.1042],\n",
      "          [-0.5584,  0.9932, -0.1105,  ...,  0.2486,  0.4005,  0.6046]],\n",
      "\n",
      "         [[-0.2081,  0.2785,  0.0613,  ..., -0.0353, -0.8389, -0.0026],\n",
      "          [-0.4516,  0.8092, -0.0513,  ...,  0.1182,  0.4294,  0.4781]]],\n",
      "\n",
      "\n",
      "        [[[-0.6850, -0.2168, -0.6087,  ...,  0.1402, -0.7267, -0.1502],\n",
      "          [ 0.0907,  0.7927, -0.0524,  ..., -0.4610, -0.4295,  0.4391]],\n",
      "\n",
      "         [[-0.2084, -0.1325, -0.1151,  ...,  0.0938, -0.8963,  0.1296],\n",
      "          [-0.2352,  1.0586, -0.1117,  ..., -0.4943, -0.6546,  0.6617]],\n",
      "\n",
      "         [[-0.3665,  0.3408, -0.6133,  ...,  0.1938, -0.6681,  0.5929],\n",
      "          [ 0.8269,  1.7861, -1.1207,  ..., -0.0885,  0.2791,  1.4721]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.0985, -1.2861, -1.2531,  ...,  0.3609, -1.4022, -0.4444],\n",
      "          [-0.1038,  0.9623, -0.7062,  ..., -0.3340, -0.3050,  0.8792]],\n",
      "\n",
      "         [[-0.9787, -1.4207, -0.9908,  ...,  0.2989, -0.0159, -1.0060],\n",
      "          [ 0.0507,  0.6634, -0.2642,  ..., -0.4959, -0.7944,  0.7687]],\n",
      "\n",
      "         [[-0.1970,  0.2371, -0.0115,  ...,  0.0049, -0.8135,  0.1201],\n",
      "          [ 0.3364,  0.9047, -0.2037,  ..., -0.3705, -0.2893,  0.6787]]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[-0.9552,  0.6594, -6.5403,  ..., -0.7144,  0.0906,  0.3369],\n",
      "         [-2.5251,  1.3955, -0.8914,  ..., -2.1363,  0.0271,  1.1132],\n",
      "         [-3.7148,  0.6796, -0.8710,  ..., -2.6492,  0.5694, -0.1085],\n",
      "         ...,\n",
      "         [-2.2403, -0.7594,  0.5414,  ..., -3.0426,  0.8895, -0.0546],\n",
      "         [-1.6945, -0.6326, -0.8632,  ..., -4.0678,  1.7219,  0.6481],\n",
      "         [-2.9625,  0.7451, -0.8037,  ..., -2.5048,  0.3125,  0.5537]],\n",
      "\n",
      "        [[-0.5150,  0.8150, -6.5015,  ..., -0.5377, -0.4171,  0.1350],\n",
      "         [-2.9979,  1.0930, -0.2619,  ..., -3.1811, -1.0048, -1.8349],\n",
      "         [-2.8788,  0.5405, -0.0789,  ..., -2.3969, -0.7016, -0.7332],\n",
      "         ...,\n",
      "         [-1.7194,  1.5158,  1.0070,  ..., -2.8931, -2.3309,  1.1685],\n",
      "         [ 0.0717, -0.1039,  0.5084,  ..., -2.1932,  0.0751,  2.8236],\n",
      "         [-2.4774,  0.7563, -0.7502,  ..., -2.1312, -0.0685,  0.8700]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[-0.0455,  0.6529,  0.6297,  ...,  0.4139, -0.9381,  0.6769],\n",
      "         [-3.1104, -3.7282, -2.3953,  ..., -0.9155, -0.8280, -1.7070],\n",
      "         [-0.9324, -2.9333, -2.3249,  ..., -0.8455, -0.0326, -0.6998],\n",
      "         ...,\n",
      "         [-1.9000, -1.1028, -1.1281,  ..., -0.2809,  2.0206, -1.0802],\n",
      "         [-1.1088, -1.0420, -2.4026,  ..., -0.4478,  0.7391, -0.0354],\n",
      "         [ 0.7349,  0.6742, -2.6697,  ..., -0.5114,  1.5155,  2.0246]],\n",
      "\n",
      "        [[-0.0799,  0.7813,  0.4918,  ...,  0.6888, -0.7680,  0.9805],\n",
      "         [-2.8720, -1.0602, -2.3610,  ..., -2.1143,  0.9664, -1.1212],\n",
      "         [-1.4705, -2.1384, -1.9955,  ..., -0.9722,  1.5909, -0.1668],\n",
      "         ...,\n",
      "         [-2.9884, -1.1566, -2.5215,  ...,  1.1460,  0.7120, -0.6320],\n",
      "         [-3.3666, -0.7966, -3.3154,  ...,  0.5316,  1.7058,  2.1950],\n",
      "         [ 0.6626,  0.8537, -2.7251,  ..., -0.0901,  1.5883,  2.3840]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.0455,  0.6529,  0.6297,  ...,  0.4139, -0.9381,  0.6769],\n",
      "         [-3.1104, -3.7282, -2.3953,  ..., -0.9155, -0.8280, -1.7070],\n",
      "         [-0.9324, -2.9333, -2.3249,  ..., -0.8455, -0.0326, -0.6998],\n",
      "         ...,\n",
      "         [-1.9000, -1.1028, -1.1281,  ..., -0.2809,  2.0206, -1.0802],\n",
      "         [-1.1088, -1.0420, -2.4026,  ..., -0.4478,  0.7391, -0.0354],\n",
      "         [ 0.7349,  0.6742, -2.6697,  ..., -0.5114,  1.5155,  2.0246]],\n",
      "\n",
      "        [[-0.0799,  0.7813,  0.4918,  ...,  0.6888, -0.7680,  0.9805],\n",
      "         [-2.8720, -1.0602, -2.3610,  ..., -2.1143,  0.9664, -1.1212],\n",
      "         [-1.4705, -2.1384, -1.9955,  ..., -0.9722,  1.5909, -0.1668],\n",
      "         ...,\n",
      "         [-2.9884, -1.1566, -2.5215,  ...,  1.1460,  0.7120, -0.6320],\n",
      "         [-3.3666, -0.7966, -3.3154,  ...,  0.5316,  1.7058,  2.1950],\n",
      "         [ 0.6626,  0.8537, -2.7251,  ..., -0.0901,  1.5883,  2.3840]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.0455,  0.6529,  0.6297,  ...,  1.0165, -1.6055,  0.0557],\n",
      "          [-0.9141, -1.5101, -0.8415,  ...,  0.4139, -0.9381,  0.6769]],\n",
      "\n",
      "         [[-3.1104, -3.7282, -2.3953,  ..., -1.6195,  0.7426, -3.2794],\n",
      "          [-1.2694,  0.3821, -0.5687,  ..., -0.9155, -0.8280, -1.7070]],\n",
      "\n",
      "         [[-0.9324, -2.9333, -2.3249,  ..., -1.0254,  1.8158, -1.8835],\n",
      "          [-1.5265, -0.3901,  0.2734,  ..., -0.8455, -0.0326, -0.6998]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.9000, -1.1028, -1.1281,  ..., -1.2688, -0.0851, -2.3190],\n",
      "          [-2.4374,  0.0718, -2.7276,  ..., -0.2809,  2.0206, -1.0802]],\n",
      "\n",
      "         [[-1.1088, -1.0420, -2.4026,  ..., -1.0658,  0.1932, -1.7012],\n",
      "          [-2.3622, -0.5291, -1.9931,  ..., -0.4478,  0.7391, -0.0354]],\n",
      "\n",
      "         [[ 0.7349,  0.6742, -2.6697,  ..., -1.4630, -0.1686, -2.5682],\n",
      "          [-0.1401, -0.9712, -2.3801,  ..., -0.5114,  1.5155,  2.0246]]],\n",
      "\n",
      "\n",
      "        [[[-0.0799,  0.7813,  0.4918,  ...,  1.2364, -1.9500, -0.1275],\n",
      "          [-0.4080, -1.5069, -0.8504,  ...,  0.6888, -0.7680,  0.9805]],\n",
      "\n",
      "         [[-2.8720, -1.0602, -2.3610,  ..., -2.3225, -0.0351, -2.7432],\n",
      "          [-0.2305, -0.5940, -1.1570,  ..., -2.1143,  0.9664, -1.1212]],\n",
      "\n",
      "         [[-1.4705, -2.1384, -1.9955,  ..., -0.6524, -1.8025, -1.8321],\n",
      "          [-1.7742, -0.6800, -0.2172,  ..., -0.9722,  1.5909, -0.1668]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.9884, -1.1566, -2.5215,  ..., -0.5054, -1.0314, -3.4883],\n",
      "          [-1.9535,  0.5573, -2.1564,  ...,  1.1460,  0.7120, -0.6320]],\n",
      "\n",
      "         [[-3.3666, -0.7966, -3.3154,  ...,  0.7587, -0.6289, -3.4848],\n",
      "          [-1.4099, -2.0919, -1.5870,  ...,  0.5316,  1.7058,  2.1950]],\n",
      "\n",
      "         [[ 0.6626,  0.8537, -2.7251,  ..., -1.1831, -0.7083, -2.7717],\n",
      "          [ 0.4486, -1.1639, -2.1203,  ..., -0.0901,  1.5883,  2.3840]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.8947,  0.0412, -1.2359,  ...,  0.4410, -0.3965,  0.0106],\n",
      "         [-1.9196,  0.3326,  0.8482,  ..., -1.5790, -1.1817, -1.0156],\n",
      "         [-2.1664,  0.3959,  0.7476,  ..., -2.1767, -0.6488,  0.1889],\n",
      "         ...,\n",
      "         [-1.6009,  0.4887, -0.4818,  ..., -1.1268,  0.4111,  0.7892],\n",
      "         [-0.1528,  1.1728, -0.5164,  ..., -0.4340,  0.1499,  1.6704],\n",
      "         [ 1.0253,  1.4222, -0.1805,  ..., -0.6130, -0.5380,  1.6164]],\n",
      "\n",
      "        [[-0.6736, -0.0718, -1.1724,  ...,  0.2001, -0.5481,  0.0232],\n",
      "         [-1.8698, -1.2184,  0.2913,  ..., -1.1398, -1.3523, -0.7851],\n",
      "         [-1.3725, -0.8212,  0.1984,  ..., -1.8218, -1.4800, -0.2956],\n",
      "         ...,\n",
      "         [-0.5946,  0.5680,  0.8938,  ..., -1.6653,  0.8218,  1.1902],\n",
      "         [ 1.2800,  1.9566,  0.2540,  ..., -1.2290,  0.5257,  1.2667],\n",
      "         [ 1.3511,  1.3329, -0.0782,  ..., -0.8454, -0.7400,  1.5966]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.8947,  0.0412, -1.2359,  ...,  0.4410, -0.3965,  0.0106],\n",
      "         [-1.9196,  0.3326,  0.8482,  ..., -1.5790, -1.1817, -1.0156],\n",
      "         [-2.1664,  0.3959,  0.7476,  ..., -2.1767, -0.6488,  0.1889],\n",
      "         ...,\n",
      "         [-1.6009,  0.4887, -0.4818,  ..., -1.1268,  0.4111,  0.7892],\n",
      "         [-0.1528,  1.1728, -0.5164,  ..., -0.4340,  0.1499,  1.6704],\n",
      "         [ 1.0253,  1.4222, -0.1805,  ..., -0.6130, -0.5380,  1.6164]],\n",
      "\n",
      "        [[-0.6736, -0.0718, -1.1724,  ...,  0.2001, -0.5481,  0.0232],\n",
      "         [-1.8698, -1.2184,  0.2913,  ..., -1.1398, -1.3523, -0.7851],\n",
      "         [-1.3725, -0.8212,  0.1984,  ..., -1.8218, -1.4800, -0.2956],\n",
      "         ...,\n",
      "         [-0.5946,  0.5680,  0.8938,  ..., -1.6653,  0.8218,  1.1902],\n",
      "         [ 1.2800,  1.9566,  0.2540,  ..., -1.2290,  0.5257,  1.2667],\n",
      "         [ 1.3511,  1.3329, -0.0782,  ..., -0.8454, -0.7400,  1.5966]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.8947,  0.0412, -1.2359,  ...,  1.5140, -1.9812, -2.5532],\n",
      "          [-0.2951, -1.6086, -0.6381,  ...,  0.4410, -0.3965,  0.0106]],\n",
      "\n",
      "         [[-1.9196,  0.3326,  0.8482,  ..., -2.3348,  1.3935,  1.1452],\n",
      "          [-0.5277,  0.1234,  0.7865,  ..., -1.5790, -1.1817, -1.0156]],\n",
      "\n",
      "         [[-2.1664,  0.3959,  0.7476,  ..., -2.0817,  0.2852,  0.8173],\n",
      "          [-0.8414,  0.5154, -0.4553,  ..., -2.1767, -0.6488,  0.1889]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.6009,  0.4887, -0.4818,  ..., -1.8165,  1.4764,  0.5091],\n",
      "          [-0.6869,  0.4007, -1.5818,  ..., -1.1268,  0.4111,  0.7892]],\n",
      "\n",
      "         [[-0.1528,  1.1728, -0.5164,  ..., -1.3611,  1.0621,  1.1810],\n",
      "          [-0.7595, -0.1699, -1.5305,  ..., -0.4340,  0.1499,  1.6704]],\n",
      "\n",
      "         [[ 1.0253,  1.4222, -0.1805,  ..., -0.6989,  0.4721,  2.6129],\n",
      "          [-1.2381, -0.4573, -1.7561,  ..., -0.6130, -0.5380,  1.6164]]],\n",
      "\n",
      "\n",
      "        [[[-0.6736, -0.0718, -1.1724,  ...,  1.4816, -1.7920, -2.5177],\n",
      "          [-0.3929, -1.5120, -0.5353,  ...,  0.2001, -0.5481,  0.0232]],\n",
      "\n",
      "         [[-1.8698, -1.2184,  0.2913,  ..., -1.5227,  1.9764,  0.6389],\n",
      "          [-0.4202,  0.4572, -1.0780,  ..., -1.1398, -1.3523, -0.7851]],\n",
      "\n",
      "         [[-1.3725, -0.8212,  0.1984,  ..., -2.1553,  1.7041,  0.7166],\n",
      "          [-1.0124,  0.9351, -0.0954,  ..., -1.8218, -1.4800, -0.2956]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.5946,  0.5680,  0.8938,  ..., -2.1904,  1.7986,  1.0902],\n",
      "          [-1.3820,  1.0268, -1.0041,  ..., -1.6653,  0.8218,  1.1902]],\n",
      "\n",
      "         [[ 1.2800,  1.9566,  0.2540,  ..., -1.6180,  1.6176,  2.5636],\n",
      "          [-2.0592,  0.7059, -1.3359,  ..., -1.2290,  0.5257,  1.2667]],\n",
      "\n",
      "         [[ 1.3511,  1.3329, -0.0782,  ..., -0.5836,  0.6491,  2.6554],\n",
      "          [-1.3686, -0.2348, -1.7438,  ..., -0.8454, -0.7400,  1.5966]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 3.8307e-01,  1.8836e-02, -1.0314e+00,  ...,  6.4335e-01,\n",
      "          -3.1830e-01, -1.7296e+00],\n",
      "         [ 1.5897e+00,  1.3689e-01, -6.8915e-01,  ...,  1.5973e+00,\n",
      "           1.1907e+00, -9.0454e-01],\n",
      "         [-5.8138e-01,  6.7943e-01, -1.3203e+00,  ..., -5.3627e-01,\n",
      "          -1.0456e+00, -1.6301e+00],\n",
      "         ...,\n",
      "         [-1.7466e-01,  3.0706e-02,  7.5225e-01,  ..., -1.3217e+00,\n",
      "          -1.3415e+00, -3.8328e-01],\n",
      "         [ 1.5170e-01,  5.1089e-01,  1.3993e-01,  ..., -1.6600e-01,\n",
      "          -6.5011e-01,  2.1798e-02],\n",
      "         [-2.4311e-01,  1.6726e+00,  1.6682e-01,  ...,  1.3448e-03,\n",
      "          -1.6754e+00,  3.1771e-01]],\n",
      "\n",
      "        [[ 4.7844e-01, -3.1772e-01, -1.0617e+00,  ...,  6.4928e-01,\n",
      "          -3.2944e-01, -2.4185e+00],\n",
      "         [ 5.9122e-01, -2.2648e-01,  1.7474e-01,  ..., -1.8623e+00,\n",
      "          -1.1230e+00,  3.5013e-01],\n",
      "         [ 1.1642e-01,  1.2460e+00,  7.7942e-02,  ...,  6.4975e-01,\n",
      "          -7.3862e-01, -2.1510e+00],\n",
      "         ...,\n",
      "         [ 1.1291e+00, -1.3637e+00, -1.5779e+00,  ...,  1.7637e+00,\n",
      "           9.1331e-01, -1.7033e+00],\n",
      "         [ 1.5909e+00, -1.4922e+00,  1.0060e+00,  ...,  9.8096e-01,\n",
      "           8.6736e-01, -2.3894e+00],\n",
      "         [ 1.8451e-01,  1.2740e+00,  4.2857e-01,  ...,  6.2708e-01,\n",
      "          -1.3601e+00, -3.9984e-01]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 3.8307e-01,  1.8836e-02, -1.0314e+00,  ...,  6.4335e-01,\n",
      "          -3.1830e-01, -1.7296e+00],\n",
      "         [ 1.5897e+00,  1.3689e-01, -6.8915e-01,  ...,  1.5973e+00,\n",
      "           1.1907e+00, -9.0454e-01],\n",
      "         [-5.8138e-01,  6.7943e-01, -1.3203e+00,  ..., -5.3627e-01,\n",
      "          -1.0456e+00, -1.6301e+00],\n",
      "         ...,\n",
      "         [-1.7466e-01,  3.0706e-02,  7.5225e-01,  ..., -1.3217e+00,\n",
      "          -1.3415e+00, -3.8328e-01],\n",
      "         [ 1.5170e-01,  5.1089e-01,  1.3993e-01,  ..., -1.6600e-01,\n",
      "          -6.5011e-01,  2.1798e-02],\n",
      "         [-2.4311e-01,  1.6726e+00,  1.6682e-01,  ...,  1.3448e-03,\n",
      "          -1.6754e+00,  3.1771e-01]],\n",
      "\n",
      "        [[ 4.7844e-01, -3.1772e-01, -1.0617e+00,  ...,  6.4928e-01,\n",
      "          -3.2944e-01, -2.4185e+00],\n",
      "         [ 5.9122e-01, -2.2648e-01,  1.7474e-01,  ..., -1.8623e+00,\n",
      "          -1.1230e+00,  3.5013e-01],\n",
      "         [ 1.1642e-01,  1.2460e+00,  7.7942e-02,  ...,  6.4975e-01,\n",
      "          -7.3862e-01, -2.1510e+00],\n",
      "         ...,\n",
      "         [ 1.1291e+00, -1.3637e+00, -1.5779e+00,  ...,  1.7637e+00,\n",
      "           9.1331e-01, -1.7033e+00],\n",
      "         [ 1.5909e+00, -1.4922e+00,  1.0060e+00,  ...,  9.8096e-01,\n",
      "           8.6736e-01, -2.3894e+00],\n",
      "         [ 1.8451e-01,  1.2740e+00,  4.2857e-01,  ...,  6.2708e-01,\n",
      "          -1.3601e+00, -3.9984e-01]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 3.8307e-01,  1.8836e-02, -1.0314e+00,  ..., -8.0955e-01,\n",
      "           -2.8557e-01, -2.3318e-01],\n",
      "          [-9.9661e-02,  3.1722e-01, -3.0517e-01,  ...,  6.4335e-01,\n",
      "           -3.1830e-01, -1.7296e+00]],\n",
      "\n",
      "         [[ 1.5897e+00,  1.3689e-01, -6.8915e-01,  ..., -7.9549e-01,\n",
      "           -6.9279e-01, -1.8082e-01],\n",
      "          [-9.9201e-01,  9.4938e-01,  4.4198e-02,  ...,  1.5973e+00,\n",
      "            1.1907e+00, -9.0454e-01]],\n",
      "\n",
      "         [[-5.8138e-01,  6.7943e-01, -1.3203e+00,  ..., -1.8905e+00,\n",
      "            1.6226e-01, -1.2953e+00],\n",
      "          [-7.0312e-01, -6.4926e-01, -5.0913e-01,  ..., -5.3627e-01,\n",
      "           -1.0456e+00, -1.6301e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.7466e-01,  3.0706e-02,  7.5225e-01,  ..., -1.9281e+00,\n",
      "            1.1489e+00, -2.4530e-01],\n",
      "          [-7.6226e-02,  8.5814e-01, -1.5467e+00,  ..., -1.3217e+00,\n",
      "           -1.3415e+00, -3.8328e-01]],\n",
      "\n",
      "         [[ 1.5170e-01,  5.1089e-01,  1.3993e-01,  ..., -2.4168e+00,\n",
      "            3.3385e-01, -6.2115e-02],\n",
      "          [-1.6390e+00, -1.6085e-01, -1.9118e+00,  ..., -1.6600e-01,\n",
      "           -6.5011e-01,  2.1798e-02]],\n",
      "\n",
      "         [[-2.4311e-01,  1.6726e+00,  1.6682e-01,  ..., -1.0481e+00,\n",
      "           -2.7634e+00,  2.2741e-01],\n",
      "          [-1.4603e+00,  3.1239e-02,  3.8892e-01,  ...,  1.3448e-03,\n",
      "           -1.6754e+00,  3.1771e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.7844e-01, -3.1772e-01, -1.0617e+00,  ..., -7.8511e-01,\n",
      "           -3.2510e-01, -2.1300e-01],\n",
      "          [-3.9893e-01,  6.1469e-01, -3.9206e-01,  ...,  6.4928e-01,\n",
      "           -3.2944e-01, -2.4185e+00]],\n",
      "\n",
      "         [[ 5.9122e-01, -2.2648e-01,  1.7474e-01,  ..., -1.6488e+00,\n",
      "           -8.6853e-01, -8.0782e-01],\n",
      "          [-2.1516e+00, -2.4247e-01, -8.1713e-01,  ..., -1.8623e+00,\n",
      "           -1.1230e+00,  3.5013e-01]],\n",
      "\n",
      "         [[ 1.1642e-01,  1.2460e+00,  7.7942e-02,  ..., -1.3121e+00,\n",
      "           -6.7044e-01, -1.1324e+00],\n",
      "          [ 4.3930e-01,  3.4082e-01, -1.2243e+00,  ...,  6.4975e-01,\n",
      "           -7.3862e-01, -2.1510e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1291e+00, -1.3637e+00, -1.5779e+00,  ...,  8.5980e-01,\n",
      "            3.2796e-01, -1.9442e+00],\n",
      "          [-8.9502e-01,  9.7357e-01,  8.5447e-01,  ...,  1.7637e+00,\n",
      "            9.1331e-01, -1.7033e+00]],\n",
      "\n",
      "         [[ 1.5909e+00, -1.4922e+00,  1.0060e+00,  ..., -1.5965e+00,\n",
      "           -3.9380e-01, -4.3585e-01],\n",
      "          [-2.2103e+00,  4.4127e-01,  1.1554e+00,  ...,  9.8096e-01,\n",
      "            8.6736e-01, -2.3894e+00]],\n",
      "\n",
      "         [[ 1.8451e-01,  1.2740e+00,  4.2857e-01,  ..., -1.1366e+00,\n",
      "           -2.8409e+00,  4.6710e-01],\n",
      "          [-1.9576e+00,  2.0176e-01, -4.1034e-02,  ...,  6.2708e-01,\n",
      "           -1.3601e+00, -3.9984e-01]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 3.7393e-01,  3.7078e-01, -7.5553e-01,  ..., -9.4280e-01,\n",
      "           -6.5765e-01, -1.4711e-01],\n",
      "          [ 3.9396e-01,  4.7657e-02, -1.0277e+00,  ..., -8.4926e-01,\n",
      "           -2.7815e-01, -2.6627e-01],\n",
      "          [ 9.9586e-01,  2.4414e-01, -8.3459e-01,  ..., -8.5795e-01,\n",
      "           -4.3860e-01, -2.1582e-01],\n",
      "          ...,\n",
      "          [ 1.4504e+00, -1.2077e-01, -4.8160e-01,  ..., -1.6701e+00,\n",
      "            6.3807e-01, -8.3788e-02],\n",
      "          [ 3.8821e-01,  1.4150e-01, -1.5051e-01,  ..., -1.5785e+00,\n",
      "            4.1589e-01, -1.8024e-01],\n",
      "          [ 1.0467e-01,  5.5196e-01,  1.0818e-01,  ..., -2.0373e+00,\n",
      "            8.4396e-02, -6.9034e-02]],\n",
      "\n",
      "         [[-7.7230e-01, -1.1852e-01, -8.0275e-02,  ..., -1.3790e-03,\n",
      "           -5.2249e-01, -4.2095e-01],\n",
      "          [-4.6209e-01, -1.2680e-01, -2.5711e-01,  ...,  1.3235e-01,\n",
      "           -4.1385e-01, -1.3744e+00],\n",
      "          [-1.7985e-01, -2.6037e-01,  3.5678e-01,  ...,  2.4736e-01,\n",
      "           -1.6626e-01, -7.0940e-01],\n",
      "          ...,\n",
      "          [-6.2069e-01,  2.5298e-01, -7.8416e-01,  ...,  8.6186e-02,\n",
      "           -6.9561e-01, -8.5675e-01],\n",
      "          [-9.1553e-01,  1.4648e-01, -5.5621e-02,  ...,  1.8643e-01,\n",
      "           -1.0965e+00, -4.8097e-01],\n",
      "          [-1.0678e+00,  9.0884e-02, -4.5400e-02,  ...,  1.5424e-01,\n",
      "           -1.1762e+00, -2.9385e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.9445e-01,  9.6661e-03, -5.7118e-01,  ..., -9.7640e-01,\n",
      "           -9.0948e-01, -1.3761e-01],\n",
      "          [ 4.7672e-01, -2.3672e-01, -8.9246e-01,  ..., -8.9927e-01,\n",
      "           -3.9088e-01, -3.1635e-01],\n",
      "          [ 4.5120e-01, -5.8034e-02, -6.8736e-01,  ..., -1.0352e+00,\n",
      "           -4.7996e-01, -4.5624e-01],\n",
      "          ...,\n",
      "          [ 3.3362e-01,  1.5914e-03, -1.0108e+00,  ..., -1.5704e+00,\n",
      "           -3.9079e-01, -2.1742e-01],\n",
      "          [ 1.0123e+00, -1.1147e+00, -1.3032e+00,  ...,  3.4082e-01,\n",
      "            1.3298e-01, -1.5481e+00],\n",
      "          [ 1.4273e+00, -1.2951e+00,  5.7719e-01,  ..., -1.2490e+00,\n",
      "           -4.1355e-01, -5.8558e-01]],\n",
      "\n",
      "         [[-1.0884e+00,  2.0838e-01, -5.0948e-01,  ...,  2.2845e-01,\n",
      "           -8.2075e-01, -1.1496e+00],\n",
      "          [-3.4296e-01,  5.0833e-01, -8.6644e-01,  ...,  3.3008e-01,\n",
      "           -5.5070e-01, -1.8440e+00],\n",
      "          [-3.2602e-01,  6.0671e-01, -7.5711e-01,  ...,  4.7493e-01,\n",
      "           -4.6589e-01, -2.0454e+00],\n",
      "          ...,\n",
      "          [-1.7399e+00,  4.6359e-01,  6.5213e-01,  ...,  9.0025e-01,\n",
      "            3.1643e-01, -2.0784e+00],\n",
      "          [-1.8375e+00,  2.6226e-01,  3.7727e-02,  ...,  6.6286e-01,\n",
      "           -1.0588e+00, -7.6781e-01],\n",
      "          [-1.6402e+00,  3.1250e-01, -6.6090e-04,  ...,  6.6493e-01,\n",
      "           -9.1110e-01, -1.0382e+00]]]],\n",
      "       grad_fn=<ScaledDotProductFlashAttentionForCpuBackward0>)\n",
      "tensor([[[[ 3.7393e-01,  3.7078e-01, -7.5553e-01,  ..., -9.4280e-01,\n",
      "           -6.5765e-01, -1.4711e-01],\n",
      "          [-7.7230e-01, -1.1852e-01, -8.0275e-02,  ..., -1.3790e-03,\n",
      "           -5.2249e-01, -4.2095e-01]],\n",
      "\n",
      "         [[ 3.9396e-01,  4.7657e-02, -1.0277e+00,  ..., -8.4926e-01,\n",
      "           -2.7815e-01, -2.6627e-01],\n",
      "          [-4.6209e-01, -1.2680e-01, -2.5711e-01,  ...,  1.3235e-01,\n",
      "           -4.1385e-01, -1.3744e+00]],\n",
      "\n",
      "         [[ 9.9586e-01,  2.4414e-01, -8.3459e-01,  ..., -8.5795e-01,\n",
      "           -4.3860e-01, -2.1582e-01],\n",
      "          [-1.7985e-01, -2.6037e-01,  3.5678e-01,  ...,  2.4736e-01,\n",
      "           -1.6626e-01, -7.0940e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4504e+00, -1.2077e-01, -4.8160e-01,  ..., -1.6701e+00,\n",
      "            6.3807e-01, -8.3788e-02],\n",
      "          [-6.2069e-01,  2.5298e-01, -7.8416e-01,  ...,  8.6186e-02,\n",
      "           -6.9561e-01, -8.5675e-01]],\n",
      "\n",
      "         [[ 3.8821e-01,  1.4150e-01, -1.5051e-01,  ..., -1.5785e+00,\n",
      "            4.1589e-01, -1.8024e-01],\n",
      "          [-9.1553e-01,  1.4648e-01, -5.5621e-02,  ...,  1.8643e-01,\n",
      "           -1.0965e+00, -4.8097e-01]],\n",
      "\n",
      "         [[ 1.0467e-01,  5.5196e-01,  1.0818e-01,  ..., -2.0373e+00,\n",
      "            8.4396e-02, -6.9034e-02],\n",
      "          [-1.0678e+00,  9.0884e-02, -4.5400e-02,  ...,  1.5424e-01,\n",
      "           -1.1762e+00, -2.9385e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.9445e-01,  9.6661e-03, -5.7118e-01,  ..., -9.7640e-01,\n",
      "           -9.0948e-01, -1.3761e-01],\n",
      "          [-1.0884e+00,  2.0838e-01, -5.0948e-01,  ...,  2.2845e-01,\n",
      "           -8.2075e-01, -1.1496e+00]],\n",
      "\n",
      "         [[ 4.7672e-01, -2.3672e-01, -8.9246e-01,  ..., -8.9927e-01,\n",
      "           -3.9088e-01, -3.1635e-01],\n",
      "          [-3.4296e-01,  5.0833e-01, -8.6644e-01,  ...,  3.3008e-01,\n",
      "           -5.5070e-01, -1.8440e+00]],\n",
      "\n",
      "         [[ 4.5120e-01, -5.8034e-02, -6.8736e-01,  ..., -1.0352e+00,\n",
      "           -4.7996e-01, -4.5624e-01],\n",
      "          [-3.2602e-01,  6.0671e-01, -7.5711e-01,  ...,  4.7493e-01,\n",
      "           -4.6589e-01, -2.0454e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.3362e-01,  1.5914e-03, -1.0108e+00,  ..., -1.5704e+00,\n",
      "           -3.9079e-01, -2.1742e-01],\n",
      "          [-1.7399e+00,  4.6359e-01,  6.5213e-01,  ...,  9.0025e-01,\n",
      "            3.1643e-01, -2.0784e+00]],\n",
      "\n",
      "         [[ 1.0123e+00, -1.1147e+00, -1.3032e+00,  ...,  3.4082e-01,\n",
      "            1.3298e-01, -1.5481e+00],\n",
      "          [-1.8375e+00,  2.6226e-01,  3.7727e-02,  ...,  6.6286e-01,\n",
      "           -1.0588e+00, -7.6781e-01]],\n",
      "\n",
      "         [[ 1.4273e+00, -1.2951e+00,  5.7719e-01,  ..., -1.2490e+00,\n",
      "           -4.1355e-01, -5.8558e-01],\n",
      "          [-1.6402e+00,  3.1250e-01, -6.6090e-04,  ...,  6.6493e-01,\n",
      "           -9.1110e-01, -1.0382e+00]]]], grad_fn=<TransposeBackward0>)\n",
      "tensor([[0.0963, 0.1694],\n",
      "        [0.2457, 0.2182]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since imdb couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'plain_text' at /Users/yz10513/.cache/huggingface/datasets/imdb/plain_text/0.0.0/e6281661ce1c48d982bc483cf8a173c1bbeb5d31 (last modified on Sun Dec  1 05:38:09 2024).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
    "model.config.problem_type = \"single_label_classification\"\n",
    "\n",
    "mg = MaseGraph(\n",
    "    model,\n",
    "    hf_input_names=[\n",
    "        \"input_ids\",\n",
    "        \"attention_mask\",\n",
    "        \"labels\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "mg, _ = passes.init_metadata_analysis_pass(mg)\n",
    "mg, _ = passes.add_common_metadata_analysis_pass(mg)\n",
    "mg = MaseGraph.from_checkpoint(f\"{Path.home()}/tutorial_2_lora\")\n",
    "\n",
    "dataset, tokenizer = get_tokenized_dataset(\n",
    "    dataset=dataset_name,\n",
    "    checkpoint=tokenizer_checkpoint,\n",
    "    return_tokenizer=True,\n",
    ")\n",
    "quantization_config = {\n",
    "    \"by\": \"type\",\n",
    "    \"default\": {\n",
    "        \"config\": {\n",
    "            \"name\": None,\n",
    "        }\n",
    "    },\n",
    "    \"linear\": {\n",
    "        \"config\": {\n",
    "            \"name\": \"integer\",\n",
    "            # data\n",
    "            \"data_in_width\": 16,\n",
    "            \"data_in_frac_width\": 10,\n",
    "            # weight\n",
    "            \"weight_width\": 16,\n",
    "            \"weight_frac_width\": 10,\n",
    "            # bias\n",
    "            \"bias_width\": 16,\n",
    "            \"bias_frac_width\": 10,\n",
    "        }\n",
    "    },\n",
    "}\n",
    "# test with two different precision setups\n",
    "quantization_config_low = copy.deepcopy(quantization_config)\n",
    "quantization_config_high = copy.deepcopy(quantization_config)\n",
    "\n",
    "quantization_config_low[\"linear\"][\"config\"][\"data_in_width\"] = 4\n",
    "quantization_config_low[\"linear\"][\"config\"][\"data_in_frac_width\"] = 2\n",
    "quantization_config_low[\"linear\"][\"config\"][\"weight_width\"] = 4\n",
    "quantization_config_low[\"linear\"][\"config\"][\"weight_frac_width\"] = 2\n",
    "quantization_config_low[\"linear\"][\"config\"][\"bias_width\"] = 4\n",
    "quantization_config_low[\"linear\"][\"config\"][\"bias_frac_width\"] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply the transformations with two different precision configurations, both under the sam model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mTokenizing dataset imdb with AutoTokenizer for bert-base-uncased.\u001b[0m\n",
      "Using the latest cached version of the dataset since imdb couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'plain_text' at /Users/yz10513/.cache/huggingface/datasets/imdb/plain_text/0.0.0/e6281661ce1c48d982bc483cf8a173c1bbeb5d31 (last modified on Sun Dec  1 05:38:09 2024).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-01-02 10:49:38,098] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to mps (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "W0102 10:49:39.030000 25837 site-packages/torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "100%|██████████| 3125/3125 [01:22<00:00, 38.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Accuracy: 0.8218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3125/3125 [01:21<00:00, 38.29it/s]\n",
      "100%|██████████| 3125/3125 [01:18<00:00, 40.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy high: 0.82176\n",
      "Accuracy low: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "copy_mg = copy.deepcopy(mg)\n",
    "mg_high, _ = passes.quantize_transform_pass(\n",
    "    copy_mg,\n",
    "    pass_args=quantization_config_high,\n",
    ")\n",
    "\n",
    "copy_mg = copy.deepcopy(mg)\n",
    "mg_low, _ = passes.quantize_transform_pass(\n",
    "    copy_mg,\n",
    "    pass_args=quantization_config_low,\n",
    ")\n",
    "\n",
    "dataset, tokenizer = get_tokenized_dataset(\n",
    "    dataset=dataset_name,\n",
    "    checkpoint=tokenizer_checkpoint,\n",
    "    return_tokenizer=True,\n",
    ")\n",
    "\n",
    "accuracy = get_accuracy(mg, dataset, tokenizer)\n",
    "print(f\"Original Accuracy: {accuracy}\")\n",
    "\n",
    "\n",
    "accuracy_high = get_accuracy(mg_high, dataset, tokenizer)\n",
    "accuracy_low = get_accuracy(mg_low, dataset, tokenizer)\n",
    "print(f\"Accuracy high: {accuracy_high}\")\n",
    "print(f\"Accuracy low: {accuracy_low}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This way, we can compare the results of the two configurations and see how the precision affects the model's accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixed Precision Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above example, all the weights, activations and biases are quantized to the same format. However, we can also quantize them to different formats. This is called mixed precision quantization.\n",
    "\n",
    "The common problem is we do not know the best precision configuration for a given model. We can use tools to search for the best precision configuration.\n",
    "\n",
    "In the code below, we define the search space that allows weights, biases and activations in a linear layer to be quantized to different precision configurations with the integer format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-02 11:45:27,961] A new study created in memory with name: bert-tiny-mixed-q-study\n",
      "100%|██████████| 3125/3125 [01:15<00:00, 41.15it/s]\n",
      "[I 2025-01-02 11:46:47,202] Trial 0 finished with value: 0.73568 and parameters: {'data_in': 1, 'weight': 6, 'bias': 3}. Best is trial 0 with value: 0.73568.\n",
      " 20%|██        | 633/3125 [00:18<01:11, 34.68it/s]"
     ]
    }
   ],
   "source": [
    "search_space = {\n",
    "    # (x, y), (width, frac_width)\n",
    "    \"data_in\": [\n",
    "        (4, 2), (4, 3),\n",
    "        (6, 2), (6, 4), \n",
    "        (8, 2), (8, 4), (8, 6), \n",
    "        (16, 2), (16, 4), (16, 6), (16, 8), (16, 10), (16, 12)],\n",
    "    \"weight\": [\n",
    "        (4, 2), (4, 3),\n",
    "        (6, 2), (6, 4), \n",
    "        (8, 2), (8, 4), (8, 6), \n",
    "        (16, 2), (16, 4), (16, 6), (16, 8), (16, 10), (16, 12)],\n",
    "    \"bias\": [\n",
    "        (4, 2), (4, 3),\n",
    "        (6, 2), (6, 4), \n",
    "        (8, 2), (8, 4), (8, 6), \n",
    "        (16, 2), (16, 4), (16, 6), (16, 8), (16, 10), (16, 12)],\n",
    "}\n",
    "\n",
    "\n",
    "def construct_model(trial):\n",
    "    config = copy.deepcopy(quantization_config)\n",
    "    for param in [\"data_in\", \"weight\", \"bias\"]:\n",
    "        chosen_idx = trial.suggest_int(param, 0, len(search_space[param]) - 1)\n",
    "        width, frac_width = search_space[param][chosen_idx]\n",
    "        config[\"linear\"][\"config\"][f\"{param}_width\"] = width\n",
    "        config[\"linear\"][\"config\"][f\"{param}_frac_width\"] = frac_width\n",
    "    ori_mg = copy.deepcopy(mg)\n",
    "    mg_q, _ = passes.quantize_transform_pass(\n",
    "        ori_mg,\n",
    "        pass_args=config,\n",
    "    )\n",
    "    return mg_q\n",
    "\n",
    "def objective(trial):\n",
    "    mg_q = construct_model(trial)\n",
    "    return get_accuracy(mg_q, dataset, tokenizer)\n",
    "\n",
    "\n",
    "from optuna.samplers import GridSampler, RandomSampler, TPESampler\n",
    "sampler = RandomSampler()\n",
    "\n",
    "import optuna\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=\"bert-tiny-mixed-q-study\",\n",
    "    sampler=sampler,\n",
    ")\n",
    "\n",
    "study.optimize(\n",
    "    objective,\n",
    "    n_trials=10,\n",
    "    timeout=60 * 60 * 24,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
