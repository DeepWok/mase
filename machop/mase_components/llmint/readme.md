# LLMint

The LLMint module is a fully combinational circuit that takes as input an unpacked array of fixed point integers, as well as some unpacked arrays for the weights and quantized weights of the high and low precision linear layers. It outputs the resulting array of the same input dimensions of the original input array, containing the result of the LLM.int() operation. All other inputs and outputs are binary signals used for stream synchronisation. LLM.int() is a mixed-precision quantization method aiming at reducing the computation power needed for LLM inference. `ORIGINAL_PRECISION` represents the high precision, whereas `REDUCED_PRECISION` represents the low precision. The size of the tensors (input, output and in the middle) can be defined using `TENSOR_SIZE_DIM` parameter.

The LLMint module combines a scatter module, two 1D linear modules defined with the input weights, and a gather module. The parameters of the all these modules are passed as arguments to the LLMint module. The `high_precision_masked` and `low_precision_masked` arrays are used to store the low and high precision outputs of the scatter module. `low_precision_masked` is then quantized down to `REDUCED_PRECISION` in array `input_linear_low_precision`, that is used as an input of the low precision linear layer, while `high_precision_masked` is directly used as input for the low precision linear layer. The outputs of both linear layer are then quantized back to `ORIGINAL_PRECISION` using arrays `high_for_gather` and `low_for_gather`. These serve as input for the final gather module, that combines these two arrays to recompose the output value. This behviour is replicated in the software model within the tesbench for testing purposes.

