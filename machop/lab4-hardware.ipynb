{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />\n",
    "<div align=\"center\">\n",
    "  <a href=\"https://deepwok.github.io/\">\n",
    "    <img src=\"../imgs/deepwok.png\" alt=\"Logo\" width=\"160\" height=\"160\">\n",
    "  </a>\n",
    "\n",
    "  <h1 align=\"center\">Lab 4 for Advanced Deep Learning Systems (ADLS) - Hardware Stream</h1>\n",
    "\n",
    "  <p align=\"center\">\n",
    "    ELEC70109/EE9-AML3-10/EE9-AO25\n",
    "    <br />\n",
    "\t\tWritten by\n",
    "    <a href=\"https://aaron-zhao123.github.io/\">Aaron Zhao, Pedro Gimenes </a>\n",
    "  </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General introduction\n",
    "\n",
    "In this lab, you will learn how to emit SystemVerilog code for a neural network that's been transformed and optimized by MASE. Then, you'll design some hardware for a new Pytorch layer, and simulate the hardware using your new module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Hardware Emit pass\n",
    "\n",
    "The `emit_verilog` transform pass generates a top-level RTL file and testbench file according to the `MaseGraph`, which includes a hardware implementation of each layer in the network. This top-level file instantiates modules from the `components` library in MASE and/or modules generated using [HLS](https://en.wikipedia.org/wiki/High-level_synthesis), when internal components are not available. The hardware can then be simulated using [Verilator](https://www.veripool.org/verilator/), or deployed on an FPGA.\n",
    "\n",
    "First, add Machop to your system PATH (if you haven't already done so) and import the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aw1223/anaconda3/envs/mase/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mSet logging level to debug\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage:\n",
      "        verilator --help\n",
      "        verilator --version\n",
      "        verilator --binary -j 0 [options] [source_files.v]... [opt_c_files.cpp/c/cc/a/o/so]\n",
      "        verilator --cc [options] [source_files.v]... [opt_c_files.cpp/c/cc/a/o/so]\n",
      "        verilator --sc [options] [source_files.v]... [opt_c_files.cpp/c/cc/a/o/so]\n",
      "        verilator --lint-only -Wall [source_files.v]...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "from chop.ir.graph.mase_graph import MaseGraph\n",
    "\n",
    "from chop.passes.graph.analysis import (\n",
    "    init_metadata_analysis_pass,\n",
    "    add_common_metadata_analysis_pass,\n",
    "    add_hardware_metadata_analysis_pass,\n",
    "    report_node_type_analysis_pass,\n",
    ")\n",
    "\n",
    "from chop.passes.graph.transforms import (\n",
    "    emit_verilog_top_transform_pass,\n",
    "    emit_internal_rtl_transform_pass,\n",
    "    emit_bram_transform_pass,\n",
    "    emit_cocotb_transform_pass,\n",
    "    quantize_transform_pass,\n",
    ")\n",
    "\n",
    "from chop.tools.logger import set_logging_verbosity\n",
    "\n",
    "set_logging_verbosity(\"debug\")\n",
    "\n",
    "import toml\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# TO DO: remove\n",
    "import os\n",
    "os.environ[\"PATH\"] = \"/opt/homebrew/bin:\" + os.environ[\"PATH\"]\n",
    "!verilator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, define the neural network. We're using a model which can be used to perform digit classification on the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Toy FC model for digit recognition on MNIST\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(4, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, start_dim=1, end_dim=-1)\n",
    "        x = torch.nn.functional.relu(self.fc1(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll generate a MaseGraph and add metadata. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36mDEBUG   \u001b[0m \u001b[34mgraph():\n",
      "    %x : [num_users=1] = placeholder[target=x]\n",
      "    %flatten : [num_users=1] = call_function[target=torch.flatten](args = (%x,), kwargs = {start_dim: 1, end_dim: -1})\n",
      "    %fc1 : [num_users=1] = call_module[target=fc1](args = (%flatten,), kwargs = {})\n",
      "    %relu : [num_users=1] = call_function[target=torch.nn.functional.relu](args = (%fc1,), kwargs = {inplace: False})\n",
      "    return relu\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "mlp = MLP()\n",
    "mg = MaseGraph(model=mlp)\n",
    "\n",
    "# Provide a dummy input for the graph so it can use for tracing\n",
    "batch_size = 1\n",
    "x = torch.randn((batch_size, 2, 2))\n",
    "dummy_in = {\"x\": x}\n",
    "\n",
    "mg, _ = init_metadata_analysis_pass(mg, None)\n",
    "mg, _ = add_common_metadata_analysis_pass(\n",
    "    mg, {\"dummy_in\": dummy_in, \"add_value\": False}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running `emit_verilog`, we'll quantize the model to fixed precision. Refer back to [lab 2](https://github.com/DeepWok/mase/blob/main/docs/labs/lab2.md) if you've forgotten how this works. Check that the data type for each node is correct after quantization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mInspecting graph [add_common_node_type_analysis_pass]\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Node name    Fx Node op     Mase type            Mase op      Value type\n",
      "-----------  -------------  -------------------  -----------  ------------\n",
      "x            placeholder    placeholder          placeholder  NA\n",
      "flatten      call_function  implicit_func        flatten      float\n",
      "fc1          call_module    module_related_func  linear       fixed\n",
      "relu         call_function  module_related_func  relu         fixed\n",
      "output       output         output               output       NA\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "config_file = os.path.join(\n",
    "    # os.path.abspath(\"\"),\n",
    "    # \"..\",\n",
    "    # \"..\",\n",
    "    # \"machop\",\n",
    "    \"configs\",\n",
    "    \"tests\",\n",
    "    \"quantize\",\n",
    "    \"fixed.toml\",\n",
    ")\n",
    "with open(config_file, \"r\") as f:\n",
    "    quan_args = toml.load(f)[\"passes\"][\"quantize\"]\n",
    "mg, _ = quantize_transform_pass(mg, quan_args)\n",
    "\n",
    "_ = report_node_type_analysis_pass(mg)\n",
    "\n",
    "# Update the metadata\n",
    "for node in mg.fx_graph.nodes:\n",
    "    for arg, arg_info in node.meta[\"mase\"][\"common\"][\"args\"].items():\n",
    "        if isinstance(arg_info, dict):\n",
    "            arg_info[\"type\"] = \"fixed\"\n",
    "            arg_info[\"precision\"] = [8, 3]\n",
    "    for result, result_info in node.meta[\"mase\"][\"common\"][\"results\"].items():\n",
    "        if isinstance(result_info, dict):\n",
    "            result_info[\"type\"] = \"fixed\"\n",
    "            result_info[\"precision\"] = [8, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, it's important to run the `add_hardware_metadata` analysis pass. This adds all the required metadata which is later used by the `emit_verilog` pass, including:\n",
    "\n",
    "1. The node's toolchain, which defines whether we use internal Verilog modules from the `components` library or the HLS flow.\n",
    "2. The Verilog parameters associated with each node.\n",
    "\n",
    "> **_TASK:_** Read [this page](https://jianyicheng.github.io/mase-tools/modules/analysis/add_metadata.html#add-hardware-metadata-analysis-pass) for more information on the hardware metadata pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg, _ = add_hardware_metadata_analysis_pass(mg, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, run the emit verilog pass to generate the SystemVerilog files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mEmitting Verilog...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEmitting internal components...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "mg, _ = emit_verilog_top_transform_pass(mg)\n",
    "mg, _ = emit_internal_rtl_transform_pass(mg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generated files should now be found under `top/hardware`. \n",
    "\n",
    "> **_TASK:_** Read through `top/hardware/rtl/top.sv` and make sure you understand how our MLP model maps to this hardware design. \n",
    "\n",
    "You will notice the following instantiated modules:\n",
    "\n",
    "* `fixed_linear`: this is found under `components/linear/fixed_linear.sv` and implements each Linear layer in the model.\n",
    "* `fc<layer number>_weight/bias_source`: these are [BRAM](https://nandland.com/lesson-15-what-is-a-block-ram-bram/) memories which drive the weights and biases into the linear layers for computation.\n",
    "* `fixed_relu`: found under `components/activations/fixed_relu.sv`, implements the ReLU activation.\n",
    "\n",
    "As of now, we can't yet run a simulation on the model, as we haven't yet generated the memory components. To do this, run the `emit_bram` transform pass as follows, which will generate the memory initialization files and SystemVerilog modules to drive weights and biases into the linear layers. Finally, the `emit_verilog_tb` transform pass will generate the testbench files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mEmitting BRAM...\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[34mEmitting DAT file for node: fc1, parameter: weight\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[34mROM module weight successfully written into /home/aw1223/.mase/top/hardware/rtl/fc1_weight_source.sv\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[34mInit data weight successfully written into /home/aw1223/.mase/top/hardware/rtl/fc1_weight_rom.dat\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[34mEmitting DAT file for node: fc1, parameter: bias\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[34mROM module bias successfully written into /home/aw1223/.mase/top/hardware/rtl/fc1_bias_source.sv\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[34mInit data bias successfully written into /home/aw1223/.mase/top/hardware/rtl/fc1_bias_rom.dat\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "mg, _ = emit_bram_transform_pass(mg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mEmitting testbench...\u001b[0m\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'verilator_buff' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m mg, _ \u001b[38;5;241m=\u001b[39m emit_cocotb_transform_pass(mg)\n",
      "File \u001b[0;32m~/new/mase/machop/chop/passes/graph/transforms/verilog/emit_tb.py:170\u001b[0m, in \u001b[0;36memit_cocotb_transform_pass\u001b[0;34m(graph, pass_args)\u001b[0m\n\u001b[1;32m    164\u001b[0m project_dir \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    165\u001b[0m     pass_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproject_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproject_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m pass_args\u001b[38;5;241m.\u001b[39mkeys() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    166\u001b[0m )\n\u001b[1;32m    168\u001b[0m init_project(project_dir)\n\u001b[0;32m--> 170\u001b[0m _emit_cocotb_test(graph)\n\u001b[1;32m    171\u001b[0m _emit_cocotb_tb(graph)\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph, \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/new/mase/machop/chop/passes/graph/transforms/verilog/emit_tb.py:58\u001b[0m, in \u001b[0;36m_emit_cocotb_test\u001b[0;34m(graph)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(tb_path \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest.py\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     53\u001b[0m         f\u001b[38;5;241m.\u001b[39mwrite(test_template)\n\u001b[1;32m     55\u001b[0m     verilator_build \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;124m#!/bin/bash\u001b[39m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;124m# This script is used to build the verilator simulation\u001b[39m\n\u001b[0;32m---> 58\u001b[0m \u001b[38;5;124mverilator --binary --build \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mverilator_buff\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     60\u001b[0m     verilator_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(sim_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuild.sh\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(verilator_file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m outf:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'verilator_buff' is not defined"
     ]
    }
   ],
   "source": [
    "mg, _ = emit_cocotb_transform_pass(mg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **_TASK:_** Now, you're ready to launch a simulation by calling the simulate action as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Running command perl /home/aw1223/anaconda3/envs/mase/bin/verilator -cc --exe -Mdir /home/aw1223/new/mase/machop/sim_build -DCOCOTB_SIM=1 --top-module top --vpi --public-flat-rw --prefix Vtop -o top -LDFLAGS '-Wl,-rpath,/home/aw1223/anaconda3/envs/mase/lib/python3.11/site-packages/cocotb/libs -L/home/aw1223/anaconda3/envs/mase/lib/python3.11/site-packages/cocotb/libs -lcocotbvpi_verilator' -Wno-fatal -Wno-lint -Wno-style --trace -I/home/aw1223/.mase/top/hardware/rtl -I/home/aw1223/new/mase/machop/mase_components/attention/rtl -I/home/aw1223/new/mase/machop/mase_components/axi/rtl -I/home/aw1223/new/mase/machop/mase_components/linear/rtl -I/home/aw1223/new/mase/machop/mase_components/float_arithmetic/rtl -I/home/aw1223/new/mase/machop/mase_components/conv/rtl -I/home/aw1223/new/mase/machop/mase_components/binary_arith/rtl -I/home/aw1223/new/mase/machop/mase_components/activations/rtl -I/home/aw1223/new/mase/machop/mase_components/sim/rtl -I/home/aw1223/new/mase/machop/mase_components/testbench/rtl -I/home/aw1223/new/mase/machop/mase_components/buffers/rtl -I/home/aw1223/new/mase/machop/mase_components/matmul/rtl -I/home/aw1223/new/mase/machop/mase_components/cast/rtl -I/home/aw1223/new/mase/machop/mase_components/fixed_arithmetic/rtl -I/home/aw1223/new/mase/machop/mase_components/systolic_arrays/rtl -I/home/aw1223/new/mase/machop/mase_components/arithmetic/rtl -I/home/aw1223/new/mase/machop/mase_components/memory/rtl -I/home/aw1223/new/mase/machop/mase_components/common/rtl -I/home/aw1223/new/mase/machop/mase_components/ViT/rtl /home/aw1223/anaconda3/envs/mase/lib/python3.11/site-packages/cocotb/share/lib/verilator/verilator.cpp /home/aw1223/.mase/top/hardware/rtl/top.sv in directory /home/aw1223/new/mase/machop/sim_build\n",
      "INFO: Running command make -C /home/aw1223/new/mase/machop/sim_build -f Vtop.mk in directory /home/aw1223/new/mase/machop/sim_build\n",
      "make: Entering directory '/home/aw1223/new/mase/machop/sim_build'\n",
      "/home/aw1223/anaconda3/envs/mase/bin/x86_64-conda-linux-gnu-c++     verilator.o verilated.o verilated_dpi.o verilated_vpi.o verilated_vcd_c.o verilated_threads.o Vtop__ALL.a   -Wl,-rpath,/home/aw1223/anaconda3/envs/mase/lib/python3.11/site-packages/cocotb/libs -L/home/aw1223/anaconda3/envs/mase/lib/python3.11/site-packages/cocotb/libs -lcocotbvpi_verilator  -pthread -lpthread -latomic   -o top\n",
      "make: Leaving directory '/home/aw1223/new/mase/machop/sim_build'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aw1223/anaconda3/envs/mase/bin/../lib/gcc/x86_64-conda-linux-gnu/9.3.0/../../../../x86_64-conda-linux-gnu/bin/ld: /home/aw1223/anaconda3/envs/mase/lib/python3.11/site-packages/cocotb/libs/libcocotbvpi_verilator.so: undefined reference to `memcpy@GLIBC_2.14'\n",
      "/home/aw1223/anaconda3/envs/mase/bin/../lib/gcc/x86_64-conda-linux-gnu/9.3.0/../../../../x86_64-conda-linux-gnu/bin/ld: /home/aw1223/anaconda3/envs/mase/bin/../lib/gcc/x86_64-conda-linux-gnu/9.3.0/../../../../x86_64-conda-linux-gnu/lib/../lib/libstdc++.so: undefined reference to `aligned_alloc@GLIBC_2.16'\n",
      "/home/aw1223/anaconda3/envs/mase/bin/../lib/gcc/x86_64-conda-linux-gnu/9.3.0/../../../../x86_64-conda-linux-gnu/bin/ld: /home/aw1223/anaconda3/envs/mase/bin/../lib/gcc/x86_64-conda-linux-gnu/9.3.0/../../../../x86_64-conda-linux-gnu/lib/../lib/libstdc++.so: undefined reference to `clock_gettime@GLIBC_2.17'\n",
      "collect2: error: ld returned 1 exit status\n",
      "make: *** [Vtop.mk:66: top] Error 1\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "Process 'make' terminated with error 2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m Process 'make' terminated with error 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aw1223/anaconda3/envs/mase/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3561: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from chop.actions import simulate\n",
    "\n",
    "simulate(skip_build=False, skip_test=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `simulate` action creates a `dump.vcd` file within the `sim_build` directory, which contains the waveform trace of the simulation. The waveforms can be opened with a viewer like GTKWave.\n",
    "\n",
    "> **TASK**: Follow the instructions [here](https://gtkwave.sourceforge.net/) to install GTKWave on your platform, then open the generated trace file to inspect the signals in the simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Task\n",
    "\n",
    "Pytorch has a number of layers which are available to users to define neural network models. At the moment, `emit_verilog` supports generating Verilog for models including Linear layers and the ReLU activation.\n",
    "\n",
    "> **_MAIN TASK:_** choose another layer type from the [Pytorch list](https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity) and write a SystemVerilog file to implement that layer in hardware. Then, change the generated `top.sv` file to inject that layer within the design. For example, you may replace the ReLU activations with [Leaky ReLU](https://pytorch.org/docs/stable/generated/torch.nn.RReLU.html#torch.nn.RReLU). Re-run the simulation and observe the effect on latency and accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
