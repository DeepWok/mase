# basics
model = "vgg7"
dataset = "cifar10"
task = "cls"

max_epochs = 5512
batch_size = 512
learning_rate = 1e-3
accelerator = "gpu"
project = "vgg7"
seed = 42
log_every_n_steps = 5
load_name = "/home/lch121600/ADLSlab/mase/mase_output/vgg7_classification_cifar10_2024-02-21/test-accu-0.9332.ckpt"
load_type = "pl"




[search.search_space]
name = "graph/quantize/mixed_precision_ptq"

[search.search_space.setup]
by = "type_revised"

[search.search_space.seed.default.config]
# the only choice "NA" is used to indicate that layers are not quantized by default
name = ["NA"]

[search.search_space.seed.linear.config]
# if search.search_space.setup.by = "type", this seed will be used to quantize all torch.nn.Linear/ F.linear
name = ["integer"]
data_in_width = [4, 8, 16, 32]
data_in_frac_width = ["NA"] # "NA" means data_in_frac_width = data_in_width // 2
weight_width = [4, 8, 16, 32]
weight_frac_width = ["NA"]
bias_width = [4, 8, 16, 32]
bias_frac_width = ["NA"]

[search.search_space.seed.conv2d.config]
# if search.search_space.setup.by = "type", this seed will be used to quantize all torch.nn.Linear/ F.linear
name = ["integer"]
data_in_width = [4, 8, 16, 32]
data_in_frac_width = ["NA"] # "NA" means data_in_frac_width = data_in_width // 2
weight_width = [4, 8, 16, 32]
weight_frac_width = ["NA"]
bias_width = [4, 8, 16, 32]
bias_frac_width = ["NA"]

# [search.search_space.seed.batch_norm2d.config]
# if search.search_space.setup.by = "type", this seed will be used to quantize all torch.nn.Linear/ F.linear
# name = ["integer"]
# data_in_width = [ 16, 8, 4]
# data_in_frac_width = ["NA"] # "NA" means data_in_frac_width = data_in_width // 2
# weight_width = [2, 4, 8]
# weight_frac_width = ["NA"]
# bias_width = [2, 4, 8]
# bias_frac_width = ["NA"]


[search.strategy]
name = "rl"

[search.strategy.sw_runner.basic_evaluation]
data_loader = "val_dataloader"
num_samples = 512

[search.strategy.hw_runner.average_bitwidth]
compare_to = 32 # compare to FP32

[search.strategy.setup]
algorithm = 'a2c' # 'ppo'
device = 'cuda' # 'cpu'
env = 'mixed_precision'
total_timesteps = 3000#32000
save_name = 'test'
mode='load'  # 'train', "continue-training"
load_path='/home/super_monkey/PycharmProjects/mase_aux/logs/Best_Model/rl_model_3000_steps.zip'
# load_path='/home/super_monkey/PycharmProjects/mase_aux/mase_output/gpu-100/gpu-100.zip'
# load_path='/home/super_monkey/PycharmProjects/mase_aux/mase_output/cpu-100/cpu-100.zip'
model_parallel = false
runner_style = "lm"

#sampler = "brute-force"
# sum_scaled_metrics = true # single objective
# direction = "maximize"
sum_scaled_metrics = false # multi objective

[search.strategy.metrics]
# loss.scale = 1.0
# loss.direction = "minimize"
accuracy.scale = 1.0
accuracy.direction = "maximize"
average_bitwidth.scale = 0.2
average_bitwidth.direction = "minimize"
