# basics
model = "vgg7"
dataset = "cifar10"
task = "cls"

batch_size = 1024
accelerator = "cpu"
project = "rl_search"
seed = 42
load_name = "/mnt/c/Users/1/Downloads/test-accu-0.9332.ckpt"
load_type = "pl"

[search.search_space]
name = "rl/quantize/mixed_precision_ptq"

[search.search_space.setup]
by = "type"

[search.search_space.seed.default.config]
# the only choice "NA" is used to indicate that layers are not quantized by default
name = ["NA"]

[search.search_space.seed.linear.config]
# if search.search_space.setup.by = "type", this seed will be used to quantize all torch.nn.Linear/ F.linear
name = ["integer"]
data_in_width = [6, 8, 10, 12]
data_in_frac_width = ["NA"] # "NA" means data_in_frac_width = data_in_width // 2
weight_width = [6, 8, 10, 12]
weight_frac_width = ["NA"]
bias_width = [6, 8, 10, 12]
bias_frac_width = ["NA"]

[search.search_space.seed.conv2d.config]
# this seed will be used to quantize all torch.nn.Conv2d
name = ["integer"]
data_in_width = [6, 8, 10, 12]
data_in_frac_width = ["NA"] # "NA" means data_in_frac_width = data_in_width // 2
weight_width = [6, 8, 10, 12]
weight_frac_width = ["NA"]
bias_width = [6, 8, 10, 12]
bias_frac_width = ["NA"]

[search.strategy]
name = "rl"
eval_mode = true

[search.strategy.sw_runner.basic_evaluation]
data_loader = "val_dataloader"
num_samples = 1024

[search.strategy.hw_runner.average_bitwidth]
compare_to = 32 # compare to FP32

[search.strategy.setup]
device = "cpu"
total_trials = 10
# choose between ppo, a2c, ddpg, sac
algorithm = "a2c"
env = "MixedPrecisionEnv"

[search.strategy.metrics]
accuracy.scale = 0.7
# let algorith to know whether this metric is the larger the better or the smaller the better
accuracy.direction = "maximize"
average_bitwidth.scale = 0.3
average_bitwidth.direction = "minimize"
# boundary to normalize the metric to [0, 1]
average_bitwidth.lower_bound = 6
average_bitwidth.upper_bound = 12
