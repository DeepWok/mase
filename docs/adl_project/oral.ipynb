{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for |: 'type' and 'type'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 33\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mdata\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# import torchvision\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# import torchvision.transforms as transforms\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# import torchvision.datasets as datasets\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m \n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# print(pytorch_quantization.__version__)\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mchop\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MaseDataModule, get_dataset_info\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mchop\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogger\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m set_logging_verbosity\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mchop\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_cf_args, get_dummy_input, load_config\n",
      "File \u001b[0;32m~/mase/machop/chop/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogger\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m root_logger\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mir\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmase_graph\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MaseGraph\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m passes\n",
      "File \u001b[0;32m~/mase/machop/chop/tools/__init__.py:7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# import os\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# import pathlib\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# DATA_DIR = os.path.join(pathlib.Path(__file__).parent.parent.resolve(), \"data\")\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# os.environ[\"GG_DATA_DIR\"] = DATA_DIR\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcheckpoint_load\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_model\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig_load\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_config, post_parse_load_config\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogger\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m root_logger, set_logging_verbosity\n",
      "File \u001b[0;32m~/mase/machop/chop/tools/checkpoint_load.py:51\u001b[0m\n\u001b[1;32m     45\u001b[0m     model \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(checkpoint)\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model\u001b[39m(\n\u001b[1;32m     50\u001b[0m     load_name: \u001b[38;5;28mstr\u001b[39m, load_type: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmz\u001b[39m\u001b[38;5;124m\"\u001b[39m, model: torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mModule\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m|\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGraphModule\u001b[49m:\n\u001b[1;32m     52\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load a pytorch/lightning/mase checkpoint to a model.\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \n\u001b[1;32m     54\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m        nn.Module/fx.GraphModule: the model with the checkpoint loaded\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m load_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhf\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for |: 'type' and 'type'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "from pprint import pprint as pp\n",
    "\n",
    "# # figure out the correct path\n",
    "machop_path = Path(\"/home/gabriella/mase/machop\")\n",
    "assert machop_path.exists(), \"Failed to find machop at: {}\".format(machop_path)\n",
    "sys.path.append(str(machop_path))\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "# import torchvision\n",
    "# import torchvision.transforms as transforms\n",
    "# import torchvision.datasets as datasets\n",
    "# import torch_tensorrt\n",
    "\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# import pytorch_quantization\n",
    "# from pytorch_quantization import nn as quant_nn\n",
    "# from pytorch_quantization import quant_modules\n",
    "# from pytorch_quantization.tensor_quant import QuantDescriptor\n",
    "# from pytorch_quantization import calib\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# print(pytorch_quantization.__version__)\n",
    "\n",
    "from chop.dataset import MaseDataModule, get_dataset_info\n",
    "from chop.tools.logger import set_logging_verbosity\n",
    "\n",
    "from chop.tools import get_cf_args, get_dummy_input, load_config\n",
    "from chop.passes.graph import (\n",
    "    save_node_meta_param_interface_pass,\n",
    "    report_node_meta_param_analysis_pass,\n",
    "    profile_statistics_analysis_pass,\n",
    "    add_common_metadata_analysis_pass,\n",
    "    init_metadata_analysis_pass,\n",
    "    add_software_metadata_analysis_pass,\n",
    "    quantize_tensorrt_transform_pass,\n",
    "    test_quantize_tensorrt_transform_pass,\n",
    "    fake_quantize_transform_pass,\n",
    "    graph_calibration_pass,\n",
    "    evaluate_fake_quantize_pass,\n",
    "    fake_quantize_to_trt_pass\n",
    ")\n",
    "from chop.tools.get_input import InputGenerator\n",
    "from chop.tools.checkpoint_load import load_model\n",
    "from chop.ir import MaseGraph\n",
    "\n",
    "from chop.models import get_model_info, get_model, get_tokenizer\n",
    "\n",
    "set_logging_verbosity(\"info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MaseDataModule' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvgg7\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m dataset_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcifar10\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 5\u001b[0m data_module \u001b[38;5;241m=\u001b[39m \u001b[43mMaseDataModule\u001b[49m(\n\u001b[1;32m      6\u001b[0m     name\u001b[38;5;241m=\u001b[39mdataset_name,\n\u001b[1;32m      7\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m      8\u001b[0m     model_name\u001b[38;5;241m=\u001b[39mmodel_name,\n\u001b[1;32m      9\u001b[0m     num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     11\u001b[0m data_module\u001b[38;5;241m.\u001b[39mprepare_data()\n\u001b[1;32m     12\u001b[0m data_module\u001b[38;5;241m.\u001b[39msetup()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MaseDataModule' is not defined"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "model_name = \"vgg7\"\n",
    "dataset_name = \"cifar10\"\n",
    "\n",
    "data_module = MaseDataModule(\n",
    "    name=dataset_name,\n",
    "    batch_size=batch_size,\n",
    "    model_name=model_name,\n",
    "    num_workers=0,\n",
    ")\n",
    "data_module.prepare_data()\n",
    "data_module.setup()\n",
    "\n",
    "\n",
    "# load the VGG model\n",
    "CHECKPOINT_PATH = \"/home/gabriella/mase/machop/test-accu-0.9332.ckpt\"\n",
    "# CHECKPOINT_PATH = \"/home/qizhu/Desktop/Work/mase/mase_output/opt125.ckpt\"\n",
    "\n",
    "model_info = get_model_info(model_name)\n",
    "# quant_modules.initialize()\n",
    "model = get_model(\n",
    "    model_name,\n",
    "    task=\"cls\",\n",
    "    dataset_info=data_module.dataset_info,\n",
    "    pretrained=False)\n",
    "\n",
    "model = load_model(load_name=CHECKPOINT_PATH, load_type=\"pl\", model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transfer the model into mase graph\n",
    "mg = MaseGraph(model=model)\n",
    "ori_mg = MaseGraph(model=model)\n",
    "\n",
    "# get the input generator\n",
    "input_generator = InputGenerator(\n",
    "    data_module=data_module,\n",
    "    model_info=model_info,\n",
    "    task=\"cls\",\n",
    "    which_dataloader=\"train\",\n",
    ")\n",
    "\n",
    "# a demonstration of how to feed an input value to the model\n",
    "dummy_in = next(iter(input_generator))\n",
    "# _ = model(**dummy_in)\n",
    "\n",
    "#add all the parameters to masegraph\n",
    "mg, _ = init_metadata_analysis_pass(mg, None)\n",
    "mg, _ = add_common_metadata_analysis_pass(mg, {\"dummy_in\": dummy_in})\n",
    "mg, _ = add_software_metadata_analysis_pass(mg, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantization pass based on pytorch-quantization\n",
    "\n",
    "To achieve QAT, we could use fake quantization to simulate the quantization process. We could use the `FakeQuantize` argument to select it.\n",
    "\n",
    "Here's an example of pass_args, we use name to specify the layer we want to quantize, achieving layer-wise PTQ, and we could select the specific calibrate method and precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fake quantize the graph\n",
    "pass_args = {\n",
    "    \"by\": \"name\",\n",
    "    \"default\": {\"config\": {\"name\": None}},\n",
    "    \"feature_layers_0\": {\n",
    "        \"config\": {\n",
    "            \"name\": \"int\",\n",
    "            \"input\": {\n",
    "                \"precesion\": 8,\n",
    "                \"calibrator\": \"max\",\n",
    "                \"quantize_axis\": None,\n",
    "            },\n",
    "            \"weight\": {\n",
    "                \"calibrator\": \"histogram\",\n",
    "                \"quantize_axis\": None,\n",
    "            },\n",
    "        }\n",
    "    },    \n",
    "    \"classifier_0\": {\n",
    "        \"config\": {\n",
    "            \"name\": \"int\",\n",
    "            \"input\": {\n",
    "                \"precesion\": 8,\n",
    "                \"calibrator\": \"histogram\",\n",
    "                \"quantize_axis\": None,\n",
    "            },\n",
    "            \"weight\": {\n",
    "                \"calibrator\": \"max\",\n",
    "                \"quantize_axis\": None,\n",
    "            },\n",
    "        }\n",
    "    },\n",
    "    \"classifier_1\": {\n",
    "        \"config\": {\n",
    "            \"name\": \"int\",\n",
    "            \"input\": {\n",
    "                \"precesion\": 8,\n",
    "                \"calibrator\": \"histogram\",\n",
    "                \"quantize_axis\": None,\n",
    "            },\n",
    "            \"weight\": {\n",
    "                \"calibrator\": \"max\",\n",
    "                \"quantize_axis\": None,\n",
    "            },\n",
    "        }\n",
    "    },\n",
    "    \"classifier_2\": {\n",
    "        \"config\": {\n",
    "            \"name\": \"int\",\n",
    "            \"input\": {\n",
    "                \"precesion\": 8,\n",
    "                \"calibrator\": \"histogram\",\n",
    "                \"quantize_axis\": None,\n",
    "            },\n",
    "            \"weight\": {\n",
    "                \"calibrator\": \"max\",\n",
    "                \"quantize_axis\": None,\n",
    "            },\n",
    "        }\n",
    "    },\n",
    "    \"classifier_3\": {\n",
    "        \"config\": {\n",
    "            \"name\": \"int\",\n",
    "            \"input\": {\n",
    "                \"precesion\": 8,\n",
    "                \"calibrator\": \"histogram\",\n",
    "                \"quantize_axis\": None,\n",
    "            },\n",
    "            \"weight\": {\n",
    "                \"calibrator\": \"max\",\n",
    "                \"quantize_axis\": None,\n",
    "            },\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "mg = fake_quantize_transform_pass(mg, pass_args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibration\n",
    "\n",
    "After quantization the model, we need to calibrate the model and get amax to each layer. We can use the following pass_args to contral the calibration process, including the method, the number of samples, and the calibration dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the pass of calibration for tenssor_quantization\n",
    "pass_args_calibrate = {\n",
    "    \"calibrator\": \"percentile\",\n",
    "    \"percentiles\": [99],\n",
    "    \"data_module\": data_module,\n",
    "    \"num_batches\": 100,\n",
    "}\n",
    "\n",
    "graph_calibration_pass(mg,  pass_args_calibrate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass_args_eval = {\n",
    "    \"data_module\": data_module,\n",
    "}\n",
    "\n",
    "mg = evaluate_fake_quantize_pass(mg, pass_args_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model export\n",
    "\n",
    "We first need to export the model to ONNX format, then to tensorrt engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using tenssor quantization\n",
    "pass_args = {\n",
    "    \"onnxFile\": \"onnx_test.onnx\",\n",
    "    \"engineFile\": \"engine_test.plan\",\n",
    "    \"dataloader\": data_module.test_dataloader,\n",
    "}\n",
    "mg = fake_quantize_to_trt_pass(mg, pass_args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "visualize",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
