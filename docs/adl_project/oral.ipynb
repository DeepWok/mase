{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### initialize model and dataset and mase graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.1\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'fake_quantize_to_trt_pass' from 'chop.passes.graph' (/home/qizhu/Desktop/Work/mase/machop/chop/passes/graph/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 37\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mchop\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogger\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m set_logging_verbosity\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mchop\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_cf_args, get_dummy_input, load_config\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mchop\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpasses\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     38\u001b[0m     save_node_meta_param_interface_pass,\n\u001b[1;32m     39\u001b[0m     report_node_meta_param_analysis_pass,\n\u001b[1;32m     40\u001b[0m     profile_statistics_analysis_pass,\n\u001b[1;32m     41\u001b[0m     add_common_metadata_analysis_pass,\n\u001b[1;32m     42\u001b[0m     init_metadata_analysis_pass,\n\u001b[1;32m     43\u001b[0m     add_software_metadata_analysis_pass,\n\u001b[1;32m     44\u001b[0m     quantize_tensorrt_transform_pass,\n\u001b[1;32m     45\u001b[0m     test_quantize_tensorrt_transform_pass,\n\u001b[1;32m     46\u001b[0m     quantization_aware_training_pass,\n\u001b[1;32m     47\u001b[0m     graph_calibration_pass,\n\u001b[1;32m     48\u001b[0m     evaluate_pytorch_model_pass,\n\u001b[1;32m     49\u001b[0m     fake_quantize_to_trt_pass,\n\u001b[1;32m     50\u001b[0m     mixed_precision_transform_pass,\n\u001b[1;32m     51\u001b[0m     test_trt_engine\n\u001b[1;32m     52\u001b[0m )\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mchop\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mget_input\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InputGenerator\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mchop\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcheckpoint_load\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_model\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'fake_quantize_to_trt_pass' from 'chop.passes.graph' (/home/qizhu/Desktop/Work/mase/machop/chop/passes/graph/__init__.py)"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "from pprint import pprint as pp\n",
    "\n",
    "# # figure out the correct path\n",
    "machop_path = Path(\".\").resolve().parent.parent /\"machop\"\n",
    "assert machop_path.exists(), \"Failed to find machop at: {}\".format(machop_path)\n",
    "sys.path.append(str(machop_path))\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch_tensorrt\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import pytorch_quantization\n",
    "from pytorch_quantization import nn as quant_nn\n",
    "from pytorch_quantization import quant_modules\n",
    "from pytorch_quantization.tensor_quant import QuantDescriptor\n",
    "from pytorch_quantization import calib\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(pytorch_quantization.__version__)\n",
    "\n",
    "from chop.dataset import MaseDataModule, get_dataset_info\n",
    "from chop.tools.logger import set_logging_verbosity\n",
    "\n",
    "from chop.tools import get_cf_args, get_dummy_input, load_config\n",
    "from chop.passes.graph import (\n",
    "    save_node_meta_param_interface_pass,\n",
    "    report_node_meta_param_analysis_pass,\n",
    "    profile_statistics_analysis_pass,\n",
    "    add_common_metadata_analysis_pass,\n",
    "    init_metadata_analysis_pass,\n",
    "    add_software_metadata_analysis_pass,\n",
    "    quantize_tensorrt_transform_pass,\n",
    "    test_quantize_tensorrt_transform_pass,\n",
    "    quantization_aware_training_pass,\n",
    "    graph_calibration_pass,\n",
    "    evaluate_pytorch_model_pass,\n",
    "    graph_to_trt_pass,\n",
    "    mixed_precision_transform_pass,\n",
    "    test_trt_engine\n",
    ")\n",
    "from chop.tools.get_input import InputGenerator\n",
    "from chop.tools.checkpoint_load import load_model\n",
    "from chop.ir import MaseGraph\n",
    "\n",
    "from chop.models import get_model_info, get_model, get_tokenizer\n",
    "\n",
    "set_logging_verbosity(\"info\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from /home/qizhu/Desktop/Work/mase/mase_output/test-accu-0.9332.ckpt\u001b[0m\n",
      "I0329 00:03:18.717492 140339404171072 checkpoint_load.py:85] Loaded pytorch lightning checkpoint from /home/qizhu/Desktop/Work/mase/mase_output/test-accu-0.9332.ckpt\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "model_name = \"vgg7\"\n",
    "dataset_name = \"cifar10\"\n",
    "\n",
    "# batch_size = 1\n",
    "# model_name = \"facebook/opt-125m:patched\"\n",
    "# dataset_name = \"cola\"\n",
    "\n",
    "\n",
    "data_module = MaseDataModule(\n",
    "    name=dataset_name,\n",
    "    batch_size=batch_size,\n",
    "    model_name=model_name,\n",
    "    num_workers=0,\n",
    ")\n",
    "data_module.prepare_data()\n",
    "data_module.setup()\n",
    "\n",
    "# 📝️ change this CHECKPOINT_PATH to the one you trained in Lab1\n",
    "CHECKPOINT_PATH = \"/home/qizhu/Desktop/Work/mase/mase_output/test-accu-0.9332.ckpt\"\n",
    "# CHECKPOINT_PATH = \"/home/qizhu/Desktop/Work/mase/mase_output/opt125.ckpt\"\n",
    "\n",
    "model_info = get_model_info(model_name)\n",
    "# quant_modules.initialize()\n",
    "model = get_model(\n",
    "    model_name,\n",
    "    task=\"cls\",\n",
    "    dataset_info=data_module.dataset_info,\n",
    "    pretrained=False)\n",
    "\n",
    "model = load_model(load_name=CHECKPOINT_PATH, load_type=\"pl\", model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MaseGraph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#transfer the model into mase graph\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m mg \u001b[38;5;241m=\u001b[39m \u001b[43mMaseGraph\u001b[49m(model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m      3\u001b[0m ori_mg \u001b[38;5;241m=\u001b[39m MaseGraph(model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# get the input generator\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MaseGraph' is not defined"
     ]
    }
   ],
   "source": [
    "#transfer the model into mase graph\n",
    "mg = MaseGraph(model=model)\n",
    "ori_mg = MaseGraph(model=model)\n",
    "\n",
    "# get the input generator\n",
    "input_generator = InputGenerator(\n",
    "    data_module=data_module,\n",
    "    model_info=model_info,\n",
    "    task=\"cls\",\n",
    "    which_dataloader=\"train\",\n",
    ")\n",
    "\n",
    "# a demonstration of how to feed an input value to the model\n",
    "dummy_in = next(iter(input_generator))\n",
    "# _ = model(**dummy_in)\n",
    "\n",
    "#add all the parameters to masegraph\n",
    "mg, _ = init_metadata_analysis_pass(mg, None)\n",
    "mg, _ = add_common_metadata_analysis_pass(mg, {\"dummy_in\": dummy_in})\n",
    "mg, _ = add_software_metadata_analysis_pass(mg, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantization pass based on pytorch-quantization\n",
    "\n",
    "To achieve QAT, we could use fake quantization to simulate the quantization process. We could use the `FakeQuantize` argument to select it.\n",
    "\n",
    "Here's an example of pass_args, we use name to specify the layer we want to quantize, achieving layer-wise PTQ, and we could select the specific calibrate method and precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0329 00:03:20.852674 140339404171072 tensor_quantizer.py:184] Disable MaxCalibrator\n",
      "W0329 00:03:20.853337 140339404171072 tensor_quantizer.py:184] Disable MaxCalibrator\n",
      "W0329 00:03:20.853760 140339404171072 tensor_quantizer.py:184] Disable MaxCalibrator\n",
      "W0329 00:03:20.854099 140339404171072 tensor_quantizer.py:184] Disable MaxCalibrator\n",
      "W0329 00:03:20.854486 140339404171072 tensor_quantizer.py:184] Disable MaxCalibrator\n",
      "W0329 00:03:20.854938 140339404171072 tensor_quantizer.py:184] Disable MaxCalibrator\n",
      "W0329 00:03:20.855399 140339404171072 tensor_quantizer.py:184] Disable MaxCalibrator\n",
      "W0329 00:03:20.855891 140339404171072 tensor_quantizer.py:184] Disable MaxCalibrator\n",
      "W0329 00:03:20.856315 140339404171072 tensor_quantizer.py:184] Disable MaxCalibrator\n",
      "W0329 00:03:20.856642 140339404171072 tensor_quantizer.py:184] Disable MaxCalibrator\n",
      "W0329 00:03:20.857153 140339404171072 tensor_quantizer.py:184] Disable MaxCalibrator\n",
      "W0329 00:03:20.857544 140339404171072 tensor_quantizer.py:184] Disable MaxCalibrator\n",
      "W0329 00:03:20.857908 140339404171072 tensor_quantizer.py:184] Disable MaxCalibrator\n",
      "W0329 00:03:20.858325 140339404171072 tensor_quantizer.py:184] Disable MaxCalibrator\n",
      "W0329 00:03:20.859758 140339404171072 tensor_quantizer.py:261] Load calibrated amax, shape=torch.Size([]).\n",
      "W0329 00:03:20.860085 140339404171072 tensor_quantizer.py:262] Call .cuda() if running on GPU after loading calibrated amax.\n",
      "W0329 00:03:20.860609 140339404171072 tensor_quantizer.py:261] Load calibrated amax, shape=torch.Size([]).\n",
      "W0329 00:03:20.861083 140339404171072 tensor_quantizer.py:261] Load calibrated amax, shape=torch.Size([]).\n",
      "W0329 00:03:20.861536 140339404171072 tensor_quantizer.py:261] Load calibrated amax, shape=torch.Size([]).\n",
      "W0329 00:03:20.861984 140339404171072 tensor_quantizer.py:261] Load calibrated amax, shape=torch.Size([]).\n",
      "W0329 00:03:20.862353 140339404171072 tensor_quantizer.py:261] Load calibrated amax, shape=torch.Size([]).\n",
      "W0329 00:03:20.862840 140339404171072 tensor_quantizer.py:261] Load calibrated amax, shape=torch.Size([]).\n",
      "W0329 00:03:20.863363 140339404171072 tensor_quantizer.py:261] Load calibrated amax, shape=torch.Size([]).\n",
      "W0329 00:03:20.863823 140339404171072 tensor_quantizer.py:261] Load calibrated amax, shape=torch.Size([]).\n",
      "W0329 00:03:20.864234 140339404171072 tensor_quantizer.py:261] Load calibrated amax, shape=torch.Size([]).\n",
      "W0329 00:03:20.864628 140339404171072 tensor_quantizer.py:261] Load calibrated amax, shape=torch.Size([]).\n",
      "W0329 00:03:20.865056 140339404171072 tensor_quantizer.py:261] Load calibrated amax, shape=torch.Size([]).\n",
      "W0329 00:03:20.865447 140339404171072 tensor_quantizer.py:261] Load calibrated amax, shape=torch.Size([]).\n",
      "W0329 00:03:20.865817 140339404171072 tensor_quantizer.py:261] Load calibrated amax, shape=torch.Size([]).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_layers.0._input_quantizer       : TensorQuantizer(8bit fake per-tensor amax=5.3472 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "feature_layers.0._weight_quantizer      : TensorQuantizer(8bit fake per-tensor amax=0.5699 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "feature_layers.3._input_quantizer       : TensorQuantizer(8bit fake per-tensor amax=26.2659 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "feature_layers.3._weight_quantizer      : TensorQuantizer(8bit fake per-tensor amax=0.5960 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "feature_layers.7._input_quantizer       : TensorQuantizer(8bit fake per-tensor amax=10.3720 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "feature_layers.7._weight_quantizer      : TensorQuantizer(8bit fake per-tensor amax=0.7710 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "feature_layers.10._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=7.8593 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "feature_layers.10._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.4954 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "feature_layers.14._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=7.7431 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "feature_layers.14._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.5511 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "feature_layers.17._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=9.7274 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "feature_layers.17._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.4490 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "classifier.0._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=10.4440 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "classifier.0._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.4703 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "Succeeded calibrating model in pyTorch!\n"
     ]
    }
   ],
   "source": [
    "## fake quantize the graph\n",
    "pass_args_mixed_precision = {\n",
    "    \"by\": \"name\",\n",
    "    \"default\": {\"config\": {\"name\": None}},\n",
    "    \"feature_layers_0\": {\n",
    "        \"config\": {\n",
    "            \"FakeQuantize\": True,\n",
    "            \"name\": \"int\",\n",
    "            \"input\": {\n",
    "                \"precesion\": 8,\n",
    "                \"calibrator\": \"max\",\n",
    "                \"quantize_axis\": None,\n",
    "            },\n",
    "            \"weight\": {\n",
    "                \"calibrator\": \"max\",\n",
    "                \"quantize_axis\": None,\n",
    "            },\n",
    "        }\n",
    "    },   \n",
    "    \"feature_layers_3\": {\n",
    "        \"config\": {\n",
    "            \"FakeQuantize\": True,\n",
    "            \"name\": \"int\",\n",
    "            \"input\": {\n",
    "                \"precesion\": 8,\n",
    "                \"calibrator\": \"max\",\n",
    "                \"quantize_axis\": None,\n",
    "            },\n",
    "            \"weight\": {\n",
    "                \"calibrator\": \"max\",\n",
    "                \"quantize_axis\": None,\n",
    "            },\n",
    "        }\n",
    "    },  \n",
    "    \"feature_layers_7\": {\n",
    "        \"config\": {\n",
    "            \"FakeQuantize\": True,\n",
    "            \"name\": \"int\",\n",
    "            \"input\": {\n",
    "                \"precesion\": 8,\n",
    "                \"calibrator\": \"max\",\n",
    "                \"quantize_axis\": None,\n",
    "            },\n",
    "            \"weight\": {\n",
    "                \"calibrator\": \"max\",\n",
    "                \"quantize_axis\": None,\n",
    "            },\n",
    "        }\n",
    "    }, \n",
    "    \"feature_layers_10\": {\n",
    "        \"config\": {\n",
    "            \"FakeQuantize\": True,\n",
    "            \"name\": \"int\",\n",
    "            \"input\": {\n",
    "                \"precesion\": 8,\n",
    "                \"calibrator\": \"max\",\n",
    "                \"quantize_axis\": None,\n",
    "            },\n",
    "            \"weight\": {\n",
    "                \"calibrator\": \"max\",\n",
    "                \"quantize_axis\": None,\n",
    "            },\n",
    "        }\n",
    "    }, \n",
    "    \"feature_layers_14\": {\n",
    "        \"config\": {\n",
    "            \"FakeQuantize\": True,\n",
    "            \"name\": \"int\",\n",
    "            \"input\": {\n",
    "                \"precesion\": 8,\n",
    "                \"calibrator\": \"max\",\n",
    "                \"quantize_axis\": None,\n",
    "            },\n",
    "            \"weight\": {\n",
    "                \"calibrator\": \"max\",\n",
    "                \"quantize_axis\": None,\n",
    "            },\n",
    "        }\n",
    "    }, \n",
    "    \"feature_layers_17\": {\n",
    "        \"config\": {\n",
    "            \"FakeQuantize\": True,\n",
    "            \"name\": \"int\",\n",
    "            \"input\": {\n",
    "                \"precesion\": 8,\n",
    "                \"calibrator\": \"max\",\n",
    "                \"quantize_axis\": None,\n",
    "            },\n",
    "            \"weight\": {\n",
    "                \"calibrator\": \"max\",\n",
    "                \"quantize_axis\": None,\n",
    "            },\n",
    "        }\n",
    "    }, \n",
    "    \"classifier_0\": {\n",
    "        \"config\": {\n",
    "            \"FakeQuantize\": True,\n",
    "            \"name\": \"int\",\n",
    "            \"input\": {\n",
    "                \"precesion\": 8,\n",
    "                \"calibrator\": \"max\",\n",
    "                \"quantize_axis\": None,\n",
    "            },\n",
    "            \"weight\": {\n",
    "                \"calibrator\": \"max\",\n",
    "                \"quantize_axis\": None,\n",
    "            },\n",
    "        }\n",
    "    },\n",
    "    # \"classifier_1\": {\n",
    "    #     \"config\": {\n",
    "    #         \"FakeQuantize\": True,\n",
    "    #         \"name\": \"int\",\n",
    "    #         \"input\": {\n",
    "    #             \"precesion\": 8,\n",
    "    #             \"calibrator\": \"histogram\",\n",
    "    #             \"quantize_axis\": None,\n",
    "    #         },\n",
    "    #         \"weight\": {\n",
    "    #             \"calibrator\": \"max\",\n",
    "    #             \"quantize_axis\": None,\n",
    "    #         },\n",
    "    #     }\n",
    "    # },\n",
    "    # \"classifier_2\": {\n",
    "    #     \"config\": {\n",
    "    #         \"FakeQuantize\": True,\n",
    "    #         \"name\": \"int\",\n",
    "    #         \"input\": {\n",
    "    #             \"precesion\": 8,\n",
    "    #             \"calibrator\": \"max\",\n",
    "    #             \"quantize_axis\": None,\n",
    "    #         },\n",
    "    #         \"weight\": {\n",
    "    #             \"calibrator\": \"max\",\n",
    "    #             \"quantize_axis\": None,\n",
    "    #         },\n",
    "    #     }\n",
    "    # },\n",
    "    # \"classifier_3\": {\n",
    "    #     \"config\": {\n",
    "    #         \"FakeQuantize\": True,\n",
    "    #         \"name\": \"int\",\n",
    "    #         \"input\": {\n",
    "    #             \"precesion\": 8,\n",
    "    #             \"calibrator\": \"max\",\n",
    "    #             \"quantize_axis\": None,\n",
    "    #         },\n",
    "    #         \"weight\": {\n",
    "    #             \"calibrator\": \"max\",\n",
    "    #             \"quantize_axis\": None,\n",
    "    #         },\n",
    "    #     }\n",
    "    # },\n",
    "}\n",
    "\n",
    "pass_args_calibrate = {\n",
    "    \"calibrator\": \"\",\n",
    "    \"percentiles\": [99],\n",
    "    \"data_module\": data_module,\n",
    "    \"num_batches\": 100,\n",
    "}\n",
    "\n",
    "\n",
    "mg = mixed_precision_transform_pass(mg, pass_args_mixed_precision, pass_args_calibrate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Event device type CUDA does not match blocking stream's device type CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# quantization aware training (QAT)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m pass_args \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m\"\u001b[39m: data_module,\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.001\u001b[39m,\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_iter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m100\u001b[39m,\n\u001b[1;32m      6\u001b[0m }\n\u001b[0;32m----> 8\u001b[0m \u001b[43mquantization_aware_training_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpass_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Work/mase/machop/chop/passes/graph/transforms/quantize_tensorRT/qat.py:199\u001b[0m, in \u001b[0;36mquantization_aware_training_pass\u001b[0;34m(graph, pass_args)\u001b[0m\n\u001b[1;32m    197\u001b[0m         y_ \u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39mmodel(xTrain)\n\u001b[1;32m    198\u001b[0m         loss \u001b[38;5;241m=\u001b[39m ceLoss(y_, yTrain)\n\u001b[0;32m--> 199\u001b[0m         \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m         opt\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSucceeded fine tuning model in pyTorch!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/mase/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mase/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Event device type CUDA does not match blocking stream's device type CPU."
     ]
    }
   ],
   "source": [
    "# quantization aware training (QAT)\n",
    "pass_args = {\n",
    "    \"dataset\": data_module,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"max_iter\": 100,\n",
    "}\n",
    "\n",
    "quantization_aware_training_pass(mg, pass_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibration\n",
    "\n",
    "After quantization the model, we need to calibrate the model and get amax to each layer. We can use the following pass_args to contral the calibration process, including the method, the number of samples, and the calibration dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average execute time for one batch: 2.83ms\n",
      "Total accuracy: 92.52%\n"
     ]
    }
   ],
   "source": [
    "pass_args_eval = {\n",
    "    \"data_module\": data_module,\n",
    "}\n",
    "\n",
    "mg = evaluate_pytorch_model_pass(mg, pass_args_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model export\n",
    "\n",
    "We first need to export the model to ONNX format, then to tensorrt engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'onnx_a_3_1.onnx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 8\u001b[0m\n\u001b[1;32m      2\u001b[0m pass_args \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monnxFile\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monnx_a_3_1.onnx\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengineFile\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengine_a_3_1.plan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataloader\u001b[39m\u001b[38;5;124m\"\u001b[39m: data_module\u001b[38;5;241m.\u001b[39mtest_dataloader,\n\u001b[1;32m      6\u001b[0m }\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# mg = fake_quantize_to_trt_pass(mg, pass_args)\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[43mtest_trt_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43monnx_a_3_1.onnx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Work/mase/machop/chop/passes/graph/transforms/quantize_tensorRT/qat.py:269\u001b[0m, in \u001b[0;36mtest_trt_engine\u001b[0;34m(engineFile, dataloader)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;124;03mThis function tests the TensorRT engine by running the model on the test dataset.\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \n\u001b[1;32m    266\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    267\u001b[0m logger \u001b[38;5;241m=\u001b[39m trt\u001b[38;5;241m.\u001b[39mLogger(trt\u001b[38;5;241m.\u001b[39mLogger\u001b[38;5;241m.\u001b[39mERROR)\n\u001b[0;32m--> 269\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mengineFile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    270\u001b[0m     engine \u001b[38;5;241m=\u001b[39m trt\u001b[38;5;241m.\u001b[39mRuntime(logger)\u001b[38;5;241m.\u001b[39mdeserialize_cuda_engine(f\u001b[38;5;241m.\u001b[39mread())\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengine.__len__() = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mlen\u001b[39m(engine))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'onnx_a_3_1.onnx'"
     ]
    }
   ],
   "source": [
    "#using tenssor quantization\n",
    "pass_args = {\n",
    "    \"onnxFile\": \"onnx_a_3_1.onnx\",\n",
    "    \"engineFile\": \"engine_a_3_1.plan\",\n",
    "    \"dataloader\": data_module.test_dataloader,\n",
    "}\n",
    "# mg = fake_quantize_to_trt_pass(mg, pass_args)\n",
    "test_trt_engine(\"onnx_a_3_1.plan\", data_module.test_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantization pass based "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n",
      "Succeeded finding ONNX file!\n",
      "Succeeded parsing .onnx file!\n",
      "Succeed finding cahce file: model_int8.INT8Cache\n",
      "Succeed finding cahce file: model_int8.INT8Cache\n",
      "Succeeded building engine!\n",
      "Succeed finding cahce file: model_int8.INT8Cache\n",
      "Succeed finding cahce file: model_int8.INT8Cache\n",
      "engine.__len__() = 2\n",
      "engine.__sizeof__() = 56\n",
      "engine.__str__() = <tensorrt_bindings.tensorrt.ICudaEngine object at 0x7f9a1d0fb530>\n",
      "\n",
      "Engine related ========================================================\n",
      "inspector.execution_context= None\n",
      "inspector.error_recorder= None\n",
      "Engine information:\n",
      "Layers:\n",
      "(Unnamed Layer* 5) [Shuffle]\n",
      "/seq_blocks.0/BatchNormalization + /seq_blocks.1/Relu\n",
      "/seq_blocks.2/Gemm\n",
      "reshape_after_/seq_blocks.2/Gemm\n",
      "PWN(/seq_blocks.3/Relu)\n",
      "\n",
      "Bindings:\n",
      "input\n",
      "output\n",
      "\n",
      "Layer information:\n",
      "(Unnamed Layer* 5) [Shuffle]\n",
      "\n",
      "/seq_blocks.0/BatchNormalization + /seq_blocks.1/Relu\n",
      "\n",
      "/seq_blocks.2/Gemm\n",
      "\n",
      "reshape_after_/seq_blocks.2/Gemm\n",
      "\n",
      "PWN(/seq_blocks.3/Relu)\n",
      "\n",
      "[ 0]Input -> DataType.FLOAT (-1, 16) (16, 16) input\n",
      "[ 1]Output-> DataType.FLOAT (-1, 5) (16, 5) output\n",
      "Succeeded running model in TensorRT!\n",
      "Average execute time for one batch: 0.02ms\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 11\u001b[0m\n\u001b[1;32m      1\u001b[0m pass_args \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint8\u001b[39m\u001b[38;5;124m'\u001b[39m,                                                     \u001b[38;5;66;03m# collect weight statistics for linear layers\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnCalibration\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m10\u001b[39m,                                                \u001b[38;5;66;03m# collect activation statistics for relu layers\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengineFile\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_int8.plan\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      9\u001b[0m }\n\u001b[1;32m     10\u001b[0m engine \u001b[38;5;241m=\u001b[39m quantize_tensorrt_transform_pass(mg, pass_args)\n\u001b[0;32m---> 11\u001b[0m \u001b[43mtest_quantize_tensorrt_transform_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpass_args\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mengineFile\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Work/mase/machop/chop/passes/graph/transforms/quantize_tensorRT/quantize_tensorrt.py:281\u001b[0m, in \u001b[0;36mtest_quantize_tensorrt_transform_pass\u001b[0;34m(dataloader, engineFile)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSucceeded running model in TensorRT!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAverage execute time for one batch: \u001b[39m\u001b[38;5;132;01m%.2f\u001b[39;00m\u001b[38;5;124mms\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28msum\u001b[39m(execute_time) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(execute_time)))\n\u001b[0;32m--> 281\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal accuracy: \u001b[39m\u001b[38;5;132;01m%.2f\u001b[39;00m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43maccuracy\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43maccuracy\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m))\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "pass_args = {\n",
    "    \"precision\": 'int8',                                                     # collect weight statistics for linear layers\n",
    "    \"nCalibration\": 10,                                                # collect activation statistics for relu layers\n",
    "    \"dummy_in\": dummy_in,\n",
    "    \"input_generator\": input_generator,                                      # the input generator for feeding data to the model\n",
    "    \"onnxFile\": 'model_int8.onnx',\n",
    "    \"cacheFile\": 'model_int8.INT8Cache',  \n",
    "    \"engineFile\": 'model_int8.plan'\n",
    "}\n",
    "engine = quantize_tensorrt_transform_pass(mg, pass_args)\n",
    "test_quantize_tensorrt_transform_pass(data_module.test_dataloader, pass_args['engineFile'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "visualize",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
