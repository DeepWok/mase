{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# TensorRT Quantization Tutorial\n",
                "\n",
                "This notebook is designed to show the features of the TensorRT passes integrated into MASE as part of the MASERT framework.\n",
                "\n",
                "## Section 1. INT8 Quantization\n",
                "Firstly, we will show you how to do a int8 quantization of a simple model, `jsc-toy`, and compare the quantized model to the original model using the `Machop API`. The quantization process is split into the following stages, each using their own individual pass, and are explained in depth at each subsection:\n",
                "\n",
                "1. [Fake quantization](#section-11-fake-quantization): `tensorrt_fake_quantize_transform_pass`\n",
                "2. [Calibration](#section-12-calibration): `tensorrt_calibrate_transform_pass`\n",
                "3. [Quantized Aware Training](#section-13-quantized-aware-training-qat): `tensorrt_fine_tune_transform_pass`\n",
                "4. [Quantization](#section-14-tensorrt-quantization): `tensorrt_engine_interface_pass`\n",
                "5. [Analysis](#section-15-performance-analysis): `tensorrt_analysis_pass`\n",
                "\n",
                "We start by loading in the required libraries and passes required for the notebook as well as ensuring the correct path is set for machop to be used."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[2024-03-28 07:10:18,870] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\u001b[32mINFO    \u001b[0m \u001b[34mSet logging level to info\u001b[0m\n",
                        "WARNING: Logging before flag parsing goes to stderr.\n",
                        "I0328 07:10:21.221665 140447335733056 logger.py:44] Set logging level to info\n"
                    ]
                }
            ],
            "source": [
                "import sys\n",
                "import os\n",
                "from pathlib import Path\n",
                "import toml\n",
                "\n",
                "# Figure out the correct path\n",
                "machop_path = Path(\".\").resolve().parent.parent.parent /\"machop\"\n",
                "assert machop_path.exists(), \"Failed to find machop at: {}\".format(machop_path)\n",
                "sys.path.append(str(machop_path))\n",
                "\n",
                "# Add directory to the PATH so that chop can be called\n",
                "new_path = \"../../../machop\"\n",
                "full_path = os.path.abspath(new_path)\n",
                "os.environ['PATH'] += os.pathsep + full_path\n",
                "\n",
                "from chop.tools.utils import to_numpy_if_tensor\n",
                "from chop.tools.logger import set_logging_verbosity\n",
                "from chop.tools import get_cf_args, get_dummy_input\n",
                "from chop.passes.graph.utils import deepcopy_mase_graph\n",
                "from chop.tools.get_input import InputGenerator\n",
                "from chop.tools.checkpoint_load import load_model\n",
                "from chop.ir import MaseGraph\n",
                "from chop.models import get_model_info, get_model, get_tokenizer\n",
                "from chop.dataset import MaseDataModule, get_dataset_info\n",
                "from chop.passes.graph.transforms import metadata_value_type_cast_transform_pass\n",
                "from chop.passes.graph import (\n",
                "    summarize_quantization_analysis_pass,\n",
                "    add_common_metadata_analysis_pass,\n",
                "    init_metadata_analysis_pass,\n",
                "    add_software_metadata_analysis_pass,\n",
                "    tensorrt_calibrate_transform_pass,\n",
                "    tensorrt_fake_quantize_transform_pass,\n",
                "    tensorrt_fine_tune_transform_pass,\n",
                "    tensorrt_engine_interface_pass,\n",
                "    runtime_analysis_pass,\n",
                "    )\n",
                "\n",
                "set_logging_verbosity(\"info\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Next, we load in the toml file used for quantization. To view the configuration, click [here](../../../machop/configs/tensorrt/jsc_toy_INT8_quantization_by_type.toml)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Path to your TOML file\n",
                "JSC_TOML_PATH = '../../../machop/configs/tensorrt/jsc_toy_INT8_quantization_by_type.toml'\n",
                "\n",
                "# Reading TOML file and converting it into a Python dictionary\n",
                "with open(JSC_TOML_PATH, 'r') as toml_file:\n",
                "    pass_args = toml.load(toml_file)\n",
                "\n",
                "# Extract the 'passes.tensorrt' section and its children\n",
                "tensorrt_config = pass_args.get('passes', {}).get('tensorrt', {})\n",
                "# Extract the 'passes.runtime_analysis' section and its children\n",
                "runtime_analysis_config = pass_args.get('passes', {}).get('runtime_analysis', {})"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We then create a `MaseGraph` by loading in a model and training it using the toml configuration model arguments."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load the basics in\n",
                "model_name = pass_args['model']\n",
                "dataset_name = pass_args['dataset']\n",
                "max_epochs = pass_args['max_epochs']\n",
                "batch_size = pass_args['batch_size']\n",
                "learning_rate = pass_args['learning_rate']\n",
                "accelerator = pass_args['accelerator']\n",
                "\n",
                "data_module = MaseDataModule(\n",
                "    name=dataset_name,\n",
                "    batch_size=batch_size,\n",
                "    model_name=model_name,\n",
                "    num_workers=0,\n",
                ")\n",
                "data_module.prepare_data()\n",
                "data_module.setup()\n",
                "\n",
                "# Add the data_module and other necessary information to the configs\n",
                "configs = [tensorrt_config, runtime_analysis_config]\n",
                "for config in configs:\n",
                "    config['task'] = pass_args['task']\n",
                "    config['dataset'] = pass_args['dataset']\n",
                "    config['batch_size'] = pass_args['batch_size']\n",
                "    config['model'] = pass_args['model']\n",
                "    config['data_module'] = data_module\n",
                "    config['accelerator'] = 'cuda' if pass_args['accelerator'] == 'gpu' else pass_args['accelerator']\n",
                "    if config['accelerator'] == 'gpu':\n",
                "        os.environ['CUDA_MODULE_LOADING'] = 'LAZY'\n",
                "\n",
                "model_info = get_model_info(model_name)\n",
                "# quant_modules.initialize()\n",
                "model = get_model(\n",
                "    model_name,\n",
                "    task=\"cls\",\n",
                "    dataset_info=data_module.dataset_info,\n",
                "    pretrained=False)\n",
                "\n",
                "\n",
                "input_generator = InputGenerator(\n",
                "    data_module=data_module,\n",
                "    model_info=model_info,\n",
                "    task=\"cls\",\n",
                "    which_dataloader=\"train\",\n",
                ")\n",
                "\n",
                "# generate the mase graph and initialize node metadata\n",
                "mg = MaseGraph(model=model)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Next, we train the `jsc-toy` model using the machop `train` action with the config from the toml file."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "# !ch train --config {JSC_TOML_PATH}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Then we load in the checkpoint. You will have to adjust this according to where it has been stored in the mase_output directory."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from ../../../mase_output/jsc-toy_cls_jsc-pre-trained/best.ckpt\u001b[0m\n",
                        "I0328 07:10:23.969384 140447335733056 checkpoint_load.py:85] Loaded pytorch lightning checkpoint from ../../../mase_output/jsc-toy_cls_jsc-pre-trained/best.ckpt\n"
                    ]
                }
            ],
            "source": [
                "# Load in the trained checkpoint - change this accordingly\n",
                "JSC_CHECKPOINT_PATH = \"../../../mase_output/jsc-toy_cls_jsc-pre-trained/best.ckpt\"\n",
                "\n",
                "model = load_model(load_name=JSC_CHECKPOINT_PATH, load_type=\"pl\", model=model)\n",
                "\n",
                "# Initiate metadata\n",
                "dummy_in = next(iter(input_generator))\n",
                "_ = model(**dummy_in)\n",
                "mg, _ = init_metadata_analysis_pass(mg, None)\n",
                "mg, _ = add_common_metadata_analysis_pass(mg, {\"dummy_in\": dummy_in})\n",
                "mg, _ = add_software_metadata_analysis_pass(mg, None)\n",
                "mg, _ = metadata_value_type_cast_transform_pass(mg, pass_args={\"fn\": to_numpy_if_tensor})\n",
                "\n",
                "# Before we begin, we will copy the original MaseGraph model to use for comparison during quantization analysis\n",
                "mg_original = deepcopy_mase_graph(mg)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Section 1.1 Fake Quantization\n",
                "\n",
                "Firstly, we fake quantize the module in order to perform calibration and fine tuning before actually quantizing - this is only used if we have int8 calibration as other precisions are not currently supported within [pytorch-quantization](https://docs.nvidia.com/deeplearning/tensorrt/pytorch-quantization-toolkit/docs/index.html#) library.\n",
                "\n",
                "This is acheived through the `tensorrt_fake_quantize_transform_pass` which goes through the model, either by type or by name, replaces each layer appropriately to a fake quantized form if the `quantize` parameter is set in the default config (`passes.tensorrt_quantize.default.config`) or on a per name or type basis. \n",
                "\n",
                "Currently the quantizable layers are:\n",
                "- Linear\n",
                "- Conv1d, Conv2d, Conv3d \n",
                "- ConvTranspose1d, ConvTranspose2d, ConvTranspose3d \n",
                "- MaxPool1d, MaxPool2d, MaxPool3d\n",
                "- AvgPool1d, AvgPool2d, AvgPool3d\n",
                "- LSTM, LSTMCell\n",
                "\n",
                "To create a custom quantized module, click [here](https://docs.nvidia.com/deeplearning/tensorrt/pytorch-quantization-toolkit/docs/index.html#document-tutorials/creating_custom_quantized_modules).\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\u001b[32mINFO    \u001b[0m \u001b[34mApplying fake quantization to PyTorch model...\u001b[0m\n",
                        "I0328 07:10:24.099733 140447335733056 utils.py:240] Applying fake quantization to PyTorch model...\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mFake quantization applied to PyTorch model.\u001b[0m\n",
                        "I0328 07:10:24.360137 140447335733056 utils.py:265] Fake quantization applied to PyTorch model.\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mQuantized graph histogram:\u001b[0m\n",
                        "I0328 07:10:24.372440 140447335733056 summary.py:84] Quantized graph histogram:\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
                        "| Original type   | OP           |   Total |   Changed |   Unchanged |\n",
                        "|-----------------+--------------+---------+-----------+-------------|\n",
                        "| BatchNorm1d     | batch_norm1d |       4 |         0 |           4 |\n",
                        "| Linear          | linear       |       3 |         3 |           0 |\n",
                        "| ReLU            | relu         |       4 |         0 |           4 |\n",
                        "| output          | output       |       1 |         0 |           1 |\n",
                        "| x               | placeholder  |       1 |         0 |           1 |\u001b[0m\n",
                        "I0328 07:10:24.374239 140447335733056 summary.py:85] \n",
                        "| Original type   | OP           |   Total |   Changed |   Unchanged |\n",
                        "|-----------------+--------------+---------+-----------+-------------|\n",
                        "| BatchNorm1d     | batch_norm1d |       4 |         0 |           4 |\n",
                        "| Linear          | linear       |       3 |         3 |           0 |\n",
                        "| ReLU            | relu         |       4 |         0 |           4 |\n",
                        "| output          | output       |       1 |         0 |           1 |\n",
                        "| x               | placeholder  |       1 |         0 |           1 |\n"
                    ]
                }
            ],
            "source": [
                "mg, _ = tensorrt_fake_quantize_transform_pass(mg, pass_args=tensorrt_config)\n",
                "summarize_quantization_analysis_pass(mg_original, mg)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "As you can see we have succesfully fake quantized all linear layers inside `jsc-toy`. This means that we will be able to simulate a quantized model in order to calibrate and fine tune it. This fake quantization was done on typewise i.e. for linear layers only. See [Section 4](#section-4-layer-wise-mixed-precision) for how to apply quantization layerwise - i.e. only first and second layers for example."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Section 1.2 Calibration\n",
                "\n",
                "Next, we perform calibration using the `tensorrt_calibrate_transform_pass`. Calibration is achieved by passing data samples to the quantizer and deciding the best amax for activations. \n",
                "\n",
                "Calibrators can be added as a search space parameter to examine the best performing calibrator. The calibrators have been included in the toml as follows.\n",
                "For example: `calibrators = [\"percentile\", \"mse\", \"entropy\"]`\n",
                "\n",
                "Note: \n",
                "- To use `percentile` calibration, a list of percentiles must be given\n",
                "- To use `max` calibration, the `histogram` weight and input calibrators must be removed and replaced with `max`. This will use global maximum absolute value to calibrate the model.\n",
                "- If `post_calibration_analysis` is set true the `tensorrt_analysis_pass` will be run for each calibrator tested to evaluate the most suitable calibrator for the model."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\u001b[32mINFO    \u001b[0m \u001b[34mStarting calibration of the model in PyTorch...\u001b[0m\n",
                        "I0328 07:10:24.383733 140447335733056 calibrate.py:142] Starting calibration of the model in PyTorch...\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
                        "I0328 07:10:24.387609 140447335733056 calibrate.py:151] Disabling Quantization and Enabling Calibration\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
                        "I0328 07:10:24.388971 140447335733056 calibrate.py:151] Disabling Quantization and Enabling Calibration\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
                        "I0328 07:10:24.390182 140447335733056 calibrate.py:151] Disabling Quantization and Enabling Calibration\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
                        "I0328 07:10:24.391498 140447335733056 calibrate.py:151] Disabling Quantization and Enabling Calibration\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
                        "I0328 07:10:24.392848 140447335733056 calibrate.py:151] Disabling Quantization and Enabling Calibration\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
                        "I0328 07:10:24.394141 140447335733056 calibrate.py:151] Disabling Quantization and Enabling Calibration\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
                        "I0328 07:10:24.560103 140447335733056 calibrate.py:171] Enabling Quantization and Disabling Calibration\n",
                        "W0328 07:10:24.561658 140447335733056 tensor_quantizer.py:174] Disable MaxCalibrator\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
                        "I0328 07:10:24.562432 140447335733056 calibrate.py:171] Enabling Quantization and Disabling Calibration\n",
                        "W0328 07:10:24.563709 140447335733056 tensor_quantizer.py:174] Disable MaxCalibrator\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
                        "I0328 07:10:24.564395 140447335733056 calibrate.py:171] Enabling Quantization and Disabling Calibration\n",
                        "W0328 07:10:24.565578 140447335733056 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
                        "I0328 07:10:24.566179 140447335733056 calibrate.py:171] Enabling Quantization and Disabling Calibration\n",
                        "W0328 07:10:24.567278 140447335733056 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
                        "I0328 07:10:24.567916 140447335733056 calibrate.py:171] Enabling Quantization and Disabling Calibration\n",
                        "W0328 07:10:24.569262 140447335733056 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
                        "I0328 07:10:24.569916 140447335733056 calibrate.py:171] Enabling Quantization and Disabling Calibration\n",
                        "W0328 07:10:24.571086 140447335733056 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
                        "W0328 07:10:24.571707 140447335733056 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "W0328 07:10:24.572395 140447335733056 tensor_quantizer.py:239] Call .cuda() if running on GPU after loading calibrated amax.\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=5.3010 calibrator=MaxCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 07:10:24.573091 140447335733056 calibrate.py:130] seq_blocks.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=5.3010 calibrator=MaxCalibrator scale=1.0 quant)\n",
                        "W0328 07:10:24.574263 140447335733056 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([8, 1]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.2._weight_quantizer          : TensorQuantizer(8bit fake axis=0 amax=[0.4018, 0.7529](8) calibrator=MaxCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 07:10:24.575459 140447335733056 calibrate.py:130] seq_blocks.2._weight_quantizer          : TensorQuantizer(8bit fake axis=0 amax=[0.4018, 0.7529](8) calibrator=MaxCalibrator scale=1.0 quant)\n",
                        "W0328 07:10:24.584795 140447335733056 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.5._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=2.4583 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 07:10:24.585740 140447335733056 calibrate.py:130] seq_blocks.5._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=2.4583 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "W0328 07:10:24.587965 140447335733056 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.5._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5621 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 07:10:24.588653 140447335733056 calibrate.py:130] seq_blocks.5._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5621 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "W0328 07:10:24.590816 140447335733056 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.8._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=1.7310 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 07:10:24.591368 140447335733056 calibrate.py:130] seq_blocks.8._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=1.7310 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "W0328 07:10:24.593429 140447335733056 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.8._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5606 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 07:10:24.594073 140447335733056 calibrate.py:130] seq_blocks.8._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5606 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mPerforming post calibration analysis for calibrator percentile_99.0...\u001b[0m\n",
                        "I0328 07:10:24.596432 140447335733056 calibrate.py:104] Performing post calibration analysis for calibrator percentile_99.0...\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on jsc-toy\u001b[0m\n",
                        "I0328 07:10:24.597545 140447335733056 runtime_analysis.py:309] Starting transformation analysis on jsc-toy\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
                        "Results jsc-toy:\n",
                        "+------------------------------+--------------+\n",
                        "|      Metric (Per Batch)      |    Value     |\n",
                        "+------------------------------+--------------+\n",
                        "|    Average Test Accuracy     |   0.71232    |\n",
                        "|      Average Precision       |   0.71349    |\n",
                        "|        Average Recall        |   0.70401    |\n",
                        "|       Average F1 Score       |   0.70544    |\n",
                        "|         Average Loss         |   0.84152    |\n",
                        "|       Average Latency        |  2.6948 ms   |\n",
                        "|   Average GPU Power Usage    |   22.998 W   |\n",
                        "| Inference Energy Consumption | 0.017215 mWh |\n",
                        "+------------------------------+--------------+\u001b[0m\n",
                        "I0328 07:10:27.723552 140447335733056 runtime_analysis.py:437] \n",
                        "Results jsc-toy:\n",
                        "+------------------------------+--------------+\n",
                        "|      Metric (Per Batch)      |    Value     |\n",
                        "+------------------------------+--------------+\n",
                        "|    Average Test Accuracy     |   0.71232    |\n",
                        "|      Average Precision       |   0.71349    |\n",
                        "|        Average Recall        |   0.70401    |\n",
                        "|       Average F1 Score       |   0.70544    |\n",
                        "|         Average Loss         |   0.84152    |\n",
                        "|       Average Latency        |  2.6948 ms   |\n",
                        "|   Average GPU Power Usage    |   22.998 W   |\n",
                        "| Inference Energy Consumption | 0.017215 mWh |\n",
                        "+------------------------------+--------------+\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /root/mase_output/tensorrt/quantization/jsc-toy_cls_jsc_2024-03-28/mase_graph/version_37/model.json\u001b[0m\n",
                        "I0328 07:10:27.725978 140447335733056 runtime_analysis.py:123] Runtime analysis results saved to /root/mase_output/tensorrt/quantization/jsc-toy_cls_jsc_2024-03-28/mase_graph/version_37/model.json\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mPost calibration analysis complete.\u001b[0m\n",
                        "I0328 07:10:27.727029 140447335733056 calibrate.py:117] Post calibration analysis complete.\n",
                        "W0328 07:10:27.728205 140447335733056 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=5.3010 calibrator=MaxCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 07:10:27.728906 140447335733056 calibrate.py:130] seq_blocks.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=5.3010 calibrator=MaxCalibrator scale=1.0 quant)\n",
                        "W0328 07:10:27.729929 140447335733056 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([8, 1]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.2._weight_quantizer          : TensorQuantizer(8bit fake axis=0 amax=[0.4018, 0.7529](8) calibrator=MaxCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 07:10:27.731426 140447335733056 calibrate.py:130] seq_blocks.2._weight_quantizer          : TensorQuantizer(8bit fake axis=0 amax=[0.4018, 0.7529](8) calibrator=MaxCalibrator scale=1.0 quant)\n",
                        "W0328 07:10:27.732776 140447335733056 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.5._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=4.0614 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 07:10:27.733406 140447335733056 calibrate.py:130] seq_blocks.5._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=4.0614 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "W0328 07:10:27.734630 140447335733056 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.5._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5621 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 07:10:27.735234 140447335733056 calibrate.py:130] seq_blocks.5._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5621 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "W0328 07:10:27.736493 140447335733056 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.8._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=2.6858 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 07:10:27.737098 140447335733056 calibrate.py:130] seq_blocks.8._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=2.6858 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "W0328 07:10:27.738309 140447335733056 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.8._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5606 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 07:10:27.738928 140447335733056 calibrate.py:130] seq_blocks.8._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5606 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mPerforming post calibration analysis for calibrator percentile_99.9...\u001b[0m\n",
                        "I0328 07:10:27.740252 140447335733056 calibrate.py:104] Performing post calibration analysis for calibrator percentile_99.9...\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on jsc-toy\u001b[0m\n",
                        "I0328 07:10:27.741091 140447335733056 runtime_analysis.py:309] Starting transformation analysis on jsc-toy\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
                        "Results jsc-toy:\n",
                        "+------------------------------+--------------+\n",
                        "|      Metric (Per Batch)      |    Value     |\n",
                        "+------------------------------+--------------+\n",
                        "| Average Validation Accuracy  |   0.71678    |\n",
                        "|      Average Precision       |   0.71959    |\n",
                        "|        Average Recall        |   0.71039    |\n",
                        "|       Average F1 Score       |   0.71209    |\n",
                        "|         Average Loss         |   0.81512    |\n",
                        "|       Average Latency        |  2.8015 ms   |\n",
                        "|   Average GPU Power Usage    |   23.099 W   |\n",
                        "| Inference Energy Consumption | 0.017976 mWh |\n",
                        "+------------------------------+--------------+\u001b[0m\n",
                        "I0328 07:10:31.086910 140447335733056 runtime_analysis.py:437] \n",
                        "Results jsc-toy:\n",
                        "+------------------------------+--------------+\n",
                        "|      Metric (Per Batch)      |    Value     |\n",
                        "+------------------------------+--------------+\n",
                        "| Average Validation Accuracy  |   0.71678    |\n",
                        "|      Average Precision       |   0.71959    |\n",
                        "|        Average Recall        |   0.71039    |\n",
                        "|       Average F1 Score       |   0.71209    |\n",
                        "|         Average Loss         |   0.81512    |\n",
                        "|       Average Latency        |  2.8015 ms   |\n",
                        "|   Average GPU Power Usage    |   23.099 W   |\n",
                        "| Inference Energy Consumption | 0.017976 mWh |\n",
                        "+------------------------------+--------------+\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /root/mase_output/tensorrt/quantization/jsc-toy_cls_jsc_2024-03-28/mase_graph/version_38/model.json\u001b[0m\n",
                        "I0328 07:10:31.089621 140447335733056 runtime_analysis.py:123] Runtime analysis results saved to /root/mase_output/tensorrt/quantization/jsc-toy_cls_jsc_2024-03-28/mase_graph/version_38/model.json\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mPost calibration analysis complete.\u001b[0m\n",
                        "I0328 07:10:31.090769 140447335733056 calibrate.py:117] Post calibration analysis complete.\n",
                        "W0328 07:10:31.091874 140447335733056 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=5.3010 calibrator=MaxCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 07:10:31.092648 140447335733056 calibrate.py:130] seq_blocks.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=5.3010 calibrator=MaxCalibrator scale=1.0 quant)\n",
                        "W0328 07:10:31.093777 140447335733056 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([8, 1]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.2._weight_quantizer          : TensorQuantizer(8bit fake axis=0 amax=[0.4018, 0.7529](8) calibrator=MaxCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 07:10:31.094864 140447335733056 calibrate.py:130] seq_blocks.2._weight_quantizer          : TensorQuantizer(8bit fake axis=0 amax=[0.4018, 0.7529](8) calibrator=MaxCalibrator scale=1.0 quant)\n",
                        "W0328 07:10:31.096890 140447335733056 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.5._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=4.9840 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 07:10:31.097617 140447335733056 calibrate.py:130] seq_blocks.5._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=4.9840 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "W0328 07:10:31.099627 140447335733056 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.5._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5621 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 07:10:31.100457 140447335733056 calibrate.py:130] seq_blocks.5._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5621 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "W0328 07:10:31.102833 140447335733056 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.8._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=3.0583 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 07:10:31.103694 140447335733056 calibrate.py:130] seq_blocks.8._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=3.0583 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "W0328 07:10:31.105296 140447335733056 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.8._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5606 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 07:10:31.106118 140447335733056 calibrate.py:130] seq_blocks.8._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5606 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mPerforming post calibration analysis for calibrator percentile_99.99...\u001b[0m\n",
                        "I0328 07:10:31.108101 140447335733056 calibrate.py:104] Performing post calibration analysis for calibrator percentile_99.99...\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on jsc-toy\u001b[0m\n",
                        "I0328 07:10:31.109150 140447335733056 runtime_analysis.py:309] Starting transformation analysis on jsc-toy\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
                        "Results jsc-toy:\n",
                        "+------------------------------+-------------+\n",
                        "|      Metric (Per Batch)      |    Value    |\n",
                        "+------------------------------+-------------+\n",
                        "| Average Validation Accuracy  |   0.71766   |\n",
                        "|      Average Precision       |   0.72036   |\n",
                        "|        Average Recall        |   0.71136   |\n",
                        "|       Average F1 Score       |   0.71308   |\n",
                        "|         Average Loss         |   0.81424   |\n",
                        "|       Average Latency        |  2.8566 ms  |\n",
                        "|   Average GPU Power Usage    |  23.049 W   |\n",
                        "| Inference Energy Consumption | 0.01829 mWh |\n",
                        "+------------------------------+-------------+\u001b[0m\n",
                        "I0328 07:10:34.488277 140447335733056 runtime_analysis.py:437] \n",
                        "Results jsc-toy:\n",
                        "+------------------------------+-------------+\n",
                        "|      Metric (Per Batch)      |    Value    |\n",
                        "+------------------------------+-------------+\n",
                        "| Average Validation Accuracy  |   0.71766   |\n",
                        "|      Average Precision       |   0.72036   |\n",
                        "|        Average Recall        |   0.71136   |\n",
                        "|       Average F1 Score       |   0.71308   |\n",
                        "|         Average Loss         |   0.81424   |\n",
                        "|       Average Latency        |  2.8566 ms  |\n",
                        "|   Average GPU Power Usage    |  23.049 W   |\n",
                        "| Inference Energy Consumption | 0.01829 mWh |\n",
                        "+------------------------------+-------------+\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /root/mase_output/tensorrt/quantization/jsc-toy_cls_jsc_2024-03-28/mase_graph/version_39/model.json\u001b[0m\n",
                        "I0328 07:10:34.491147 140447335733056 runtime_analysis.py:123] Runtime analysis results saved to /root/mase_output/tensorrt/quantization/jsc-toy_cls_jsc_2024-03-28/mase_graph/version_39/model.json\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mPost calibration analysis complete.\u001b[0m\n",
                        "I0328 07:10:34.492419 140447335733056 calibrate.py:117] Post calibration analysis complete.\n",
                        "W0328 07:10:34.493581 140447335733056 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=5.3010 calibrator=MaxCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 07:10:34.495476 140447335733056 calibrate.py:130] seq_blocks.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=5.3010 calibrator=MaxCalibrator scale=1.0 quant)\n",
                        "W0328 07:10:34.496582 140447335733056 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([8, 1]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.2._weight_quantizer          : TensorQuantizer(8bit fake axis=0 amax=[0.4018, 0.7529](8) calibrator=MaxCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 07:10:34.498093 140447335733056 calibrate.py:130] seq_blocks.2._weight_quantizer          : TensorQuantizer(8bit fake axis=0 amax=[0.4018, 0.7529](8) calibrator=MaxCalibrator scale=1.0 quant)\n",
                        "W0328 07:10:35.873021 140447335733056 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.5._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=4.9235 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 07:10:35.874269 140447335733056 calibrate.py:130] seq_blocks.5._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=4.9235 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "W0328 07:10:36.941784 140447335733056 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.5._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5601 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 07:10:36.942927 140447335733056 calibrate.py:130] seq_blocks.5._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5601 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "W0328 07:10:38.492084 140447335733056 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.8._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=3.0265 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 07:10:38.493444 140447335733056 calibrate.py:130] seq_blocks.8._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=3.0265 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "W0328 07:10:39.571171 140447335733056 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.8._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5588 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 07:10:39.572497 140447335733056 calibrate.py:130] seq_blocks.8._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5588 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mPerforming post calibration analysis for calibrator mse...\u001b[0m\n",
                        "I0328 07:10:39.574858 140447335733056 calibrate.py:104] Performing post calibration analysis for calibrator mse...\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on jsc-toy\u001b[0m\n",
                        "I0328 07:10:39.575930 140447335733056 runtime_analysis.py:309] Starting transformation analysis on jsc-toy\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
                        "Results jsc-toy:\n",
                        "+------------------------------+--------------+\n",
                        "|      Metric (Per Batch)      |    Value     |\n",
                        "+------------------------------+--------------+\n",
                        "| Average Validation Accuracy  |   0.71739    |\n",
                        "|      Average Precision       |   0.72013    |\n",
                        "|        Average Recall        |   0.71102    |\n",
                        "|       Average F1 Score       |   0.71269    |\n",
                        "|         Average Loss         |   0.81419    |\n",
                        "|       Average Latency        |  2.6877 ms   |\n",
                        "|   Average GPU Power Usage    |   23.028 W   |\n",
                        "| Inference Energy Consumption | 0.017192 mWh |\n",
                        "+------------------------------+--------------+\u001b[0m\n",
                        "I0328 07:10:42.651890 140447335733056 runtime_analysis.py:437] \n",
                        "Results jsc-toy:\n",
                        "+------------------------------+--------------+\n",
                        "|      Metric (Per Batch)      |    Value     |\n",
                        "+------------------------------+--------------+\n",
                        "| Average Validation Accuracy  |   0.71739    |\n",
                        "|      Average Precision       |   0.72013    |\n",
                        "|        Average Recall        |   0.71102    |\n",
                        "|       Average F1 Score       |   0.71269    |\n",
                        "|         Average Loss         |   0.81419    |\n",
                        "|       Average Latency        |  2.6877 ms   |\n",
                        "|   Average GPU Power Usage    |   23.028 W   |\n",
                        "| Inference Energy Consumption | 0.017192 mWh |\n",
                        "+------------------------------+--------------+\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /root/mase_output/tensorrt/quantization/jsc-toy_cls_jsc_2024-03-28/mase_graph/version_40/model.json\u001b[0m\n",
                        "I0328 07:10:42.654335 140447335733056 runtime_analysis.py:123] Runtime analysis results saved to /root/mase_output/tensorrt/quantization/jsc-toy_cls_jsc_2024-03-28/mase_graph/version_40/model.json\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mPost calibration analysis complete.\u001b[0m\n",
                        "I0328 07:10:42.655249 140447335733056 calibrate.py:117] Post calibration analysis complete.\n",
                        "W0328 07:10:42.656156 140447335733056 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=5.3010 calibrator=MaxCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 07:10:42.657255 140447335733056 calibrate.py:130] seq_blocks.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=5.3010 calibrator=MaxCalibrator scale=1.0 quant)\n",
                        "W0328 07:10:42.658146 140447335733056 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([8, 1]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.2._weight_quantizer          : TensorQuantizer(8bit fake axis=0 amax=[0.4018, 0.7529](8) calibrator=MaxCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 07:10:42.659076 140447335733056 calibrate.py:130] seq_blocks.2._weight_quantizer          : TensorQuantizer(8bit fake axis=0 amax=[0.4018, 0.7529](8) calibrator=MaxCalibrator scale=1.0 quant)\n",
                        "W0328 07:10:46.357601 140447335733056 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.5._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=4.7816 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 07:10:46.358672 140447335733056 calibrate.py:130] seq_blocks.5._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=4.7816 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "W0328 07:10:48.450974 140447335733056 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.5._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5624 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 07:10:48.452098 140447335733056 calibrate.py:130] seq_blocks.5._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5624 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "W0328 07:10:53.517924 140447335733056 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.8._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=3.0593 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 07:10:53.518944 140447335733056 calibrate.py:130] seq_blocks.8._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=3.0593 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "W0328 07:10:55.558441 140447335733056 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.8._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5609 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 07:10:55.559624 140447335733056 calibrate.py:130] seq_blocks.8._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5609 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mPerforming post calibration analysis for calibrator entropy...\u001b[0m\n",
                        "I0328 07:10:55.561555 140447335733056 calibrate.py:104] Performing post calibration analysis for calibrator entropy...\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on jsc-toy\u001b[0m\n",
                        "I0328 07:10:55.562688 140447335733056 runtime_analysis.py:309] Starting transformation analysis on jsc-toy\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
                        "Results jsc-toy:\n",
                        "+------------------------------+--------------+\n",
                        "|      Metric (Per Batch)      |    Value     |\n",
                        "+------------------------------+--------------+\n",
                        "| Average Validation Accuracy  |   0.71737    |\n",
                        "|      Average Precision       |   0.72008    |\n",
                        "|        Average Recall        |   0.71095    |\n",
                        "|       Average F1 Score       |   0.71263    |\n",
                        "|         Average Loss         |   0.81421    |\n",
                        "|       Average Latency        |  2.6637 ms   |\n",
                        "|   Average GPU Power Usage    |   22.922 W   |\n",
                        "| Inference Energy Consumption | 0.016961 mWh |\n",
                        "+------------------------------+--------------+\u001b[0m\n",
                        "I0328 07:10:58.628575 140447335733056 runtime_analysis.py:437] \n",
                        "Results jsc-toy:\n",
                        "+------------------------------+--------------+\n",
                        "|      Metric (Per Batch)      |    Value     |\n",
                        "+------------------------------+--------------+\n",
                        "| Average Validation Accuracy  |   0.71737    |\n",
                        "|      Average Precision       |   0.72008    |\n",
                        "|        Average Recall        |   0.71095    |\n",
                        "|       Average F1 Score       |   0.71263    |\n",
                        "|         Average Loss         |   0.81421    |\n",
                        "|       Average Latency        |  2.6637 ms   |\n",
                        "|   Average GPU Power Usage    |   22.922 W   |\n",
                        "| Inference Energy Consumption | 0.016961 mWh |\n",
                        "+------------------------------+--------------+\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /root/mase_output/tensorrt/quantization/jsc-toy_cls_jsc_2024-03-28/mase_graph/version_41/model.json\u001b[0m\n",
                        "I0328 07:10:58.631345 140447335733056 runtime_analysis.py:123] Runtime analysis results saved to /root/mase_output/tensorrt/quantization/jsc-toy_cls_jsc_2024-03-28/mase_graph/version_41/model.json\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mPost calibration analysis complete.\u001b[0m\n",
                        "I0328 07:10:58.632577 140447335733056 calibrate.py:117] Post calibration analysis complete.\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mSucceeded in calibrating the model in PyTorch!\u001b[0m\n",
                        "I0328 07:10:58.633719 140447335733056 calibrate.py:209] Succeeded in calibrating the model in PyTorch!\n"
                    ]
                }
            ],
            "source": [
                "mg, _ = tensorrt_calibrate_transform_pass(mg, pass_args=tensorrt_config)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "From the results, the 99% `percentile` clips too many values during the amax calibration, compromising the loss. However 99.99% demonstrates higher validation accuracy alongside `mse` and `entropy` for `jsc-toy`. For such a small model, the methods are not highly distinguished, however for larger models this calibration process will be important for ensuring the quantized model still performs well. "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Section 1.3 Quantized Aware Training (QAT)\n",
                "\n",
                "The `tensorrt_fine_tune_transform_pass` is used to fine tune the quantized model. \n",
                "\n",
                "For QAT it is typical to employ 10% of the original training epochs, starting at 1% of the initial training learning rate, and a cosine annealing learning rate schedule that follows the decreasing half of a cosine period, down to 1% of the initial fine tuning learning rate (0.01% of the initial training learning rate). However this default can be overidden by setting the `epochs`, `initial_learning_rate` and `final_learning_rate` in `passes.tensorrt_quantize.fine_tune`.\n",
                "\n",
                "The fine tuned checkpoints are stored in the ckpts/fine_tuning folder:\n",
                "\n",
                "```\n",
                "mase_output\n",
                "└── tensorrt\n",
                "    └── quantization\n",
                "        └──model_task_dataset_date\n",
                "            ├── cache\n",
                "            ├── ckpts\n",
                "            │   └── fine_tuning\n",
                "            ├── json\n",
                "            ├── onnx\n",
                "            └── trt\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "# mg, _ = tensorrt_fine_tune_transform_pass(mg, pass_args=tensorrt_config)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Section 1.4 TensorRT Quantization\n",
                "\n",
                "After QAT, we are now ready to convert the model to a tensorRT engine so that it can be run with the superior inference speeds. To do so, we use the `tensorrt_engine_interface_pass` which converts the `MaseGraph`'s model from a Pytorch one to an ONNX format as an intermediate stage of the conversion.\n",
                "\n",
                "During the conversion process, the `.onnx` and `.trt` files are stored to their respective folders shown in [Section 1.3](#section-13-quantized-aware-training-qat).\n",
                "\n",
                "This interface pass returns a dictionary containing the `onnx_path` and `trt_engine_path`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
                        "I0328 07:10:58.712838 140447335733056 quantize.py:159] Converting PyTorch model to ONNX...\n",
                        "/root/anaconda3/envs/mase/lib/python3.11/site-packages/pytorch_quantization/tensor_quant.py:363: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
                        "  if min_amax < 0:\n",
                        "/root/anaconda3/envs/mase/lib/python3.11/site-packages/pytorch_quantization/tensor_quant.py:366: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
                        "  max_bound = torch.tensor((2.0**(num_bits - 1 + int(unsigned))) - 1.0, device=amax.device)\n",
                        "/root/anaconda3/envs/mase/lib/python3.11/site-packages/pytorch_quantization/tensor_quant.py:376: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
                        "  if min_amax <= epsilon:  # Treat amax smaller than minimum representable of fp16 0\n",
                        "/root/anaconda3/envs/mase/lib/python3.11/site-packages/pytorch_quantization/tensor_quant.py:382: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
                        "  if min_amax <= epsilon:\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /root/mase/mase_output/tensorrt/quantization/onnx/2024-03-28/version_4/model.onnx\u001b[0m\n",
                        "I0328 07:10:58.928578 140447335733056 quantize.py:182] ONNX Conversion Complete. Stored ONNX model to /root/mase/mase_output/tensorrt/quantization/onnx/2024-03-28/version_4/model.onnx\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
                        "I0328 07:10:58.930228 140447335733056 quantize.py:85] Converting PyTorch model to TensorRT...\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /root/mase/mase_output/tensorrt/quantization/trt/2024-03-28/version_2/model.trt\u001b[0m\n",
                        "I0328 07:11:51.045901 140447335733056 quantize.py:154] TensorRT Conversion Complete. Stored trt model to /root/mase/mase_output/tensorrt/quantization/trt/2024-03-28/version_2/model.trt\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /root/mase/mase_output/tensorrt/quantization/json/2024-03-28/version_2/model.json\u001b[0m\n",
                        "I0328 07:11:51.284646 140447335733056 quantize.py:198] TensorRT Model Summary Exported to /root/mase/mase_output/tensorrt/quantization/json/2024-03-28/version_2/model.json\n"
                    ]
                }
            ],
            "source": [
                "mg, meta = tensorrt_engine_interface_pass(mg, pass_args=tensorrt_config)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Section 1.5 Performance Analysis\n",
                "\n",
                "To showcase the improved inference speeds and to evaluate accuracy and other performance metrics, the `tensorrt_analysis_pass` can be used.\n",
                "\n",
                "The tensorRT engine path obtained the previous interface pass is now inputted into the the analysis pass. The same pass can take a MaseGraph as an input, as well as an ONNX graph. For this comparison, we will first run the anaylsis pass on the original unquantized model and then on the int8 quantized model."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on jsc-toy\u001b[0m\n",
                        "I0328 07:11:53.804656 140447335733056 runtime_analysis.py:309] Starting transformation analysis on jsc-toy\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
                        "Results jsc-toy:\n",
                        "+------------------------------+--------------+\n",
                        "|      Metric (Per Batch)      |    Value     |\n",
                        "+------------------------------+--------------+\n",
                        "|    Average Test Accuracy     |   0.71971    |\n",
                        "|      Average Precision       |   0.71884    |\n",
                        "|        Average Recall        |   0.71127    |\n",
                        "|       Average F1 Score       |   0.71274    |\n",
                        "|         Average Loss         |    0.8116    |\n",
                        "|       Average Latency        |  1.5855 ms   |\n",
                        "|   Average GPU Power Usage    |   22.883 W   |\n",
                        "| Inference Energy Consumption | 0.010078 mWh |\n",
                        "+------------------------------+--------------+\u001b[0m\n",
                        "I0328 07:11:59.751923 140447335733056 runtime_analysis.py:437] \n",
                        "Results jsc-toy:\n",
                        "+------------------------------+--------------+\n",
                        "|      Metric (Per Batch)      |    Value     |\n",
                        "+------------------------------+--------------+\n",
                        "|    Average Test Accuracy     |   0.71971    |\n",
                        "|      Average Precision       |   0.71884    |\n",
                        "|        Average Recall        |   0.71127    |\n",
                        "|       Average F1 Score       |   0.71274    |\n",
                        "|         Average Loss         |    0.8116    |\n",
                        "|       Average Latency        |  1.5855 ms   |\n",
                        "|   Average GPU Power Usage    |   22.883 W   |\n",
                        "| Inference Energy Consumption | 0.010078 mWh |\n",
                        "+------------------------------+--------------+\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /root/mase_output/tensorrt/quantization/jsc-toy_cls_jsc_2024-03-28/mase_graph/version_42/model.json\u001b[0m\n",
                        "I0328 07:11:59.755820 140447335733056 runtime_analysis.py:123] Runtime analysis results saved to /root/mase_output/tensorrt/quantization/jsc-toy_cls_jsc_2024-03-28/mase_graph/version_42/model.json\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
                        "TensorRT Engine Input/Output Information:\n",
                        "Index | Type    | DataType | Static Shape         | Dynamic Shape        | Name\n",
                        "------|---------|----------|----------------------|----------------------|-----------------------\n",
                        "0     | Input   | FLOAT    | (64, 16)               | (64, 16)               | input\n",
                        "1     | Output  | FLOAT    | (64, 5)                | (64, 5)                | 109\u001b[0m\n",
                        "I0328 07:11:59.774097 140447335733056 runtime_analysis.py:167] \n",
                        "TensorRT Engine Input/Output Information:\n",
                        "Index | Type    | DataType | Static Shape         | Dynamic Shape        | Name\n",
                        "------|---------|----------|----------------------|----------------------|-----------------------\n",
                        "0     | Input   | FLOAT    | (64, 16)               | (64, 16)               | input\n",
                        "1     | Output  | FLOAT    | (64, 5)                | (64, 5)                | 109\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on jsc-toy-trt_quantized\u001b[0m\n",
                        "I0328 07:11:59.775382 140447335733056 runtime_analysis.py:309] Starting transformation analysis on jsc-toy-trt_quantized\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
                        "Results jsc-toy-trt_quantized:\n",
                        "+------------------------------+---------------+\n",
                        "|      Metric (Per Batch)      |     Value     |\n",
                        "+------------------------------+---------------+\n",
                        "|    Average Test Accuracy     |    0.73413    |\n",
                        "|      Average Precision       |    0.74291    |\n",
                        "|        Average Recall        |    0.73314    |\n",
                        "|       Average F1 Score       |    0.73549    |\n",
                        "|         Average Loss         |    0.75526    |\n",
                        "|       Average Latency        |  0.24262 ms   |\n",
                        "|   Average GPU Power Usage    |   22.861 W    |\n",
                        "| Inference Energy Consumption | 0.0015407 mWh |\n",
                        "+------------------------------+---------------+\u001b[0m\n",
                        "I0328 07:12:04.846008 140447335733056 runtime_analysis.py:437] \n",
                        "Results jsc-toy-trt_quantized:\n",
                        "+------------------------------+---------------+\n",
                        "|      Metric (Per Batch)      |     Value     |\n",
                        "+------------------------------+---------------+\n",
                        "|    Average Test Accuracy     |    0.73413    |\n",
                        "|      Average Precision       |    0.74291    |\n",
                        "|        Average Recall        |    0.73314    |\n",
                        "|       Average F1 Score       |    0.73549    |\n",
                        "|         Average Loss         |    0.75526    |\n",
                        "|       Average Latency        |  0.24262 ms   |\n",
                        "|   Average GPU Power Usage    |   22.861 W    |\n",
                        "| Inference Energy Consumption | 0.0015407 mWh |\n",
                        "+------------------------------+---------------+\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /root/mase_output/tensorrt/quantization/jsc-toy_cls_jsc_2024-03-28/tensorrt/version_0/model.json\u001b[0m\n",
                        "I0328 07:12:04.850239 140447335733056 runtime_analysis.py:123] Runtime analysis results saved to /root/mase_output/tensorrt/quantization/jsc-toy_cls_jsc_2024-03-28/tensorrt/version_0/model.json\n"
                    ]
                }
            ],
            "source": [
                "_, _ = runtime_analysis_pass(mg_original, pass_args=runtime_analysis_config)\n",
                "_, _ = runtime_analysis_pass(meta['trt_engine_path'], pass_args=runtime_analysis_config)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "As shown above, the latency has decreased around 6x with the `jsc-toy` model without compromising accuracy due to the well calibrated amax and quantization-aware fine tuning and additional runtime optimizations from TensorRT. The inference energy consumption has thus also dropped tremendously and this is an excellent demonstration for the need to quantize in industry especially for LLMs in order to reduce energy usage. \n",
                "\n",
                "## Section 2. FP16 Quantization\n",
                "\n",
                "We will now load in a new toml configuration that uses fp16 instead of int8, whilst keeping the other settings the exact same for a fair comparison. This time however, we will use chop from the terminal which runs all the passes showcased in [Section 1](#section-1---int8-quantization).\n",
                "\n",
                "Since float quantization does not require calibration, nor is it supported by `pytorch-quantization`, the model will not undergo fake quantization; for the time being this unfortunately means QAT is unavailable and only undergoes Post Training Quantization (PTQ). "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "8808.24s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
                        "[2024-03-28 09:37:03,989] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
                        "INFO: Seed set to 0\n",
                        "WARNING: Logging before flag parsing goes to stderr.\n",
                        "I0328 09:37:06.938809 140201001654080 seed.py:54] Seed set to 0\n",
                        "+-------------------------+------------------------+--------------------------+--------------------------+--------------------------+\n",
                        "| Name                    |        Default         |       Config. File       |     Manual Override      |        Effective         |\n",
                        "+-------------------------+------------------------+--------------------------+--------------------------+--------------------------+\n",
                        "| task                    |     \u001b[38;5;8mclassification\u001b[0m     |           cls            |                          |           cls            |\n",
                        "| load_name               |          \u001b[38;5;8mNone\u001b[0m          | \u001b[38;5;8m../mase_output/jsc-toy_c\u001b[0m | /root/mase/mase_output/j | /root/mase/mase_output/j |\n",
                        "|                         |                        | \u001b[38;5;8mls_jsc/software/training\u001b[0m |   sc-toy_cls_jsc-pre-    |   sc-toy_cls_jsc-pre-    |\n",
                        "|                         |                        |     \u001b[38;5;8m_ckpts/best.ckpt\u001b[0m     |    trained/best.ckpt     |    trained/best.ckpt     |\n",
                        "| load_type               |           \u001b[38;5;8mmz\u001b[0m           |            \u001b[38;5;8mpl\u001b[0m            |            pl            |            pl            |\n",
                        "| batch_size              |          \u001b[38;5;8m128\u001b[0m           |            64            |                          |            64            |\n",
                        "| to_debug                |         False          |                          |                          |          False           |\n",
                        "| log_level               |          info          |                          |                          |           info           |\n",
                        "| report_to               |      tensorboard       |                          |                          |       tensorboard        |\n",
                        "| seed                    |           0            |                          |                          |            0             |\n",
                        "| quant_config            |          None          |                          |                          |           None           |\n",
                        "| training_optimizer      |          adam          |                          |                          |           adam           |\n",
                        "| trainer_precision       |        16-mixed        |                          |                          |         16-mixed         |\n",
                        "| learning_rate           |         \u001b[38;5;8m1e-05\u001b[0m          |          0.001           |                          |          0.001           |\n",
                        "| weight_decay            |           0            |                          |                          |            0             |\n",
                        "| max_epochs              |           \u001b[38;5;8m20\u001b[0m           |            10            |                          |            10            |\n",
                        "| max_steps               |           -1           |                          |                          |            -1            |\n",
                        "| accumulate_grad_batches |           1            |                          |                          |            1             |\n",
                        "| log_every_n_steps       |           50           |                          |                          |            50            |\n",
                        "| num_workers             |           28           |                          |                          |            28            |\n",
                        "| num_devices             |           1            |                          |                          |            1             |\n",
                        "| num_nodes               |           1            |                          |                          |            1             |\n",
                        "| accelerator             |          \u001b[38;5;8mauto\u001b[0m          |           gpu            |                          |           gpu            |\n",
                        "| strategy                |          auto          |                          |                          |           auto           |\n",
                        "| is_to_auto_requeue      |         False          |                          |                          |          False           |\n",
                        "| github_ci               |         False          |                          |                          |          False           |\n",
                        "| disable_dataset_cache   |         False          |                          |                          |          False           |\n",
                        "| target                  |  xcu250-figd2104-2L-e  |                          |                          |   xcu250-figd2104-2L-e   |\n",
                        "| num_targets             |          100           |                          |                          |           100            |\n",
                        "| is_pretrained           |         False          |                          |                          |          False           |\n",
                        "| max_token_len           |          512           |                          |                          |           512            |\n",
                        "| project_dir             | /root/mase/mase_output |                          |                          |  /root/mase/mase_output  |\n",
                        "| project                 |          None          |                          |                          |           None           |\n",
                        "| model                   |          \u001b[38;5;8mNone\u001b[0m          |         jsc-toy          |                          |         jsc-toy          |\n",
                        "| dataset                 |          \u001b[38;5;8mNone\u001b[0m          |           jsc            |                          |           jsc            |\n",
                        "| t_max                   |           20           |                          |                          |            20            |\n",
                        "| eta_min                 |         1e-06          |                          |                          |          1e-06           |\n",
                        "+-------------------------+------------------------+--------------------------+--------------------------+--------------------------+\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mInitialising model 'jsc-toy'...\u001b[0m\n",
                        "I0328 09:37:06.948820 140201001654080 cli.py:841] Initialising model 'jsc-toy'...\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mInitialising dataset 'jsc'...\u001b[0m\n",
                        "I0328 09:37:06.950793 140201001654080 cli.py:869] Initialising dataset 'jsc'...\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mProject will be created at /root/mase/mase_output/jsc-toy_cls_jsc_2024-03-28\u001b[0m\n",
                        "I0328 09:37:06.951038 140201001654080 cli.py:905] Project will be created at /root/mase/mase_output/jsc-toy_cls_jsc_2024-03-28\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mTransforming model 'jsc-toy'...\u001b[0m\n",
                        "I0328 09:37:07.078488 140201001654080 cli.py:365] Transforming model 'jsc-toy'...\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from /root/mase/mase_output/jsc-toy_cls_jsc-pre-trained/best.ckpt\u001b[0m\n",
                        "I0328 09:37:09.420990 140201001654080 checkpoint_load.py:85] Loaded pytorch lightning checkpoint from /root/mase/mase_output/jsc-toy_cls_jsc-pre-trained/best.ckpt\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mApplying fake quantization to PyTorch model...\u001b[0m\n",
                        "I0328 09:37:11.531935 140201001654080 utils.py:240] Applying fake quantization to PyTorch model...\n",
                        "\u001b[33mWARNING \u001b[0m \u001b[34mint8 precision not found in config. Skipping fake quantization.\u001b[0m\n",
                        "W0328 09:37:11.532341 140201001654080 utils.py:243] int8 precision not found in config. Skipping fake quantization.\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mQuantized graph histogram:\u001b[0m\n",
                        "I0328 09:37:11.550864 140201001654080 summary.py:84] Quantized graph histogram:\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
                        "| Original type   | OP           |   Total |   Changed |   Unchanged |\n",
                        "|-----------------+--------------+---------+-----------+-------------|\n",
                        "| BatchNorm1d     | batch_norm1d |       4 |         0 |           4 |\n",
                        "| Linear          | linear       |       3 |         0 |           3 |\n",
                        "| ReLU            | relu         |       4 |         0 |           4 |\n",
                        "| output          | output       |       1 |         0 |           1 |\n",
                        "| x               | placeholder  |       1 |         0 |           1 |\u001b[0m\n",
                        "I0328 09:37:11.551648 140201001654080 summary.py:85] \n",
                        "| Original type   | OP           |   Total |   Changed |   Unchanged |\n",
                        "|-----------------+--------------+---------+-----------+-------------|\n",
                        "| BatchNorm1d     | batch_norm1d |       4 |         0 |           4 |\n",
                        "| Linear          | linear       |       3 |         0 |           3 |\n",
                        "| ReLU            | relu         |       4 |         0 |           4 |\n",
                        "| output          | output       |       1 |         0 |           1 |\n",
                        "| x               | placeholder  |       1 |         0 |           1 |\n",
                        "\u001b[33mWARNING \u001b[0m \u001b[34mint8 precision not found in config. Skipping calibration.\u001b[0m\n",
                        "W0328 09:37:11.552517 140201001654080 calibrate.py:137] int8 precision not found in config. Skipping calibration.\n",
                        "\u001b[33mWARNING \u001b[0m \u001b[34mint8 precision not found in config. Skipping QAT fine tuning.\u001b[0m\n",
                        "W0328 09:37:11.553805 140201001654080 fine_tune.py:92] int8 precision not found in config. Skipping QAT fine tuning.\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
                        "I0328 09:37:11.556088 140201001654080 quantize.py:171] Converting PyTorch model to ONNX...\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /root/mase/mase_output/tensorrt/quantization/jsc-toy_cls_jsc_2024-03-28/2024-03-28/version_1/model.onnx\u001b[0m\n",
                        "I0328 09:37:13.650603 140201001654080 quantize.py:194] ONNX Conversion Complete. Stored ONNX model to /root/mase/mase_output/tensorrt/quantization/jsc-toy_cls_jsc_2024-03-28/2024-03-28/version_1/model.onnx\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
                        "I0328 09:37:13.651079 140201001654080 quantize.py:97] Converting PyTorch model to TensorRT...\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /root/mase/mase_output/tensorrt/quantization/jsc-toy_cls_jsc_2024-03-28/2024-03-28/version_2/model.trt\u001b[0m\n",
                        "I0328 09:37:30.438357 140201001654080 quantize.py:166] TensorRT Conversion Complete. Stored trt model to /root/mase/mase_output/tensorrt/quantization/jsc-toy_cls_jsc_2024-03-28/2024-03-28/version_2/model.trt\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /root/mase/mase_output/tensorrt/quantization/jsc-toy_cls_jsc_2024-03-28/2024-03-28/version_3/model.json\u001b[0m\n",
                        "I0328 09:37:30.664676 140201001654080 quantize.py:210] TensorRT Model Summary Exported to /root/mase/mase_output/tensorrt/quantization/jsc-toy_cls_jsc_2024-03-28/2024-03-28/version_3/model.json\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on jsc-toy\u001b[0m\n",
                        "I0328 09:37:30.666585 140201001654080 runtime_analysis.py:309] Starting transformation analysis on jsc-toy\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
                        "Results jsc-toy:\n",
                        "+------------------------------+---------------+\n",
                        "|      Metric (Per Batch)      |     Value     |\n",
                        "+------------------------------+---------------+\n",
                        "|    Average Test Accuracy     |    0.71971    |\n",
                        "|      Average Precision       |    0.71884    |\n",
                        "|        Average Recall        |    0.71127    |\n",
                        "|       Average F1 Score       |    0.71274    |\n",
                        "|         Average Loss         |    0.8116     |\n",
                        "|       Average Latency        |  0.80336 ms   |\n",
                        "|   Average GPU Power Usage    |   22.024 W    |\n",
                        "| Inference Energy Consumption | 0.0049148 mWh |\n",
                        "+------------------------------+---------------+\u001b[0m\n",
                        "I0328 09:37:36.951404 140201001654080 runtime_analysis.py:437] \n",
                        "Results jsc-toy:\n",
                        "+------------------------------+---------------+\n",
                        "|      Metric (Per Batch)      |     Value     |\n",
                        "+------------------------------+---------------+\n",
                        "|    Average Test Accuracy     |    0.71971    |\n",
                        "|      Average Precision       |    0.71884    |\n",
                        "|        Average Recall        |    0.71127    |\n",
                        "|       Average F1 Score       |    0.71274    |\n",
                        "|         Average Loss         |    0.8116     |\n",
                        "|       Average Latency        |  0.80336 ms   |\n",
                        "|   Average GPU Power Usage    |   22.024 W    |\n",
                        "| Inference Energy Consumption | 0.0049148 mWh |\n",
                        "+------------------------------+---------------+\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /root/mase_output/tensorrt/quantization/jsc-toy_cls_jsc_2024-03-28/mase_graph/version_43/model.json\u001b[0m\n",
                        "I0328 09:37:36.952783 140201001654080 runtime_analysis.py:123] Runtime analysis results saved to /root/mase_output/tensorrt/quantization/jsc-toy_cls_jsc_2024-03-28/mase_graph/version_43/model.json\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
                        "TensorRT Engine Input/Output Information:\n",
                        "Index | Type    | DataType | Static Shape         | Dynamic Shape        | Name\n",
                        "------|---------|----------|----------------------|----------------------|-----------------------\n",
                        "0     | Input   | FLOAT    | (64, 16)               | (64, 16)               | input\n",
                        "1     | Output  | FLOAT    | (64, 5)                | (64, 5)                | 37\u001b[0m\n",
                        "I0328 09:37:36.960667 140201001654080 runtime_analysis.py:167] \n",
                        "TensorRT Engine Input/Output Information:\n",
                        "Index | Type    | DataType | Static Shape         | Dynamic Shape        | Name\n",
                        "------|---------|----------|----------------------|----------------------|-----------------------\n",
                        "0     | Input   | FLOAT    | (64, 16)               | (64, 16)               | input\n",
                        "1     | Output  | FLOAT    | (64, 5)                | (64, 5)                | 37\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on jsc-toy-trt_quantized\u001b[0m\n",
                        "I0328 09:37:36.960840 140201001654080 runtime_analysis.py:309] Starting transformation analysis on jsc-toy-trt_quantized\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
                        "Results jsc-toy-trt_quantized:\n",
                        "+------------------------------+----------------+\n",
                        "|      Metric (Per Batch)      |     Value      |\n",
                        "+------------------------------+----------------+\n",
                        "|    Average Test Accuracy     |    0.73639     |\n",
                        "|      Average Precision       |    0.74849     |\n",
                        "|        Average Recall        |    0.73504     |\n",
                        "|       Average F1 Score       |    0.73822     |\n",
                        "|         Average Loss         |    0.74597     |\n",
                        "|       Average Latency        |   0.09133 ms   |\n",
                        "|   Average GPU Power Usage    |    21.706 W    |\n",
                        "| Inference Energy Consumption | 0.00055067 mWh |\n",
                        "+------------------------------+----------------+\u001b[0m\n",
                        "I0328 09:37:43.052305 140201001654080 runtime_analysis.py:437] \n",
                        "Results jsc-toy-trt_quantized:\n",
                        "+------------------------------+----------------+\n",
                        "|      Metric (Per Batch)      |     Value      |\n",
                        "+------------------------------+----------------+\n",
                        "|    Average Test Accuracy     |    0.73639     |\n",
                        "|      Average Precision       |    0.74849     |\n",
                        "|        Average Recall        |    0.73504     |\n",
                        "|       Average F1 Score       |    0.73822     |\n",
                        "|         Average Loss         |    0.74597     |\n",
                        "|       Average Latency        |   0.09133 ms   |\n",
                        "|   Average GPU Power Usage    |    21.706 W    |\n",
                        "| Inference Energy Consumption | 0.00055067 mWh |\n",
                        "+------------------------------+----------------+\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /root/mase_output/tensorrt/quantization/jsc-toy_cls_jsc_2024-03-28/tensorrt/version_1/model.json\u001b[0m\n",
                        "I0328 09:37:43.054715 140201001654080 runtime_analysis.py:123] Runtime analysis results saved to /root/mase_output/tensorrt/quantization/jsc-toy_cls_jsc_2024-03-28/tensorrt/version_1/model.json\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mSaved mase graph to /root/mase/mase_output/jsc-toy_cls_jsc_2024-03-28/software/transform/transformed_ckpt\u001b[0m\n",
                        "I0328 09:37:43.132117 140201001654080 save_and_load.py:147] Saved mase graph to /root/mase/mase_output/jsc-toy_cls_jsc_2024-03-28/software/transform/transformed_ckpt\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mTransformation is completed\u001b[0m\n",
                        "I0328 09:37:43.132461 140201001654080 cli.py:383] Transformation is completed\n"
                    ]
                }
            ],
            "source": [
                "JSC_FP16_BY_TYPE_TOML = \"../../../machop/configs/tensorrt/jsc_toy_FP16_quantization_by_type.toml\"\n",
                "!ch transform --config {JSC_FP16_BY_TYPE_TOML} --load {JSC_CHECKPOINT_PATH} --load-type pl"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "As you can see, `fp16` acheives a slighty higher test accuracy but a slightly lower latency (~30%) from that of int8 quantization; it is still ~2.5x faster than the unquantized model. Now lets apply quantization to a more complicated model.\n",
                "\n",
                "## Section 3. Type-wise Mixed Precision on Larger Model\n",
                "We will now quantize `vgg7` which includes both convolutional and linear layers, however for this demonstration we want to quantize all layer types except the linear layers.\n",
                "\n",
                "In this case, we set:\n",
                "\n",
                "- The `by` parameter to `type`\n",
                "- The `quantize` parameter to true for `passes.tensorrt_quantize.conv2d.config` and `precision` parameter to 'int8'.\n",
                "- The `input` and `weight` quantize axis for the conv2d layers.\n",
                "- The default `passes.tensorrt_quantize.default.config` precision to true. \n",
                "\n",
                "During the TensorRT quantization, the model's conv2d layers will be converted to an int8 fake quantized form, whilst the linear layers are kept to their default 'fp16'. Calibration of the conv2d layers and then fine tuning will be undergone before quantization and inference.\n",
                "\n",
                "You may either download a pretrained model [here](https://imperiallondon-my.sharepoint.com/:f:/g/personal/zz7522_ic_ac_uk/Emh3VT7Q_qRFmnp8kDrcgDoBwGUuzLwwKNtX8ZAt368jJQ?e=gsKONa), otherwise train it yourself as shown below. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "VGG_TYPEWISE_TOML = \"../../../machop/configs/tensorrt/vgg7_typewise_mixed_precision.toml\"\n",
                "\n",
                "!ch train --config {VGG_TYPEWISE_TOML}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We will now load the checkpoint in, quantize the model and compare it to the unquantized version as we did in [Section 1.5](#section-15-performance-analysis)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Change this checkpoint path accordingly\n",
                "VGG_CHECKPOINT_PATH = \"../../../mase_output/vgg7-pre-trained/test-accu-0.9332.ckpt\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[2024-03-28 09:46:54,374] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
                        "INFO: Seed set to 0\n",
                        "WARNING: Logging before flag parsing goes to stderr.\n",
                        "I0328 09:46:57.608664 140172556609344 seed.py:54] Seed set to 0\n",
                        "+-------------------------+------------------------+--------------+--------------------------+--------------------------+\n",
                        "| Name                    |        Default         | Config. File |     Manual Override      |        Effective         |\n",
                        "+-------------------------+------------------------+--------------+--------------------------+--------------------------+\n",
                        "| task                    |     \u001b[38;5;8mclassification\u001b[0m     |     cls      |                          |           cls            |\n",
                        "| load_name               |          \u001b[38;5;8mNone\u001b[0m          |              | /root/mase/mase_output/v | /root/mase/mase_output/v |\n",
                        "|                         |                        |              |  gg7-pre-trained/test-   |  gg7-pre-trained/test-   |\n",
                        "|                         |                        |              |     accu-0.9332.ckpt     |     accu-0.9332.ckpt     |\n",
                        "| load_type               |           \u001b[38;5;8mmz\u001b[0m           |              |            pl            |            pl            |\n",
                        "| batch_size              |          \u001b[38;5;8m128\u001b[0m           |      64      |                          |            64            |\n",
                        "| to_debug                |         False          |              |                          |          False           |\n",
                        "| log_level               |          info          |              |                          |           info           |\n",
                        "| report_to               |      tensorboard       |              |                          |       tensorboard        |\n",
                        "| seed                    |           0            |              |                          |            0             |\n",
                        "| quant_config            |          None          |              |                          |           None           |\n",
                        "| training_optimizer      |          adam          |              |                          |           adam           |\n",
                        "| trainer_precision       |        16-mixed        |              |                          |         16-mixed         |\n",
                        "| learning_rate           |         \u001b[38;5;8m1e-05\u001b[0m          |    0.001     |                          |          0.001           |\n",
                        "| weight_decay            |           0            |              |                          |            0             |\n",
                        "| max_epochs              |           \u001b[38;5;8m20\u001b[0m           |      10      |                          |            10            |\n",
                        "| max_steps               |           -1           |              |                          |            -1            |\n",
                        "| accumulate_grad_batches |           1            |              |                          |            1             |\n",
                        "| log_every_n_steps       |           50           |              |                          |            50            |\n",
                        "| num_workers             |           28           |              |                          |            28            |\n",
                        "| num_devices             |           1            |              |                          |            1             |\n",
                        "| num_nodes               |           1            |              |                          |            1             |\n",
                        "| accelerator             |          \u001b[38;5;8mauto\u001b[0m          |     gpu      |                          |           gpu            |\n",
                        "| strategy                |          auto          |              |                          |           auto           |\n",
                        "| is_to_auto_requeue      |         False          |              |                          |          False           |\n",
                        "| github_ci               |         False          |              |                          |          False           |\n",
                        "| disable_dataset_cache   |         False          |              |                          |          False           |\n",
                        "| target                  |  xcu250-figd2104-2L-e  |              |                          |   xcu250-figd2104-2L-e   |\n",
                        "| num_targets             |          100           |              |                          |           100            |\n",
                        "| is_pretrained           |         False          |              |                          |          False           |\n",
                        "| max_token_len           |          512           |              |                          |           512            |\n",
                        "| project_dir             | /root/mase/mase_output |              |                          |  /root/mase/mase_output  |\n",
                        "| project                 |          None          |              |                          |           None           |\n",
                        "| model                   |          \u001b[38;5;8mNone\u001b[0m          |     vgg7     |                          |           vgg7           |\n",
                        "| dataset                 |          \u001b[38;5;8mNone\u001b[0m          |   cifar10    |                          |         cifar10          |\n",
                        "| t_max                   |           20           |              |                          |            20            |\n",
                        "| eta_min                 |         1e-06          |              |                          |          1e-06           |\n",
                        "+-------------------------+------------------------+--------------+--------------------------+--------------------------+\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mInitialising model 'vgg7'...\u001b[0m\n",
                        "I0328 09:46:57.618832 140172556609344 cli.py:841] Initialising model 'vgg7'...\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mInitialising dataset 'cifar10'...\u001b[0m\n",
                        "I0328 09:46:57.727339 140172556609344 cli.py:869] Initialising dataset 'cifar10'...\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mProject will be created at /root/mase/mase_output/vgg7_cls_cifar10_2024-03-28\u001b[0m\n",
                        "I0328 09:46:57.727733 140172556609344 cli.py:905] Project will be created at /root/mase/mase_output/vgg7_cls_cifar10_2024-03-28\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mTransforming model 'vgg7'...\u001b[0m\n",
                        "I0328 09:46:57.861471 140172556609344 cli.py:365] Transforming model 'vgg7'...\n",
                        "Files already downloaded and verified\n",
                        "Files already downloaded and verified\n",
                        "Files already downloaded and verified\n",
                        "Files already downloaded and verified\n",
                        "Files already downloaded and verified\n",
                        "Files already downloaded and verified\n",
                        "Files already downloaded and verified\n",
                        "Files already downloaded and verified\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from /root/mase/mase_output/vgg7-pre-trained/test-accu-0.9332.ckpt\u001b[0m\n",
                        "I0328 09:47:03.910642 140172556609344 checkpoint_load.py:85] Loaded pytorch lightning checkpoint from /root/mase/mase_output/vgg7-pre-trained/test-accu-0.9332.ckpt\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mApplying fake quantization to PyTorch model...\u001b[0m\n",
                        "I0328 09:47:28.046219 140172556609344 utils.py:240] Applying fake quantization to PyTorch model...\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mFake quantization applied to PyTorch model.\u001b[0m\n",
                        "I0328 09:47:28.307848 140172556609344 utils.py:265] Fake quantization applied to PyTorch model.\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mQuantized graph histogram:\u001b[0m\n",
                        "I0328 09:47:28.326442 140172556609344 summary.py:84] Quantized graph histogram:\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
                        "| Original type   | OP           |   Total |   Changed |   Unchanged |\n",
                        "|-----------------+--------------+---------+-----------+-------------|\n",
                        "| BatchNorm2d     | batch_norm2d |       6 |         0 |           6 |\n",
                        "| Conv2d          | conv2d       |       6 |         6 |           0 |\n",
                        "| Linear          | linear       |       3 |         0 |           3 |\n",
                        "| MaxPool2d       | max_pool2d   |       3 |         0 |           3 |\n",
                        "| ReLU            | relu         |       8 |         0 |           8 |\n",
                        "| output          | output       |       1 |         0 |           1 |\n",
                        "| view            | view         |       1 |         0 |           1 |\n",
                        "| x               | placeholder  |       1 |         0 |           1 |\u001b[0m\n",
                        "I0328 09:47:28.327185 140172556609344 summary.py:85] \n",
                        "| Original type   | OP           |   Total |   Changed |   Unchanged |\n",
                        "|-----------------+--------------+---------+-----------+-------------|\n",
                        "| BatchNorm2d     | batch_norm2d |       6 |         0 |           6 |\n",
                        "| Conv2d          | conv2d       |       6 |         6 |           0 |\n",
                        "| Linear          | linear       |       3 |         0 |           3 |\n",
                        "| MaxPool2d       | max_pool2d   |       3 |         0 |           3 |\n",
                        "| ReLU            | relu         |       8 |         0 |           8 |\n",
                        "| output          | output       |       1 |         0 |           1 |\n",
                        "| view            | view         |       1 |         0 |           1 |\n",
                        "| x               | placeholder  |       1 |         0 |           1 |\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mStarting calibration of the model in PyTorch...\u001b[0m\n",
                        "I0328 09:47:28.327921 140172556609344 calibrate.py:142] Starting calibration of the model in PyTorch...\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
                        "I0328 09:47:28.331665 140172556609344 calibrate.py:151] Disabling Quantization and Enabling Calibration\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
                        "I0328 09:47:28.331817 140172556609344 calibrate.py:151] Disabling Quantization and Enabling Calibration\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
                        "I0328 09:47:28.331937 140172556609344 calibrate.py:151] Disabling Quantization and Enabling Calibration\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
                        "I0328 09:47:28.332038 140172556609344 calibrate.py:151] Disabling Quantization and Enabling Calibration\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
                        "I0328 09:47:28.332136 140172556609344 calibrate.py:151] Disabling Quantization and Enabling Calibration\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
                        "I0328 09:47:28.332226 140172556609344 calibrate.py:151] Disabling Quantization and Enabling Calibration\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
                        "I0328 09:47:28.332322 140172556609344 calibrate.py:151] Disabling Quantization and Enabling Calibration\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
                        "I0328 09:47:28.332412 140172556609344 calibrate.py:151] Disabling Quantization and Enabling Calibration\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
                        "I0328 09:47:28.332508 140172556609344 calibrate.py:151] Disabling Quantization and Enabling Calibration\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
                        "I0328 09:47:28.332597 140172556609344 calibrate.py:151] Disabling Quantization and Enabling Calibration\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
                        "I0328 09:47:28.332705 140172556609344 calibrate.py:151] Disabling Quantization and Enabling Calibration\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
                        "I0328 09:47:28.332795 140172556609344 calibrate.py:151] Disabling Quantization and Enabling Calibration\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
                        "I0328 09:47:35.725847 140172556609344 calibrate.py:171] Enabling Quantization and Disabling Calibration\n",
                        "W0328 09:47:35.726246 140172556609344 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
                        "I0328 09:47:35.726319 140172556609344 calibrate.py:171] Enabling Quantization and Disabling Calibration\n",
                        "W0328 09:47:35.726422 140172556609344 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
                        "I0328 09:47:35.726486 140172556609344 calibrate.py:171] Enabling Quantization and Disabling Calibration\n",
                        "W0328 09:47:35.726591 140172556609344 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
                        "I0328 09:47:35.726642 140172556609344 calibrate.py:171] Enabling Quantization and Disabling Calibration\n",
                        "W0328 09:47:35.726738 140172556609344 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
                        "I0328 09:47:35.726800 140172556609344 calibrate.py:171] Enabling Quantization and Disabling Calibration\n",
                        "W0328 09:47:35.726896 140172556609344 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
                        "I0328 09:47:35.726942 140172556609344 calibrate.py:171] Enabling Quantization and Disabling Calibration\n",
                        "W0328 09:47:35.727033 140172556609344 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
                        "I0328 09:47:35.727088 140172556609344 calibrate.py:171] Enabling Quantization and Disabling Calibration\n",
                        "W0328 09:47:35.727185 140172556609344 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
                        "I0328 09:47:35.727230 140172556609344 calibrate.py:171] Enabling Quantization and Disabling Calibration\n",
                        "W0328 09:47:35.727319 140172556609344 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
                        "I0328 09:47:35.727373 140172556609344 calibrate.py:171] Enabling Quantization and Disabling Calibration\n",
                        "W0328 09:47:35.727461 140172556609344 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
                        "I0328 09:47:35.727505 140172556609344 calibrate.py:171] Enabling Quantization and Disabling Calibration\n",
                        "W0328 09:47:35.727590 140172556609344 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
                        "I0328 09:47:35.727640 140172556609344 calibrate.py:171] Enabling Quantization and Disabling Calibration\n",
                        "W0328 09:47:35.727727 140172556609344 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
                        "I0328 09:47:35.727770 140172556609344 calibrate.py:171] Enabling Quantization and Disabling Calibration\n",
                        "W0328 09:47:35.727857 140172556609344 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
                        "W0328 09:47:35.736799 140172556609344 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "W0328 09:47:35.736884 140172556609344 tensor_quantizer.py:239] Call .cuda() if running on GPU after loading calibrated amax.\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.0._input_quantizer       : TensorQuantizer(8bit fake per-tensor amax=2.6051 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 09:47:35.737027 140172556609344 calibrate.py:130] feature_layers.0._input_quantizer       : TensorQuantizer(8bit fake per-tensor amax=2.6051 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "W0328 09:47:35.737357 140172556609344 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.0._weight_quantizer      : TensorQuantizer(8bit fake per-tensor amax=0.2797 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 09:47:35.737461 140172556609344 calibrate.py:130] feature_layers.0._weight_quantizer      : TensorQuantizer(8bit fake per-tensor amax=0.2797 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "W0328 09:47:35.737834 140172556609344 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.3._input_quantizer       : TensorQuantizer(8bit fake per-tensor amax=3.3027 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 09:47:35.737938 140172556609344 calibrate.py:130] feature_layers.3._input_quantizer       : TensorQuantizer(8bit fake per-tensor amax=3.3027 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "W0328 09:47:35.738215 140172556609344 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.3._weight_quantizer      : TensorQuantizer(8bit fake per-tensor amax=0.2366 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 09:47:35.738314 140172556609344 calibrate.py:130] feature_layers.3._weight_quantizer      : TensorQuantizer(8bit fake per-tensor amax=0.2366 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "W0328 09:47:35.738668 140172556609344 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.7._input_quantizer       : TensorQuantizer(8bit fake per-tensor amax=1.8357 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 09:47:35.738766 140172556609344 calibrate.py:130] feature_layers.7._input_quantizer       : TensorQuantizer(8bit fake per-tensor amax=1.8357 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "W0328 09:47:35.739056 140172556609344 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.7._weight_quantizer      : TensorQuantizer(8bit fake per-tensor amax=0.2296 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 09:47:35.739151 140172556609344 calibrate.py:130] feature_layers.7._weight_quantizer      : TensorQuantizer(8bit fake per-tensor amax=0.2296 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "W0328 09:47:35.739479 140172556609344 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.10._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=1.4749 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 09:47:35.739578 140172556609344 calibrate.py:130] feature_layers.10._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=1.4749 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "W0328 09:47:35.739875 140172556609344 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.10._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.2080 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 09:47:35.739976 140172556609344 calibrate.py:130] feature_layers.10._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.2080 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "W0328 09:47:35.740257 140172556609344 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.14._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=1.9279 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 09:47:35.740352 140172556609344 calibrate.py:130] feature_layers.14._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=1.9279 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "W0328 09:47:35.740627 140172556609344 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.14._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.2013 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 09:47:35.740719 140172556609344 calibrate.py:130] feature_layers.14._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.2013 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "W0328 09:47:35.740999 140172556609344 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.17._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=1.6148 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 09:47:35.741092 140172556609344 calibrate.py:130] feature_layers.17._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=1.6148 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "W0328 09:47:35.741392 140172556609344 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.17._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.1879 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 09:47:35.741485 140172556609344 calibrate.py:130] feature_layers.17._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.1879 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mPerforming post calibration analysis for calibrator percentile_99.0...\u001b[0m\n",
                        "I0328 09:47:35.742280 140172556609344 calibrate.py:104] Performing post calibration analysis for calibrator percentile_99.0...\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on vgg7\u001b[0m\n",
                        "I0328 09:47:35.742495 140172556609344 runtime_analysis.py:309] Starting transformation analysis on vgg7\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
                        "Results vgg7:\n",
                        "+------------------------------+-------------+\n",
                        "|      Metric (Per Batch)      |    Value    |\n",
                        "+------------------------------+-------------+\n",
                        "|    Average Test Accuracy     |   0.91305   |\n",
                        "|      Average Precision       |   0.91207   |\n",
                        "|        Average Recall        |   0.91246   |\n",
                        "|       Average F1 Score       |   0.9122    |\n",
                        "|         Average Loss         |   0.26363   |\n",
                        "|       Average Latency        |  15.734 ms  |\n",
                        "|   Average GPU Power Usage    |  58.651 W   |\n",
                        "| Inference Energy Consumption | 0.25634 mWh |\n",
                        "+------------------------------+-------------+\u001b[0m\n",
                        "I0328 09:47:48.751667 140172556609344 runtime_analysis.py:437] \n",
                        "Results vgg7:\n",
                        "+------------------------------+-------------+\n",
                        "|      Metric (Per Batch)      |    Value    |\n",
                        "+------------------------------+-------------+\n",
                        "|    Average Test Accuracy     |   0.91305   |\n",
                        "|      Average Precision       |   0.91207   |\n",
                        "|        Average Recall        |   0.91246   |\n",
                        "|       Average F1 Score       |   0.9122    |\n",
                        "|         Average Loss         |   0.26363   |\n",
                        "|       Average Latency        |  15.734 ms  |\n",
                        "|   Average GPU Power Usage    |  58.651 W   |\n",
                        "| Inference Energy Consumption | 0.25634 mWh |\n",
                        "+------------------------------+-------------+\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /root/mase_output/tensorrt/quantization/vgg7_cls_cifar10_2024-03-28/mase_graph/version_0/model.json\u001b[0m\n",
                        "I0328 09:47:48.754101 140172556609344 runtime_analysis.py:123] Runtime analysis results saved to /root/mase_output/tensorrt/quantization/vgg7_cls_cifar10_2024-03-28/mase_graph/version_0/model.json\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mPost calibration analysis complete.\u001b[0m\n",
                        "I0328 09:47:48.754428 140172556609344 calibrate.py:117] Post calibration analysis complete.\n",
                        "W0328 09:47:48.755508 140172556609344 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.0._input_quantizer       : TensorQuantizer(8bit fake per-tensor amax=2.6381 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 09:47:48.755877 140172556609344 calibrate.py:130] feature_layers.0._input_quantizer       : TensorQuantizer(8bit fake per-tensor amax=2.6381 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "W0328 09:47:48.756515 140172556609344 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.0._weight_quantizer      : TensorQuantizer(8bit fake per-tensor amax=0.3434 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 09:47:48.756810 140172556609344 calibrate.py:130] feature_layers.0._weight_quantizer      : TensorQuantizer(8bit fake per-tensor amax=0.3434 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "W0328 09:47:48.757537 140172556609344 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.3._input_quantizer       : TensorQuantizer(8bit fake per-tensor amax=5.9141 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 09:47:48.757825 140172556609344 calibrate.py:130] feature_layers.3._input_quantizer       : TensorQuantizer(8bit fake per-tensor amax=5.9141 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "W0328 09:47:48.758470 140172556609344 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.3._weight_quantizer      : TensorQuantizer(8bit fake per-tensor amax=0.3704 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 09:47:48.758758 140172556609344 calibrate.py:130] feature_layers.3._weight_quantizer      : TensorQuantizer(8bit fake per-tensor amax=0.3704 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "W0328 09:47:48.759475 140172556609344 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.7._input_quantizer       : TensorQuantizer(8bit fake per-tensor amax=3.2644 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 09:47:48.759761 140172556609344 calibrate.py:130] feature_layers.7._input_quantizer       : TensorQuantizer(8bit fake per-tensor amax=3.2644 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "W0328 09:47:48.760371 140172556609344 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.7._weight_quantizer      : TensorQuantizer(8bit fake per-tensor amax=0.3621 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 09:47:48.760654 140172556609344 calibrate.py:130] feature_layers.7._weight_quantizer      : TensorQuantizer(8bit fake per-tensor amax=0.3621 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "W0328 09:47:48.761625 140172556609344 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.10._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=2.4170 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 09:47:48.761930 140172556609344 calibrate.py:130] feature_layers.10._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=2.4170 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "W0328 09:47:48.762573 140172556609344 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.10._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.2821 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 09:47:48.762866 140172556609344 calibrate.py:130] feature_layers.10._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.2821 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "W0328 09:47:48.763506 140172556609344 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.14._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=2.9863 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 09:47:48.763795 140172556609344 calibrate.py:130] feature_layers.14._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=2.9863 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "W0328 09:47:48.764409 140172556609344 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.14._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.2734 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 09:47:48.764693 140172556609344 calibrate.py:130] feature_layers.14._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.2734 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "W0328 09:47:48.765363 140172556609344 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.17._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=2.7147 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 09:47:48.765654 140172556609344 calibrate.py:130] feature_layers.17._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=2.7147 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "W0328 09:47:48.766286 140172556609344 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.17._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.2519 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 09:47:48.766568 140172556609344 calibrate.py:130] feature_layers.17._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.2519 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mPerforming post calibration analysis for calibrator percentile_99.9...\u001b[0m\n",
                        "I0328 09:47:48.767648 140172556609344 calibrate.py:104] Performing post calibration analysis for calibrator percentile_99.9...\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on vgg7\u001b[0m\n",
                        "I0328 09:47:48.767965 140172556609344 runtime_analysis.py:309] Starting transformation analysis on vgg7\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
                        "Results vgg7:\n",
                        "+------------------------------+-------------+\n",
                        "|      Metric (Per Batch)      |    Value    |\n",
                        "+------------------------------+-------------+\n",
                        "| Average Validation Accuracy  |   0.92028   |\n",
                        "|      Average Precision       |   0.91911   |\n",
                        "|        Average Recall        |   0.9195    |\n",
                        "|       Average F1 Score       |   0.91919   |\n",
                        "|         Average Loss         |   0.24024   |\n",
                        "|       Average Latency        |  15.239 ms  |\n",
                        "|   Average GPU Power Usage    |  58.141 W   |\n",
                        "| Inference Energy Consumption | 0.24612 mWh |\n",
                        "+------------------------------+-------------+\u001b[0m\n",
                        "I0328 09:48:01.357649 140172556609344 runtime_analysis.py:437] \n",
                        "Results vgg7:\n",
                        "+------------------------------+-------------+\n",
                        "|      Metric (Per Batch)      |    Value    |\n",
                        "+------------------------------+-------------+\n",
                        "| Average Validation Accuracy  |   0.92028   |\n",
                        "|      Average Precision       |   0.91911   |\n",
                        "|        Average Recall        |   0.9195    |\n",
                        "|       Average F1 Score       |   0.91919   |\n",
                        "|         Average Loss         |   0.24024   |\n",
                        "|       Average Latency        |  15.239 ms  |\n",
                        "|   Average GPU Power Usage    |  58.141 W   |\n",
                        "| Inference Energy Consumption | 0.24612 mWh |\n",
                        "+------------------------------+-------------+\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /root/mase_output/tensorrt/quantization/vgg7_cls_cifar10_2024-03-28/mase_graph/version_1/model.json\u001b[0m\n",
                        "I0328 09:48:01.358966 140172556609344 runtime_analysis.py:123] Runtime analysis results saved to /root/mase_output/tensorrt/quantization/vgg7_cls_cifar10_2024-03-28/mase_graph/version_1/model.json\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mPost calibration analysis complete.\u001b[0m\n",
                        "I0328 09:48:01.359134 140172556609344 calibrate.py:117] Post calibration analysis complete.\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mSucceeded in calibrating the model in PyTorch!\u001b[0m\n",
                        "I0328 09:48:01.359266 140172556609344 calibrate.py:209] Succeeded in calibrating the model in PyTorch!\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mStarting Fine Tuning for 2 epochs...\u001b[0m\n",
                        "I0328 09:48:01.362987 140172556609344 fine_tune.py:136] Starting Fine Tuning for 2 epochs...\n",
                        "INFO: GPU available: True (cuda), used: True\n",
                        "I0328 09:48:01.552734 140172556609344 rank_zero.py:64] GPU available: True (cuda), used: True\n",
                        "INFO: TPU available: False, using: 0 TPU cores\n",
                        "I0328 09:48:01.579539 140172556609344 rank_zero.py:64] TPU available: False, using: 0 TPU cores\n",
                        "INFO: IPU available: False, using: 0 IPUs\n",
                        "I0328 09:48:01.579623 140172556609344 rank_zero.py:64] IPU available: False, using: 0 IPUs\n",
                        "INFO: HPU available: False, using: 0 HPUs\n",
                        "I0328 09:48:01.579678 140172556609344 rank_zero.py:64] HPU available: False, using: 0 HPUs\n",
                        "Files already downloaded and verified\n",
                        "Files already downloaded and verified\n",
                        "Files already downloaded and verified\n",
                        "Files already downloaded and verified\n",
                        "Files already downloaded and verified\n",
                        "Files already downloaded and verified\n",
                        "I0328 09:48:06.389344 140172556609344 cuda.py:61] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
                        "I0328 09:48:06.398172 140172556609344 model_summary.py:94] \n",
                        "  | Name      | Type               | Params\n",
                        "-------------------------------------------------\n",
                        "0 | model     | GraphModule        | 14.0 M\n",
                        "1 | loss_fn   | CrossEntropyLoss   | 0     \n",
                        "2 | acc_train | MulticlassAccuracy | 0     \n",
                        "3 | loss_val  | MeanMetric         | 0     \n",
                        "4 | loss_test | MeanMetric         | 0     \n",
                        "-------------------------------------------------\n",
                        "14.0 M    Trainable params\n",
                        "0         Non-trainable params\n",
                        "14.0 M    Total params\n",
                        "56.118    Total estimated model params size (MB)\n",
                        "Epoch 0: 100%|█| 782/782 [00:37<00:00, 20.80it/s, v_num=10, train_acc_step=0.938\n",
                        "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
                        "Validation:   0%|                                       | 0/157 [00:00<?, ?it/s]\u001b[A\n",
                        "Validation DataLoader 0:   0%|                          | 0/157 [00:00<?, ?it/s]\u001b[A\n",
                        "Validation DataLoader 0:   1%|                  | 1/157 [00:00<00:04, 37.70it/s]\u001b[A\n",
                        "Validation DataLoader 0:   1%|▏                 | 2/157 [00:00<00:04, 35.70it/s]\u001b[A\n",
                        "Validation DataLoader 0:   2%|▎                 | 3/157 [00:00<00:06, 22.80it/s]\u001b[A\n",
                        "Validation DataLoader 0:   3%|▍                 | 4/157 [00:00<00:05, 25.75it/s]\u001b[A\n",
                        "Validation DataLoader 0:   3%|▌                 | 5/157 [00:00<00:05, 28.38it/s]\u001b[A\n",
                        "Validation DataLoader 0:   4%|▋                 | 6/157 [00:00<00:04, 30.68it/s]\u001b[A\n",
                        "Validation DataLoader 0:   4%|▊                 | 7/157 [00:00<00:04, 32.34it/s]\u001b[A\n",
                        "Validation DataLoader 0:   5%|▉                 | 8/157 [00:00<00:04, 33.85it/s]\u001b[A\n",
                        "Validation DataLoader 0:   6%|█                 | 9/157 [00:00<00:04, 35.22it/s]\u001b[A\n",
                        "Validation DataLoader 0:   6%|█                | 10/157 [00:00<00:04, 36.40it/s]\u001b[A\n",
                        "Validation DataLoader 0:   7%|█▏               | 11/157 [00:00<00:03, 37.41it/s]\u001b[A\n",
                        "Validation DataLoader 0:   8%|█▎               | 12/157 [00:00<00:03, 38.30it/s]\u001b[A\n",
                        "Validation DataLoader 0:   8%|█▍               | 13/157 [00:00<00:03, 39.09it/s]\u001b[A\n",
                        "Validation DataLoader 0:   9%|█▌               | 14/157 [00:00<00:03, 39.76it/s]\u001b[A\n",
                        "Validation DataLoader 0:  10%|█▌               | 15/157 [00:00<00:03, 40.39it/s]\u001b[A\n",
                        "Validation DataLoader 0:  10%|█▋               | 16/157 [00:00<00:03, 40.60it/s]\u001b[A\n",
                        "Validation DataLoader 0:  11%|█▊               | 17/157 [00:00<00:03, 41.07it/s]\u001b[A\n",
                        "Validation DataLoader 0:  11%|█▉               | 18/157 [00:00<00:03, 41.66it/s]\u001b[A\n",
                        "Validation DataLoader 0:  12%|██               | 19/157 [00:00<00:03, 42.23it/s]\u001b[A\n",
                        "Validation DataLoader 0:  13%|██▏              | 20/157 [00:00<00:03, 42.76it/s]\u001b[A\n",
                        "Validation DataLoader 0:  13%|██▎              | 21/157 [00:00<00:03, 43.26it/s]\u001b[A\n",
                        "Validation DataLoader 0:  14%|██▍              | 22/157 [00:00<00:03, 43.74it/s]\u001b[A\n",
                        "Validation DataLoader 0:  15%|██▍              | 23/157 [00:00<00:03, 44.18it/s]\u001b[A\n",
                        "Validation DataLoader 0:  15%|██▌              | 24/157 [00:00<00:02, 44.59it/s]\u001b[A\n",
                        "Validation DataLoader 0:  16%|██▋              | 25/157 [00:00<00:02, 44.98it/s]\u001b[A\n",
                        "Validation DataLoader 0:  17%|██▊              | 26/157 [00:00<00:02, 45.36it/s]\u001b[A\n",
                        "Validation DataLoader 0:  17%|██▉              | 27/157 [00:00<00:02, 45.70it/s]\u001b[A\n",
                        "Validation DataLoader 0:  18%|███              | 28/157 [00:00<00:02, 45.62it/s]\u001b[A\n",
                        "Validation DataLoader 0:  18%|███▏             | 29/157 [00:00<00:02, 45.93it/s]\u001b[A\n",
                        "Validation DataLoader 0:  19%|███▏             | 30/157 [00:00<00:02, 46.24it/s]\u001b[A\n",
                        "Validation DataLoader 0:  20%|███▎             | 31/157 [00:00<00:02, 46.52it/s]\u001b[A\n",
                        "Validation DataLoader 0:  20%|███▍             | 32/157 [00:00<00:02, 46.59it/s]\u001b[A\n",
                        "Validation DataLoader 0:  21%|███▌             | 33/157 [00:00<00:02, 46.82it/s]\u001b[A\n",
                        "Validation DataLoader 0:  22%|███▋             | 34/157 [00:00<00:02, 47.13it/s]\u001b[A\n",
                        "Validation DataLoader 0:  22%|███▊             | 35/157 [00:00<00:02, 47.42it/s]\u001b[A\n",
                        "Validation DataLoader 0:  23%|███▉             | 36/157 [00:00<00:02, 47.69it/s]\u001b[A\n",
                        "Validation DataLoader 0:  24%|████             | 37/157 [00:00<00:02, 47.96it/s]\u001b[A\n",
                        "Validation DataLoader 0:  24%|████             | 38/157 [00:00<00:02, 48.21it/s]\u001b[A\n",
                        "Validation DataLoader 0:  25%|████▏            | 39/157 [00:00<00:02, 48.46it/s]\u001b[A\n",
                        "Validation DataLoader 0:  25%|████▎            | 40/157 [00:00<00:02, 48.69it/s]\u001b[A\n",
                        "Validation DataLoader 0:  26%|████▍            | 41/157 [00:00<00:02, 48.90it/s]\u001b[A\n",
                        "Validation DataLoader 0:  27%|████▌            | 42/157 [00:00<00:02, 49.12it/s]\u001b[A\n",
                        "Validation DataLoader 0:  27%|████▋            | 43/157 [00:00<00:02, 49.32it/s]\u001b[A\n",
                        "Validation DataLoader 0:  28%|████▊            | 44/157 [00:00<00:02, 49.32it/s]\u001b[A\n",
                        "Validation DataLoader 0:  29%|████▊            | 45/157 [00:00<00:02, 49.44it/s]\u001b[A\n",
                        "Validation DataLoader 0:  29%|████▉            | 46/157 [00:00<00:02, 49.63it/s]\u001b[A\n",
                        "Validation DataLoader 0:  30%|█████            | 47/157 [00:00<00:02, 49.81it/s]\u001b[A\n",
                        "Validation DataLoader 0:  31%|█████▏           | 48/157 [00:00<00:02, 49.98it/s]\u001b[A\n",
                        "Validation DataLoader 0:  31%|█████▎           | 49/157 [00:00<00:02, 50.16it/s]\u001b[A\n",
                        "Validation DataLoader 0:  32%|█████▍           | 50/157 [00:00<00:02, 50.33it/s]\u001b[A\n",
                        "Validation DataLoader 0:  32%|█████▌           | 51/157 [00:01<00:02, 50.48it/s]\u001b[A\n",
                        "Validation DataLoader 0:  33%|█████▋           | 52/157 [00:01<00:02, 50.63it/s]\u001b[A\n",
                        "Validation DataLoader 0:  34%|█████▋           | 53/157 [00:01<00:02, 50.67it/s]\u001b[A\n",
                        "Validation DataLoader 0:  34%|█████▊           | 54/157 [00:01<00:02, 50.82it/s]\u001b[A\n",
                        "Validation DataLoader 0:  35%|█████▉           | 55/157 [00:01<00:02, 50.96it/s]\u001b[A\n",
                        "Validation DataLoader 0:  36%|██████           | 56/157 [00:01<00:01, 51.10it/s]\u001b[A\n",
                        "Validation DataLoader 0:  36%|██████▏          | 57/157 [00:01<00:01, 51.17it/s]\u001b[A\n",
                        "Validation DataLoader 0:  37%|██████▎          | 58/157 [00:01<00:01, 51.25it/s]\u001b[A\n",
                        "Validation DataLoader 0:  38%|██████▍          | 59/157 [00:01<00:01, 51.33it/s]\u001b[A\n",
                        "Validation DataLoader 0:  38%|██████▍          | 60/157 [00:01<00:01, 51.27it/s]\u001b[A\n",
                        "Validation DataLoader 0:  39%|██████▌          | 61/157 [00:01<00:01, 51.28it/s]\u001b[A\n",
                        "Validation DataLoader 0:  39%|██████▋          | 62/157 [00:01<00:01, 51.36it/s]\u001b[A\n",
                        "Validation DataLoader 0:  40%|██████▊          | 63/157 [00:01<00:01, 51.43it/s]\u001b[A\n",
                        "Validation DataLoader 0:  41%|██████▉          | 64/157 [00:01<00:01, 51.50it/s]\u001b[A\n",
                        "Validation DataLoader 0:  41%|███████          | 65/157 [00:01<00:01, 51.57it/s]\u001b[A\n",
                        "Validation DataLoader 0:  42%|███████▏         | 66/157 [00:01<00:01, 51.64it/s]\u001b[A\n",
                        "Validation DataLoader 0:  43%|███████▎         | 67/157 [00:01<00:01, 51.71it/s]\u001b[A\n",
                        "Validation DataLoader 0:  43%|███████▎         | 68/157 [00:01<00:01, 51.79it/s]\u001b[A\n",
                        "Validation DataLoader 0:  44%|███████▍         | 69/157 [00:01<00:01, 51.86it/s]\u001b[A\n",
                        "Validation DataLoader 0:  45%|███████▌         | 70/157 [00:01<00:01, 51.92it/s]\u001b[A\n",
                        "Validation DataLoader 0:  45%|███████▋         | 71/157 [00:01<00:01, 51.98it/s]\u001b[A\n",
                        "Validation DataLoader 0:  46%|███████▊         | 72/157 [00:01<00:01, 51.90it/s]\u001b[A\n",
                        "Validation DataLoader 0:  46%|███████▉         | 73/157 [00:01<00:01, 51.90it/s]\u001b[A\n",
                        "Validation DataLoader 0:  47%|████████         | 74/157 [00:01<00:01, 51.95it/s]\u001b[A\n",
                        "Validation DataLoader 0:  48%|████████         | 75/157 [00:01<00:01, 51.99it/s]\u001b[A\n",
                        "Validation DataLoader 0:  48%|████████▏        | 76/157 [00:01<00:01, 52.05it/s]\u001b[A\n",
                        "Validation DataLoader 0:  49%|████████▎        | 77/157 [00:01<00:01, 52.10it/s]\u001b[A\n",
                        "Validation DataLoader 0:  50%|████████▍        | 78/157 [00:01<00:01, 52.16it/s]\u001b[A\n",
                        "Validation DataLoader 0:  50%|████████▌        | 79/157 [00:01<00:01, 52.21it/s]\u001b[A\n",
                        "Validation DataLoader 0:  51%|████████▋        | 80/157 [00:01<00:01, 52.26it/s]\u001b[A\n",
                        "Validation DataLoader 0:  52%|████████▊        | 81/157 [00:01<00:01, 52.29it/s]\u001b[A\n",
                        "Validation DataLoader 0:  52%|████████▉        | 82/157 [00:01<00:01, 52.34it/s]\u001b[A\n",
                        "Validation DataLoader 0:  53%|████████▉        | 83/157 [00:01<00:01, 52.38it/s]\u001b[A\n",
                        "Validation DataLoader 0:  54%|█████████        | 84/157 [00:01<00:01, 52.43it/s]\u001b[A\n",
                        "Validation DataLoader 0:  54%|█████████▏       | 85/157 [00:01<00:01, 52.47it/s]\u001b[A\n",
                        "Validation DataLoader 0:  55%|█████████▎       | 86/157 [00:01<00:01, 52.51it/s]\u001b[A\n",
                        "Validation DataLoader 0:  55%|█████████▍       | 87/157 [00:01<00:01, 52.54it/s]\u001b[A\n",
                        "Validation DataLoader 0:  56%|█████████▌       | 88/157 [00:01<00:01, 52.49it/s]\u001b[A\n",
                        "Validation DataLoader 0:  57%|█████████▋       | 89/157 [00:01<00:01, 52.49it/s]\u001b[A\n",
                        "Validation DataLoader 0:  57%|█████████▋       | 90/157 [00:01<00:01, 52.53it/s]\u001b[A\n",
                        "Validation DataLoader 0:  58%|█████████▊       | 91/157 [00:01<00:01, 52.57it/s]\u001b[A\n",
                        "Validation DataLoader 0:  59%|█████████▉       | 92/157 [00:01<00:01, 52.61it/s]\u001b[A\n",
                        "Validation DataLoader 0:  59%|██████████       | 93/157 [00:01<00:01, 52.65it/s]\u001b[A\n",
                        "Validation DataLoader 0:  60%|██████████▏      | 94/157 [00:01<00:01, 52.69it/s]\u001b[A\n",
                        "Validation DataLoader 0:  61%|██████████▎      | 95/157 [00:01<00:01, 52.73it/s]\u001b[A\n",
                        "Validation DataLoader 0:  61%|██████████▍      | 96/157 [00:01<00:01, 52.77it/s]\u001b[A\n",
                        "Validation DataLoader 0:  62%|██████████▌      | 97/157 [00:01<00:01, 52.81it/s]\u001b[A\n",
                        "Validation DataLoader 0:  62%|██████████▌      | 98/157 [00:01<00:01, 52.85it/s]\u001b[A\n",
                        "Validation DataLoader 0:  63%|██████████▋      | 99/157 [00:01<00:01, 52.87it/s]\u001b[A\n",
                        "Validation DataLoader 0:  64%|██████████▏     | 100/157 [00:01<00:01, 52.81it/s]\u001b[A\n",
                        "Validation DataLoader 0:  64%|██████████▎     | 101/157 [00:01<00:01, 52.80it/s]\u001b[A\n",
                        "Validation DataLoader 0:  65%|██████████▍     | 102/157 [00:01<00:01, 52.83it/s]\u001b[A\n",
                        "Validation DataLoader 0:  66%|██████████▍     | 103/157 [00:01<00:01, 52.87it/s]\u001b[A\n",
                        "Validation DataLoader 0:  66%|██████████▌     | 104/157 [00:01<00:01, 52.90it/s]\u001b[A\n",
                        "Validation DataLoader 0:  67%|██████████▋     | 105/157 [00:01<00:00, 52.94it/s]\u001b[A\n",
                        "Validation DataLoader 0:  68%|██████████▊     | 106/157 [00:02<00:00, 52.97it/s]\u001b[A\n",
                        "Validation DataLoader 0:  68%|██████████▉     | 107/157 [00:02<00:00, 53.01it/s]\u001b[A\n",
                        "Validation DataLoader 0:  69%|███████████     | 108/157 [00:02<00:00, 53.04it/s]\u001b[A\n",
                        "Validation DataLoader 0:  69%|███████████     | 109/157 [00:02<00:00, 53.07it/s]\u001b[A\n",
                        "Validation DataLoader 0:  70%|███████████▏    | 110/157 [00:02<00:00, 53.10it/s]\u001b[A\n",
                        "Validation DataLoader 0:  71%|███████████▎    | 111/157 [00:02<00:00, 53.13it/s]\u001b[A\n",
                        "Validation DataLoader 0:  71%|███████████▍    | 112/157 [00:02<00:00, 53.16it/s]\u001b[A\n",
                        "Validation DataLoader 0:  72%|███████████▌    | 113/157 [00:02<00:00, 53.19it/s]\u001b[A\n",
                        "Validation DataLoader 0:  73%|███████████▌    | 114/157 [00:02<00:00, 53.19it/s]\u001b[A\n",
                        "Validation DataLoader 0:  73%|███████████▋    | 115/157 [00:02<00:00, 53.19it/s]\u001b[A\n",
                        "Validation DataLoader 0:  74%|███████████▊    | 116/157 [00:02<00:00, 53.19it/s]\u001b[A\n",
                        "Validation DataLoader 0:  75%|███████████▉    | 117/157 [00:02<00:00, 53.19it/s]\u001b[A\n",
                        "Validation DataLoader 0:  75%|████████████    | 118/157 [00:02<00:00, 53.19it/s]\u001b[A\n",
                        "Validation DataLoader 0:  76%|████████████▏   | 119/157 [00:02<00:00, 53.20it/s]\u001b[A\n",
                        "Validation DataLoader 0:  76%|████████████▏   | 120/157 [00:02<00:00, 53.20it/s]\u001b[A\n",
                        "Validation DataLoader 0:  77%|████████████▎   | 121/157 [00:02<00:00, 53.20it/s]\u001b[A\n",
                        "Validation DataLoader 0:  78%|████████████▍   | 122/157 [00:02<00:00, 53.20it/s]\u001b[A\n",
                        "Validation DataLoader 0:  78%|████████████▌   | 123/157 [00:02<00:00, 53.20it/s]\u001b[A\n",
                        "Validation DataLoader 0:  79%|████████████▋   | 124/157 [00:02<00:00, 53.21it/s]\u001b[A\n",
                        "Validation DataLoader 0:  80%|████████████▋   | 125/157 [00:02<00:00, 53.22it/s]\u001b[A\n",
                        "Validation DataLoader 0:  80%|████████████▊   | 126/157 [00:02<00:00, 53.22it/s]\u001b[A\n",
                        "Validation DataLoader 0:  81%|████████████▉   | 127/157 [00:02<00:00, 53.22it/s]\u001b[A\n",
                        "Validation DataLoader 0:  82%|█████████████   | 128/157 [00:02<00:00, 53.22it/s]\u001b[A\n",
                        "Validation DataLoader 0:  82%|█████████████▏  | 129/157 [00:02<00:00, 53.22it/s]\u001b[A\n",
                        "Validation DataLoader 0:  83%|█████████████▏  | 130/157 [00:02<00:00, 53.22it/s]\u001b[A\n",
                        "Validation DataLoader 0:  83%|█████████████▎  | 131/157 [00:02<00:00, 53.23it/s]\u001b[A\n",
                        "Validation DataLoader 0:  84%|█████████████▍  | 132/157 [00:02<00:00, 53.23it/s]\u001b[A\n",
                        "Validation DataLoader 0:  85%|█████████████▌  | 133/157 [00:02<00:00, 53.24it/s]\u001b[A\n",
                        "Validation DataLoader 0:  85%|█████████████▋  | 134/157 [00:02<00:00, 53.27it/s]\u001b[A\n",
                        "Validation DataLoader 0:  86%|█████████████▊  | 135/157 [00:02<00:00, 53.29it/s]\u001b[A\n",
                        "Validation DataLoader 0:  87%|█████████████▊  | 136/157 [00:02<00:00, 53.31it/s]\u001b[A\n",
                        "Validation DataLoader 0:  87%|█████████████▉  | 137/157 [00:02<00:00, 53.33it/s]\u001b[A\n",
                        "Validation DataLoader 0:  88%|██████████████  | 138/157 [00:02<00:00, 53.35it/s]\u001b[A\n",
                        "Validation DataLoader 0:  89%|██████████████▏ | 139/157 [00:02<00:00, 53.37it/s]\u001b[A\n",
                        "Validation DataLoader 0:  89%|██████████████▎ | 140/157 [00:02<00:00, 53.39it/s]\u001b[A\n",
                        "Validation DataLoader 0:  90%|██████████████▎ | 141/157 [00:02<00:00, 53.41it/s]\u001b[A\n",
                        "Validation DataLoader 0:  90%|██████████████▍ | 142/157 [00:02<00:00, 53.43it/s]\u001b[A\n",
                        "Validation DataLoader 0:  91%|██████████████▌ | 143/157 [00:02<00:00, 53.45it/s]\u001b[A\n",
                        "Validation DataLoader 0:  92%|██████████████▋ | 144/157 [00:02<00:00, 53.47it/s]\u001b[A\n",
                        "Validation DataLoader 0:  92%|██████████████▊ | 145/157 [00:02<00:00, 53.49it/s]\u001b[A\n",
                        "Validation DataLoader 0:  93%|██████████████▉ | 146/157 [00:02<00:00, 53.51it/s]\u001b[A\n",
                        "Validation DataLoader 0:  94%|██████████████▉ | 147/157 [00:02<00:00, 53.54it/s]\u001b[A\n",
                        "Validation DataLoader 0:  94%|███████████████ | 148/157 [00:02<00:00, 53.56it/s]\u001b[A\n",
                        "Validation DataLoader 0:  95%|███████████████▏| 149/157 [00:02<00:00, 53.57it/s]\u001b[A\n",
                        "Validation DataLoader 0:  96%|███████████████▎| 150/157 [00:02<00:00, 53.60it/s]\u001b[A\n",
                        "Validation DataLoader 0:  96%|███████████████▍| 151/157 [00:02<00:00, 53.61it/s]\u001b[A\n",
                        "Validation DataLoader 0:  97%|███████████████▍| 152/157 [00:02<00:00, 53.63it/s]\u001b[A\n",
                        "Validation DataLoader 0:  97%|███████████████▌| 153/157 [00:02<00:00, 53.65it/s]\u001b[A\n",
                        "Validation DataLoader 0:  98%|███████████████▋| 154/157 [00:02<00:00, 53.67it/s]\u001b[A\n",
                        "Validation DataLoader 0:  99%|███████████████▊| 155/157 [00:02<00:00, 53.68it/s]\u001b[A\n",
                        "Validation DataLoader 0:  99%|███████████████▉| 156/157 [00:02<00:00, 53.70it/s]\u001b[A\n",
                        "Validation DataLoader 0: 100%|████████████████| 157/157 [00:02<00:00, 53.85it/s]\u001b[A\n",
                        "Epoch 1: 100%|█| 782/782 [00:45<00:00, 17.06it/s, v_num=10, train_acc_step=0.812\u001b[A\n",
                        "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
                        "Validation:   0%|                                       | 0/157 [00:00<?, ?it/s]\u001b[A\n",
                        "Validation DataLoader 0:   0%|                          | 0/157 [00:00<?, ?it/s]\u001b[A\n",
                        "Validation DataLoader 0:   1%|                  | 1/157 [00:00<00:04, 36.85it/s]\u001b[A\n",
                        "Validation DataLoader 0:   1%|▏                 | 2/157 [00:00<00:03, 40.14it/s]\u001b[A\n",
                        "Validation DataLoader 0:   2%|▎                 | 3/157 [00:00<00:03, 42.26it/s]\u001b[A\n",
                        "Validation DataLoader 0:   3%|▍                 | 4/157 [00:00<00:03, 40.29it/s]\u001b[A\n",
                        "Validation DataLoader 0:   3%|▌                 | 5/157 [00:00<00:03, 42.11it/s]\u001b[A\n",
                        "Validation DataLoader 0:   4%|▋                 | 6/157 [00:00<00:03, 40.66it/s]\u001b[A\n",
                        "Validation DataLoader 0:   4%|▊                 | 7/157 [00:00<00:03, 42.09it/s]\u001b[A\n",
                        "Validation DataLoader 0:   5%|▉                 | 8/157 [00:00<00:03, 43.23it/s]\u001b[A\n",
                        "Validation DataLoader 0:   6%|█                 | 9/157 [00:00<00:03, 44.14it/s]\u001b[A\n",
                        "Validation DataLoader 0:   6%|█                | 10/157 [00:00<00:03, 44.90it/s]\u001b[A\n",
                        "Validation DataLoader 0:   7%|█▏               | 11/157 [00:00<00:03, 42.57it/s]\u001b[A\n",
                        "Validation DataLoader 0:   8%|█▎               | 12/157 [00:00<00:03, 43.54it/s]\u001b[A\n",
                        "Validation DataLoader 0:   8%|█▍               | 13/157 [00:00<00:03, 44.40it/s]\u001b[A\n",
                        "Validation DataLoader 0:   9%|█▌               | 14/157 [00:00<00:03, 45.17it/s]\u001b[A\n",
                        "Validation DataLoader 0:  10%|█▌               | 15/157 [00:00<00:03, 45.86it/s]\u001b[A\n",
                        "Validation DataLoader 0:  10%|█▋               | 16/157 [00:00<00:03, 46.46it/s]\u001b[A\n",
                        "Validation DataLoader 0:  11%|█▊               | 17/157 [00:00<00:02, 46.99it/s]\u001b[A\n",
                        "Validation DataLoader 0:  11%|█▉               | 18/157 [00:00<00:02, 47.49it/s]\u001b[A\n",
                        "Validation DataLoader 0:  12%|██               | 19/157 [00:00<00:02, 47.94it/s]\u001b[A\n",
                        "Validation DataLoader 0:  13%|██▏              | 20/157 [00:00<00:02, 48.00it/s]\u001b[A\n",
                        "Validation DataLoader 0:  13%|██▎              | 21/157 [00:00<00:02, 47.75it/s]\u001b[A\n",
                        "Validation DataLoader 0:  14%|██▍              | 22/157 [00:00<00:02, 48.16it/s]\u001b[A\n",
                        "Validation DataLoader 0:  15%|██▍              | 23/157 [00:00<00:02, 48.53it/s]\u001b[A\n",
                        "Validation DataLoader 0:  15%|██▌              | 24/157 [00:00<00:02, 48.87it/s]\u001b[A\n",
                        "Validation DataLoader 0:  16%|██▋              | 25/157 [00:00<00:02, 49.19it/s]\u001b[A\n",
                        "Validation DataLoader 0:  17%|██▊              | 26/157 [00:00<00:02, 49.47it/s]\u001b[A\n",
                        "Validation DataLoader 0:  17%|██▉              | 27/157 [00:00<00:02, 49.74it/s]\u001b[A\n",
                        "Validation DataLoader 0:  18%|███              | 28/157 [00:00<00:02, 49.98it/s]\u001b[A\n",
                        "Validation DataLoader 0:  18%|███▏             | 29/157 [00:00<00:02, 50.21it/s]\u001b[A\n",
                        "Validation DataLoader 0:  19%|███▏             | 30/157 [00:00<00:02, 50.43it/s]\u001b[A\n",
                        "Validation DataLoader 0:  20%|███▎             | 31/157 [00:00<00:02, 50.64it/s]\u001b[A\n",
                        "Validation DataLoader 0:  20%|███▍             | 32/157 [00:00<00:02, 50.85it/s]\u001b[A\n",
                        "Validation DataLoader 0:  21%|███▌             | 33/157 [00:00<00:02, 51.04it/s]\u001b[A\n",
                        "Validation DataLoader 0:  22%|███▋             | 34/157 [00:00<00:02, 51.02it/s]\u001b[A\n",
                        "Validation DataLoader 0:  22%|███▊             | 35/157 [00:00<00:02, 50.81it/s]\u001b[A\n",
                        "Validation DataLoader 0:  23%|███▉             | 36/157 [00:00<00:02, 50.93it/s]\u001b[A\n",
                        "Validation DataLoader 0:  24%|████             | 37/157 [00:00<00:02, 51.10it/s]\u001b[A\n",
                        "Validation DataLoader 0:  24%|████             | 38/157 [00:00<00:02, 51.24it/s]\u001b[A\n",
                        "Validation DataLoader 0:  25%|████▏            | 39/157 [00:00<00:02, 51.32it/s]\u001b[A\n",
                        "Validation DataLoader 0:  25%|████▎            | 40/157 [00:00<00:02, 51.45it/s]\u001b[A\n",
                        "Validation DataLoader 0:  26%|████▍            | 41/157 [00:00<00:02, 51.58it/s]\u001b[A\n",
                        "Validation DataLoader 0:  27%|████▌            | 42/157 [00:00<00:02, 51.71it/s]\u001b[A\n",
                        "Validation DataLoader 0:  27%|████▋            | 43/157 [00:00<00:02, 51.84it/s]\u001b[A\n",
                        "Validation DataLoader 0:  28%|████▊            | 44/157 [00:00<00:02, 52.00it/s]\u001b[A\n",
                        "Validation DataLoader 0:  29%|████▊            | 45/157 [00:00<00:02, 52.17it/s]\u001b[A\n",
                        "Validation DataLoader 0:  29%|████▉            | 46/157 [00:00<00:02, 52.32it/s]\u001b[A\n",
                        "Validation DataLoader 0:  30%|█████            | 47/157 [00:00<00:02, 52.47it/s]\u001b[A\n",
                        "Validation DataLoader 0:  31%|█████▏           | 48/157 [00:00<00:02, 52.61it/s]\u001b[A\n",
                        "Validation DataLoader 0:  31%|█████▎           | 49/157 [00:00<00:02, 52.70it/s]\u001b[A\n",
                        "Validation DataLoader 0:  32%|█████▍           | 50/157 [00:00<00:02, 52.84it/s]\u001b[A\n",
                        "Validation DataLoader 0:  32%|█████▌           | 51/157 [00:00<00:02, 52.97it/s]\u001b[A\n",
                        "Validation DataLoader 0:  33%|█████▋           | 52/157 [00:00<00:01, 53.10it/s]\u001b[A\n",
                        "Validation DataLoader 0:  34%|█████▋           | 53/157 [00:00<00:01, 53.22it/s]\u001b[A\n",
                        "Validation DataLoader 0:  34%|█████▊           | 54/157 [00:01<00:01, 53.34it/s]\u001b[A\n",
                        "Validation DataLoader 0:  35%|█████▉           | 55/157 [00:01<00:01, 53.45it/s]\u001b[A\n",
                        "Validation DataLoader 0:  36%|██████           | 56/157 [00:01<00:01, 53.57it/s]\u001b[A\n",
                        "Validation DataLoader 0:  36%|██████▏          | 57/157 [00:01<00:01, 53.63it/s]\u001b[A\n",
                        "Validation DataLoader 0:  37%|██████▎          | 58/157 [00:01<00:01, 53.69it/s]\u001b[A\n",
                        "Validation DataLoader 0:  38%|██████▍          | 59/157 [00:01<00:01, 53.75it/s]\u001b[A\n",
                        "Validation DataLoader 0:  38%|██████▍          | 60/157 [00:01<00:01, 53.81it/s]\u001b[A\n",
                        "Validation DataLoader 0:  39%|██████▌          | 61/157 [00:01<00:01, 53.86it/s]\u001b[A\n",
                        "Validation DataLoader 0:  39%|██████▋          | 62/157 [00:01<00:01, 53.92it/s]\u001b[A\n",
                        "Validation DataLoader 0:  40%|██████▊          | 63/157 [00:01<00:01, 53.96it/s]\u001b[A\n",
                        "Validation DataLoader 0:  41%|██████▉          | 64/157 [00:01<00:01, 54.01it/s]\u001b[A\n",
                        "Validation DataLoader 0:  41%|███████          | 65/157 [00:01<00:01, 54.06it/s]\u001b[A\n",
                        "Validation DataLoader 0:  42%|███████▏         | 66/157 [00:01<00:01, 54.11it/s]\u001b[A\n",
                        "Validation DataLoader 0:  43%|███████▎         | 67/157 [00:01<00:01, 54.14it/s]\u001b[A\n",
                        "Validation DataLoader 0:  43%|███████▎         | 68/157 [00:01<00:01, 54.19it/s]\u001b[A\n",
                        "Validation DataLoader 0:  44%|███████▍         | 69/157 [00:01<00:01, 54.24it/s]\u001b[A\n",
                        "Validation DataLoader 0:  45%|███████▌         | 70/157 [00:01<00:01, 54.29it/s]\u001b[A\n",
                        "Validation DataLoader 0:  45%|███████▋         | 71/157 [00:01<00:01, 54.33it/s]\u001b[A\n",
                        "Validation DataLoader 0:  46%|███████▊         | 72/157 [00:01<00:01, 54.38it/s]\u001b[A\n",
                        "Validation DataLoader 0:  46%|███████▉         | 73/157 [00:01<00:01, 54.42it/s]\u001b[A\n",
                        "Validation DataLoader 0:  47%|████████         | 74/157 [00:01<00:01, 54.46it/s]\u001b[A\n",
                        "Validation DataLoader 0:  48%|████████         | 75/157 [00:01<00:01, 54.49it/s]\u001b[A\n",
                        "Validation DataLoader 0:  48%|████████▏        | 76/157 [00:01<00:01, 54.52it/s]\u001b[A\n",
                        "Validation DataLoader 0:  49%|████████▎        | 77/157 [00:01<00:01, 54.56it/s]\u001b[A\n",
                        "Validation DataLoader 0:  50%|████████▍        | 78/157 [00:01<00:01, 54.60it/s]\u001b[A\n",
                        "Validation DataLoader 0:  50%|████████▌        | 79/157 [00:01<00:01, 54.64it/s]\u001b[A\n",
                        "Validation DataLoader 0:  51%|████████▋        | 80/157 [00:01<00:01, 54.66it/s]\u001b[A\n",
                        "Validation DataLoader 0:  52%|████████▊        | 81/157 [00:01<00:01, 54.69it/s]\u001b[A\n",
                        "Validation DataLoader 0:  52%|████████▉        | 82/157 [00:01<00:01, 54.72it/s]\u001b[A\n",
                        "Validation DataLoader 0:  53%|████████▉        | 83/157 [00:01<00:01, 54.76it/s]\u001b[A\n",
                        "Validation DataLoader 0:  54%|█████████        | 84/157 [00:01<00:01, 54.79it/s]\u001b[A\n",
                        "Validation DataLoader 0:  54%|█████████▏       | 85/157 [00:01<00:01, 54.82it/s]\u001b[A\n",
                        "Validation DataLoader 0:  55%|█████████▎       | 86/157 [00:01<00:01, 54.86it/s]\u001b[A\n",
                        "Validation DataLoader 0:  55%|█████████▍       | 87/157 [00:01<00:01, 54.89it/s]\u001b[A\n",
                        "Validation DataLoader 0:  56%|█████████▌       | 88/157 [00:01<00:01, 54.92it/s]\u001b[A\n",
                        "Validation DataLoader 0:  57%|█████████▋       | 89/157 [00:01<00:01, 54.95it/s]\u001b[A\n",
                        "Validation DataLoader 0:  57%|█████████▋       | 90/157 [00:01<00:01, 54.97it/s]\u001b[A\n",
                        "Validation DataLoader 0:  58%|█████████▊       | 91/157 [00:01<00:01, 55.00it/s]\u001b[A\n",
                        "Validation DataLoader 0:  59%|█████████▉       | 92/157 [00:01<00:01, 55.03it/s]\u001b[A\n",
                        "Validation DataLoader 0:  59%|██████████       | 93/157 [00:01<00:01, 55.04it/s]\u001b[A\n",
                        "Validation DataLoader 0:  60%|██████████▏      | 94/157 [00:01<00:01, 55.07it/s]\u001b[A\n",
                        "Validation DataLoader 0:  61%|██████████▎      | 95/157 [00:01<00:01, 55.09it/s]\u001b[A\n",
                        "Validation DataLoader 0:  61%|██████████▍      | 96/157 [00:01<00:01, 55.12it/s]\u001b[A\n",
                        "Validation DataLoader 0:  62%|██████████▌      | 97/157 [00:01<00:01, 55.14it/s]\u001b[A\n",
                        "Validation DataLoader 0:  62%|██████████▌      | 98/157 [00:01<00:01, 55.16it/s]\u001b[A\n",
                        "Validation DataLoader 0:  63%|██████████▋      | 99/157 [00:01<00:01, 55.18it/s]\u001b[A\n",
                        "Validation DataLoader 0:  64%|██████████▏     | 100/157 [00:01<00:01, 55.20it/s]\u001b[A\n",
                        "Validation DataLoader 0:  64%|██████████▎     | 101/157 [00:01<00:01, 55.22it/s]\u001b[A\n",
                        "Validation DataLoader 0:  65%|██████████▍     | 102/157 [00:01<00:00, 55.25it/s]\u001b[A\n",
                        "Validation DataLoader 0:  66%|██████████▍     | 103/157 [00:01<00:00, 55.28it/s]\u001b[A\n",
                        "Validation DataLoader 0:  66%|██████████▌     | 104/157 [00:01<00:00, 55.31it/s]\u001b[A\n",
                        "Validation DataLoader 0:  67%|██████████▋     | 105/157 [00:01<00:00, 55.33it/s]\u001b[A\n",
                        "Validation DataLoader 0:  68%|██████████▊     | 106/157 [00:01<00:00, 55.35it/s]\u001b[A\n",
                        "Validation DataLoader 0:  68%|██████████▉     | 107/157 [00:01<00:00, 55.37it/s]\u001b[A\n",
                        "Validation DataLoader 0:  69%|███████████     | 108/157 [00:01<00:00, 55.39it/s]\u001b[A\n",
                        "Validation DataLoader 0:  69%|███████████     | 109/157 [00:01<00:00, 55.41it/s]\u001b[A\n",
                        "Validation DataLoader 0:  70%|███████████▏    | 110/157 [00:01<00:00, 55.43it/s]\u001b[A\n",
                        "Validation DataLoader 0:  71%|███████████▎    | 111/157 [00:02<00:00, 55.45it/s]\u001b[A\n",
                        "Validation DataLoader 0:  71%|███████████▍    | 112/157 [00:02<00:00, 55.47it/s]\u001b[A\n",
                        "Validation DataLoader 0:  72%|███████████▌    | 113/157 [00:02<00:00, 55.49it/s]\u001b[A\n",
                        "Validation DataLoader 0:  73%|███████████▌    | 114/157 [00:02<00:00, 55.51it/s]\u001b[A\n",
                        "Validation DataLoader 0:  73%|███████████▋    | 115/157 [00:02<00:00, 55.54it/s]\u001b[A\n",
                        "Validation DataLoader 0:  74%|███████████▊    | 116/157 [00:02<00:00, 55.56it/s]\u001b[A\n",
                        "Validation DataLoader 0:  75%|███████████▉    | 117/157 [00:02<00:00, 55.58it/s]\u001b[A\n",
                        "Validation DataLoader 0:  75%|████████████    | 118/157 [00:02<00:00, 55.60it/s]\u001b[A\n",
                        "Validation DataLoader 0:  76%|████████████▏   | 119/157 [00:02<00:00, 55.61it/s]\u001b[A\n",
                        "Validation DataLoader 0:  76%|████████████▏   | 120/157 [00:02<00:00, 55.63it/s]\u001b[A\n",
                        "Validation DataLoader 0:  77%|████████████▎   | 121/157 [00:02<00:00, 55.65it/s]\u001b[A\n",
                        "Validation DataLoader 0:  78%|████████████▍   | 122/157 [00:02<00:00, 55.66it/s]\u001b[A\n",
                        "Validation DataLoader 0:  78%|████████████▌   | 123/157 [00:02<00:00, 55.68it/s]\u001b[A\n",
                        "Validation DataLoader 0:  79%|████████████▋   | 124/157 [00:02<00:00, 55.70it/s]\u001b[A\n",
                        "Validation DataLoader 0:  80%|████████████▋   | 125/157 [00:02<00:00, 55.70it/s]\u001b[A\n",
                        "Validation DataLoader 0:  80%|████████████▊   | 126/157 [00:02<00:00, 55.71it/s]\u001b[A\n",
                        "Validation DataLoader 0:  81%|████████████▉   | 127/157 [00:02<00:00, 55.72it/s]\u001b[A\n",
                        "Validation DataLoader 0:  82%|█████████████   | 128/157 [00:02<00:00, 55.73it/s]\u001b[A\n",
                        "Validation DataLoader 0:  82%|█████████████▏  | 129/157 [00:02<00:00, 55.75it/s]\u001b[A\n",
                        "Validation DataLoader 0:  83%|█████████████▏  | 130/157 [00:02<00:00, 55.76it/s]\u001b[A\n",
                        "Validation DataLoader 0:  83%|█████████████▎  | 131/157 [00:02<00:00, 55.78it/s]\u001b[A\n",
                        "Validation DataLoader 0:  84%|█████████████▍  | 132/157 [00:02<00:00, 55.80it/s]\u001b[A\n",
                        "Validation DataLoader 0:  85%|█████████████▌  | 133/157 [00:02<00:00, 55.82it/s]\u001b[A\n",
                        "Validation DataLoader 0:  85%|█████████████▋  | 134/157 [00:02<00:00, 55.83it/s]\u001b[A\n",
                        "Validation DataLoader 0:  86%|█████████████▊  | 135/157 [00:02<00:00, 55.84it/s]\u001b[A\n",
                        "Validation DataLoader 0:  87%|█████████████▊  | 136/157 [00:02<00:00, 55.86it/s]\u001b[A\n",
                        "Validation DataLoader 0:  87%|█████████████▉  | 137/157 [00:02<00:00, 55.87it/s]\u001b[A\n",
                        "Validation DataLoader 0:  88%|██████████████  | 138/157 [00:02<00:00, 55.88it/s]\u001b[A\n",
                        "Validation DataLoader 0:  89%|██████████████▏ | 139/157 [00:02<00:00, 55.90it/s]\u001b[A\n",
                        "Validation DataLoader 0:  89%|██████████████▎ | 140/157 [00:02<00:00, 55.91it/s]\u001b[A\n",
                        "Validation DataLoader 0:  90%|██████████████▎ | 141/157 [00:02<00:00, 55.92it/s]\u001b[A\n",
                        "Validation DataLoader 0:  90%|██████████████▍ | 142/157 [00:02<00:00, 55.94it/s]\u001b[A\n",
                        "Validation DataLoader 0:  91%|██████████████▌ | 143/157 [00:02<00:00, 55.95it/s]\u001b[A\n",
                        "Validation DataLoader 0:  92%|██████████████▋ | 144/157 [00:02<00:00, 55.96it/s]\u001b[A\n",
                        "Validation DataLoader 0:  92%|██████████████▊ | 145/157 [00:02<00:00, 55.98it/s]\u001b[A\n",
                        "Validation DataLoader 0:  93%|██████████████▉ | 146/157 [00:02<00:00, 55.99it/s]\u001b[A\n",
                        "Validation DataLoader 0:  94%|██████████████▉ | 147/157 [00:02<00:00, 56.00it/s]\u001b[A\n",
                        "Validation DataLoader 0:  94%|███████████████ | 148/157 [00:02<00:00, 56.01it/s]\u001b[A\n",
                        "Validation DataLoader 0:  95%|███████████████▏| 149/157 [00:02<00:00, 56.02it/s]\u001b[A\n",
                        "Validation DataLoader 0:  96%|███████████████▎| 150/157 [00:02<00:00, 56.02it/s]\u001b[A\n",
                        "Validation DataLoader 0:  96%|███████████████▍| 151/157 [00:02<00:00, 56.04it/s]\u001b[A\n",
                        "Validation DataLoader 0:  97%|███████████████▍| 152/157 [00:02<00:00, 56.05it/s]\u001b[A\n",
                        "Validation DataLoader 0:  97%|███████████████▌| 153/157 [00:02<00:00, 56.06it/s]\u001b[A\n",
                        "Validation DataLoader 0:  98%|███████████████▋| 154/157 [00:02<00:00, 56.07it/s]\u001b[A\n",
                        "Validation DataLoader 0:  99%|███████████████▊| 155/157 [00:02<00:00, 56.08it/s]\u001b[A\n",
                        "Validation DataLoader 0:  99%|███████████████▉| 156/157 [00:02<00:00, 56.09it/s]\u001b[A\n",
                        "Validation DataLoader 0: 100%|████████████████| 157/157 [00:02<00:00, 56.24it/s]\u001b[A\n",
                        "Epoch 1: 100%|█| 782/782 [00:57<00:00, 13.59it/s, v_num=10, train_acc_step=0.812\u001b[AINFO: `Trainer.fit` stopped: `max_epochs=2` reached.\n",
                        "I0328 09:50:17.732864 140172556609344 rank_zero.py:64] `Trainer.fit` stopped: `max_epochs=2` reached.\n",
                        "Epoch 1: 100%|█| 782/782 [01:00<00:00, 12.99it/s, v_num=10, train_acc_step=0.812\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mFine Tuning Complete\u001b[0m\n",
                        "I0328 09:50:25.864511 140172556609344 fine_tune.py:155] Fine Tuning Complete\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
                        "I0328 09:50:25.874945 140172556609344 quantize.py:171] Converting PyTorch model to ONNX...\n",
                        "/root/anaconda3/envs/mase/lib/python3.11/site-packages/pytorch_quantization/tensor_quant.py:363: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
                        "  if min_amax < 0:\n",
                        "/root/anaconda3/envs/mase/lib/python3.11/site-packages/pytorch_quantization/tensor_quant.py:366: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
                        "  max_bound = torch.tensor((2.0**(num_bits - 1 + int(unsigned))) - 1.0, device=amax.device)\n",
                        "/root/anaconda3/envs/mase/lib/python3.11/site-packages/pytorch_quantization/tensor_quant.py:376: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
                        "  if min_amax <= epsilon:  # Treat amax smaller than minimum representable of fp16 0\n",
                        "/root/anaconda3/envs/mase/lib/python3.11/site-packages/pytorch_quantization/tensor_quant.py:382: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
                        "  if min_amax <= epsilon:\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /root/mase/mase_output/tensorrt/quantization/vgg7_cls_cifar10_2024-03-28/2024-03-28/version_1/model.onnx\u001b[0m\n",
                        "I0328 09:50:36.668042 140172556609344 quantize.py:194] ONNX Conversion Complete. Stored ONNX model to /root/mase/mase_output/tensorrt/quantization/vgg7_cls_cifar10_2024-03-28/2024-03-28/version_1/model.onnx\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
                        "I0328 09:50:36.671018 140172556609344 quantize.py:97] Converting PyTorch model to TensorRT...\n",
                        "[03/28/2024-09:50:45] [TRT] [W] onnx2trt_utils.cpp:374: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /root/mase/mase_output/tensorrt/quantization/vgg7_cls_cifar10_2024-03-28/2024-03-28/version_2/model.trt\u001b[0m\n",
                        "I0328 09:53:46.257610 140172556609344 quantize.py:166] TensorRT Conversion Complete. Stored trt model to /root/mase/mase_output/tensorrt/quantization/vgg7_cls_cifar10_2024-03-28/2024-03-28/version_2/model.trt\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /root/mase/mase_output/tensorrt/quantization/vgg7_cls_cifar10_2024-03-28/2024-03-28/version_3/model.json\u001b[0m\n",
                        "I0328 09:53:46.621903 140172556609344 quantize.py:210] TensorRT Model Summary Exported to /root/mase/mase_output/tensorrt/quantization/vgg7_cls_cifar10_2024-03-28/2024-03-28/version_3/model.json\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on vgg7\u001b[0m\n",
                        "I0328 09:53:46.629899 140172556609344 runtime_analysis.py:309] Starting transformation analysis on vgg7\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
                        "Results vgg7:\n",
                        "+------------------------------+-------------+\n",
                        "|      Metric (Per Batch)      |    Value    |\n",
                        "+------------------------------+-------------+\n",
                        "| Average Validation Accuracy  |   0.92094   |\n",
                        "|      Average Precision       |   0.91981   |\n",
                        "|        Average Recall        |   0.92012   |\n",
                        "|       Average F1 Score       |   0.91983   |\n",
                        "|         Average Loss         |   0.23915   |\n",
                        "|       Average Latency        |  8.8177 ms  |\n",
                        "|   Average GPU Power Usage    |  57.597 W   |\n",
                        "| Inference Energy Consumption | 0.14108 mWh |\n",
                        "+------------------------------+-------------+\u001b[0m\n",
                        "I0328 09:54:01.494776 140172556609344 runtime_analysis.py:437] \n",
                        "Results vgg7:\n",
                        "+------------------------------+-------------+\n",
                        "|      Metric (Per Batch)      |    Value    |\n",
                        "+------------------------------+-------------+\n",
                        "| Average Validation Accuracy  |   0.92094   |\n",
                        "|      Average Precision       |   0.91981   |\n",
                        "|        Average Recall        |   0.92012   |\n",
                        "|       Average F1 Score       |   0.91983   |\n",
                        "|         Average Loss         |   0.23915   |\n",
                        "|       Average Latency        |  8.8177 ms  |\n",
                        "|   Average GPU Power Usage    |  57.597 W   |\n",
                        "| Inference Energy Consumption | 0.14108 mWh |\n",
                        "+------------------------------+-------------+\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /root/mase_output/tensorrt/quantization/vgg7_cls_cifar10_2024-03-28/mase_graph/version_2/model.json\u001b[0m\n",
                        "I0328 09:54:01.497412 140172556609344 runtime_analysis.py:123] Runtime analysis results saved to /root/mase_output/tensorrt/quantization/vgg7_cls_cifar10_2024-03-28/mase_graph/version_2/model.json\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
                        "TensorRT Engine Input/Output Information:\n",
                        "Index | Type    | DataType | Static Shape         | Dynamic Shape        | Name\n",
                        "------|---------|----------|----------------------|----------------------|-----------------------\n",
                        "0     | Input   | FLOAT    | (64, 3, 32, 32)        | (64, 3, 32, 32)        | input\n",
                        "1     | Output  | FLOAT    | (64, 10)               | (64, 10)               | 220\u001b[0m\n",
                        "I0328 09:54:01.709864 140172556609344 runtime_analysis.py:167] \n",
                        "TensorRT Engine Input/Output Information:\n",
                        "Index | Type    | DataType | Static Shape         | Dynamic Shape        | Name\n",
                        "------|---------|----------|----------------------|----------------------|-----------------------\n",
                        "0     | Input   | FLOAT    | (64, 3, 32, 32)        | (64, 3, 32, 32)        | input\n",
                        "1     | Output  | FLOAT    | (64, 10)               | (64, 10)               | 220\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on vgg7-trt_quantized\u001b[0m\n",
                        "I0328 09:54:01.710174 140172556609344 runtime_analysis.py:309] Starting transformation analysis on vgg7-trt_quantized\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
                        "Results vgg7-trt_quantized:\n",
                        "+------------------------------+-------------+\n",
                        "|      Metric (Per Batch)      |    Value    |\n",
                        "+------------------------------+-------------+\n",
                        "| Average Validation Accuracy  |   0.92348   |\n",
                        "|      Average Precision       |   0.9251    |\n",
                        "|        Average Recall        |   0.92436   |\n",
                        "|       Average F1 Score       |   0.92419   |\n",
                        "|         Average Loss         |   0.24202   |\n",
                        "|       Average Latency        |  8.4811 ms  |\n",
                        "|   Average GPU Power Usage    |  51.683 W   |\n",
                        "| Inference Energy Consumption | 0.12176 mWh |\n",
                        "+------------------------------+-------------+\u001b[0m\n",
                        "I0328 09:54:15.276237 140172556609344 runtime_analysis.py:437] \n",
                        "Results vgg7-trt_quantized:\n",
                        "+------------------------------+-------------+\n",
                        "|      Metric (Per Batch)      |    Value    |\n",
                        "+------------------------------+-------------+\n",
                        "| Average Validation Accuracy  |   0.92348   |\n",
                        "|      Average Precision       |   0.9251    |\n",
                        "|        Average Recall        |   0.92436   |\n",
                        "|       Average F1 Score       |   0.92419   |\n",
                        "|         Average Loss         |   0.24202   |\n",
                        "|       Average Latency        |  8.4811 ms  |\n",
                        "|   Average GPU Power Usage    |  51.683 W   |\n",
                        "| Inference Energy Consumption | 0.12176 mWh |\n",
                        "+------------------------------+-------------+\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /root/mase_output/tensorrt/quantization/vgg7_cls_cifar10_2024-03-28/tensorrt/version_0/model.json\u001b[0m\n",
                        "I0328 09:54:15.278630 140172556609344 runtime_analysis.py:123] Runtime analysis results saved to /root/mase_output/tensorrt/quantization/vgg7_cls_cifar10_2024-03-28/tensorrt/version_0/model.json\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mSaved mase graph to /root/mase/mase_output/vgg7_cls_cifar10_2024-03-28/software/transform/transformed_ckpt\u001b[0m\n",
                        "I0328 10:01:15.227788 140172556609344 save_and_load.py:147] Saved mase graph to /root/mase/mase_output/vgg7_cls_cifar10_2024-03-28/software/transform/transformed_ckpt\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mTransformation is completed\u001b[0m\n",
                        "I0328 10:01:15.230174 140172556609344 cli.py:383] Transformation is completed\n"
                    ]
                }
            ],
            "source": [
                "!ch transform --config {VGG_TYPEWISE_TOML} --load {VGG_CHECKPOINT_PATH} --load-type pl"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Section 4. Layer-wise Mixed Precision\n",
                "\n",
                "So far we have strictly quantized either in int8 or fp16. Now, we will show how to conduct layerwise mixed precision using the same `vgg7` model. In this case we will show how for instance, layer 0 and 1 can be set to fp16, while layer 2 and 3 can be int8 quantized. \n",
                "\n",
                "For this, we set:\n",
                "- The `by` parameter to `name`\n",
                "- The `precision` to 'fp16' for `passes.tensorrt_quantize.feature_layers_0.config and passes.tensorrt_quantize.feature_layers_1.config`\n",
                "- The `precision` to 'int8' for `passes.tensorrt_quantize.feature_layers_0.config and passes.tensorrt_quantize.feature_layers_1.config`\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[2024-03-28 11:35:41,094] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\u001b[32mINFO    \u001b[0m \u001b[34mSet logging level to info\u001b[0m\n",
                        "WARNING: Logging before flag parsing goes to stderr.\n",
                        "I0328 11:35:43.486492 139897021998912 logger.py:44] Set logging level to info\n"
                    ]
                }
            ],
            "source": [
                "import sys\n",
                "import os\n",
                "from pathlib import Path\n",
                "import toml\n",
                "from copy import copy, deepcopy\n",
                "\n",
                "# Figure out the correct path\n",
                "machop_path = Path(\".\").resolve().parent.parent.parent /\"machop\"\n",
                "assert machop_path.exists(), \"Failed to find machop at: {}\".format(machop_path)\n",
                "sys.path.append(str(machop_path))\n",
                "\n",
                "# Add directory to the PATH so that chop can be called\n",
                "new_path = \"../../../machop\"\n",
                "full_path = os.path.abspath(new_path)\n",
                "os.environ['PATH'] += os.pathsep + full_path\n",
                "\n",
                "from chop.tools.utils import to_numpy_if_tensor\n",
                "from chop.tools.logger import set_logging_verbosity\n",
                "from chop.tools import get_cf_args, get_dummy_input\n",
                "from chop.passes.graph.utils import deepcopy_mase_graph\n",
                "from chop.tools.get_input import InputGenerator\n",
                "from chop.tools.checkpoint_load import load_model\n",
                "from chop.ir import MaseGraph\n",
                "from chop.models import get_model_info, get_model, get_tokenizer\n",
                "from chop.dataset import MaseDataModule, get_dataset_info\n",
                "from chop.passes.graph.transforms import metadata_value_type_cast_transform_pass\n",
                "from chop.passes.graph import (\n",
                "    summarize_quantization_analysis_pass,\n",
                "    add_common_metadata_analysis_pass,\n",
                "    init_metadata_analysis_pass,\n",
                "    add_software_metadata_analysis_pass,\n",
                "    tensorrt_calibrate_transform_pass,\n",
                "    tensorrt_fake_quantize_transform_pass,\n",
                "    tensorrt_fine_tune_transform_pass,\n",
                "    tensorrt_engine_interface_pass,\n",
                "    runtime_analysis_pass,\n",
                "    )\n",
                "\n",
                "set_logging_verbosity(\"info\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Files already downloaded and verified\n",
                        "Files already downloaded and verified\n",
                        "Files already downloaded and verified\n",
                        "Files already downloaded and verified\n",
                        "Files already downloaded and verified\n",
                        "Files already downloaded and verified\n",
                        "Files already downloaded and verified\n",
                        "Files already downloaded and verified\n"
                    ]
                }
            ],
            "source": [
                "# Path to your TOML file\n",
                "toml_file_path = '../../../machop/configs/tensorrt/vgg7_layerwise_mixed_precision.toml'\n",
                "# toml_file_path = '../../../machop/configs/tensorrt/vgg7_typewise_mixed_precision.toml'\n",
                "\n",
                "# Reading TOML file and converting it into a Python dictionary\n",
                "with open(toml_file_path, 'r') as toml_file:\n",
                "    pass_args = toml.load(toml_file)\n",
                "\n",
                "# Extract the 'passes.tensorrt' section and its children\n",
                "tensorrt_config = pass_args.get('passes', {}).get('tensorrt', {})\n",
                "# Extract the 'passes.runtime_analysis' section and its children\n",
                "runtime_analysis_config = pass_args.get('passes', {}).get('runtime_analysis', {})\n",
                "\n",
                "# Load the basics in\n",
                "model_name = pass_args['model']\n",
                "dataset_name = pass_args['dataset']\n",
                "max_epochs = pass_args['max_epochs']\n",
                "batch_size = pass_args['batch_size']\n",
                "learning_rate = pass_args['learning_rate']\n",
                "accelerator = pass_args['accelerator']\n",
                "\n",
                "data_module = MaseDataModule(\n",
                "    name=dataset_name,\n",
                "    batch_size=batch_size,\n",
                "    model_name=model_name,\n",
                "    num_workers=0,\n",
                ")\n",
                "data_module.prepare_data()\n",
                "data_module.setup()\n",
                "\n",
                "# Add the data_module and other necessary information to the configs\n",
                "configs = [tensorrt_config, runtime_analysis_config]\n",
                "for config in configs:\n",
                "    config['task'] = pass_args['task']\n",
                "    config['dataset'] = pass_args['dataset']\n",
                "    config['batch_size'] = pass_args['batch_size']\n",
                "    config['model'] = pass_args['model']\n",
                "    config['data_module'] = data_module\n",
                "    config['accelerator'] = 'cuda' if pass_args['accelerator'] == 'gpu' else pass_args['accelerator']\n",
                "    if config['accelerator'] == 'gpu':\n",
                "        os.environ['CUDA_MODULE_LOADING'] = 'LAZY'\n",
                "\n",
                "model_info = get_model_info(model_name)\n",
                "model = get_model(\n",
                "    model_name,\n",
                "    task=\"cls\",\n",
                "    dataset_info=data_module.dataset_info,\n",
                "    pretrained=False)\n",
                "\n",
                "input_generator = InputGenerator(\n",
                "    data_module=data_module,\n",
                "    model_info=model_info,\n",
                "    task=\"cls\",\n",
                "    which_dataloader=\"train\",\n",
                ")\n",
                "\n",
                "# generate the mase graph and initialize node metadata\n",
                "mg = MaseGraph(model=model)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from ../../../mase_output/vgg7-pre-trained/test-accu-0.9332.ckpt\u001b[0m\n",
                        "I0328 11:35:50.418819 139897021998912 checkpoint_load.py:85] Loaded pytorch lightning checkpoint from ../../../mase_output/vgg7-pre-trained/test-accu-0.9332.ckpt\n"
                    ]
                }
            ],
            "source": [
                "# Load in the trained checkpoint - change this accordingly\n",
                "VGG_CHECKPOINT_PATH = \"../../../mase_output/vgg7-pre-trained/test-accu-0.9332.ckpt\"\n",
                "\n",
                "model = load_model(load_name=VGG_CHECKPOINT_PATH, load_type=\"pl\", model=model)\n",
                "\n",
                "# Initiate metadata\n",
                "dummy_in = next(iter(input_generator))\n",
                "_ = model(**dummy_in)\n",
                "mg, _ = init_metadata_analysis_pass(mg, None)\n",
                "\n",
                "mg_original = deepcopy_mase_graph(mg)\n",
                "\n",
                "mg, _ = add_common_metadata_analysis_pass(mg, {\"dummy_in\": dummy_in})\n",
                "mg, _ = add_software_metadata_analysis_pass(mg, None)\n",
                "mg, _ = metadata_value_type_cast_transform_pass(mg, pass_args={\"fn\": to_numpy_if_tensor})"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on vgg7\u001b[0m\n",
                        "I0328 10:46:39.331468 139766199060288 runtime_analysis.py:308] Starting transformation analysis on vgg7\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
                        "Results vgg7:\n",
                        "+------------------------------+-------------+\n",
                        "|      Metric (Per Batch)      |    Value    |\n",
                        "+------------------------------+-------------+\n",
                        "|    Average Test Accuracy     |   0.92094   |\n",
                        "|      Average Precision       |   0.91981   |\n",
                        "|        Average Recall        |   0.92012   |\n",
                        "|       Average F1 Score       |   0.91983   |\n",
                        "|         Average Loss         |   0.23915   |\n",
                        "|       Average Latency        |  9.0671 ms  |\n",
                        "|   Average GPU Power Usage    |  49.736 W   |\n",
                        "| Inference Energy Consumption | 0.12527 mWh |\n",
                        "+------------------------------+-------------+\u001b[0m\n",
                        "I0328 10:46:45.046680 139766199060288 runtime_analysis.py:436] \n",
                        "Results vgg7:\n",
                        "+------------------------------+-------------+\n",
                        "|      Metric (Per Batch)      |    Value    |\n",
                        "+------------------------------+-------------+\n",
                        "|    Average Test Accuracy     |   0.92094   |\n",
                        "|      Average Precision       |   0.91981   |\n",
                        "|        Average Recall        |   0.92012   |\n",
                        "|       Average F1 Score       |   0.91983   |\n",
                        "|         Average Loss         |   0.23915   |\n",
                        "|       Average Latency        |  9.0671 ms  |\n",
                        "|   Average GPU Power Usage    |  49.736 W   |\n",
                        "| Inference Energy Consumption | 0.12527 mWh |\n",
                        "+------------------------------+-------------+\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /root/mase_output/tensorrt/quantization/vgg7_cls_cifar10_2024-03-28/mase_graph/version_11/model.json\u001b[0m\n",
                        "I0328 10:46:45.049585 139766199060288 runtime_analysis.py:122] Runtime analysis results saved to /root/mase_output/tensorrt/quantization/vgg7_cls_cifar10_2024-03-28/mase_graph/version_11/model.json\n"
                    ]
                }
            ],
            "source": [
                "_, _ = runtime_analysis_pass(mg_original, pass_args=runtime_analysis_config)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\u001b[32mINFO    \u001b[0m \u001b[34mApplying fake quantization to PyTorch model...\u001b[0m\n",
                        "I0328 11:36:00.189613 139897021998912 utils.py:272] Applying fake quantization to PyTorch model...\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mFake quantization applied to PyTorch model.\u001b[0m\n",
                        "I0328 11:36:01.439067 139897021998912 utils.py:297] Fake quantization applied to PyTorch model.\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mStarting calibration of the model in PyTorch...\u001b[0m\n",
                        "I0328 11:36:01.441239 139897021998912 calibrate.py:142] Starting calibration of the model in PyTorch...\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
                        "I0328 11:36:01.456726 139897021998912 calibrate.py:151] Disabling Quantization and Enabling Calibration\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
                        "I0328 11:36:01.458556 139897021998912 calibrate.py:151] Disabling Quantization and Enabling Calibration\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
                        "I0328 11:36:01.460059 139897021998912 calibrate.py:151] Disabling Quantization and Enabling Calibration\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
                        "I0328 11:36:01.461545 139897021998912 calibrate.py:151] Disabling Quantization and Enabling Calibration\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
                        "I0328 11:36:01.462974 139897021998912 calibrate.py:151] Disabling Quantization and Enabling Calibration\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
                        "I0328 11:36:01.464422 139897021998912 calibrate.py:151] Disabling Quantization and Enabling Calibration\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
                        "I0328 11:36:01.465882 139897021998912 calibrate.py:151] Disabling Quantization and Enabling Calibration\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
                        "I0328 11:36:01.467289 139897021998912 calibrate.py:151] Disabling Quantization and Enabling Calibration\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
                        "I0328 11:36:01.468600 139897021998912 calibrate.py:151] Disabling Quantization and Enabling Calibration\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
                        "I0328 11:36:01.470026 139897021998912 calibrate.py:151] Disabling Quantization and Enabling Calibration\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
                        "I0328 11:36:01.471583 139897021998912 calibrate.py:151] Disabling Quantization and Enabling Calibration\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
                        "I0328 11:36:01.473250 139897021998912 calibrate.py:151] Disabling Quantization and Enabling Calibration\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
                        "I0328 11:36:01.474904 139897021998912 calibrate.py:151] Disabling Quantization and Enabling Calibration\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
                        "I0328 11:36:01.476476 139897021998912 calibrate.py:151] Disabling Quantization and Enabling Calibration\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
                        "I0328 11:36:01.478117 139897021998912 calibrate.py:151] Disabling Quantization and Enabling Calibration\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
                        "I0328 11:36:01.479733 139897021998912 calibrate.py:151] Disabling Quantization and Enabling Calibration\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
                        "I0328 11:36:02.685918 139897021998912 calibrate.py:171] Enabling Quantization and Disabling Calibration\n",
                        "W0328 11:36:02.687668 139897021998912 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
                        "I0328 11:36:02.688413 139897021998912 calibrate.py:171] Enabling Quantization and Disabling Calibration\n",
                        "W0328 11:36:02.689660 139897021998912 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
                        "I0328 11:36:02.690325 139897021998912 calibrate.py:171] Enabling Quantization and Disabling Calibration\n",
                        "W0328 11:36:02.691567 139897021998912 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
                        "I0328 11:36:02.692210 139897021998912 calibrate.py:171] Enabling Quantization and Disabling Calibration\n",
                        "W0328 11:36:02.693594 139897021998912 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
                        "I0328 11:36:02.694253 139897021998912 calibrate.py:171] Enabling Quantization and Disabling Calibration\n",
                        "W0328 11:36:02.695628 139897021998912 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
                        "I0328 11:36:02.696292 139897021998912 calibrate.py:171] Enabling Quantization and Disabling Calibration\n",
                        "W0328 11:36:02.697668 139897021998912 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
                        "I0328 11:36:02.698381 139897021998912 calibrate.py:171] Enabling Quantization and Disabling Calibration\n",
                        "W0328 11:36:02.699742 139897021998912 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
                        "I0328 11:36:02.700532 139897021998912 calibrate.py:171] Enabling Quantization and Disabling Calibration\n",
                        "W0328 11:36:02.702007 139897021998912 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
                        "I0328 11:36:02.702673 139897021998912 calibrate.py:171] Enabling Quantization and Disabling Calibration\n",
                        "W0328 11:36:02.703878 139897021998912 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
                        "I0328 11:36:02.704665 139897021998912 calibrate.py:171] Enabling Quantization and Disabling Calibration\n",
                        "W0328 11:36:02.706094 139897021998912 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
                        "I0328 11:36:02.706766 139897021998912 calibrate.py:171] Enabling Quantization and Disabling Calibration\n",
                        "W0328 11:36:02.708078 139897021998912 tensor_quantizer.py:174] Disable MaxCalibrator\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
                        "I0328 11:36:02.708723 139897021998912 calibrate.py:171] Enabling Quantization and Disabling Calibration\n",
                        "W0328 11:36:02.710057 139897021998912 tensor_quantizer.py:174] Disable MaxCalibrator\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
                        "I0328 11:36:02.710710 139897021998912 calibrate.py:171] Enabling Quantization and Disabling Calibration\n",
                        "W0328 11:36:02.712025 139897021998912 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
                        "I0328 11:36:02.712815 139897021998912 calibrate.py:171] Enabling Quantization and Disabling Calibration\n",
                        "W0328 11:36:02.714131 139897021998912 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
                        "I0328 11:36:02.714833 139897021998912 calibrate.py:171] Enabling Quantization and Disabling Calibration\n",
                        "W0328 11:36:02.716313 139897021998912 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
                        "I0328 11:36:02.717008 139897021998912 calibrate.py:171] Enabling Quantization and Disabling Calibration\n",
                        "W0328 11:36:02.718350 139897021998912 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
                        "W0328 11:36:02.727974 139897021998912 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "W0328 11:36:02.728621 139897021998912 tensor_quantizer.py:239] Call .cuda() if running on GPU after loading calibrated amax.\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.3._input_quantizer       : TensorQuantizer(8bit fake per-tensor amax=3.3024 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 11:36:02.729475 139897021998912 calibrate.py:130] feature_layers.3._input_quantizer       : TensorQuantizer(8bit fake per-tensor amax=3.3024 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "W0328 11:36:02.731342 139897021998912 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.3._weight_quantizer      : TensorQuantizer(8bit fake per-tensor amax=0.2366 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 11:36:02.731979 139897021998912 calibrate.py:130] feature_layers.3._weight_quantizer      : TensorQuantizer(8bit fake per-tensor amax=0.2366 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "W0328 11:36:02.734633 139897021998912 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.7._input_quantizer       : TensorQuantizer(8bit fake per-tensor amax=1.8338 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 11:36:02.735312 139897021998912 calibrate.py:130] feature_layers.7._input_quantizer       : TensorQuantizer(8bit fake per-tensor amax=1.8338 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "W0328 11:36:02.737290 139897021998912 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.7._weight_quantizer      : TensorQuantizer(8bit fake per-tensor amax=0.2296 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 11:36:02.737948 139897021998912 calibrate.py:130] feature_layers.7._weight_quantizer      : TensorQuantizer(8bit fake per-tensor amax=0.2296 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "W0328 11:36:02.740001 139897021998912 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.10._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=1.4711 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 11:36:02.740665 139897021998912 calibrate.py:130] feature_layers.10._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=1.4711 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "W0328 11:36:02.744047 139897021998912 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.10._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.2080 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 11:36:02.744734 139897021998912 calibrate.py:130] feature_layers.10._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.2080 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "W0328 11:36:02.747157 139897021998912 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.14._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=1.9255 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 11:36:02.747869 139897021998912 calibrate.py:130] feature_layers.14._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=1.9255 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "W0328 11:36:02.750152 139897021998912 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.14._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.2013 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 11:36:02.750873 139897021998912 calibrate.py:130] feature_layers.14._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.2013 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "W0328 11:36:02.753345 139897021998912 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.17._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=1.6132 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 11:36:02.754069 139897021998912 calibrate.py:130] feature_layers.17._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=1.6132 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "W0328 11:36:02.756330 139897021998912 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.17._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.1879 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 11:36:02.757028 139897021998912 calibrate.py:130] feature_layers.17._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.1879 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "W0328 11:36:02.758451 139897021998912 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mclassifier.0._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=12.3067 calibrator=MaxCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 11:36:02.759540 139897021998912 calibrate.py:130] classifier.0._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=12.3067 calibrator=MaxCalibrator scale=1.0 quant)\n",
                        "W0328 11:36:02.760859 139897021998912 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([1024, 1]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mclassifier.0._weight_quantizer          : TensorQuantizer(8bit fake axis=0 amax=[0.0158, 0.4703](1024) calibrator=MaxCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 11:36:02.763098 139897021998912 calibrate.py:130] classifier.0._weight_quantizer          : TensorQuantizer(8bit fake axis=0 amax=[0.0158, 0.4703](1024) calibrator=MaxCalibrator scale=1.0 quant)\n",
                        "W0328 11:36:02.765289 139897021998912 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mclassifier.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=9.7691 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 11:36:02.766043 139897021998912 calibrate.py:130] classifier.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=9.7691 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "W0328 11:36:02.768385 139897021998912 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mclassifier.2._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.0590 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 11:36:02.769151 139897021998912 calibrate.py:130] classifier.2._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.0590 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "W0328 11:36:02.771540 139897021998912 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mlast_layer._input_quantizer             : TensorQuantizer(8bit fake per-tensor amax=7.4315 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 11:36:02.772288 139897021998912 calibrate.py:130] last_layer._input_quantizer             : TensorQuantizer(8bit fake per-tensor amax=7.4315 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "W0328 11:36:02.774654 139897021998912 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mlast_layer._weight_quantizer            : TensorQuantizer(8bit fake per-tensor amax=0.1019 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 11:36:02.775399 139897021998912 calibrate.py:130] last_layer._weight_quantizer            : TensorQuantizer(8bit fake per-tensor amax=0.1019 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mPerforming post calibration analysis for calibrator percentile_99.0...\u001b[0m\n",
                        "I0328 11:36:02.779210 139897021998912 calibrate.py:104] Performing post calibration analysis for calibrator percentile_99.0...\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on vgg7\u001b[0m\n",
                        "I0328 11:36:02.781507 139897021998912 runtime_analysis.py:308] Starting transformation analysis on vgg7\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
                        "Results vgg7:\n",
                        "+------------------------------+-------------+\n",
                        "|      Metric (Per Batch)      |    Value    |\n",
                        "+------------------------------+-------------+\n",
                        "|    Average Test Accuracy     |   0.87673   |\n",
                        "|      Average Precision       |   0.87543   |\n",
                        "|        Average Recall        |   0.87397   |\n",
                        "|       Average F1 Score       |   0.87343   |\n",
                        "|         Average Loss         |    0.651    |\n",
                        "|       Average Latency        |  20.994 ms  |\n",
                        "|   Average GPU Power Usage    |  31.838 W   |\n",
                        "| Inference Energy Consumption | 0.18567 mWh |\n",
                        "+------------------------------+-------------+\u001b[0m\n",
                        "I0328 11:36:11.394050 139897021998912 runtime_analysis.py:436] \n",
                        "Results vgg7:\n",
                        "+------------------------------+-------------+\n",
                        "|      Metric (Per Batch)      |    Value    |\n",
                        "+------------------------------+-------------+\n",
                        "|    Average Test Accuracy     |   0.87673   |\n",
                        "|      Average Precision       |   0.87543   |\n",
                        "|        Average Recall        |   0.87397   |\n",
                        "|       Average F1 Score       |   0.87343   |\n",
                        "|         Average Loss         |    0.651    |\n",
                        "|       Average Latency        |  20.994 ms  |\n",
                        "|   Average GPU Power Usage    |  31.838 W   |\n",
                        "| Inference Energy Consumption | 0.18567 mWh |\n",
                        "+------------------------------+-------------+\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /root/mase_output/tensorrt/quantization/vgg7_cls_cifar10_2024-03-28/mase_graph/version_14/model.json\u001b[0m\n",
                        "I0328 11:36:11.397661 139897021998912 runtime_analysis.py:122] Runtime analysis results saved to /root/mase_output/tensorrt/quantization/vgg7_cls_cifar10_2024-03-28/mase_graph/version_14/model.json\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mPost calibration analysis complete.\u001b[0m\n",
                        "I0328 11:36:11.398979 139897021998912 calibrate.py:117] Post calibration analysis complete.\n",
                        "W0328 11:36:11.401443 139897021998912 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.3._input_quantizer       : TensorQuantizer(8bit fake per-tensor amax=5.9479 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 11:36:11.403746 139897021998912 calibrate.py:130] feature_layers.3._input_quantizer       : TensorQuantizer(8bit fake per-tensor amax=5.9479 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "W0328 11:36:11.405590 139897021998912 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.3._weight_quantizer      : TensorQuantizer(8bit fake per-tensor amax=0.3704 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 11:36:11.406314 139897021998912 calibrate.py:130] feature_layers.3._weight_quantizer      : TensorQuantizer(8bit fake per-tensor amax=0.3704 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "W0328 11:36:11.407751 139897021998912 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.7._input_quantizer       : TensorQuantizer(8bit fake per-tensor amax=3.2686 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 11:36:11.408517 139897021998912 calibrate.py:130] feature_layers.7._input_quantizer       : TensorQuantizer(8bit fake per-tensor amax=3.2686 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "W0328 11:36:11.409907 139897021998912 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.7._weight_quantizer      : TensorQuantizer(8bit fake per-tensor amax=0.3621 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 11:36:11.410660 139897021998912 calibrate.py:130] feature_layers.7._weight_quantizer      : TensorQuantizer(8bit fake per-tensor amax=0.3621 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "W0328 11:36:11.412127 139897021998912 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.10._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=2.4184 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 11:36:11.412849 139897021998912 calibrate.py:130] feature_layers.10._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=2.4184 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "W0328 11:36:11.414228 139897021998912 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.10._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.2821 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 11:36:11.414968 139897021998912 calibrate.py:130] feature_layers.10._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.2821 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "W0328 11:36:11.416383 139897021998912 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.14._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=2.9915 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 11:36:11.417110 139897021998912 calibrate.py:130] feature_layers.14._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=2.9915 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "W0328 11:36:11.418494 139897021998912 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.14._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.2734 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 11:36:11.419200 139897021998912 calibrate.py:130] feature_layers.14._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.2734 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "W0328 11:36:11.420607 139897021998912 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.17._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=2.7140 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 11:36:11.421372 139897021998912 calibrate.py:130] feature_layers.17._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=2.7140 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "W0328 11:36:11.422717 139897021998912 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.17._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.2519 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 11:36:11.423501 139897021998912 calibrate.py:130] feature_layers.17._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.2519 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "W0328 11:36:11.424525 139897021998912 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mclassifier.0._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=12.3067 calibrator=MaxCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 11:36:11.425435 139897021998912 calibrate.py:130] classifier.0._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=12.3067 calibrator=MaxCalibrator scale=1.0 quant)\n",
                        "W0328 11:36:11.426414 139897021998912 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([1024, 1]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mclassifier.0._weight_quantizer          : TensorQuantizer(8bit fake axis=0 amax=[0.0158, 0.4703](1024) calibrator=MaxCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 11:36:11.427383 139897021998912 calibrate.py:130] classifier.0._weight_quantizer          : TensorQuantizer(8bit fake axis=0 amax=[0.0158, 0.4703](1024) calibrator=MaxCalibrator scale=1.0 quant)\n",
                        "W0328 11:36:11.428821 139897021998912 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mclassifier.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=37.6017 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 11:36:11.429557 139897021998912 calibrate.py:130] classifier.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=37.6017 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "W0328 11:36:11.431090 139897021998912 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mclassifier.2._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.1175 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 11:36:11.431839 139897021998912 calibrate.py:130] classifier.2._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.1175 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "W0328 11:36:11.433268 139897021998912 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mlast_layer._input_quantizer             : TensorQuantizer(8bit fake per-tensor amax=19.0007 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 11:36:11.434005 139897021998912 calibrate.py:130] last_layer._input_quantizer             : TensorQuantizer(8bit fake per-tensor amax=19.0007 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "W0328 11:36:11.435397 139897021998912 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mlast_layer._weight_quantizer            : TensorQuantizer(8bit fake per-tensor amax=0.1626 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
                        "I0328 11:36:11.436123 139897021998912 calibrate.py:130] last_layer._weight_quantizer            : TensorQuantizer(8bit fake per-tensor amax=0.1626 calibrator=HistogramCalibrator scale=1.0 quant)\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mPerforming post calibration analysis for calibrator percentile_99.9...\u001b[0m\n",
                        "I0328 11:36:11.438119 139897021998912 calibrate.py:104] Performing post calibration analysis for calibrator percentile_99.9...\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on vgg7\u001b[0m\n",
                        "I0328 11:36:11.439184 139897021998912 runtime_analysis.py:308] Starting transformation analysis on vgg7\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
                        "Results vgg7:\n",
                        "+------------------------------+-------------+\n",
                        "|      Metric (Per Batch)      |    Value    |\n",
                        "+------------------------------+-------------+\n",
                        "| Average Validation Accuracy  |   0.92128   |\n",
                        "|      Average Precision       |   0.92004   |\n",
                        "|        Average Recall        |   0.92032   |\n",
                        "|       Average F1 Score       |   0.91999   |\n",
                        "|         Average Loss         |   0.24018   |\n",
                        "|       Average Latency        |  21.239 ms  |\n",
                        "|   Average GPU Power Usage    |  32.335 W   |\n",
                        "| Inference Energy Consumption | 0.19076 mWh |\n",
                        "+------------------------------+-------------+\u001b[0m\n",
                        "I0328 11:36:19.980949 139897021998912 runtime_analysis.py:436] \n",
                        "Results vgg7:\n",
                        "+------------------------------+-------------+\n",
                        "|      Metric (Per Batch)      |    Value    |\n",
                        "+------------------------------+-------------+\n",
                        "| Average Validation Accuracy  |   0.92128   |\n",
                        "|      Average Precision       |   0.92004   |\n",
                        "|        Average Recall        |   0.92032   |\n",
                        "|       Average F1 Score       |   0.91999   |\n",
                        "|         Average Loss         |   0.24018   |\n",
                        "|       Average Latency        |  21.239 ms  |\n",
                        "|   Average GPU Power Usage    |  32.335 W   |\n",
                        "| Inference Energy Consumption | 0.19076 mWh |\n",
                        "+------------------------------+-------------+\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /root/mase_output/tensorrt/quantization/vgg7_cls_cifar10_2024-03-28/mase_graph/version_15/model.json\u001b[0m\n",
                        "I0328 11:36:19.987492 139897021998912 runtime_analysis.py:122] Runtime analysis results saved to /root/mase_output/tensorrt/quantization/vgg7_cls_cifar10_2024-03-28/mase_graph/version_15/model.json\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mPost calibration analysis complete.\u001b[0m\n",
                        "I0328 11:36:19.989494 139897021998912 calibrate.py:117] Post calibration analysis complete.\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mSucceeded in calibrating the model in PyTorch!\u001b[0m\n",
                        "I0328 11:36:19.991356 139897021998912 calibrate.py:209] Succeeded in calibrating the model in PyTorch!\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
                        "I0328 11:36:19.999619 139897021998912 quantize.py:180] Converting PyTorch model to ONNX...\n",
                        "/root/anaconda3/envs/mase/lib/python3.11/site-packages/pytorch_quantization/tensor_quant.py:363: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
                        "  if min_amax < 0:\n",
                        "/root/anaconda3/envs/mase/lib/python3.11/site-packages/pytorch_quantization/tensor_quant.py:366: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
                        "  max_bound = torch.tensor((2.0**(num_bits - 1 + int(unsigned))) - 1.0, device=amax.device)\n",
                        "/root/anaconda3/envs/mase/lib/python3.11/site-packages/pytorch_quantization/tensor_quant.py:376: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
                        "  if min_amax <= epsilon:  # Treat amax smaller than minimum representable of fp16 0\n",
                        "/root/anaconda3/envs/mase/lib/python3.11/site-packages/pytorch_quantization/tensor_quant.py:382: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
                        "  if min_amax <= epsilon:\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /root/mase/mase_output/tensorrt/quantization/vgg7_cls_cifar10_2024-03-28/2024-03-28/version_13/model.onnx\u001b[0m\n",
                        "I0328 11:36:21.205467 139897021998912 quantize.py:203] ONNX Conversion Complete. Stored ONNX model to /root/mase/mase_output/tensorrt/quantization/vgg7_cls_cifar10_2024-03-28/2024-03-28/version_13/model.onnx\n",
                        "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
                        "I0328 11:36:21.209562 139897021998912 quantize.py:97] Converting PyTorch model to TensorRT...\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[03/28/2024-11:36:28] [TRT] [W] onnx2trt_utils.cpp:374: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\n",
                        "[03/28/2024-11:37:41] [TRT] [E] 4: [network.cpp::validate::3041] Error Code 4: Internal Error (Int8 precision has been set for a layer or layer output, but int8 is not configured in the builder)\n"
                    ]
                }
            ],
            "source": [
                "mg, _ = tensorrt_fake_quantize_transform_pass(mg, pass_args=tensorrt_config)\n",
                "# summarize_quantization_analysis_pass(mg_original, mg)\n",
                "mg, _ = tensorrt_calibrate_transform_pass(mg, pass_args=tensorrt_config)\n",
                "# mg, _ = tensorrt_fine_tune_transform_pass(mg, pass_args=tensorrt_config)\n",
                "mg, meta = tensorrt_engine_interface_pass(mg, pass_args=tensorrt_config)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Traceback (most recent call last):\n",
                        "  File \"_pydevd_bundle/pydevd_cython.pyx\", line 577, in _pydevd_bundle.pydevd_cython.PyDBFrame._handle_exception\n",
                        "  File \"_pydevd_bundle/pydevd_cython.pyx\", line 312, in _pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\n",
                        "  File \"/root/anaconda3/envs/mase/lib/python3.11/site-packages/debugpy/_vendored/pydevd/pydevd.py\", line 2070, in do_wait_suspend\n",
                        "    keep_suspended = self._do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\n",
                        "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
                        "  File \"/root/anaconda3/envs/mase/lib/python3.11/site-packages/debugpy/_vendored/pydevd/pydevd.py\", line 2106, in _do_wait_suspend\n",
                        "    time.sleep(0.01)\n",
                        "KeyboardInterrupt\n"
                    ]
                },
                {
                    "ename": "NameError",
                    "evalue": "name 'meta' is not defined",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m _, _ \u001b[38;5;241m=\u001b[39m runtime_analysis_pass(\u001b[43mmeta\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrt_engine_path\u001b[39m\u001b[38;5;124m'\u001b[39m], pass_args\u001b[38;5;241m=\u001b[39mruntime_analysis_config)\n",
                        "\u001b[0;31mNameError\u001b[0m: name 'meta' is not defined"
                    ]
                }
            ],
            "source": [
                "_, _ = runtime_analysis_pass(meta['trt_engine_path'], pass_args=runtime_analysis_config)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Section 5. Language Models"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Path to your TOML file\n",
                "toml_file_path = '../../../machop/configs/tensorrt/opt-125M_layerwise_mixed_precision_by_name.toml'\n",
                "\n",
                "# Reading TOML file and converting it into a Python dictionary\n",
                "with open(toml_file_path, 'r') as toml_file:\n",
                "    pass_args = toml.load(toml_file)\n",
                "\n",
                "# Extract the 'passes.tensorrt' section and its children\n",
                "tensorrt_config = pass_args.get('passes', {}).get('tensorrt', {})\n",
                "# Extract the 'passes.runtime_analysis' section and its children\n",
                "runtime_analysis_config = pass_args.get('passes', {}).get('runtime_analysis', {})\n",
                "\n",
                "# Load the basics in\n",
                "model_name = pass_args['model']\n",
                "dataset_name = pass_args['dataset']\n",
                "max_epochs = pass_args['max_epochs']\n",
                "batch_size = pass_args['batch_size']\n",
                "learning_rate = pass_args['learning_rate']\n",
                "accelerator = pass_args['accelerator']\n",
                "\n",
                "opt_tokenizer = get_tokenizer(\"facebook/opt-125m\")\n",
                "\n",
                "data_module = MaseDataModule(\n",
                "    name=dataset_name,\n",
                "    batch_size=batch_size,\n",
                "    model_name=model_name,\n",
                "    num_workers=0, # os.cpu_count()\n",
                "    max_token_len=128,\n",
                "    tokenizer=opt_tokenizer,\n",
                "    load_from_cache_file=True,\n",
                ")\n",
                "data_module.prepare_data()\n",
                "data_module.setup()\n",
                "\n",
                "# Add the data_module and other necessary information to the configs\n",
                "configs = [tensorrt_config, runtime_analysis_config]\n",
                "for config in configs:\n",
                "    config['task'] = pass_args['task']\n",
                "    config['batch_size'] = pass_args['batch_size']\n",
                "    config['model'] = pass_args['model']\n",
                "    config['data_module'] = data_module\n",
                "    config['accelerator'] = 'cuda' if pass_args['accelerator'] == 'gpu' else pass_args['accelerator']\n",
                "    if config['accelerator'] == 'gpu':\n",
                "        os.environ['CUDA_MODULE_LOADING'] = 'LAZY'"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "model_info = get_model_info(model_name)\n",
                "model = get_model(\n",
                "    \"facebook/opt-125m:patched\",\n",
                "    task=\"lm\",\n",
                "    dataset_info=get_dataset_info(\"wikitext2\"),\n",
                "    pretrained=True,\n",
                ")\n",
                "\n",
                "# Load in the trained checkpoint - change this accordingly\n",
                "# OPT125M_CHECKPOINT_PATH = \"../../../mase_output/jsc-toy_classification_jsc_2024-03-17/software/training_ckpts/best.ckpt\"\n",
                "# model = load_model(load_name=OPT125M_CHECKPOINT_PATH, load_type=\"pl\", model=model)\n",
                "\n",
                "model_info = get_model_info(\"facebook/opt-125m:patched\")\n",
                "cf_args = get_cf_args(model_info=model_info, task=\"lm\", model=model)\n",
                "\n",
                "mg = MaseGraph(model=model, cf_args=cf_args)\n",
                "\n",
                "# dummy_in = get_dummy_input(model_info, data_module=data_module, task=\"lm\")\n",
                "# if len(mg.model.additional_inputs) > 0:\n",
                "#     dummy_in = dummy_in | mg.model.additional_inputs\n",
                "\n",
                "# Initiate metadata\n",
                "mg, _ = init_metadata_analysis_pass(mg, pass_args=None)\n",
                "\n",
                "# # Before we begin, we will copy the original MaseGraph model to use for comparison during quantization analysis\n",
                "# mg_original = deepcopy_mase_graph(mg)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# _, _ = runtime_analysis_pass(mg, pass_args=runtime_analysis_config)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
                        "I0318 08:54:47.010779 139760749061952 quantize.py:129] Converting PyTorch model to ONNX...\n",
                        "ERROR:tornado.general:SEND Error: Host unreachable\n",
                        "Traceback (most recent call last):\n",
                        "  File \"_pydevd_bundle/pydevd_cython.pyx\", line 577, in _pydevd_bundle.pydevd_cython.PyDBFrame._handle_exception\n",
                        "  File \"_pydevd_bundle/pydevd_cython.pyx\", line 312, in _pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\n",
                        "  File \"/opt/conda/envs/mase/lib/python3.11/site-packages/debugpy/_vendored/pydevd/pydevd.py\", line 2070, in do_wait_suspend\n",
                        "    keep_suspended = self._do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\n",
                        "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
                        "  File \"/opt/conda/envs/mase/lib/python3.11/site-packages/debugpy/_vendored/pydevd/pydevd.py\", line 2106, in _do_wait_suspend\n",
                        "    time.sleep(0.01)\n",
                        "KeyboardInterrupt\n"
                    ]
                }
            ],
            "source": [
                "# mg, _ = tensorrt_fake_quantize_transform_pass(mg, pass_args=tensorrt_config)\n",
                "# summarize_quantization_analysis_pass(mg_original, mg)\n",
                "\n",
                "# mg, _ = tensorrt_calibrate_transform_pass(mg, pass_args=tensorrt_config)\n",
                "\n",
                "# mg, _ = tensorrt_fine_tune_transform_pass(mg, pass_args=tensorrt_config)\n",
                "\n",
                "mg, meta = tensorrt_engine_interface_pass(mg, pass_args=tensorrt_config)\n",
                "\n",
                "_, _ = runtime_analysis_pass(mg_original, pass_args=runtime_analysis_config)\n",
                "_, _ = runtime_analysis_pass(meta['trt_engine_path'], pass_args=runtime_analysis_config)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "mase",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.4"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
