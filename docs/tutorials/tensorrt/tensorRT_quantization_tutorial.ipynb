{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome To the TensorRT Quantization Tutorial!\n",
    "\n",
    "This notebook is designed to show the features of the TensorRT passes integrated into MASE.\n",
    "\n",
    "## Section 1. INT8 Quantization\n",
    "Firstly, we will show you how to do a INT8 quantization of a simple model, `jsc-toy`, and compare the quantized model to the original model using the `Machop API`. The quantization process is split into the following stages, each using their own individual pass, and are explained in depth at each subsection:\n",
    "\n",
    "1. [Fake quantization](#section-11-fake-quantization): `tensorrt_fake_quantize_transform_pass`\n",
    "2. [Calibration](#sect): `tensorrt_calibrate_transform_pass`\n",
    "3. [Quantized Aware Training](#quantized-aware-training): `tensorrt_fine_tune_transform_pass`\n",
    "4. [Quantization](#quantization): `tensorrt_engine_interface_pass`\n",
    "5. [Analysis](#analysis): `tensorrt_analysis_pass`\n",
    "\n",
    "We start by loading in the required libraries and passes required for the notebook as well as ensuring the correct path is set for machop to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mSet logging level to info\u001b[0m\n",
      "I0318 13:21:49.075905 139755614467904 logger.py:44] Set logging level to info\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import toml\n",
    "from copy import copy, deepcopy\n",
    "\n",
    "# Figure out the correct path\n",
    "machop_path = Path(\".\").resolve().parent.parent.parent /\"machop\"\n",
    "assert machop_path.exists(), \"Failed to find machop at: {}\".format(machop_path)\n",
    "sys.path.append(str(machop_path))\n",
    "\n",
    "# Add directory to the PATH so that chop can be called\n",
    "new_path = \"../../../machop\"\n",
    "full_path = os.path.abspath(new_path)\n",
    "os.environ['PATH'] += os.pathsep + full_path\n",
    "\n",
    "from chop.tools.utils import to_numpy_if_tensor\n",
    "from chop.tools.logger import set_logging_verbosity\n",
    "from chop.tools import get_cf_args, get_dummy_input\n",
    "from chop.passes.graph.utils import deepcopy_mase_graph\n",
    "from chop.tools.get_input import InputGenerator\n",
    "from chop.tools.checkpoint_load import load_model\n",
    "from chop.ir import MaseGraph\n",
    "from chop.models import get_model_info, get_model, get_tokenizer\n",
    "from chop.dataset import MaseDataModule, get_dataset_info\n",
    "from chop.passes.graph.transforms import metadata_value_type_cast_transform_pass\n",
    "from chop.passes.graph import (\n",
    "    summarize_quantization_analysis_pass,\n",
    "    add_common_metadata_analysis_pass,\n",
    "    init_metadata_analysis_pass,\n",
    "    add_software_metadata_analysis_pass,\n",
    "    tensorrt_calibrate_transform_pass,\n",
    "    tensorrt_fake_quantize_transform_pass,\n",
    "    tensorrt_fine_tune_transform_pass,\n",
    "    tensorrt_engine_interface_pass,\n",
    "    tensorrt_analysis_pass,\n",
    "    )\n",
    "\n",
    "set_logging_verbosity(\"info\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we load in the toml file used for quantization. To view the configuration, click [here](../../machop/configs/tensorrt/jsc_toy_INT8_quantization_by_type.toml), or read the documentation on Mase [here]()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your TOML file\n",
    "toml_file_path = '../../../machop/configs/tensorrt/jsc_toy_INT8_quantization_by_type.toml'\n",
    "\n",
    "# Reading TOML file and converting it into a Python dictionary\n",
    "with open(toml_file_path, 'r') as toml_file:\n",
    "    pass_args = toml.load(toml_file)\n",
    "\n",
    "# Extract the 'passes.tensorrt_quantize' section and its children\n",
    "tensorrt_quantize_config = pass_args.get('passes', {}).get('tensorrt_quantize', {})\n",
    "# Extract the 'passes.tensorrt_analysis' section and its children\n",
    "tensorrt_analysis_config = pass_args.get('passes', {}).get('tensorrt_analysis', {})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then create a `MaseGraph` by loading in a model and training it using the toml configuration model arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the basics in\n",
    "model_name = pass_args['model']\n",
    "dataset_name = pass_args['dataset']\n",
    "max_epochs = pass_args['max_epochs']\n",
    "batch_size = pass_args['batch_size']\n",
    "learning_rate = pass_args['learning_rate']\n",
    "accelerator = pass_args['accelerator']\n",
    "\n",
    "data_module = MaseDataModule(\n",
    "    name=dataset_name,\n",
    "    batch_size=batch_size,\n",
    "    model_name=model_name,\n",
    "    num_workers=0,\n",
    ")\n",
    "data_module.prepare_data()\n",
    "data_module.setup()\n",
    "\n",
    "# Add the data_module and other necessary information to the configs\n",
    "configs = [tensorrt_quantize_config, tensorrt_analysis_config]\n",
    "for config in configs:\n",
    "    config['task'] = pass_args['task']\n",
    "    config['batch_size'] = pass_args['batch_size']\n",
    "    config['model'] = pass_args['model']\n",
    "    config['data_module'] = data_module\n",
    "    config['accelerator'] = 'cuda' if pass_args['accelerator'] == 'gpu' else pass_args['accelerator']\n",
    "    if config['accelerator'] == 'gpu':\n",
    "        os.environ['CUDA_MODULE_LOADING'] = 'LAZY'\n",
    "\n",
    "model_info = get_model_info(model_name)\n",
    "# quant_modules.initialize()\n",
    "model = get_model(\n",
    "    model_name,\n",
    "    task=\"cls\",\n",
    "    dataset_info=data_module.dataset_info,\n",
    "    pretrained=False)\n",
    "\n",
    "\n",
    "input_generator = InputGenerator(\n",
    "    data_module=data_module,\n",
    "    model_info=model_info,\n",
    "    task=\"cls\",\n",
    "    which_dataloader=\"train\",\n",
    ")\n",
    "\n",
    "# generate the mase graph and initialize node metadata\n",
    "mg = MaseGraph(model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we train the `jsc-toy` model using the machop `train` action with the config from the toml file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-18 11:44:36,191] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "INFO: Seed set to 0\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0318 11:44:37.795595 139634499045184 seed.py:54] Seed set to 0\n",
      "+-------------------------+------------------------+--------------+-----------------+------------------------+\n",
      "| Name                    |        Default         | Config. File | Manual Override |       Effective        |\n",
      "+-------------------------+------------------------+--------------+-----------------+------------------------+\n",
      "| task                    |     \u001b[38;5;8mclassification\u001b[0m     |     cls      |                 |          cls           |\n",
      "| load_name               |          None          |              |                 |          None          |\n",
      "| load_type               |           mz           |              |                 |           mz           |\n",
      "| batch_size              |          \u001b[38;5;8m128\u001b[0m           |     256      |                 |          256           |\n",
      "| to_debug                |         False          |              |                 |         False          |\n",
      "| log_level               |          info          |              |                 |          info          |\n",
      "| report_to               |      tensorboard       |              |                 |      tensorboard       |\n",
      "| seed                    |           0            |              |                 |           0            |\n",
      "| quant_config            |          None          |              |                 |          None          |\n",
      "| training_optimizer      |          adam          |              |                 |          adam          |\n",
      "| trainer_precision       |        16-mixed        |              |                 |        16-mixed        |\n",
      "| learning_rate           |         \u001b[38;5;8m1e-05\u001b[0m          |    0.001     |                 |         0.001          |\n",
      "| weight_decay            |           0            |              |                 |           0            |\n",
      "| max_epochs              |           \u001b[38;5;8m20\u001b[0m           |      10      |                 |           10           |\n",
      "| max_steps               |           -1           |              |                 |           -1           |\n",
      "| accumulate_grad_batches |           1            |              |                 |           1            |\n",
      "| log_every_n_steps       |           50           |              |                 |           50           |\n",
      "| num_workers             |           32           |              |                 |           32           |\n",
      "| num_devices             |           1            |              |                 |           1            |\n",
      "| num_nodes               |           1            |              |                 |           1            |\n",
      "| accelerator             |          \u001b[38;5;8mauto\u001b[0m          |     gpu      |                 |          gpu           |\n",
      "| strategy                |          auto          |              |                 |          auto          |\n",
      "| is_to_auto_requeue      |         False          |              |                 |         False          |\n",
      "| github_ci               |         False          |              |                 |         False          |\n",
      "| disable_dataset_cache   |         False          |              |                 |         False          |\n",
      "| target                  |  xcu250-figd2104-2L-e  |              |                 |  xcu250-figd2104-2L-e  |\n",
      "| num_targets             |          100           |              |                 |          100           |\n",
      "| is_pretrained           |         False          |              |                 |         False          |\n",
      "| max_token_len           |          512           |              |                 |          512           |\n",
      "| project_dir             | /root/mase/mase_output |              |                 | /root/mase/mase_output |\n",
      "| project                 |          None          |              |                 |          None          |\n",
      "| model                   |          \u001b[38;5;8mNone\u001b[0m          |   jsc-toy    |                 |        jsc-toy         |\n",
      "| dataset                 |          \u001b[38;5;8mNone\u001b[0m          |     jsc      |                 |          jsc           |\n",
      "| t_max                   |           20           |              |                 |           20           |\n",
      "| eta_min                 |         1e-06          |              |                 |         1e-06          |\n",
      "+-------------------------+------------------------+--------------+-----------------+------------------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mInitialising model 'jsc-toy'...\u001b[0m\n",
      "I0318 11:44:37.804295 139634499045184 cli.py:841] Initialising model 'jsc-toy'...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mInitialising dataset 'jsc'...\u001b[0m\n",
      "I0318 11:44:37.828583 139634499045184 cli.py:869] Initialising dataset 'jsc'...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mProject will be created at /root/mase/mase_output/jsc-toy_cls_jsc_2024-03-18\u001b[0m\n",
      "I0318 11:44:37.829264 139634499045184 cli.py:905] Project will be created at /root/mase/mase_output/jsc-toy_cls_jsc_2024-03-18\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTraining model 'jsc-toy'...\u001b[0m\n",
      "I0318 11:44:37.862516 139634499045184 cli.py:276] Training model 'jsc-toy'...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m##### WEIGHT DECAY ##### 0\u001b[0m\n",
      "I0318 11:44:37.863071 139634499045184 cli.py:320] ##### WEIGHT DECAY ##### 0\n",
      "INFO: Using 16bit Automatic Mixed Precision (AMP)\n",
      "I0318 11:44:37.943161 139634499045184 rank_zero.py:64] Using 16bit Automatic Mixed Precision (AMP)\n",
      "INFO: GPU available: True (cuda), used: True\n",
      "I0318 11:44:37.951574 139634499045184 rank_zero.py:64] GPU available: True (cuda), used: True\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "I0318 11:44:37.965183 139634499045184 rank_zero.py:64] TPU available: False, using: 0 TPU cores\n",
      "INFO: IPU available: False, using: 0 IPUs\n",
      "I0318 11:44:37.965238 139634499045184 rank_zero.py:64] IPU available: False, using: 0 IPUs\n",
      "INFO: HPU available: False, using: 0 HPUs\n",
      "I0318 11:44:37.965278 139634499045184 rank_zero.py:64] HPU available: False, using: 0 HPUs\n",
      "I0318 11:44:40.324936 139634499045184 cuda.py:61] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "I0318 11:44:40.413176 139634499045184 model_summary.py:94] \n",
      "  | Name      | Type               | Params\n",
      "-------------------------------------------------\n",
      "0 | model     | JSC_Toy            | 327   \n",
      "1 | loss_fn   | CrossEntropyLoss   | 0     \n",
      "2 | acc_train | MulticlassAccuracy | 0     \n",
      "3 | loss_val  | MeanMetric         | 0     \n",
      "4 | loss_test | MeanMetric         | 0     \n",
      "-------------------------------------------------\n",
      "327       Trainable params\n",
      "0         Non-trainable params\n",
      "327       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "Epoch 0: 100%|█| 3084/3084 [00:21<00:00, 140.80it/s, v_num=0, train_acc_step=0.7\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                      | 0/3084 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                         | 0/3084 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                 | 1/3084 [00:00<04:57, 10.37it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "!ch train --config ../../../machop/configs/tensorrt/jsc_toy_INT8_quantization_by_type.toml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we load in the checkpoint. You will have to adjust this according to where it has been stored in the mase_output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from ../../../mase_output/jsc-toy-cls_jsc/best.ckpt\u001b[0m\n",
      "I0318 13:22:01.808165 139755614467904 checkpoint_load.py:85] Loaded pytorch lightning checkpoint from ../../../mase_output/jsc-toy-cls_jsc/best.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Load in the trained checkpoint - change this accordingly\n",
    "JSC_CHECKPOINT_PATH = \"../../../mase_output/jsc-toy-cls_jsc/best.ckpt\"\n",
    "\n",
    "model = load_model(load_name=JSC_CHECKPOINT_PATH, load_type=\"pl\", model=model)\n",
    "\n",
    "# Initiate metadata\n",
    "dummy_in = next(iter(input_generator))\n",
    "_ = model(**dummy_in)\n",
    "mg, _ = init_metadata_analysis_pass(mg, None)\n",
    "mg, _ = add_common_metadata_analysis_pass(mg, {\"dummy_in\": dummy_in})\n",
    "mg, _ = add_software_metadata_analysis_pass(mg, None)\n",
    "mg, _ = metadata_value_type_cast_transform_pass(mg, pass_args={\"fn\": to_numpy_if_tensor})\n",
    "\n",
    "# Before we begin, we will copy the original MaseGraph model to use for comparison during quantization analysis\n",
    "mg_original = deepcopy_mase_graph(mg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1.1 Fake Quantization\n",
    "\n",
    "Firstly, we fake quantize the module in order to perform calibration and fine tuning before actually quantizing - this is only used if we have INT8 calibration as other precisions are not currently supported within [pytorch-quantization](https://docs.nvidia.com/deeplearning/tensorrt/pytorch-quantization-toolkit/docs/index.html#) library.\n",
    "\n",
    "This is acheived through the `tensorrt_fake_quantize_transform_pass` which goes through the model, either by type or by name, replaces each layer appropriately to a fake quantized form if the `quantize` parameter is set in the default config (`passes.tensorrt_quantize.default.config`) or on a per name or type basis. \n",
    "\n",
    "Currently the quantizable layers are:\n",
    "- Linear\n",
    "- Conv1d, Conv2d, ConvNd \n",
    "- ConvTranspose1d, ConvTranspose2d, ConvTransposeNd \n",
    "- MaxPool1d, MaxPool2d, MaxPool3d\n",
    "- AvgPool1d, AvgPool2d, AvgPool3d\n",
    "- Clip (Tensor)\n",
    "- LSTM, LSTMCell\n",
    "\n",
    "To create a custom quantized module, click [here](https://docs.nvidia.com/deeplearning/tensorrt/pytorch-quantization-toolkit/docs/index.html#document-tutorials/creating_custom_quantized_modules).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mApplying fake quantization to PyTorch model...\u001b[0m\n",
      "I0318 13:22:13.968679 139755614467904 utils.py:167] Applying fake quantization to PyTorch model...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mFake quantization applied to PyTorch model.\u001b[0m\n",
      "I0318 13:22:14.145424 139755614467904 utils.py:192] Fake quantization applied to PyTorch model.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mQuantized graph histogram:\u001b[0m\n",
      "I0318 13:22:14.156768 139755614467904 summary.py:84] Quantized graph histogram:\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "| Original type   | OP           |   Total |   Changed |   Unchanged |\n",
      "|-----------------+--------------+---------+-----------+-------------|\n",
      "| BatchNorm1d     | batch_norm1d |       4 |         0 |           4 |\n",
      "| Linear          | linear       |       3 |         3 |           0 |\n",
      "| ReLU            | relu         |       4 |         0 |           4 |\n",
      "| output          | output       |       1 |         0 |           1 |\n",
      "| x               | placeholder  |       1 |         0 |           1 |\u001b[0m\n",
      "I0318 13:22:14.158703 139755614467904 summary.py:85] \n",
      "| Original type   | OP           |   Total |   Changed |   Unchanged |\n",
      "|-----------------+--------------+---------+-----------+-------------|\n",
      "| BatchNorm1d     | batch_norm1d |       4 |         0 |           4 |\n",
      "| Linear          | linear       |       3 |         3 |           0 |\n",
      "| ReLU            | relu         |       4 |         0 |           4 |\n",
      "| output          | output       |       1 |         0 |           1 |\n",
      "| x               | placeholder  |       1 |         0 |           1 |\n"
     ]
    }
   ],
   "source": [
    "mg, _ = tensorrt_fake_quantize_transform_pass(mg, pass_args=tensorrt_quantize_config)\n",
    "summarize_quantization_analysis_pass(mg_original, mg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see we have succesfully quantized all linear layers inside `jsc-toy`. See [Section 4](#section-4-layer-wise-mixed-precision) for how to apply quantization layerwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1.2 Calibration\n",
    "\n",
    "Next, we perform calibration using the `tensorrt_calibrate_transform_pass`. Calibration is achieved by passing data samples to the quantizer and deciding the best amax for activations. \n",
    "\n",
    "Calibrators can be added as a search space parameter to examine the best performing calibrator. The calibrators have been included in the toml as follows.\n",
    "For example: `calibrators = [\"percentile\", \"mse\", \"entropy\"]`\n",
    "\n",
    "Note: \n",
    "- To use `percentile` calibration, a list of percentiles must be given\n",
    "- To use `max` calibration, the `histogram` weight and input calibrators must be removed and replaced with `max`. This will use global maximum absolute value to calibrate the model.\n",
    "- If `post_calibration_analysis` is set true the `tensorrt_analysis_pass` will be run for each calibrator tested to evaluate the most suitable calibrator for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting calibration of the model in PyTorch...\u001b[0m\n",
      "I0318 13:22:19.642365 139755614467904 calibrate.py:91] Starting calibration of the model in PyTorch...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "I0318 13:22:19.651999 139755614467904 calibrate.py:100] Disabling Quantization and Enabling Calibration\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "I0318 13:22:19.653707 139755614467904 calibrate.py:100] Disabling Quantization and Enabling Calibration\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "I0318 13:22:19.655657 139755614467904 calibrate.py:100] Disabling Quantization and Enabling Calibration\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "I0318 13:22:19.657295 139755614467904 calibrate.py:100] Disabling Quantization and Enabling Calibration\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "I0318 13:22:19.658708 139755614467904 calibrate.py:100] Disabling Quantization and Enabling Calibration\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "I0318 13:22:19.661043 139755614467904 calibrate.py:100] Disabling Quantization and Enabling Calibration\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "I0318 13:22:19.846983 139755614467904 calibrate.py:121] Enabling Quantization and Disabling Calibration\n",
      "W0318 13:22:19.848139 139755614467904 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "I0318 13:22:19.848706 139755614467904 calibrate.py:121] Enabling Quantization and Disabling Calibration\n",
      "W0318 13:22:19.849354 139755614467904 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "I0318 13:22:19.849881 139755614467904 calibrate.py:121] Enabling Quantization and Disabling Calibration\n",
      "W0318 13:22:19.850522 139755614467904 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "I0318 13:22:19.851068 139755614467904 calibrate.py:121] Enabling Quantization and Disabling Calibration\n",
      "W0318 13:22:19.851693 139755614467904 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "I0318 13:22:19.852017 139755614467904 calibrate.py:121] Enabling Quantization and Disabling Calibration\n",
      "W0318 13:22:19.852626 139755614467904 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "I0318 13:22:19.852959 139755614467904 calibrate.py:121] Enabling Quantization and Disabling Calibration\n",
      "W0318 13:22:19.854428 139755614467904 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "W0318 13:22:19.862320 139755614467904 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0318 13:22:19.862721 139755614467904 tensor_quantizer.py:239] Call .cuda() if running on GPU after loading calibrated amax.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=2.9824 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 13:22:19.863394 139755614467904 calibrate.py:79] seq_blocks.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=2.9824 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 13:22:19.864465 139755614467904 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.2._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.7247 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 13:22:19.864872 139755614467904 calibrate.py:79] seq_blocks.2._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.7247 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 13:22:19.866095 139755614467904 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.5._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=2.3918 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 13:22:19.866499 139755614467904 calibrate.py:79] seq_blocks.5._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=2.3918 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 13:22:19.867702 139755614467904 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.5._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5201 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 13:22:19.868119 139755614467904 calibrate.py:79] seq_blocks.5._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5201 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 13:22:19.869469 139755614467904 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.8._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=1.7210 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 13:22:19.869887 139755614467904 calibrate.py:79] seq_blocks.8._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=1.7210 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 13:22:19.871118 139755614467904 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.8._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5546 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 13:22:19.871570 139755614467904 calibrate.py:79] seq_blocks.8._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5546 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPerforming post calibration analysis for calibrator percentile_99.0...\u001b[0m\n",
      "I0318 13:22:19.872970 139755614467904 calibrate.py:53] Performing post calibration analysis for calibrator percentile_99.0...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis\u001b[0m\n",
      "I0318 13:22:19.873783 139755614467904 analysis.py:214] Starting transformation analysis\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results jsc-toy:\n",
      "+------------------------------+-------------+\n",
      "|            Metric            |    Value    |\n",
      "+------------------------------+-------------+\n",
      "|    Average Test Accuracy     |   0.72115   |\n",
      "|      Average Precision       |   0.73523   |\n",
      "|        Average Recall        |   0.71953   |\n",
      "|       Average F1 Score       |   0.72267   |\n",
      "|         Average Loss         |   0.80283   |\n",
      "|       Average Latency        |  1.9909 ms  |\n",
      "|   Average GPU Power Usage    |  54.084 W   |\n",
      "| Inference Energy Consumption | 0.02991 mWh |\n",
      "+------------------------------+-------------+\u001b[0m\n",
      "I0318 13:22:23.013608 139755614467904 analysis.py:330] \n",
      "Results jsc-toy:\n",
      "+------------------------------+-------------+\n",
      "|            Metric            |    Value    |\n",
      "+------------------------------+-------------+\n",
      "|    Average Test Accuracy     |   0.72115   |\n",
      "|      Average Precision       |   0.73523   |\n",
      "|        Average Recall        |   0.71953   |\n",
      "|       Average F1 Score       |   0.72267   |\n",
      "|         Average Loss         |   0.80283   |\n",
      "|       Average Latency        |  1.9909 ms  |\n",
      "|   Average GPU Power Usage    |  54.084 W   |\n",
      "| Inference Energy Consumption | 0.02991 mWh |\n",
      "+------------------------------+-------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPost calibration analysis complete.\u001b[0m\n",
      "I0318 13:22:23.016494 139755614467904 calibrate.py:66] Post calibration analysis complete.\n",
      "W0318 13:22:23.018086 139755614467904 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=4.1848 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 13:22:23.018626 139755614467904 calibrate.py:79] seq_blocks.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=4.1848 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 13:22:23.020167 139755614467904 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.2._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.7462 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 13:22:23.020888 139755614467904 calibrate.py:79] seq_blocks.2._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.7462 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 13:22:23.022411 139755614467904 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.5._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=3.8256 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 13:22:23.023213 139755614467904 calibrate.py:79] seq_blocks.5._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=3.8256 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 13:22:23.024677 139755614467904 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.5._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5201 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 13:22:23.025231 139755614467904 calibrate.py:79] seq_blocks.5._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5201 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 13:22:23.026346 139755614467904 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.8._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=2.2771 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 13:22:23.026892 139755614467904 calibrate.py:79] seq_blocks.8._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=2.2771 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 13:22:23.027963 139755614467904 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.8._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5546 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 13:22:23.028511 139755614467904 calibrate.py:79] seq_blocks.8._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5546 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPerforming post calibration analysis for calibrator percentile_99.9...\u001b[0m\n",
      "I0318 13:22:23.029680 139755614467904 calibrate.py:53] Performing post calibration analysis for calibrator percentile_99.9...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis\u001b[0m\n",
      "I0318 13:22:23.030415 139755614467904 analysis.py:214] Starting transformation analysis\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results jsc-toy:\n",
      "+------------------------------+-------------+\n",
      "|            Metric            |    Value    |\n",
      "+------------------------------+-------------+\n",
      "| Average Validation Accuracy  |   0.73235   |\n",
      "|      Average Precision       |   0.74538   |\n",
      "|        Average Recall        |   0.73063   |\n",
      "|       Average F1 Score       |   0.73399   |\n",
      "|         Average Loss         |   0.76725   |\n",
      "|       Average Latency        |  1.9984 ms  |\n",
      "|   Average GPU Power Usage    |  57.412 W   |\n",
      "| Inference Energy Consumption | 0.03187 mWh |\n",
      "+------------------------------+-------------+\u001b[0m\n",
      "I0318 13:22:25.768678 139755614467904 analysis.py:330] \n",
      "Results jsc-toy:\n",
      "+------------------------------+-------------+\n",
      "|            Metric            |    Value    |\n",
      "+------------------------------+-------------+\n",
      "| Average Validation Accuracy  |   0.73235   |\n",
      "|      Average Precision       |   0.74538   |\n",
      "|        Average Recall        |   0.73063   |\n",
      "|       Average F1 Score       |   0.73399   |\n",
      "|         Average Loss         |   0.76725   |\n",
      "|       Average Latency        |  1.9984 ms  |\n",
      "|   Average GPU Power Usage    |  57.412 W   |\n",
      "| Inference Energy Consumption | 0.03187 mWh |\n",
      "+------------------------------+-------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPost calibration analysis complete.\u001b[0m\n",
      "I0318 13:22:25.770843 139755614467904 calibrate.py:66] Post calibration analysis complete.\n",
      "W0318 13:22:25.771903 139755614467904 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=5.7926 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 13:22:25.772400 139755614467904 calibrate.py:79] seq_blocks.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=5.7926 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 13:22:25.773333 139755614467904 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.2._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.7462 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 13:22:25.773803 139755614467904 calibrate.py:79] seq_blocks.2._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.7462 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 13:22:25.774759 139755614467904 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.5._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=5.7153 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 13:22:25.775239 139755614467904 calibrate.py:79] seq_blocks.5._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=5.7153 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 13:22:25.776401 139755614467904 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.5._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5201 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 13:22:25.777046 139755614467904 calibrate.py:79] seq_blocks.5._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5201 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 13:22:25.778368 139755614467904 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.8._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=2.8661 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 13:22:25.779024 139755614467904 calibrate.py:79] seq_blocks.8._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=2.8661 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 13:22:25.780269 139755614467904 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.8._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5546 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 13:22:25.780915 139755614467904 calibrate.py:79] seq_blocks.8._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5546 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPerforming post calibration analysis for calibrator percentile_99.99...\u001b[0m\n",
      "I0318 13:22:25.782278 139755614467904 calibrate.py:53] Performing post calibration analysis for calibrator percentile_99.99...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis\u001b[0m\n",
      "I0318 13:22:25.783110 139755614467904 analysis.py:214] Starting transformation analysis\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results jsc-toy:\n",
      "+------------------------------+-------------+\n",
      "|            Metric            |    Value    |\n",
      "+------------------------------+-------------+\n",
      "| Average Validation Accuracy  |   0.73267   |\n",
      "|      Average Precision       |   0.74556   |\n",
      "|        Average Recall        |   0.73097   |\n",
      "|       Average F1 Score       |   0.73429   |\n",
      "|         Average Loss         |   0.76364   |\n",
      "|       Average Latency        |  2.0014 ms  |\n",
      "|   Average GPU Power Usage    |  57.504 W   |\n",
      "| Inference Energy Consumption | 0.03197 mWh |\n",
      "+------------------------------+-------------+\u001b[0m\n",
      "I0318 13:22:28.523978 139755614467904 analysis.py:330] \n",
      "Results jsc-toy:\n",
      "+------------------------------+-------------+\n",
      "|            Metric            |    Value    |\n",
      "+------------------------------+-------------+\n",
      "| Average Validation Accuracy  |   0.73267   |\n",
      "|      Average Precision       |   0.74556   |\n",
      "|        Average Recall        |   0.73097   |\n",
      "|       Average F1 Score       |   0.73429   |\n",
      "|         Average Loss         |   0.76364   |\n",
      "|       Average Latency        |  2.0014 ms  |\n",
      "|   Average GPU Power Usage    |  57.504 W   |\n",
      "| Inference Energy Consumption | 0.03197 mWh |\n",
      "+------------------------------+-------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPost calibration analysis complete.\u001b[0m\n",
      "I0318 13:22:28.526261 139755614467904 calibrate.py:66] Post calibration analysis complete.\n",
      "W0318 13:22:29.754698 139755614467904 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=7.1553 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 13:22:29.755807 139755614467904 calibrate.py:79] seq_blocks.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=7.1553 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 13:22:30.601948 139755614467904 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.2._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.7464 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 13:22:30.602879 139755614467904 calibrate.py:79] seq_blocks.2._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.7464 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 13:22:31.914243 139755614467904 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.5._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=6.4895 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 13:22:31.915047 139755614467904 calibrate.py:79] seq_blocks.5._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=6.4895 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 13:22:32.743558 139755614467904 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.5._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5179 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 13:22:32.744498 139755614467904 calibrate.py:79] seq_blocks.5._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5179 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 13:22:34.152468 139755614467904 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.8._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=3.3733 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 13:22:34.153729 139755614467904 calibrate.py:79] seq_blocks.8._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=3.3733 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 13:22:35.017431 139755614467904 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.8._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5531 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 13:22:35.018441 139755614467904 calibrate.py:79] seq_blocks.8._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5531 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPerforming post calibration analysis for calibrator mse...\u001b[0m\n",
      "I0318 13:22:35.020324 139755614467904 calibrate.py:53] Performing post calibration analysis for calibrator mse...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis\u001b[0m\n",
      "I0318 13:22:35.021559 139755614467904 analysis.py:214] Starting transformation analysis\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results jsc-toy:\n",
      "+------------------------------+--------------+\n",
      "|            Metric            |    Value     |\n",
      "+------------------------------+--------------+\n",
      "| Average Validation Accuracy  |   0.73272    |\n",
      "|      Average Precision       |   0.74538    |\n",
      "|        Average Recall        |   0.73103    |\n",
      "|       Average F1 Score       |    0.7343    |\n",
      "|         Average Loss         |   0.76502    |\n",
      "|       Average Latency        |  1.9966 ms   |\n",
      "|   Average GPU Power Usage    |   56.178 W   |\n",
      "| Inference Energy Consumption | 0.031157 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "I0318 13:22:38.135719 139755614467904 analysis.py:330] \n",
      "Results jsc-toy:\n",
      "+------------------------------+--------------+\n",
      "|            Metric            |    Value     |\n",
      "+------------------------------+--------------+\n",
      "| Average Validation Accuracy  |   0.73272    |\n",
      "|      Average Precision       |   0.74538    |\n",
      "|        Average Recall        |   0.73103    |\n",
      "|       Average F1 Score       |    0.7343    |\n",
      "|         Average Loss         |   0.76502    |\n",
      "|       Average Latency        |  1.9966 ms   |\n",
      "|   Average GPU Power Usage    |   56.178 W   |\n",
      "| Inference Energy Consumption | 0.031157 mWh |\n",
      "+------------------------------+--------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPost calibration analysis complete.\u001b[0m\n",
      "I0318 13:22:38.138723 139755614467904 calibrate.py:66] Post calibration analysis complete.\n",
      "W0318 13:22:43.433615 139755614467904 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=6.2402 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 13:22:43.434860 139755614467904 calibrate.py:79] seq_blocks.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=6.2402 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 13:22:45.434811 139755614467904 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.2._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.7465 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 13:22:45.436088 139755614467904 calibrate.py:79] seq_blocks.2._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.7465 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 13:22:51.187860 139755614467904 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.5._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=5.7175 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 13:22:51.189001 139755614467904 calibrate.py:79] seq_blocks.5._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=5.7175 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 13:22:53.107534 139755614467904 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.5._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5203 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 13:22:53.108866 139755614467904 calibrate.py:79] seq_blocks.5._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5203 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 13:22:59.775393 139755614467904 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.8._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=2.8672 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 13:22:59.776729 139755614467904 calibrate.py:79] seq_blocks.8._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=2.8672 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 13:23:01.662585 139755614467904 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.8._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5548 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 13:23:01.663614 139755614467904 calibrate.py:79] seq_blocks.8._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5548 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPerforming post calibration analysis for calibrator entropy...\u001b[0m\n",
      "I0318 13:23:01.665429 139755614467904 calibrate.py:53] Performing post calibration analysis for calibrator entropy...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis\u001b[0m\n",
      "I0318 13:23:01.666694 139755614467904 analysis.py:214] Starting transformation analysis\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results jsc-toy:\n",
      "+------------------------------+--------------+\n",
      "|            Metric            |    Value     |\n",
      "+------------------------------+--------------+\n",
      "| Average Validation Accuracy  |   0.73316    |\n",
      "|      Average Precision       |    0.746     |\n",
      "|        Average Recall        |   0.73142    |\n",
      "|       Average F1 Score       |   0.73475    |\n",
      "|         Average Loss         |   0.76419    |\n",
      "|       Average Latency        |  2.0012 ms   |\n",
      "|   Average GPU Power Usage    |   56.568 W   |\n",
      "| Inference Energy Consumption | 0.031446 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "I0318 13:23:04.402893 139755614467904 analysis.py:330] \n",
      "Results jsc-toy:\n",
      "+------------------------------+--------------+\n",
      "|            Metric            |    Value     |\n",
      "+------------------------------+--------------+\n",
      "| Average Validation Accuracy  |   0.73316    |\n",
      "|      Average Precision       |    0.746     |\n",
      "|        Average Recall        |   0.73142    |\n",
      "|       Average F1 Score       |   0.73475    |\n",
      "|         Average Loss         |   0.76419    |\n",
      "|       Average Latency        |  2.0012 ms   |\n",
      "|   Average GPU Power Usage    |   56.568 W   |\n",
      "| Inference Energy Consumption | 0.031446 mWh |\n",
      "+------------------------------+--------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPost calibration analysis complete.\u001b[0m\n",
      "I0318 13:23:04.405836 139755614467904 calibrate.py:66] Post calibration analysis complete.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mSucceeded in calibrating the model in PyTorch!\u001b[0m\n",
      "I0318 13:23:04.407040 139755614467904 calibrate.py:159] Succeeded in calibrating the model in PyTorch!\n"
     ]
    }
   ],
   "source": [
    "mg, _ = tensorrt_calibrate_transform_pass(mg, pass_args=tensorrt_quantize_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results, the 99% `percentile` clips too many values during the amax calibration, comprimising the loss. However 99.99% demonstrates higher validation accuracy alongside `mse` and `entropy` for `jsc-toy`. For such a small model, the methods are not highly distinguished, however for larger models this calibration process will be important for ensuring the quantized model still performs well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1.3 Quantized Aware Training (QAT)\n",
    "\n",
    "The `tensorrt_fine_tune_transform_pass` is used to fine tune the quantized model. \n",
    "\n",
    "For QAT it is typical to employ 10% of the original training epochs, starting at 1% of the initial training learning rate, and a cosine annealing learning rate schedule that follows the decreasing half of a cosine period, down to 1% of the initial fine tuning learning rate (0.01% of the initial training learning rate). However this default can be overidden by setting the `epochs`, `initial_learning_rate` and `final_learning_rate` in `passes.tensorrt_quantize.fine_tune`.\n",
    "\n",
    "The fine tuned checkpoints are stored in the ckpts/fine_tuning folder:\n",
    "\n",
    "```\n",
    "mase_output\n",
    "└── tensorrt\n",
    "    └── quantization\n",
    "        ├── cache\n",
    "        ├── ckpts\n",
    "        │   └── fine_tuning\n",
    "        ├── json\n",
    "        ├── onnx\n",
    "        └── trt\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting Fine Tuning...\u001b[0m\n",
      "I0318 13:23:20.128491 139755614467904 fine_tune.py:62] Starting Fine Tuning...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mFine tuninig for 2 epochs\u001b[0m\n",
      "I0318 13:23:20.170033 139755614467904 fine_tune.py:102] Fine tuninig for 2 epochs\n",
      "I0318 13:23:20.252301 139755614467904 rank_zero.py:64] GPU available: True (cuda), used: True\n",
      "I0318 13:23:20.266848 139755614467904 rank_zero.py:64] TPU available: False, using: 0 TPU cores\n",
      "I0318 13:23:20.267485 139755614467904 rank_zero.py:64] IPU available: False, using: 0 IPUs\n",
      "I0318 13:23:20.268031 139755614467904 rank_zero.py:64] HPU available: False, using: 0 HPUs\n",
      "I0318 13:23:20.274132 139755614467904 rank_zero.py:64] You are using a CUDA device ('NVIDIA GeForce RTX 3070') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "I0318 13:23:22.531366 139755614467904 cuda.py:61] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "I0318 13:23:22.546064 139755614467904 model_summary.py:94] \n",
      "  | Name      | Type               | Params\n",
      "-------------------------------------------------\n",
      "0 | model     | GraphModule        | 327   \n",
      "1 | loss_fn   | CrossEntropyLoss   | 0     \n",
      "2 | acc_train | MulticlassAccuracy | 0     \n",
      "3 | loss_val  | MeanMetric         | 0     \n",
      "4 | loss_test | MeanMetric         | 0     \n",
      "-------------------------------------------------\n",
      "327       Trainable params\n",
      "0         Non-trainable params\n",
      "327       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/mase/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n",
      "/opt/conda/envs/mase/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 3084/3084 [00:57<00:00, 53.90it/s, v_num=4, train_acc_step=0.765, val_acc_epoch=0.733, val_loss_epoch=0.750]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0318 13:25:17.216056 139755614467904 rank_zero.py:64] `Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 3084/3084 [00:57<00:00, 53.90it/s, v_num=4, train_acc_step=0.765, val_acc_epoch=0.733, val_loss_epoch=0.750]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mFine Tuning Complete\u001b[0m\n",
      "I0318 13:25:17.223005 139755614467904 fine_tune.py:121] Fine Tuning Complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mg, _ = tensorrt_fine_tune_transform_pass(mg, pass_args=tensorrt_quantize_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1.4 TensorRT Quantization\n",
    "\n",
    "After QAT, we are now ready to convert the model to a tensorRT engine so that it can be run with the superior inference speeds. To do so, we use the `tensorrt_engine_interface_pass` which converts the `MaseGraph`'s model from a Pytorch one to an ONNX format as an intermediate stage of the conversion.\n",
    "\n",
    "During the conversion process, the `.onnx` and `.trt` files are stored to their respective folders shown in [Section 1.3](#section-13-quantized-aware-training-qat).\n",
    "\n",
    "This interface pass returns a dictionary containing the `onnx_path` and `trt_engine_path`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "I0318 13:27:06.409828 139755614467904 quantize.py:129] Converting PyTorch model to ONNX...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /root/mase/mase_output/tensorrt/quantization/onnx/2024_03_18/version_10/model.onnx\u001b[0m\n",
      "I0318 13:27:31.306156 139755614467904 quantize.py:152] ONNX Conversion Complete. Stored ONNX model to /root/mase/mase_output/tensorrt/quantization/onnx/2024_03_18/version_10/model.onnx\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "I0318 13:27:37.806547 139755614467904 quantize.py:55] Converting PyTorch model to TensorRT...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /root/mase/mase_output/tensorrt/quantization/trt/2024_03_18/version_6/model.trt\u001b[0m\n",
      "I0318 13:27:46.186066 139755614467904 quantize.py:124] TensorRT Conversion Complete. Stored trt model to /root/mase/mase_output/tensorrt/quantization/trt/2024_03_18/version_6/model.trt\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /root/mase/mase_output/tensorrt/quantization/json/2024_03_18/version_6/model.json\u001b[0m\n",
      "I0318 13:27:53.259016 139755614467904 quantize.py:168] TensorRT Model Summary Exported to /root/mase/mase_output/tensorrt/quantization/json/2024_03_18/version_6/model.json\n"
     ]
    }
   ],
   "source": [
    "mg, meta = tensorrt_engine_interface_pass(mg, pass_args=tensorrt_quantize_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1.5 Performance Analysis\n",
    "\n",
    "To showcase the improved inference speeds and to evaluate accuracy and other performance metrics, the `tensorrt_analysis_pass` can be used.\n",
    "\n",
    "The tensorRT engine path obtained the previous interface pass is now inputted into the the analysis pass. The same pass can take a MaseGraph as an input, as well as an ONNX graph. For this comparison, we will first run the anaylsis pass on the original unquantized model and then on the INT8 quantized model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis\u001b[0m\n",
      "I0318 13:28:06.032049 139755614467904 analysis.py:214] Starting transformation analysis\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results jsc-toy:\n",
      "+------------------------------+--------------+\n",
      "|            Metric            |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.73168    |\n",
      "|      Average Precision       |   0.74472    |\n",
      "|        Average Recall        |   0.73037    |\n",
      "|       Average F1 Score       |   0.73369    |\n",
      "|         Average Loss         |   0.76315    |\n",
      "|       Average Latency        |  1.0634 ms   |\n",
      "|   Average GPU Power Usage    |   59.251 W   |\n",
      "| Inference Energy Consumption | 0.017502 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "I0318 13:28:11.978660 139755614467904 analysis.py:330] \n",
      "Results jsc-toy:\n",
      "+------------------------------+--------------+\n",
      "|            Metric            |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.73168    |\n",
      "|      Average Precision       |   0.74472    |\n",
      "|        Average Recall        |   0.73037    |\n",
      "|       Average F1 Score       |   0.73369    |\n",
      "|         Average Loss         |   0.76315    |\n",
      "|       Average Latency        |  1.0634 ms   |\n",
      "|   Average GPU Power Usage    |   59.251 W   |\n",
      "| Inference Energy Consumption | 0.017502 mWh |\n",
      "+------------------------------+--------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "TensorRT Engine Input/Output Information:\n",
      "Index | Type    | DataType | Static Shape         | Dynamic Shape        | Name\n",
      "------|---------|----------|----------------------|----------------------|-----------------------\n",
      "0     | Input   | FLOAT    | (256, 16)              | (256, 16)              | input\n",
      "1     | Output  | FLOAT    | (256, 5)               | (256, 5)               | 109\u001b[0m\n",
      "I0318 13:28:11.995075 139755614467904 analysis.py:117] \n",
      "TensorRT Engine Input/Output Information:\n",
      "Index | Type    | DataType | Static Shape         | Dynamic Shape        | Name\n",
      "------|---------|----------|----------------------|----------------------|-----------------------\n",
      "0     | Input   | FLOAT    | (256, 16)              | (256, 16)              | input\n",
      "1     | Output  | FLOAT    | (256, 5)               | (256, 5)               | 109\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis\u001b[0m\n",
      "I0318 13:28:11.996511 139755614467904 analysis.py:214] Starting transformation analysis\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results jsc-toy-quantized:\n",
      "+------------------------------+---------------+\n",
      "|            Metric            |     Value     |\n",
      "+------------------------------+---------------+\n",
      "|    Average Test Accuracy     |    0.73394    |\n",
      "|      Average Precision       |    0.74894    |\n",
      "|        Average Recall        |    0.73414    |\n",
      "|       Average F1 Score       |    0.73757    |\n",
      "|         Average Loss         |    0.75233    |\n",
      "|       Average Latency        |  0.20819 ms   |\n",
      "|   Average GPU Power Usage    |   59.366 W    |\n",
      "| Inference Energy Consumption | 0.0034331 mWh |\n",
      "+------------------------------+---------------+\u001b[0m\n",
      "I0318 13:28:17.535370 139755614467904 analysis.py:330] \n",
      "Results jsc-toy-quantized:\n",
      "+------------------------------+---------------+\n",
      "|            Metric            |     Value     |\n",
      "+------------------------------+---------------+\n",
      "|    Average Test Accuracy     |    0.73394    |\n",
      "|      Average Precision       |    0.74894    |\n",
      "|        Average Recall        |    0.73414    |\n",
      "|       Average F1 Score       |    0.73757    |\n",
      "|         Average Loss         |    0.75233    |\n",
      "|       Average Latency        |  0.20819 ms   |\n",
      "|   Average GPU Power Usage    |   59.366 W    |\n",
      "| Inference Energy Consumption | 0.0034331 mWh |\n",
      "+------------------------------+---------------+\n"
     ]
    }
   ],
   "source": [
    "_, _ = tensorrt_analysis_pass(mg_original, pass_args=tensorrt_analysis_config)\n",
    "_, _ = tensorrt_analysis_pass(meta['trt_engine_path'], pass_args=tensorrt_analysis_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, the latency has decreased around 4x with the `jsc-toy` model without compromising accuracy due to the well calibrated amax and quantization-aware fine tuning. The inference energy consumption has thus also dropped tremendously and this is an excellent demonstration for the need to quantize in industry especially for LLMs in order to reduce energy usage. \n",
    "\n",
    "## Section 2. FP16 Quantization\n",
    "\n",
    "We will now load in a new toml configuration that uses FP16 instead of INT8, whilst keeping the other settings the exact same for a fair comparison. This time however, we will use chop from the terminal which runs all the passes showcased in [Section 1](#section-1---int8-quantization).\n",
    "\n",
    "Since float quantization does not require calibration, nor is it supported by `pytorch-quantization`, the model will not undergo fake quantization, unfortunately, for the time being this means QAT is unavailable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-18 13:15:17,844] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "INFO: Seed set to 0\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0318 13:15:19.415035 140626882156352 seed.py:54] Seed set to 0\n",
      "+-------------------------+------------------------+--------------+--------------------------+--------------------------+\n",
      "| Name                    |        Default         | Config. File |     Manual Override      |        Effective         |\n",
      "+-------------------------+------------------------+--------------+--------------------------+--------------------------+\n",
      "| task                    |     \u001b[38;5;8mclassification\u001b[0m     |     cls      |                          |           cls            |\n",
      "| load_name               |          \u001b[38;5;8mNone\u001b[0m          |              | /root/mase/mase_output/j | /root/mase/mase_output/j |\n",
      "|                         |                        |              | sc-toy-cls_jsc/best.ckpt | sc-toy-cls_jsc/best.ckpt |\n",
      "| load_type               |           \u001b[38;5;8mmz\u001b[0m           |              |            pl            |            pl            |\n",
      "| batch_size              |          \u001b[38;5;8m128\u001b[0m           |     256      |                          |           256            |\n",
      "| to_debug                |         False          |              |                          |          False           |\n",
      "| log_level               |          info          |              |                          |           info           |\n",
      "| report_to               |      tensorboard       |              |                          |       tensorboard        |\n",
      "| seed                    |           0            |              |                          |            0             |\n",
      "| quant_config            |          None          |              |                          |           None           |\n",
      "| training_optimizer      |          adam          |              |                          |           adam           |\n",
      "| trainer_precision       |        16-mixed        |              |                          |         16-mixed         |\n",
      "| learning_rate           |         \u001b[38;5;8m1e-05\u001b[0m          |    0.001     |                          |          0.001           |\n",
      "| weight_decay            |           0            |              |                          |            0             |\n",
      "| max_epochs              |           \u001b[38;5;8m20\u001b[0m           |      20      |                          |            20            |\n",
      "| max_steps               |           -1           |              |                          |            -1            |\n",
      "| accumulate_grad_batches |           1            |              |                          |            1             |\n",
      "| log_every_n_steps       |           50           |              |                          |            50            |\n",
      "| num_workers             |           32           |              |                          |            32            |\n",
      "| num_devices             |           1            |              |                          |            1             |\n",
      "| num_nodes               |           1            |              |                          |            1             |\n",
      "| accelerator             |          \u001b[38;5;8mauto\u001b[0m          |     gpu      |                          |           gpu            |\n",
      "| strategy                |          auto          |              |                          |           auto           |\n",
      "| is_to_auto_requeue      |         False          |              |                          |          False           |\n",
      "| github_ci               |         False          |              |                          |          False           |\n",
      "| disable_dataset_cache   |         False          |              |                          |          False           |\n",
      "| target                  |  xcu250-figd2104-2L-e  |              |                          |   xcu250-figd2104-2L-e   |\n",
      "| num_targets             |          100           |              |                          |           100            |\n",
      "| is_pretrained           |         False          |              |                          |          False           |\n",
      "| max_token_len           |          512           |              |                          |           512            |\n",
      "| project_dir             | /root/mase/mase_output |              |                          |  /root/mase/mase_output  |\n",
      "| project                 |          None          |              |                          |           None           |\n",
      "| model                   |          \u001b[38;5;8mNone\u001b[0m          |   jsc-toy    |                          |         jsc-toy          |\n",
      "| dataset                 |          \u001b[38;5;8mNone\u001b[0m          |     jsc      |                          |           jsc            |\n",
      "| t_max                   |           20           |              |                          |            20            |\n",
      "| eta_min                 |         1e-06          |              |                          |          1e-06           |\n",
      "+-------------------------+------------------------+--------------+--------------------------+--------------------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mInitialising model 'jsc-toy'...\u001b[0m\n",
      "I0318 13:15:19.425006 140626882156352 cli.py:841] Initialising model 'jsc-toy'...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mInitialising dataset 'jsc'...\u001b[0m\n",
      "I0318 13:15:19.448592 140626882156352 cli.py:869] Initialising dataset 'jsc'...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mProject will be created at /root/mase/mase_output/jsc-toy_cls_jsc_2024-03-18\u001b[0m\n",
      "I0318 13:15:19.449044 140626882156352 cli.py:905] Project will be created at /root/mase/mase_output/jsc-toy_cls_jsc_2024-03-18\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTransforming model 'jsc-toy'...\u001b[0m\n",
      "I0318 13:15:19.485546 140626882156352 cli.py:365] Transforming model 'jsc-toy'...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from /root/mase/mase_output/jsc-toy-cls_jsc/best.ckpt\u001b[0m\n",
      "I0318 13:15:21.900986 140626882156352 checkpoint_load.py:85] Loaded pytorch lightning checkpoint from /root/mase/mase_output/jsc-toy-cls_jsc/best.ckpt\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mApplying fake quantization to PyTorch model...\u001b[0m\n",
      "I0318 13:15:24.777764 140626882156352 utils.py:167] Applying fake quantization to PyTorch model...\n",
      "\u001b[33mWARNING \u001b[0m \u001b[34mINT8 precision not found in config. Skipping fake quantization.\u001b[0m\n",
      "W0318 13:15:24.778099 140626882156352 utils.py:170] INT8 precision not found in config. Skipping fake quantization.\n",
      "\u001b[33mWARNING \u001b[0m \u001b[34mINT8 precision not found in config. Skipping calibration.\u001b[0m\n",
      "W0318 13:15:24.778237 140626882156352 calibrate.py:86] INT8 precision not found in config. Skipping calibration.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mQuantized graph histogram:\u001b[0m\n",
      "I0318 13:15:24.799415 140626882156352 summary.py:84] Quantized graph histogram:\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "| Original type   | OP           |   Total |   Changed |   Unchanged |\n",
      "|-----------------+--------------+---------+-----------+-------------|\n",
      "| BatchNorm1d     | batch_norm1d |       4 |         0 |           4 |\n",
      "| Linear          | linear       |       3 |         0 |           3 |\n",
      "| ReLU            | relu         |       4 |         0 |           4 |\n",
      "| output          | output       |       1 |         0 |           1 |\n",
      "| x               | placeholder  |       1 |         0 |           1 |\u001b[0m\n",
      "I0318 13:15:24.800248 140626882156352 summary.py:85] \n",
      "| Original type   | OP           |   Total |   Changed |   Unchanged |\n",
      "|-----------------+--------------+---------+-----------+-------------|\n",
      "| BatchNorm1d     | batch_norm1d |       4 |         0 |           4 |\n",
      "| Linear          | linear       |       3 |         0 |           3 |\n",
      "| ReLU            | relu         |       4 |         0 |           4 |\n",
      "| output          | output       |       1 |         0 |           1 |\n",
      "| x               | placeholder  |       1 |         0 |           1 |\n",
      "\u001b[33mWARNING \u001b[0m \u001b[34mINT8 precision not found in config. Skipping QAT fine tuning.\u001b[0m\n",
      "W0318 13:15:24.801328 140626882156352 fine_tune.py:57] INT8 precision not found in config. Skipping QAT fine tuning.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mQuantized graph histogram:\u001b[0m\n",
      "I0318 13:15:24.811759 140626882156352 summary.py:84] Quantized graph histogram:\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "| Original type   | OP           |   Total |   Changed |   Unchanged |\n",
      "|-----------------+--------------+---------+-----------+-------------|\n",
      "| BatchNorm1d     | batch_norm1d |       4 |         0 |           4 |\n",
      "| Linear          | linear       |       3 |         0 |           3 |\n",
      "| ReLU            | relu         |       4 |         0 |           4 |\n",
      "| output          | output       |       1 |         0 |           1 |\n",
      "| x               | placeholder  |       1 |         0 |           1 |\u001b[0m\n",
      "I0318 13:15:24.812333 140626882156352 summary.py:85] \n",
      "| Original type   | OP           |   Total |   Changed |   Unchanged |\n",
      "|-----------------+--------------+---------+-----------+-------------|\n",
      "| BatchNorm1d     | batch_norm1d |       4 |         0 |           4 |\n",
      "| Linear          | linear       |       3 |         0 |           3 |\n",
      "| ReLU            | relu         |       4 |         0 |           4 |\n",
      "| output          | output       |       1 |         0 |           1 |\n",
      "| x               | placeholder  |       1 |         0 |           1 |\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "I0318 13:15:24.813695 140626882156352 quantize.py:129] Converting PyTorch model to ONNX...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /root/mase/mase_output/tensorrt/quantization/onnx/2024_03_18/version_8/model.onnx\u001b[0m\n",
      "I0318 13:15:27.405281 140626882156352 quantize.py:152] ONNX Conversion Complete. Stored ONNX model to /root/mase/mase_output/tensorrt/quantization/onnx/2024_03_18/version_8/model.onnx\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "I0318 13:15:27.405642 140626882156352 quantize.py:55] Converting PyTorch model to TensorRT...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /root/mase/mase_output/tensorrt/quantization/trt/2024_03_18/version_4/model.trt\u001b[0m\n",
      "I0318 13:15:42.514927 140626882156352 quantize.py:124] TensorRT Conversion Complete. Stored trt model to /root/mase/mase_output/tensorrt/quantization/trt/2024_03_18/version_4/model.trt\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /root/mase/mase_output/tensorrt/quantization/json/2024_03_18/version_4/model.json\u001b[0m\n",
      "I0318 13:15:42.766710 140626882156352 quantize.py:168] TensorRT Model Summary Exported to /root/mase/mase_output/tensorrt/quantization/json/2024_03_18/version_4/model.json\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mQuantized graph histogram:\u001b[0m\n",
      "I0318 13:15:42.788936 140626882156352 summary.py:84] Quantized graph histogram:\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "| Original type   | OP           |   Total |   Changed |   Unchanged |\n",
      "|-----------------+--------------+---------+-----------+-------------|\n",
      "| BatchNorm1d     | batch_norm1d |       4 |         0 |           4 |\n",
      "| Linear          | linear       |       3 |         0 |           3 |\n",
      "| ReLU            | relu         |       4 |         0 |           4 |\n",
      "| output          | output       |       1 |         0 |           1 |\n",
      "| x               | placeholder  |       1 |         0 |           1 |\u001b[0m\n",
      "I0318 13:15:42.790038 140626882156352 summary.py:85] \n",
      "| Original type   | OP           |   Total |   Changed |   Unchanged |\n",
      "|-----------------+--------------+---------+-----------+-------------|\n",
      "| BatchNorm1d     | batch_norm1d |       4 |         0 |           4 |\n",
      "| Linear          | linear       |       3 |         0 |           3 |\n",
      "| ReLU            | relu         |       4 |         0 |           4 |\n",
      "| output          | output       |       1 |         0 |           1 |\n",
      "| x               | placeholder  |       1 |         0 |           1 |\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "TensorRT Engine Input/Output Information:\n",
      "Index | Type    | DataType | Static Shape         | Dynamic Shape        | Name\n",
      "------|---------|----------|----------------------|----------------------|-----------------------\n",
      "0     | Input   | FLOAT    | (256, 16)              | (256, 16)              | input\n",
      "1     | Output  | FLOAT    | (256, 5)               | (256, 5)               | 37\u001b[0m\n",
      "I0318 13:15:43.241418 140626882156352 analysis.py:117] \n",
      "TensorRT Engine Input/Output Information:\n",
      "Index | Type    | DataType | Static Shape         | Dynamic Shape        | Name\n",
      "------|---------|----------|----------------------|----------------------|-----------------------\n",
      "0     | Input   | FLOAT    | (256, 16)              | (256, 16)              | input\n",
      "1     | Output  | FLOAT    | (256, 5)               | (256, 5)               | 37\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis\u001b[0m\n",
      "I0318 13:15:43.241670 140626882156352 analysis.py:214] Starting transformation analysis\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results jsc-toy-quantized:\n",
      "+------------------------------+---------------+\n",
      "|            Metric            |     Value     |\n",
      "+------------------------------+---------------+\n",
      "|    Average Test Accuracy     |    0.73526    |\n",
      "|      Average Precision       |    0.75069    |\n",
      "|        Average Recall        |    0.73547    |\n",
      "|       Average F1 Score       |    0.73897    |\n",
      "|         Average Loss         |    0.74842    |\n",
      "|       Average Latency        |  0.088908 ms  |\n",
      "|   Average GPU Power Usage    |   56.393 W    |\n",
      "| Inference Energy Consumption | 0.0013927 mWh |\n",
      "+------------------------------+---------------+\u001b[0m\n",
      "I0318 13:15:49.114696 140626882156352 analysis.py:330] \n",
      "Results jsc-toy-quantized:\n",
      "+------------------------------+---------------+\n",
      "|            Metric            |     Value     |\n",
      "+------------------------------+---------------+\n",
      "|    Average Test Accuracy     |    0.73526    |\n",
      "|      Average Precision       |    0.75069    |\n",
      "|        Average Recall        |    0.73547    |\n",
      "|       Average F1 Score       |    0.73897    |\n",
      "|         Average Loss         |    0.74842    |\n",
      "|       Average Latency        |  0.088908 ms  |\n",
      "|   Average GPU Power Usage    |   56.393 W    |\n",
      "| Inference Energy Consumption | 0.0013927 mWh |\n",
      "+------------------------------+---------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mSaved mase graph to /root/mase/mase_output/jsc-toy_cls_jsc_2024-03-18/software/transform/transformed_ckpt\u001b[0m\n",
      "I0318 13:15:49.227739 140626882156352 save_and_load.py:147] Saved mase graph to /root/mase/mase_output/jsc-toy_cls_jsc_2024-03-18/software/transform/transformed_ckpt\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTransformation is completed\u001b[0m\n",
      "I0318 13:15:49.228112 140626882156352 cli.py:383] Transformation is completed\n"
     ]
    }
   ],
   "source": [
    "!ch transform --config ../../../machop/configs/tensorrt/jsc_toy_FP16_quantization_by_type.toml --load {JSC_CHECKPOINT_PATH} --load-type pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2136.13s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "[2024-03-18 12:26:37,519] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "INFO: Seed set to 0\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0318 12:26:39.119276 139887962613568 seed.py:54] Seed set to 0\n",
      "+-------------------------+------------------------+--------------+--------------------------+--------------------------+\n",
      "| Name                    |        Default         | Config. File |     Manual Override      |        Effective         |\n",
      "+-------------------------+------------------------+--------------+--------------------------+--------------------------+\n",
      "| task                    |     \u001b[38;5;8mclassification\u001b[0m     |     cls      |                          |           cls            |\n",
      "| load_name               |          \u001b[38;5;8mNone\u001b[0m          |              | /root/mase/mase_output/j | /root/mase/mase_output/j |\n",
      "|                         |                        |              | sc-toy-cls_jsc/best.ckpt | sc-toy-cls_jsc/best.ckpt |\n",
      "| load_type               |           \u001b[38;5;8mmz\u001b[0m           |              |            pl            |            pl            |\n",
      "| batch_size              |          \u001b[38;5;8m128\u001b[0m           |     256      |                          |           256            |\n",
      "| to_debug                |         False          |              |                          |          False           |\n",
      "| log_level               |          info          |              |                          |           info           |\n",
      "| report_to               |      tensorboard       |              |                          |       tensorboard        |\n",
      "| seed                    |           0            |              |                          |            0             |\n",
      "| quant_config            |          None          |              |                          |           None           |\n",
      "| training_optimizer      |          adam          |              |                          |           adam           |\n",
      "| trainer_precision       |        16-mixed        |              |                          |         16-mixed         |\n",
      "| learning_rate           |         \u001b[38;5;8m1e-05\u001b[0m          |    0.001     |                          |          0.001           |\n",
      "| weight_decay            |           0            |              |                          |            0             |\n",
      "| max_epochs              |           \u001b[38;5;8m20\u001b[0m           |      10      |                          |            10            |\n",
      "| max_steps               |           -1           |              |                          |            -1            |\n",
      "| accumulate_grad_batches |           1            |              |                          |            1             |\n",
      "| log_every_n_steps       |           50           |              |                          |            50            |\n",
      "| num_workers             |           32           |              |                          |            32            |\n",
      "| num_devices             |           1            |              |                          |            1             |\n",
      "| num_nodes               |           1            |              |                          |            1             |\n",
      "| accelerator             |          \u001b[38;5;8mauto\u001b[0m          |     gpu      |                          |           gpu            |\n",
      "| strategy                |          auto          |              |                          |           auto           |\n",
      "| is_to_auto_requeue      |         False          |              |                          |          False           |\n",
      "| github_ci               |         False          |              |                          |          False           |\n",
      "| disable_dataset_cache   |         False          |              |                          |          False           |\n",
      "| target                  |  xcu250-figd2104-2L-e  |              |                          |   xcu250-figd2104-2L-e   |\n",
      "| num_targets             |          100           |              |                          |           100            |\n",
      "| is_pretrained           |         False          |              |                          |          False           |\n",
      "| max_token_len           |          512           |              |                          |           512            |\n",
      "| project_dir             | /root/mase/mase_output |              |                          |  /root/mase/mase_output  |\n",
      "| project                 |          None          |              |                          |           None           |\n",
      "| model                   |          \u001b[38;5;8mNone\u001b[0m          |   jsc-toy    |                          |         jsc-toy          |\n",
      "| dataset                 |          \u001b[38;5;8mNone\u001b[0m          |     jsc      |                          |           jsc            |\n",
      "| t_max                   |           20           |              |                          |            20            |\n",
      "| eta_min                 |         1e-06          |              |                          |          1e-06           |\n",
      "+-------------------------+------------------------+--------------+--------------------------+--------------------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mInitialising model 'jsc-toy'...\u001b[0m\n",
      "I0318 12:26:39.129218 139887962613568 cli.py:841] Initialising model 'jsc-toy'...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mInitialising dataset 'jsc'...\u001b[0m\n",
      "I0318 12:26:39.152596 139887962613568 cli.py:869] Initialising dataset 'jsc'...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mProject will be created at /root/mase/mase_output/jsc-toy_cls_jsc_2024-03-18\u001b[0m\n",
      "I0318 12:26:39.153039 139887962613568 cli.py:905] Project will be created at /root/mase/mase_output/jsc-toy_cls_jsc_2024-03-18\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTransforming model 'jsc-toy'...\u001b[0m\n",
      "I0318 12:26:39.186063 139887962613568 cli.py:365] Transforming model 'jsc-toy'...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from /root/mase/mase_output/jsc-toy-cls_jsc/best.ckpt\u001b[0m\n",
      "I0318 12:26:41.603880 139887962613568 checkpoint_load.py:85] Loaded pytorch lightning checkpoint from /root/mase/mase_output/jsc-toy-cls_jsc/best.ckpt\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mApplying fake quantization to PyTorch model...\u001b[0m\n",
      "I0318 12:26:44.169106 139887962613568 utils.py:167] Applying fake quantization to PyTorch model...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mFake quantization applied to PyTorch model.\u001b[0m\n",
      "I0318 12:26:44.300340 139887962613568 utils.py:192] Fake quantization applied to PyTorch model.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting calibration of the model in PyTorch...\u001b[0m\n",
      "I0318 12:26:44.300588 139887962613568 calibrate.py:91] Starting calibration of the model in PyTorch...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "I0318 12:26:44.301095 139887962613568 calibrate.py:100] Disabling Quantization and Enabling Calibration\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "I0318 12:26:44.301210 139887962613568 calibrate.py:100] Disabling Quantization and Enabling Calibration\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "I0318 12:26:44.301312 139887962613568 calibrate.py:100] Disabling Quantization and Enabling Calibration\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "I0318 12:26:44.301398 139887962613568 calibrate.py:100] Disabling Quantization and Enabling Calibration\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "I0318 12:26:44.301486 139887962613568 calibrate.py:100] Disabling Quantization and Enabling Calibration\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "I0318 12:26:44.301569 139887962613568 calibrate.py:100] Disabling Quantization and Enabling Calibration\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "I0318 12:26:46.930022 139887962613568 calibrate.py:121] Enabling Quantization and Disabling Calibration\n",
      "W0318 12:26:46.930445 139887962613568 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "I0318 12:26:46.930503 139887962613568 calibrate.py:121] Enabling Quantization and Disabling Calibration\n",
      "W0318 12:26:46.930587 139887962613568 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "I0318 12:26:46.930637 139887962613568 calibrate.py:121] Enabling Quantization and Disabling Calibration\n",
      "W0318 12:26:46.930718 139887962613568 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "I0318 12:26:46.930757 139887962613568 calibrate.py:121] Enabling Quantization and Disabling Calibration\n",
      "W0318 12:26:46.930831 139887962613568 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "I0318 12:26:46.930878 139887962613568 calibrate.py:121] Enabling Quantization and Disabling Calibration\n",
      "W0318 12:26:46.930958 139887962613568 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "I0318 12:26:46.930996 139887962613568 calibrate.py:121] Enabling Quantization and Disabling Calibration\n",
      "W0318 12:26:46.931070 139887962613568 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "W0318 12:26:46.938275 139887962613568 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0318 12:26:46.938361 139887962613568 tensor_quantizer.py:239] Call .cuda() if running on GPU after loading calibrated amax.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=3.0452 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 12:26:46.938514 139887962613568 calibrate.py:79] seq_blocks.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=3.0452 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 12:26:46.938810 139887962613568 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.2._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.7247 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 12:26:46.938916 139887962613568 calibrate.py:79] seq_blocks.2._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.7247 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 12:26:46.939252 139887962613568 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.5._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=2.4818 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 12:26:46.939350 139887962613568 calibrate.py:79] seq_blocks.5._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=2.4818 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 12:26:46.939619 139887962613568 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.5._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5201 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 12:26:46.939716 139887962613568 calibrate.py:79] seq_blocks.5._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5201 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 12:26:46.939989 139887962613568 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.8._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=1.7389 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 12:26:46.940085 139887962613568 calibrate.py:79] seq_blocks.8._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=1.7389 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 12:26:46.940345 139887962613568 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.8._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5546 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 12:26:46.940440 139887962613568 calibrate.py:79] seq_blocks.8._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5546 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPerforming post calibration analysis for calibrator percentile_99.0...\u001b[0m\n",
      "I0318 12:26:46.940995 139887962613568 calibrate.py:53] Performing post calibration analysis for calibrator percentile_99.0...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis\u001b[0m\n",
      "I0318 12:26:46.941255 139887962613568 analysis.py:214] Starting transformation analysis\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results jsc-toy:\n",
      "+------------------------------+--------------+\n",
      "|            Metric            |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.72168    |\n",
      "|      Average Precision       |   0.73556    |\n",
      "|        Average Recall        |   0.72013    |\n",
      "|       Average F1 Score       |   0.72328    |\n",
      "|         Average Loss         |   0.79951    |\n",
      "|       Average Latency        |  2.1592 ms   |\n",
      "|   Average GPU Power Usage    |   57.454 W   |\n",
      "| Inference Energy Consumption | 0.034459 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "I0318 12:26:52.225905 139887962613568 analysis.py:330] \n",
      "Results jsc-toy:\n",
      "+------------------------------+--------------+\n",
      "|            Metric            |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.72168    |\n",
      "|      Average Precision       |   0.73556    |\n",
      "|        Average Recall        |   0.72013    |\n",
      "|       Average F1 Score       |   0.72328    |\n",
      "|         Average Loss         |   0.79951    |\n",
      "|       Average Latency        |  2.1592 ms   |\n",
      "|   Average GPU Power Usage    |   57.454 W   |\n",
      "| Inference Energy Consumption | 0.034459 mWh |\n",
      "+------------------------------+--------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPost calibration analysis complete.\u001b[0m\n",
      "I0318 12:26:52.228116 139887962613568 calibrate.py:66] Post calibration analysis complete.\n",
      "W0318 12:26:52.229037 139887962613568 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=4.0374 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 12:26:52.229361 139887962613568 calibrate.py:79] seq_blocks.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=4.0374 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 12:26:52.229836 139887962613568 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.2._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.7462 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 12:26:52.230063 139887962613568 calibrate.py:79] seq_blocks.2._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.7462 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 12:26:52.230412 139887962613568 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.5._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=3.7418 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 12:26:52.230549 139887962613568 calibrate.py:79] seq_blocks.5._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=3.7418 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 12:26:52.230831 139887962613568 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.5._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5201 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 12:26:52.230968 139887962613568 calibrate.py:79] seq_blocks.5._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5201 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 12:26:52.231252 139887962613568 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.8._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=2.3874 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 12:26:52.231384 139887962613568 calibrate.py:79] seq_blocks.8._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=2.3874 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 12:26:52.231660 139887962613568 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.8._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5546 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 12:26:52.231793 139887962613568 calibrate.py:79] seq_blocks.8._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5546 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPerforming post calibration analysis for calibrator percentile_99.9...\u001b[0m\n",
      "I0318 12:26:52.232206 139887962613568 calibrate.py:53] Performing post calibration analysis for calibrator percentile_99.9...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis\u001b[0m\n",
      "I0318 12:26:52.232367 139887962613568 analysis.py:214] Starting transformation analysis\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results jsc-toy:\n",
      "+------------------------------+--------------+\n",
      "|            Metric            |    Value     |\n",
      "+------------------------------+--------------+\n",
      "| Average Validation Accuracy  |   0.73172    |\n",
      "|      Average Precision       |    0.7448    |\n",
      "|        Average Recall        |     0.73     |\n",
      "|       Average F1 Score       |   0.73335    |\n",
      "|         Average Loss         |    0.7687    |\n",
      "|       Average Latency        |  2.1045 ms   |\n",
      "|   Average GPU Power Usage    |   57.628 W   |\n",
      "| Inference Energy Consumption | 0.033689 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "I0318 12:26:57.522008 139887962613568 analysis.py:330] \n",
      "Results jsc-toy:\n",
      "+------------------------------+--------------+\n",
      "|            Metric            |    Value     |\n",
      "+------------------------------+--------------+\n",
      "| Average Validation Accuracy  |   0.73172    |\n",
      "|      Average Precision       |    0.7448    |\n",
      "|        Average Recall        |     0.73     |\n",
      "|       Average F1 Score       |   0.73335    |\n",
      "|         Average Loss         |    0.7687    |\n",
      "|       Average Latency        |  2.1045 ms   |\n",
      "|   Average GPU Power Usage    |   57.628 W   |\n",
      "| Inference Energy Consumption | 0.033689 mWh |\n",
      "+------------------------------+--------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPost calibration analysis complete.\u001b[0m\n",
      "I0318 12:26:57.523725 139887962613568 calibrate.py:66] Post calibration analysis complete.\n",
      "W0318 12:26:57.524403 139887962613568 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=5.9534 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 12:26:57.524590 139887962613568 calibrate.py:79] seq_blocks.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=5.9534 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 12:26:57.524877 139887962613568 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.2._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.7462 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 12:26:57.525007 139887962613568 calibrate.py:79] seq_blocks.2._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.7462 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 12:26:57.525336 139887962613568 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.5._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=5.5005 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 12:26:57.525472 139887962613568 calibrate.py:79] seq_blocks.5._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=5.5005 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 12:26:57.525744 139887962613568 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.5._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5201 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 12:26:57.525872 139887962613568 calibrate.py:79] seq_blocks.5._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5201 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 12:26:57.526150 139887962613568 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.8._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=3.2350 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 12:26:57.526275 139887962613568 calibrate.py:79] seq_blocks.8._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=3.2350 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 12:26:57.526533 139887962613568 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.8._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5546 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 12:26:57.526658 139887962613568 calibrate.py:79] seq_blocks.8._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5546 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPerforming post calibration analysis for calibrator percentile_99.99...\u001b[0m\n",
      "I0318 12:26:57.527063 139887962613568 calibrate.py:53] Performing post calibration analysis for calibrator percentile_99.99...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis\u001b[0m\n",
      "I0318 12:26:57.527209 139887962613568 analysis.py:214] Starting transformation analysis\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results jsc-toy:\n",
      "+------------------------------+--------------+\n",
      "|            Metric            |    Value     |\n",
      "+------------------------------+--------------+\n",
      "| Average Validation Accuracy  |   0.73313    |\n",
      "|      Average Precision       |   0.74607    |\n",
      "|        Average Recall        |   0.73148    |\n",
      "|       Average F1 Score       |   0.73479    |\n",
      "|         Average Loss         |   0.76336    |\n",
      "|       Average Latency        |  2.1456 ms   |\n",
      "|   Average GPU Power Usage    |   57.662 W   |\n",
      "| Inference Energy Consumption | 0.034366 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "I0318 12:27:02.817430 139887962613568 analysis.py:330] \n",
      "Results jsc-toy:\n",
      "+------------------------------+--------------+\n",
      "|            Metric            |    Value     |\n",
      "+------------------------------+--------------+\n",
      "| Average Validation Accuracy  |   0.73313    |\n",
      "|      Average Precision       |   0.74607    |\n",
      "|        Average Recall        |   0.73148    |\n",
      "|       Average F1 Score       |   0.73479    |\n",
      "|         Average Loss         |   0.76336    |\n",
      "|       Average Latency        |  2.1456 ms   |\n",
      "|   Average GPU Power Usage    |   57.662 W   |\n",
      "| Inference Energy Consumption | 0.034366 mWh |\n",
      "+------------------------------+--------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPost calibration analysis complete.\u001b[0m\n",
      "I0318 12:27:02.819806 139887962613568 calibrate.py:66] Post calibration analysis complete.\n",
      "W0318 12:27:04.370434 139887962613568 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=6.6785 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 12:27:04.370744 139887962613568 calibrate.py:79] seq_blocks.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=6.6785 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 12:27:05.211057 139887962613568 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.2._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.7464 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 12:27:05.211226 139887962613568 calibrate.py:79] seq_blocks.2._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.7464 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 12:27:06.723053 139887962613568 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.5._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=5.7790 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 12:27:06.723266 139887962613568 calibrate.py:79] seq_blocks.5._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=5.7790 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 12:27:07.994596 139887962613568 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.5._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5179 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 12:27:07.994957 139887962613568 calibrate.py:79] seq_blocks.5._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5179 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 12:27:08.836271 139887962613568 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.8._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=3.6285 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 12:27:08.836424 139887962613568 calibrate.py:79] seq_blocks.8._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=3.6285 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 12:27:09.674561 139887962613568 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.8._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5531 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 12:27:09.674697 139887962613568 calibrate.py:79] seq_blocks.8._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5531 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPerforming post calibration analysis for calibrator mse...\u001b[0m\n",
      "I0318 12:27:09.675030 139887962613568 calibrate.py:53] Performing post calibration analysis for calibrator mse...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis\u001b[0m\n",
      "I0318 12:27:09.675150 139887962613568 analysis.py:214] Starting transformation analysis\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results jsc-toy:\n",
      "+------------------------------+--------------+\n",
      "|            Metric            |    Value     |\n",
      "+------------------------------+--------------+\n",
      "| Average Validation Accuracy  |   0.73352    |\n",
      "|      Average Precision       |   0.74637    |\n",
      "|        Average Recall        |    0.7319    |\n",
      "|       Average F1 Score       |   0.73521    |\n",
      "|         Average Loss         |   0.76415    |\n",
      "|       Average Latency        |  2.2248 ms   |\n",
      "|   Average GPU Power Usage    |   57.937 W   |\n",
      "| Inference Energy Consumption | 0.035805 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "I0318 12:27:15.233562 139887962613568 analysis.py:330] \n",
      "Results jsc-toy:\n",
      "+------------------------------+--------------+\n",
      "|            Metric            |    Value     |\n",
      "+------------------------------+--------------+\n",
      "| Average Validation Accuracy  |   0.73352    |\n",
      "|      Average Precision       |   0.74637    |\n",
      "|        Average Recall        |    0.7319    |\n",
      "|       Average F1 Score       |   0.73521    |\n",
      "|         Average Loss         |   0.76415    |\n",
      "|       Average Latency        |  2.2248 ms   |\n",
      "|   Average GPU Power Usage    |   57.937 W   |\n",
      "| Inference Energy Consumption | 0.035805 mWh |\n",
      "+------------------------------+--------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPost calibration analysis complete.\u001b[0m\n",
      "I0318 12:27:15.235411 139887962613568 calibrate.py:66] Post calibration analysis complete.\n",
      "W0318 12:27:22.915838 139887962613568 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=5.7303 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 12:27:22.916156 139887962613568 calibrate.py:79] seq_blocks.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=5.7303 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 12:27:24.910984 139887962613568 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.2._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.7465 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 12:27:24.911225 139887962613568 calibrate.py:79] seq_blocks.2._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.7465 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 12:27:32.203440 139887962613568 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.5._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=4.5929 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 12:27:32.203687 139887962613568 calibrate.py:79] seq_blocks.5._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=4.5929 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 12:27:34.115335 139887962613568 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.5._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5203 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 12:27:34.115548 139887962613568 calibrate.py:79] seq_blocks.5._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5203 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 12:27:37.048137 139887962613568 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.8._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=3.0568 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 12:27:37.048408 139887962613568 calibrate.py:79] seq_blocks.8._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=3.0568 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 12:27:38.939114 139887962613568 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.8._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5548 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 12:27:38.939437 139887962613568 calibrate.py:79] seq_blocks.8._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5548 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPerforming post calibration analysis for calibrator entropy...\u001b[0m\n",
      "I0318 12:27:38.939867 139887962613568 calibrate.py:53] Performing post calibration analysis for calibrator entropy...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis\u001b[0m\n",
      "I0318 12:27:38.939998 139887962613568 analysis.py:214] Starting transformation analysis\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results jsc-toy:\n",
      "+------------------------------+--------------+\n",
      "|            Metric            |    Value     |\n",
      "+------------------------------+--------------+\n",
      "| Average Validation Accuracy  |   0.73337    |\n",
      "|      Average Precision       |   0.74641    |\n",
      "|        Average Recall        |   0.73165    |\n",
      "|       Average F1 Score       |   0.73504    |\n",
      "|         Average Loss         |   0.76299    |\n",
      "|       Average Latency        |  2.3005 ms   |\n",
      "|   Average GPU Power Usage    |   58.476 W   |\n",
      "| Inference Energy Consumption | 0.037367 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "I0318 12:27:44.325067 139887962613568 analysis.py:330] \n",
      "Results jsc-toy:\n",
      "+------------------------------+--------------+\n",
      "|            Metric            |    Value     |\n",
      "+------------------------------+--------------+\n",
      "| Average Validation Accuracy  |   0.73337    |\n",
      "|      Average Precision       |   0.74641    |\n",
      "|        Average Recall        |   0.73165    |\n",
      "|       Average F1 Score       |   0.73504    |\n",
      "|         Average Loss         |   0.76299    |\n",
      "|       Average Latency        |  2.3005 ms   |\n",
      "|   Average GPU Power Usage    |   58.476 W   |\n",
      "| Inference Energy Consumption | 0.037367 mWh |\n",
      "+------------------------------+--------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPost calibration analysis complete.\u001b[0m\n",
      "I0318 12:27:44.327483 139887962613568 calibrate.py:66] Post calibration analysis complete.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mSucceeded in calibrating the model in PyTorch!\u001b[0m\n",
      "I0318 12:27:44.327730 139887962613568 calibrate.py:159] Succeeded in calibrating the model in PyTorch!\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mQuantized graph histogram:\u001b[0m\n",
      "I0318 12:27:44.345847 139887962613568 summary.py:84] Quantized graph histogram:\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "| Original type   | OP           |   Total |   Changed |   Unchanged |\n",
      "|-----------------+--------------+---------+-----------+-------------|\n",
      "| BatchNorm1d     | batch_norm1d |       4 |         0 |           4 |\n",
      "| Linear          | linear       |       3 |         3 |           0 |\n",
      "| ReLU            | relu         |       4 |         0 |           4 |\n",
      "| output          | output       |       1 |         0 |           1 |\n",
      "| x               | placeholder  |       1 |         0 |           1 |\u001b[0m\n",
      "I0318 12:27:44.346456 139887962613568 summary.py:85] \n",
      "| Original type   | OP           |   Total |   Changed |   Unchanged |\n",
      "|-----------------+--------------+---------+-----------+-------------|\n",
      "| BatchNorm1d     | batch_norm1d |       4 |         0 |           4 |\n",
      "| Linear          | linear       |       3 |         3 |           0 |\n",
      "| ReLU            | relu         |       4 |         0 |           4 |\n",
      "| output          | output       |       1 |         0 |           1 |\n",
      "| x               | placeholder  |       1 |         0 |           1 |\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting Fine Tuning...\u001b[0m\n",
      "I0318 12:27:44.347316 139887962613568 fine_tune.py:62] Starting Fine Tuning...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mFine tuninig for 2 epochs\u001b[0m\n",
      "I0318 12:27:44.347784 139887962613568 fine_tune.py:102] Fine tuninig for 2 epochs\n",
      "INFO: GPU available: True (cuda), used: True\n",
      "I0318 12:27:44.425954 139887962613568 rank_zero.py:64] GPU available: True (cuda), used: True\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "I0318 12:27:44.439193 139887962613568 rank_zero.py:64] TPU available: False, using: 0 TPU cores\n",
      "INFO: IPU available: False, using: 0 IPUs\n",
      "I0318 12:27:44.439248 139887962613568 rank_zero.py:64] IPU available: False, using: 0 IPUs\n",
      "INFO: HPU available: False, using: 0 HPUs\n",
      "I0318 12:27:44.439298 139887962613568 rank_zero.py:64] HPU available: False, using: 0 HPUs\n",
      "I0318 12:27:46.726992 139887962613568 cuda.py:61] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "I0318 12:27:46.730333 139887962613568 model_summary.py:94] \n",
      "  | Name      | Type               | Params\n",
      "-------------------------------------------------\n",
      "0 | model     | GraphModule        | 327   \n",
      "1 | loss_fn   | CrossEntropyLoss   | 0     \n",
      "2 | acc_train | MulticlassAccuracy | 0     \n",
      "3 | loss_val  | MeanMetric         | 0     \n",
      "4 | loss_test | MeanMetric         | 0     \n",
      "-------------------------------------------------\n",
      "327       Trainable params\n",
      "0         Non-trainable params\n",
      "327       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "Epoch 0: 100%|█| 3084/3084 [00:27<00:00, 110.92it/s, v_num=3, train_acc_step=0.7:  38%|▍| 1173/3084 [00:11<00:18, 105.61it/s, v_num=3, train_acc_step=0.6��| 1185/3084 [00:11<00:17, 105.73it/s, v_num=3, train_acc_step=0.7\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                      | 0/3084 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                         | 0/3084 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                 | 1/3084 [00:00<03:28, 14.80it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                 | 2/3084 [00:00<01:55, 26.59it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                 | 3/3084 [00:00<01:23, 36.84it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                 | 4/3084 [00:00<01:05, 47.00it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                 | 5/3084 [00:00<00:54, 56.32it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                 | 6/3084 [00:00<00:49, 62.81it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                 | 7/3084 [00:00<00:44, 69.81it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                 | 8/3084 [00:00<00:40, 76.16it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                 | 9/3084 [00:00<00:37, 82.03it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                | 10/3084 [00:00<00:34, 88.24it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                | 11/3084 [00:00<00:32, 93.35it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                | 12/3084 [00:00<00:32, 95.10it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                | 13/3084 [00:00<00:30, 99.37it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|               | 14/3084 [00:00<00:29, 104.16it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|               | 15/3084 [00:00<00:28, 106.75it/s]\u001b[A\n",
      "Validation DataLoader 0:   1%|               | 16/3084 [00:00<00:27, 110.32it/s]\u001b[A\n",
      "Validation DataLoader 0:   1%|               | 17/3084 [00:00<00:26, 113.64it/s]\u001b[A\n",
      "Validation DataLoader 0:   1%|               | 18/3084 [00:00<00:26, 113.73it/s]\u001b[A\n",
      "Validation DataLoader 0:   1%|               | 19/3084 [00:00<00:26, 116.56it/s]\u001b[A\n",
      "Validation DataLoader 0:   1%|               | 20/3084 [00:00<00:25, 119.33it/s]\u001b[A\n",
      "Validation DataLoader 0:   1%|               | 21/3084 [00:00<00:24, 122.64it/s]\u001b[A\n",
      "Validation DataLoader 0:   1%|               | 22/3084 [00:00<00:24, 125.83it/s]\u001b[A\n",
      "Validation DataLoader 0:   1%|               | 23/3084 [00:00<00:26, 115.23it/s]\u001b[A\n",
      "Validation DataLoader 0:   1%|               | 24/3084 [00:00<00:25, 117.92it/s]\u001b[A\n",
      "Validation DataLoader 0:   1%|               | 25/3084 [00:00<00:25, 120.71it/s]\u001b[A\n",
      "Validation DataLoader 0:   1%|▏              | 26/3084 [00:00<00:24, 123.39it/s]\u001b[A\n",
      "Validation DataLoader 0:   1%|▏              | 27/3084 [00:00<00:24, 125.57it/s]\u001b[A\n",
      "Validation DataLoader 0:   1%|▏              | 28/3084 [00:00<00:23, 127.68it/s]\u001b[A\n",
      "Validation DataLoader 0:   1%|▏              | 29/3084 [00:00<00:24, 125.10it/s]\u001b[A\n",
      "Validation DataLoader 0:   1%|▏              | 30/3084 [00:00<00:24, 123.02it/s]\u001b[A\n",
      "Validation DataLoader 0:   1%|▏              | 31/3084 [00:00<00:24, 124.55it/s]\u001b[A\n",
      "Validation DataLoader 0:   1%|▏              | 32/3084 [00:00<00:24, 126.41it/s]\u001b[A\n",
      "Validation DataLoader 0:   1%|▏              | 33/3084 [00:00<00:23, 128.52it/s]\u001b[A\n",
      "Validation DataLoader 0:   1%|▏              | 34/3084 [00:00<00:23, 130.53it/s]\u001b[A\n",
      "Validation DataLoader 0:   1%|▏              | 35/3084 [00:00<00:23, 132.50it/s]\u001b[A\n",
      "Validation DataLoader 0:   1%|▏              | 36/3084 [00:00<00:22, 134.44it/s]\u001b[A\n",
      "Validation DataLoader 0:   1%|▏              | 37/3084 [00:00<00:22, 135.96it/s]\u001b[A\n",
      "Validation DataLoader 0:   1%|▏              | 38/3084 [00:00<00:22, 137.78it/s]\u001b[A\n",
      "Validation DataLoader 0:   1%|▏              | 39/3084 [00:00<00:21, 139.59it/s]\u001b[A\n",
      "Validation DataLoader 0:   1%|▏              | 40/3084 [00:00<00:21, 141.33it/s]\u001b[A\n",
      "Validation DataLoader 0:   1%|▏              | 41/3084 [00:00<00:21, 142.94it/s]\u001b[A\n",
      "Validation DataLoader 0:   1%|▏              | 42/3084 [00:00<00:21, 144.58it/s]\u001b[A\n",
      "Validation DataLoader 0:   1%|▏              | 43/3084 [00:00<00:20, 146.19it/s]\u001b[A\n",
      "Validation DataLoader 0:   1%|▏              | 44/3084 [00:00<00:20, 147.73it/s]\u001b[A\n",
      "Validation DataLoader 0:   1%|▏              | 45/3084 [00:00<00:20, 149.33it/s]\u001b[A\n",
      "Validation DataLoader 0:   1%|▏              | 46/3084 [00:00<00:20, 150.88it/s]\u001b[A\n",
      "Validation DataLoader 0:   2%|▏              | 47/3084 [00:00<00:19, 152.39it/s]\u001b[A\n",
      "Validation DataLoader 0:   2%|▏              | 48/3084 [00:00<00:19, 153.87it/s]\u001b[A\n",
      "Validation DataLoader 0:   2%|▏              | 49/3084 [00:00<00:19, 155.33it/s]\u001b[A\n",
      "Validation DataLoader 0:   2%|▏              | 50/3084 [00:00<00:19, 156.75it/s]\u001b[A\n",
      "Validation DataLoader 0:   2%|▏              | 51/3084 [00:00<00:19, 158.14it/s]\u001b[A\n",
      "Validation DataLoader 0:   2%|▎              | 52/3084 [00:00<00:19, 159.52it/s]\u001b[A\n",
      "Validation DataLoader 0:   2%|▎              | 53/3084 [00:00<00:18, 160.80it/s]\u001b[A\n",
      "Validation DataLoader 0:   2%|▎              | 54/3084 [00:00<00:18, 162.02it/s]\u001b[A\n",
      "Validation DataLoader 0:   2%|▎              | 55/3084 [00:00<00:18, 162.90it/s]\u001b[A\n",
      "Validation DataLoader 0:   2%|▎              | 56/3084 [00:00<00:18, 164.09it/s]\u001b[A\n",
      "Validation DataLoader 0:   2%|▎              | 57/3084 [00:00<00:18, 165.27it/s]\u001b[A\n",
      "Validation DataLoader 0:   2%|▎              | 58/3084 [00:00<00:18, 166.37it/s]\u001b[A\n",
      "Validation DataLoader 0:   2%|▎              | 59/3084 [00:00<00:18, 167.50it/s]\u001b[A\n",
      "Validation DataLoader 0:   2%|▎              | 60/3084 [00:00<00:17, 168.61it/s]\u001b[A\n",
      "Validation DataLoader 0:   2%|▎              | 61/3084 [00:00<00:17, 169.67it/s]\u001b[A\n",
      "Validation DataLoader 0:   2%|▎              | 62/3084 [00:00<00:17, 170.28it/s]\u001b[A\n",
      "Validation DataLoader 0:   2%|▎              | 63/3084 [00:00<00:17, 171.32it/s]\u001b[A\n",
      "Validation DataLoader 0:   2%|▎              | 64/3084 [00:00<00:17, 172.36it/s]\u001b[A\n",
      "Validation DataLoader 0:   2%|▎              | 65/3084 [00:00<00:17, 172.98it/s]\u001b[A\n",
      "Validation DataLoader 0:   2%|▎              | 66/3084 [00:00<00:17, 173.61it/s]\u001b[A\n",
      "Validation DataLoader 0:   2%|▎              | 67/3084 [00:00<00:17, 174.20it/s]\u001b[A\n",
      "Validation DataLoader 0:   2%|▎              | 68/3084 [00:00<00:17, 174.83it/s]\u001b[A\n",
      "Validation DataLoader 0:   2%|▎              | 69/3084 [00:00<00:17, 175.12it/s]\u001b[A\n",
      "Validation DataLoader 0:   2%|▎              | 70/3084 [00:00<00:17, 175.74it/s]\u001b[A\n",
      "Validation DataLoader 0:   2%|▎              | 71/3084 [00:00<00:17, 176.33it/s]\u001b[A\n",
      "Validation DataLoader 0:   2%|▎              | 72/3084 [00:00<00:17, 176.90it/s]\u001b[A\n",
      "Validation DataLoader 0:   2%|▎              | 73/3084 [00:00<00:16, 177.47it/s]\u001b[A\n",
      "Validation DataLoader 0:   2%|▎              | 74/3084 [00:00<00:16, 178.02it/s]\u001b[A\n",
      "Validation DataLoader 0:   2%|▎              | 75/3084 [00:00<00:16, 178.44it/s]\u001b[A\n",
      "Validation DataLoader 0:   2%|▎              | 76/3084 [00:00<00:16, 179.01it/s]\u001b[A\n",
      "Validation DataLoader 0:   2%|▎              | 77/3084 [00:00<00:16, 179.55it/s]\u001b[A\n",
      "Validation DataLoader 0:   3%|▍              | 78/3084 [00:00<00:16, 180.08it/s]\u001b[A\n",
      "Validation DataLoader 0:   3%|▍              | 79/3084 [00:00<00:16, 180.62it/s]\u001b[A\n",
      "Validation DataLoader 0:   3%|▍              | 80/3084 [00:00<00:16, 181.07it/s]\u001b[A\n",
      "Validation DataLoader 0:   3%|▍              | 81/3084 [00:00<00:16, 181.53it/s]\u001b[A\n",
      "Validation DataLoader 0:   3%|▍              | 82/3084 [00:00<00:16, 181.83it/s]\u001b[A\n",
      "Validation DataLoader 0:   3%|▍              | 83/3084 [00:00<00:16, 182.04it/s]\u001b[A\n",
      "Validation DataLoader 0:   3%|▍              | 84/3084 [00:00<00:16, 182.43it/s]\u001b[A\n",
      "Validation DataLoader 0:   3%|▍              | 85/3084 [00:00<00:16, 182.85it/s]\u001b[A\n",
      "Validation DataLoader 0:   3%|▍              | 86/3084 [00:00<00:16, 183.31it/s]\u001b[A\n",
      "Validation DataLoader 0:   3%|▍              | 87/3084 [00:00<00:16, 183.47it/s]\u001b[A\n",
      "Validation DataLoader 0:   3%|▍              | 88/3084 [00:00<00:16, 183.93it/s]\u001b[A\n",
      "Validation DataLoader 0:   3%|▍              | 89/3084 [00:00<00:16, 184.23it/s]\u001b[A\n",
      "Validation DataLoader 0:   3%|▍              | 90/3084 [00:00<00:16, 184.43it/s]\u001b[A\n",
      "Validation DataLoader 0:   3%|▍              | 91/3084 [00:00<00:16, 184.75it/s]\u001b[A\n",
      "Validation DataLoader 0:   3%|▍              | 92/3084 [00:00<00:16, 185.13it/s]\u001b[A\n",
      "Validation DataLoader 0:   3%|▍              | 93/3084 [00:00<00:16, 185.50it/s]\u001b[A\n",
      "Validation DataLoader 0:   3%|▍              | 94/3084 [00:00<00:16, 185.90it/s]\u001b[A\n",
      "Validation DataLoader 0:   3%|▍              | 95/3084 [00:00<00:16, 186.26it/s]\u001b[A\n",
      "Validation DataLoader 0:   3%|▍              | 96/3084 [00:00<00:16, 186.39it/s]\u001b[A\n",
      "Validation DataLoader 0:   3%|▍              | 97/3084 [00:00<00:15, 186.78it/s]\u001b[A\n",
      "Validation DataLoader 0:   3%|▍              | 98/3084 [00:00<00:15, 187.15it/s]\u001b[A\n",
      "Validation DataLoader 0:   3%|▍              | 99/3084 [00:00<00:15, 187.51it/s]\u001b[A\n",
      "Validation DataLoader 0:   3%|▍             | 100/3084 [00:00<00:15, 187.86it/s]\u001b[A\n",
      "Validation DataLoader 0:   3%|▍             | 101/3084 [00:00<00:15, 188.20it/s]\u001b[A\n",
      "Validation DataLoader 0:   3%|▍             | 102/3084 [00:00<00:15, 188.50it/s]\u001b[A\n",
      "Validation DataLoader 0:   3%|▍             | 103/3084 [00:00<00:15, 188.61it/s]\u001b[A\n",
      "Validation DataLoader 0:   3%|▍             | 104/3084 [00:00<00:15, 188.77it/s]\u001b[A\n",
      "Validation DataLoader 0:   3%|▍             | 105/3084 [00:00<00:15, 188.98it/s]\u001b[A\n",
      "Validation DataLoader 0:   3%|▍             | 106/3084 [00:00<00:15, 189.31it/s]\u001b[A\n",
      "Validation DataLoader 0:   3%|▍             | 107/3084 [00:00<00:15, 189.63it/s]\u001b[A\n",
      "Validation DataLoader 0:   4%|▍             | 108/3084 [00:00<00:15, 189.97it/s]\u001b[A\n",
      "Validation DataLoader 0:   4%|▍             | 109/3084 [00:00<00:15, 190.31it/s]\u001b[A\n",
      "Validation DataLoader 0:   4%|▍             | 110/3084 [00:00<00:15, 190.67it/s]\u001b[A\n",
      "Validation DataLoader 0:   4%|▌             | 111/3084 [00:00<00:15, 190.99it/s]\u001b[A\n",
      "Validation DataLoader 0:   4%|▌             | 112/3084 [00:00<00:15, 191.31it/s]\u001b[A\n",
      "Validation DataLoader 0:   4%|▌             | 113/3084 [00:00<00:15, 191.63it/s]\u001b[A\n",
      "Validation DataLoader 0:   4%|▌             | 114/3084 [00:00<00:15, 191.90it/s]\u001b[A\n",
      "Validation DataLoader 0:   4%|▌             | 115/3084 [00:00<00:15, 192.20it/s]\u001b[A\n",
      "Validation DataLoader 0:   4%|▌             | 116/3084 [00:00<00:15, 192.49it/s]\u001b[A\n",
      "Validation DataLoader 0:   4%|▌             | 117/3084 [00:00<00:15, 192.55it/s]\u001b[A\n",
      "Validation DataLoader 0:   4%|▌             | 118/3084 [00:00<00:15, 192.87it/s]\u001b[A\n",
      "Validation DataLoader 0:   4%|▌             | 119/3084 [00:00<00:15, 193.18it/s]\u001b[A\n",
      "Validation DataLoader 0:   4%|▌             | 120/3084 [00:00<00:15, 193.48it/s]\u001b[A\n",
      "Validation DataLoader 0:   4%|▌             | 121/3084 [00:00<00:15, 193.78it/s]\u001b[A\n",
      "Validation DataLoader 0:   4%|▌             | 122/3084 [00:00<00:15, 194.05it/s]\u001b[A\n",
      "Validation DataLoader 0:   4%|▌             | 123/3084 [00:00<00:15, 194.33it/s]\u001b[A\n",
      "Validation DataLoader 0:   4%|▌             | 124/3084 [00:00<00:15, 194.59it/s]\u001b[A\n",
      "Validation DataLoader 0:   4%|▌             | 125/3084 [00:00<00:15, 194.85it/s]\u001b[A\n",
      "Validation DataLoader 0:   4%|▌             | 126/3084 [00:00<00:15, 195.11it/s]\u001b[A\n",
      "Validation DataLoader 0:   4%|▌             | 127/3084 [00:00<00:15, 195.37it/s]\u001b[A\n",
      "Validation DataLoader 0:   4%|▌             | 128/3084 [00:00<00:15, 195.41it/s]\u001b[A\n",
      "Validation DataLoader 0:   4%|▌             | 129/3084 [00:00<00:15, 195.66it/s]\u001b[A\n",
      "Validation DataLoader 0:   4%|▌             | 130/3084 [00:00<00:15, 195.89it/s]\u001b[A\n",
      "Validation DataLoader 0:   4%|▌             | 131/3084 [00:00<00:15, 196.12it/s]\u001b[A\n",
      "Validation DataLoader 0:   4%|▌             | 132/3084 [00:00<00:15, 196.37it/s]\u001b[A\n",
      "Validation DataLoader 0:   4%|▌             | 133/3084 [00:00<00:15, 196.62it/s]\u001b[A\n",
      "Validation DataLoader 0:   4%|▌             | 134/3084 [00:00<00:14, 196.85it/s]\u001b[A\n",
      "Validation DataLoader 0:   4%|▌             | 135/3084 [00:00<00:14, 196.88it/s]\u001b[A\n",
      "Validation DataLoader 0:   4%|▌             | 136/3084 [00:00<00:14, 197.13it/s]\u001b[A\n",
      "Validation DataLoader 0:   4%|▌             | 137/3084 [00:00<00:14, 197.41it/s]\u001b[A\n",
      "Validation DataLoader 0:   4%|▋             | 138/3084 [00:00<00:14, 197.59it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▋             | 139/3084 [00:00<00:14, 197.80it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▋             | 140/3084 [00:00<00:14, 198.05it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▋             | 141/3084 [00:00<00:14, 198.30it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▋             | 142/3084 [00:00<00:14, 198.54it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▋             | 143/3084 [00:00<00:14, 198.78it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▋             | 144/3084 [00:00<00:14, 199.02it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▋             | 145/3084 [00:00<00:14, 199.26it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▋             | 146/3084 [00:00<00:14, 199.49it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▋             | 147/3084 [00:00<00:14, 199.71it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▋             | 148/3084 [00:00<00:14, 199.93it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▋             | 149/3084 [00:00<00:14, 199.95it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▋             | 150/3084 [00:00<00:14, 200.16it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▋             | 151/3084 [00:00<00:14, 200.38it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▋             | 152/3084 [00:00<00:14, 200.59it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▋             | 153/3084 [00:00<00:14, 200.77it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▋             | 154/3084 [00:00<00:14, 200.95it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▋             | 155/3084 [00:00<00:14, 201.15it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▋             | 156/3084 [00:00<00:14, 201.35it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▋             | 157/3084 [00:00<00:14, 201.53it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▋             | 158/3084 [00:00<00:14, 201.72it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▋             | 159/3084 [00:00<00:14, 201.91it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▋             | 160/3084 [00:00<00:14, 201.93it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▋             | 161/3084 [00:00<00:14, 202.10it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▋             | 162/3084 [00:00<00:14, 202.28it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▋             | 163/3084 [00:00<00:14, 202.45it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▋             | 164/3084 [00:00<00:14, 202.62it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▋             | 165/3084 [00:00<00:14, 202.80it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▊             | 166/3084 [00:00<00:14, 202.97it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▊             | 167/3084 [00:00<00:14, 202.96it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▊             | 168/3084 [00:00<00:14, 203.15it/s]\u001b[A\n",
      "Validation DataLoader 0:   5%|▊             | 169/3084 [00:00<00:14, 203.34it/s]\u001b[A\n",
      "Validation DataLoader 0:   6%|▊             | 170/3084 [00:00<00:14, 203.50it/s]\u001b[A\n",
      "Validation DataLoader 0:   6%|▊             | 171/3084 [00:00<00:14, 203.63it/s]\u001b[A\n",
      "Validation DataLoader 0:   6%|▊             | 172/3084 [00:00<00:14, 203.79it/s]\u001b[A\n",
      "Validation DataLoader 0:   6%|▊             | 173/3084 [00:00<00:14, 203.94it/s]\u001b[A\n",
      "Validation DataLoader 0:   6%|▊             | 174/3084 [00:00<00:14, 204.11it/s]\u001b[A\n",
      "Validation DataLoader 0:   6%|▊             | 175/3084 [00:00<00:14, 204.29it/s]\u001b[A\n",
      "Validation DataLoader 0:   6%|▊             | 176/3084 [00:00<00:14, 204.44it/s]\u001b[A\n",
      "Validation DataLoader 0:   6%|▊             | 177/3084 [00:00<00:14, 204.62it/s]\u001b[A\n",
      "Validation DataLoader 0:   6%|▊             | 178/3084 [00:00<00:14, 204.79it/s]\u001b[A\n",
      "Validation DataLoader 0:   6%|▊             | 179/3084 [00:00<00:14, 204.96it/s]\u001b[A\n",
      "Validation DataLoader 0:   6%|▊             | 180/3084 [00:00<00:14, 205.13it/s]\u001b[A\n",
      "Validation DataLoader 0:   6%|▊             | 181/3084 [00:00<00:14, 205.12it/s]\u001b[A\n",
      "Validation DataLoader 0:   6%|▊             | 182/3084 [00:00<00:14, 205.29it/s]\u001b[A\n",
      "Validation DataLoader 0:   6%|▊             | 183/3084 [00:00<00:14, 205.46it/s]\u001b[A\n",
      "Validation DataLoader 0:   6%|▊             | 184/3084 [00:00<00:14, 205.60it/s]\u001b[A\n",
      "Validation DataLoader 0:   6%|▊             | 185/3084 [00:00<00:14, 205.76it/s]\u001b[A\n",
      "Validation DataLoader 0:   6%|▊             | 186/3084 [00:00<00:14, 205.91it/s]\u001b[A\n",
      "Validation DataLoader 0:   6%|▊             | 187/3084 [00:00<00:14, 206.04it/s]\u001b[A\n",
      "Validation DataLoader 0:   6%|▊             | 188/3084 [00:00<00:14, 206.18it/s]\u001b[A\n",
      "Validation DataLoader 0:   6%|▊             | 189/3084 [00:00<00:14, 206.31it/s]\u001b[A\n",
      "Validation DataLoader 0:   6%|▊             | 190/3084 [00:00<00:14, 206.43it/s]\u001b[A\n",
      "Validation DataLoader 0:   6%|▊             | 191/3084 [00:00<00:14, 206.58it/s]\u001b[A\n",
      "Validation DataLoader 0:   6%|▊             | 192/3084 [00:00<00:14, 206.57it/s]\u001b[A\n",
      "Validation DataLoader 0:   6%|▉             | 193/3084 [00:00<00:13, 206.71it/s]\u001b[A\n",
      "Validation DataLoader 0:   6%|▉             | 194/3084 [00:00<00:13, 206.83it/s]\u001b[A\n",
      "Validation DataLoader 0:   6%|▉             | 195/3084 [00:00<00:13, 206.95it/s]\u001b[A\n",
      "Validation DataLoader 0:   6%|▉             | 196/3084 [00:00<00:13, 207.09it/s]\u001b[A\n",
      "Validation DataLoader 0:   6%|▉             | 197/3084 [00:00<00:13, 207.21it/s]\u001b[A\n",
      "Validation DataLoader 0:   6%|▉             | 198/3084 [00:00<00:13, 207.34it/s]\u001b[A\n",
      "Validation DataLoader 0:   6%|▉             | 199/3084 [00:00<00:13, 207.32it/s]\u001b[A\n",
      "Validation DataLoader 0:   6%|▉             | 200/3084 [00:00<00:13, 207.44it/s]\u001b[A\n",
      "Validation DataLoader 0:   7%|▉             | 201/3084 [00:00<00:13, 207.52it/s]\u001b[A\n",
      "Validation DataLoader 0:   7%|▉             | 202/3084 [00:00<00:13, 207.67it/s]\u001b[A\n",
      "Validation DataLoader 0:   7%|▉             | 203/3084 [00:00<00:13, 207.78it/s]\u001b[A\n",
      "Validation DataLoader 0:   7%|▉             | 204/3084 [00:00<00:13, 207.91it/s]\u001b[A\n",
      "Validation DataLoader 0:   7%|▉             | 205/3084 [00:00<00:13, 208.04it/s]\u001b[A\n",
      "Validation DataLoader 0:   7%|▉             | 206/3084 [00:00<00:13, 208.17it/s]\u001b[A\n",
      "Validation DataLoader 0:   7%|▉             | 207/3084 [00:00<00:13, 208.30it/s]\u001b[A\n",
      "Validation DataLoader 0:   7%|▉             | 208/3084 [00:00<00:13, 208.43it/s]\u001b[A\n",
      "Validation DataLoader 0:   7%|▉             | 209/3084 [00:01<00:13, 208.56it/s]\u001b[A\n",
      "Validation DataLoader 0:   7%|▉             | 210/3084 [00:01<00:13, 208.68it/s]\u001b[A\n",
      "Validation DataLoader 0:   7%|▉             | 211/3084 [00:01<00:13, 208.81it/s]\u001b[A\n",
      "Validation DataLoader 0:   7%|▉             | 212/3084 [00:01<00:13, 208.94it/s]\u001b[A\n",
      "Validation DataLoader 0:   7%|▉             | 213/3084 [00:01<00:13, 208.93it/s]\u001b[A\n",
      "Validation DataLoader 0:   7%|▉             | 214/3084 [00:01<00:13, 209.06it/s]\u001b[A\n",
      "Validation DataLoader 0:   7%|▉             | 215/3084 [00:01<00:13, 209.20it/s]\u001b[A\n",
      "Validation DataLoader 0:   7%|▉             | 216/3084 [00:01<00:13, 209.32it/s]\u001b[A\n",
      "Validation DataLoader 0:   7%|▉             | 217/3084 [00:01<00:13, 209.43it/s]\u001b[A\n",
      "Validation DataLoader 0:   7%|▉             | 218/3084 [00:01<00:13, 209.53it/s]\u001b[A\n",
      "Validation DataLoader 0:   7%|▉             | 219/3084 [00:01<00:13, 209.65it/s]\u001b[A\n",
      "Validation DataLoader 0:   7%|▉             | 220/3084 [00:01<00:13, 209.77it/s]\u001b[A\n",
      "Validation DataLoader 0:   7%|█             | 221/3084 [00:01<00:13, 209.87it/s]\u001b[A\n",
      "Validation DataLoader 0:   7%|█             | 222/3084 [00:01<00:13, 209.97it/s]\u001b[A\n",
      "Validation DataLoader 0:   7%|█             | 223/3084 [00:01<00:13, 210.05it/s]\u001b[A\n",
      "Validation DataLoader 0:   7%|█             | 224/3084 [00:01<00:13, 210.02it/s]\u001b[A\n",
      "Validation DataLoader 0:   7%|█             | 225/3084 [00:01<00:13, 210.12it/s]\u001b[A\n",
      "Validation DataLoader 0:   7%|█             | 226/3084 [00:01<00:13, 210.22it/s]\u001b[A\n",
      "Validation DataLoader 0:   7%|█             | 227/3084 [00:01<00:13, 210.32it/s]\u001b[A\n",
      "Validation DataLoader 0:   7%|█             | 228/3084 [00:01<00:13, 210.41it/s]\u001b[A\n",
      "Validation DataLoader 0:   7%|█             | 229/3084 [00:01<00:13, 210.52it/s]\u001b[A\n",
      "Validation DataLoader 0:   7%|█             | 230/3084 [00:01<00:13, 210.61it/s]\u001b[A\n",
      "Validation DataLoader 0:   7%|█             | 231/3084 [00:01<00:13, 210.58it/s]\u001b[A\n",
      "Validation DataLoader 0:   8%|█             | 232/3084 [00:01<00:13, 210.71it/s]\u001b[A\n",
      "Validation DataLoader 0:   8%|█             | 233/3084 [00:01<00:13, 210.83it/s]\u001b[A\n",
      "Validation DataLoader 0:   8%|█             | 234/3084 [00:01<00:13, 210.96it/s]\u001b[A\n",
      "Validation DataLoader 0:   8%|█             | 235/3084 [00:01<00:13, 211.04it/s]\u001b[A\n",
      "Validation DataLoader 0:   8%|█             | 236/3084 [00:01<00:13, 211.15it/s]\u001b[A\n",
      "Validation DataLoader 0:   8%|█             | 237/3084 [00:01<00:13, 211.25it/s]\u001b[A\n",
      "Validation DataLoader 0:   8%|█             | 238/3084 [00:01<00:13, 211.36it/s]\u001b[A\n",
      "Validation DataLoader 0:   8%|█             | 239/3084 [00:01<00:13, 211.47it/s]\u001b[A\n",
      "Validation DataLoader 0:   8%|█             | 240/3084 [00:01<00:13, 211.58it/s]\u001b[A\n",
      "Validation DataLoader 0:   8%|█             | 241/3084 [00:01<00:13, 211.69it/s]\u001b[A\n",
      "Validation DataLoader 0:   8%|█             | 242/3084 [00:01<00:13, 211.79it/s]\u001b[A\n",
      "Validation DataLoader 0:   8%|█             | 243/3084 [00:01<00:13, 211.89it/s]\u001b[A\n",
      "Validation DataLoader 0:   8%|█             | 244/3084 [00:01<00:13, 211.99it/s]\u001b[A\n",
      "Validation DataLoader 0:   8%|█             | 245/3084 [00:01<00:13, 211.97it/s]\u001b[A\n",
      "Validation DataLoader 0:   8%|█             | 246/3084 [00:01<00:13, 212.07it/s]\u001b[A\n",
      "Validation DataLoader 0:   8%|█             | 247/3084 [00:01<00:13, 212.17it/s]\u001b[A\n",
      "Validation DataLoader 0:   8%|█▏            | 248/3084 [00:01<00:13, 212.27it/s]\u001b[A\n",
      "Validation DataLoader 0:   8%|█▏            | 249/3084 [00:01<00:13, 212.37it/s]\u001b[A\n",
      "Validation DataLoader 0:   8%|█▏            | 250/3084 [00:01<00:13, 212.47it/s]\u001b[A\n",
      "Validation DataLoader 0:   8%|█▏            | 251/3084 [00:01<00:13, 212.55it/s]\u001b[A\n",
      "Validation DataLoader 0:   8%|█▏            | 252/3084 [00:01<00:13, 212.63it/s]\u001b[A\n",
      "Validation DataLoader 0:   8%|█▏            | 253/3084 [00:01<00:13, 212.70it/s]\u001b[A\n",
      "Validation DataLoader 0:   8%|█▏            | 254/3084 [00:01<00:13, 212.78it/s]\u001b[A\n",
      "Validation DataLoader 0:   8%|█▏            | 255/3084 [00:01<00:13, 212.86it/s]\u001b[A\n",
      "Validation DataLoader 0:   8%|█▏            | 256/3084 [00:01<00:13, 212.83it/s]\u001b[A\n",
      "Validation DataLoader 0:   8%|█▏            | 257/3084 [00:01<00:13, 212.91it/s]\u001b[A\n",
      "Validation DataLoader 0:   8%|█▏            | 258/3084 [00:01<00:13, 212.98it/s]\u001b[A\n",
      "Validation DataLoader 0:   8%|█▏            | 259/3084 [00:01<00:13, 213.05it/s]\u001b[A\n",
      "Validation DataLoader 0:   8%|█▏            | 260/3084 [00:01<00:13, 213.13it/s]\u001b[A\n",
      "Validation DataLoader 0:   8%|█▏            | 261/3084 [00:01<00:13, 213.21it/s]\u001b[A\n",
      "Validation DataLoader 0:   8%|█▏            | 262/3084 [00:01<00:13, 213.29it/s]\u001b[A\n",
      "Validation DataLoader 0:   9%|█▏            | 263/3084 [00:01<00:13, 213.23it/s]\u001b[A\n",
      "Validation DataLoader 0:   9%|█▏            | 264/3084 [00:01<00:13, 213.28it/s]\u001b[A\n",
      "Validation DataLoader 0:   9%|█▏            | 265/3084 [00:01<00:13, 213.39it/s]\u001b[A\n",
      "Validation DataLoader 0:   9%|█▏            | 266/3084 [00:01<00:13, 213.48it/s]\u001b[A\n",
      "Validation DataLoader 0:   9%|█▏            | 267/3084 [00:01<00:13, 213.55it/s]\u001b[A\n",
      "Validation DataLoader 0:   9%|█▏            | 268/3084 [00:01<00:13, 213.63it/s]\u001b[A\n",
      "Validation DataLoader 0:   9%|█▏            | 269/3084 [00:01<00:13, 213.72it/s]\u001b[A\n",
      "Validation DataLoader 0:   9%|█▏            | 270/3084 [00:01<00:13, 213.81it/s]\u001b[A\n",
      "Validation DataLoader 0:   9%|█▏            | 271/3084 [00:01<00:13, 213.89it/s]\u001b[A\n",
      "Validation DataLoader 0:   9%|█▏            | 272/3084 [00:01<00:13, 213.97it/s]\u001b[A\n",
      "Validation DataLoader 0:   9%|█▏            | 273/3084 [00:01<00:13, 214.06it/s]\u001b[A\n",
      "Validation DataLoader 0:   9%|█▏            | 274/3084 [00:01<00:13, 214.14it/s]\u001b[A\n",
      "Validation DataLoader 0:   9%|█▏            | 275/3084 [00:01<00:13, 214.22it/s]\u001b[A\n",
      "Validation DataLoader 0:   9%|█▎            | 276/3084 [00:01<00:13, 214.31it/s]\u001b[A\n",
      "Validation DataLoader 0:   9%|█▎            | 277/3084 [00:01<00:13, 214.27it/s]\u001b[A\n",
      "Validation DataLoader 0:   9%|█▎            | 278/3084 [00:01<00:13, 214.36it/s]\u001b[A\n",
      "Validation DataLoader 0:   9%|█▎            | 279/3084 [00:01<00:13, 214.45it/s]\u001b[A\n",
      "Validation DataLoader 0:   9%|█▎            | 280/3084 [00:01<00:13, 214.52it/s]\u001b[A\n",
      "Validation DataLoader 0:   9%|█▎            | 281/3084 [00:01<00:13, 214.58it/s]\u001b[A\n",
      "Validation DataLoader 0:   9%|█▎            | 282/3084 [00:01<00:13, 214.65it/s]\u001b[A\n",
      "Validation DataLoader 0:   9%|█▎            | 283/3084 [00:01<00:13, 214.73it/s]\u001b[A\n",
      "Validation DataLoader 0:   9%|█▎            | 284/3084 [00:01<00:13, 214.81it/s]\u001b[A\n",
      "Validation DataLoader 0:   9%|█▎            | 285/3084 [00:01<00:13, 214.86it/s]\u001b[A\n",
      "Validation DataLoader 0:   9%|█▎            | 286/3084 [00:01<00:13, 214.92it/s]\u001b[A\n",
      "Validation DataLoader 0:   9%|█▎            | 287/3084 [00:01<00:13, 214.99it/s]\u001b[A\n",
      "Validation DataLoader 0:   9%|█▎            | 288/3084 [00:01<00:13, 214.95it/s]\u001b[A\n",
      "Validation DataLoader 0:   9%|█▎            | 289/3084 [00:01<00:12, 215.02it/s]\u001b[A\n",
      "Validation DataLoader 0:   9%|█▎            | 290/3084 [00:01<00:12, 215.09it/s]\u001b[A\n",
      "Validation DataLoader 0:   9%|█▎            | 291/3084 [00:01<00:12, 215.15it/s]\u001b[A\n",
      "Validation DataLoader 0:   9%|█▎            | 292/3084 [00:01<00:12, 215.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▎            | 293/3084 [00:01<00:12, 215.29it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▎            | 294/3084 [00:01<00:12, 215.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▎            | 295/3084 [00:01<00:12, 215.29it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▎            | 296/3084 [00:01<00:12, 215.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▎            | 297/3084 [00:01<00:12, 214.40it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▎            | 298/3084 [00:01<00:12, 214.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▎            | 299/3084 [00:01<00:12, 214.36it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▎            | 300/3084 [00:01<00:12, 214.41it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▎            | 301/3084 [00:01<00:12, 214.46it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▎            | 302/3084 [00:01<00:12, 214.51it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▍            | 303/3084 [00:01<00:12, 214.57it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▍            | 304/3084 [00:01<00:12, 214.59it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▍            | 305/3084 [00:01<00:12, 214.63it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▍            | 306/3084 [00:01<00:12, 214.64it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▍            | 307/3084 [00:01<00:12, 214.54it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▍            | 308/3084 [00:01<00:12, 214.59it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▍            | 309/3084 [00:01<00:12, 214.63it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▍            | 310/3084 [00:01<00:12, 214.67it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▍            | 311/3084 [00:01<00:12, 214.73it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▍            | 312/3084 [00:01<00:12, 214.64it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▍            | 313/3084 [00:01<00:12, 214.12it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▍            | 314/3084 [00:01<00:12, 213.90it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▍            | 315/3084 [00:01<00:12, 213.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▍            | 316/3084 [00:01<00:12, 213.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▍            | 317/3084 [00:01<00:12, 213.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▍            | 318/3084 [00:01<00:12, 214.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▍            | 319/3084 [00:01<00:12, 214.08it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▍            | 320/3084 [00:01<00:12, 214.12it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▍            | 321/3084 [00:01<00:12, 214.14it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▍            | 322/3084 [00:01<00:12, 214.16it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█▍            | 323/3084 [00:01<00:12, 214.20it/s]\u001b[A\n",
      "Validation DataLoader 0:  11%|█▍            | 324/3084 [00:01<00:12, 214.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  11%|█▍            | 325/3084 [00:01<00:12, 214.26it/s]\u001b[A\n",
      "Validation DataLoader 0:  11%|█▍            | 326/3084 [00:01<00:12, 214.29it/s]\u001b[A\n",
      "Validation DataLoader 0:  11%|█▍            | 327/3084 [00:01<00:12, 214.28it/s]\u001b[A\n",
      "Validation DataLoader 0:  11%|█▍            | 328/3084 [00:01<00:12, 214.32it/s]\u001b[A\n",
      "Validation DataLoader 0:  11%|█▍            | 329/3084 [00:01<00:12, 214.39it/s]\u001b[A\n",
      "Validation DataLoader 0:  11%|█▍            | 330/3084 [00:01<00:12, 214.33it/s]\u001b[A\n",
      "Validation DataLoader 0:  11%|█▌            | 331/3084 [00:01<00:12, 214.29it/s]\u001b[A\n",
      "Validation DataLoader 0:  11%|█▌            | 332/3084 [00:01<00:12, 214.27it/s]\u001b[A\n",
      "Validation DataLoader 0:  11%|█▌            | 333/3084 [00:01<00:12, 214.25it/s]\u001b[A\n",
      "Validation DataLoader 0:  11%|█▌            | 334/3084 [00:01<00:12, 214.20it/s]\u001b[A\n",
      "Validation DataLoader 0:  11%|█▌            | 335/3084 [00:01<00:12, 214.14it/s]\u001b[A\n",
      "Validation DataLoader 0:  11%|█▌            | 336/3084 [00:01<00:12, 214.16it/s]\u001b[A\n",
      "Validation DataLoader 0:  11%|█▌            | 337/3084 [00:01<00:12, 214.20it/s]\u001b[A\n",
      "Validation DataLoader 0:  11%|█▌            | 338/3084 [00:01<00:12, 214.25it/s]\u001b[A\n",
      "Validation DataLoader 0:  11%|█▌            | 339/3084 [00:01<00:12, 214.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  11%|█▌            | 340/3084 [00:01<00:12, 214.14it/s]\u001b[A\n",
      "Validation DataLoader 0:  11%|█▌            | 341/3084 [00:01<00:12, 214.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  11%|█▌            | 342/3084 [00:01<00:12, 214.24it/s]\u001b[A\n",
      "Validation DataLoader 0:  11%|█▌            | 343/3084 [00:01<00:12, 214.30it/s]\u001b[A\n",
      "Validation DataLoader 0:  11%|█▌            | 344/3084 [00:01<00:12, 214.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  11%|█▌            | 345/3084 [00:01<00:12, 214.27it/s]\u001b[A\n",
      "Validation DataLoader 0:  11%|█▌            | 346/3084 [00:01<00:12, 214.31it/s]\u001b[A\n",
      "Validation DataLoader 0:  11%|█▌            | 347/3084 [00:01<00:12, 214.35it/s]\u001b[A\n",
      "Validation DataLoader 0:  11%|█▌            | 348/3084 [00:01<00:12, 214.38it/s]\u001b[A\n",
      "Validation DataLoader 0:  11%|█▌            | 349/3084 [00:01<00:12, 214.42it/s]\u001b[A\n",
      "Validation DataLoader 0:  11%|█▌            | 350/3084 [00:01<00:12, 214.45it/s]\u001b[A\n",
      "Validation DataLoader 0:  11%|█▌            | 351/3084 [00:01<00:12, 214.48it/s]\u001b[A\n",
      "Validation DataLoader 0:  11%|█▌            | 352/3084 [00:01<00:12, 214.52it/s]\u001b[A\n",
      "Validation DataLoader 0:  11%|█▌            | 353/3084 [00:01<00:12, 214.57it/s]\u001b[A\n",
      "Validation DataLoader 0:  11%|█▌            | 354/3084 [00:01<00:12, 214.62it/s]\u001b[A\n",
      "Validation DataLoader 0:  12%|█▌            | 355/3084 [00:01<00:12, 214.66it/s]\u001b[A\n",
      "Validation DataLoader 0:  12%|█▌            | 356/3084 [00:01<00:12, 214.70it/s]\u001b[A\n",
      "Validation DataLoader 0:  12%|█▌            | 357/3084 [00:01<00:12, 214.76it/s]\u001b[A\n",
      "Validation DataLoader 0:  12%|█▋            | 358/3084 [00:01<00:12, 214.36it/s]\u001b[A\n",
      "Validation DataLoader 0:  12%|█▋            | 359/3084 [00:01<00:12, 214.14it/s]\u001b[A\n",
      "Validation DataLoader 0:  12%|█▋            | 360/3084 [00:01<00:12, 214.18it/s]\u001b[A\n",
      "Validation DataLoader 0:  12%|█▋            | 361/3084 [00:01<00:12, 214.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  12%|█▋            | 362/3084 [00:01<00:12, 214.25it/s]\u001b[A\n",
      "Validation DataLoader 0:  12%|█▋            | 363/3084 [00:01<00:12, 214.28it/s]\u001b[A\n",
      "Validation DataLoader 0:  12%|█▋            | 364/3084 [00:01<00:12, 214.33it/s]\u001b[A\n",
      "Validation DataLoader 0:  12%|█▋            | 365/3084 [00:01<00:12, 214.38it/s]\u001b[A\n",
      "Validation DataLoader 0:  12%|█▋            | 366/3084 [00:01<00:12, 214.42it/s]\u001b[A\n",
      "Validation DataLoader 0:  12%|█▋            | 367/3084 [00:01<00:12, 214.47it/s]\u001b[A\n",
      "Validation DataLoader 0:  12%|█▋            | 368/3084 [00:01<00:12, 214.49it/s]\u001b[A\n",
      "Validation DataLoader 0:  12%|█▋            | 369/3084 [00:01<00:12, 214.54it/s]\u001b[A\n",
      "Validation DataLoader 0:  12%|█▋            | 370/3084 [00:01<00:12, 214.59it/s]\u001b[A\n",
      "Validation DataLoader 0:  12%|█▋            | 371/3084 [00:01<00:12, 214.60it/s]\u001b[A\n",
      "Validation DataLoader 0:  12%|█▋            | 372/3084 [00:01<00:12, 214.52it/s]\u001b[A\n",
      "Validation DataLoader 0:  12%|█▋            | 373/3084 [00:01<00:12, 214.56it/s]\u001b[A\n",
      "Validation DataLoader 0:  12%|█▋            | 374/3084 [00:01<00:12, 214.61it/s]\u001b[A\n",
      "Validation DataLoader 0:  12%|█▋            | 375/3084 [00:01<00:12, 214.66it/s]\u001b[A\n",
      "Validation DataLoader 0:  12%|█▋            | 376/3084 [00:01<00:12, 214.61it/s]\u001b[A\n",
      "Validation DataLoader 0:  12%|█▋            | 377/3084 [00:01<00:12, 214.66it/s]\u001b[A\n",
      "Validation DataLoader 0:  12%|█▋            | 378/3084 [00:01<00:12, 214.71it/s]\u001b[A\n",
      "Validation DataLoader 0:  12%|█▋            | 379/3084 [00:01<00:12, 214.75it/s]\u001b[A\n",
      "Validation DataLoader 0:  12%|█▋            | 380/3084 [00:01<00:12, 214.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  12%|█▋            | 381/3084 [00:01<00:12, 214.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  12%|█▋            | 382/3084 [00:01<00:12, 214.89it/s]\u001b[A\n",
      "Validation DataLoader 0:  12%|█▋            | 383/3084 [00:01<00:12, 214.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  12%|█▋            | 384/3084 [00:01<00:12, 214.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  12%|█▋            | 385/3084 [00:01<00:12, 215.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  13%|█▊            | 386/3084 [00:01<00:12, 215.08it/s]\u001b[A\n",
      "Validation DataLoader 0:  13%|█▊            | 387/3084 [00:01<00:12, 215.12it/s]\u001b[A\n",
      "Validation DataLoader 0:  13%|█▊            | 388/3084 [00:01<00:12, 215.14it/s]\u001b[A\n",
      "Validation DataLoader 0:  13%|█▊            | 389/3084 [00:01<00:12, 215.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  13%|█▊            | 390/3084 [00:01<00:12, 215.18it/s]\u001b[A\n",
      "Validation DataLoader 0:  13%|█▊            | 391/3084 [00:01<00:12, 215.18it/s]\u001b[A\n",
      "Validation DataLoader 0:  13%|█▊            | 392/3084 [00:01<00:12, 215.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  13%|█▊            | 393/3084 [00:01<00:12, 215.25it/s]\u001b[A\n",
      "Validation DataLoader 0:  13%|█▊            | 394/3084 [00:01<00:12, 215.27it/s]\u001b[A\n",
      "Validation DataLoader 0:  13%|█▊            | 395/3084 [00:01<00:12, 215.28it/s]\u001b[A\n",
      "Validation DataLoader 0:  13%|█▊            | 396/3084 [00:01<00:12, 215.30it/s]\u001b[A\n",
      "Validation DataLoader 0:  13%|█▊            | 397/3084 [00:01<00:12, 215.33it/s]\u001b[A\n",
      "Validation DataLoader 0:  13%|█▊            | 398/3084 [00:01<00:12, 215.33it/s]\u001b[A\n",
      "Validation DataLoader 0:  13%|█▊            | 399/3084 [00:01<00:12, 215.35it/s]\u001b[A\n",
      "Validation DataLoader 0:  13%|█▊            | 400/3084 [00:01<00:12, 215.39it/s]\u001b[A\n",
      "Validation DataLoader 0:  13%|█▊            | 401/3084 [00:01<00:12, 215.43it/s]\u001b[A\n",
      "Validation DataLoader 0:  13%|█▊            | 402/3084 [00:01<00:12, 215.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  13%|█▊            | 403/3084 [00:01<00:12, 214.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  13%|█▊            | 404/3084 [00:01<00:12, 214.89it/s]\u001b[A\n",
      "Validation DataLoader 0:  13%|█▊            | 405/3084 [00:01<00:12, 214.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  13%|█▊            | 406/3084 [00:01<00:12, 214.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  13%|█▊            | 407/3084 [00:01<00:12, 214.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  13%|█▊            | 408/3084 [00:01<00:12, 214.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  13%|█▊            | 409/3084 [00:01<00:12, 215.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  13%|█▊            | 410/3084 [00:01<00:12, 215.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  13%|█▊            | 411/3084 [00:01<00:12, 215.07it/s]\u001b[A\n",
      "Validation DataLoader 0:  13%|█▊            | 412/3084 [00:01<00:12, 215.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  13%|█▊            | 413/3084 [00:01<00:12, 215.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  13%|█▉            | 414/3084 [00:01<00:12, 215.16it/s]\u001b[A\n",
      "Validation DataLoader 0:  13%|█▉            | 415/3084 [00:01<00:12, 215.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  13%|█▉            | 416/3084 [00:01<00:12, 215.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  14%|█▉            | 417/3084 [00:01<00:12, 215.25it/s]\u001b[A\n",
      "Validation DataLoader 0:  14%|█▉            | 418/3084 [00:01<00:12, 215.26it/s]\u001b[A\n",
      "Validation DataLoader 0:  14%|█▉            | 419/3084 [00:01<00:12, 215.25it/s]\u001b[A\n",
      "Validation DataLoader 0:  14%|█▉            | 420/3084 [00:01<00:12, 215.28it/s]\u001b[A\n",
      "Validation DataLoader 0:  14%|█▉            | 421/3084 [00:01<00:12, 215.30it/s]\u001b[A\n",
      "Validation DataLoader 0:  14%|█▉            | 422/3084 [00:01<00:12, 215.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  14%|█▉            | 423/3084 [00:01<00:12, 215.37it/s]\u001b[A\n",
      "Validation DataLoader 0:  14%|█▉            | 424/3084 [00:01<00:12, 215.41it/s]\u001b[A\n",
      "Validation DataLoader 0:  14%|█▉            | 425/3084 [00:01<00:12, 215.44it/s]\u001b[A\n",
      "Validation DataLoader 0:  14%|█▉            | 426/3084 [00:01<00:12, 215.47it/s]\u001b[A\n",
      "Validation DataLoader 0:  14%|█▉            | 427/3084 [00:01<00:12, 215.50it/s]\u001b[A\n",
      "Validation DataLoader 0:  14%|█▉            | 428/3084 [00:01<00:12, 215.54it/s]\u001b[A\n",
      "Validation DataLoader 0:  14%|█▉            | 429/3084 [00:01<00:12, 215.58it/s]\u001b[A\n",
      "Validation DataLoader 0:  14%|█▉            | 430/3084 [00:01<00:12, 215.63it/s]\u001b[A\n",
      "Validation DataLoader 0:  14%|█▉            | 431/3084 [00:01<00:12, 215.65it/s]\u001b[A\n",
      "Validation DataLoader 0:  14%|█▉            | 432/3084 [00:02<00:12, 215.68it/s]\u001b[A\n",
      "Validation DataLoader 0:  14%|█▉            | 433/3084 [00:02<00:12, 215.64it/s]\u001b[A\n",
      "Validation DataLoader 0:  14%|█▉            | 434/3084 [00:02<00:12, 215.57it/s]\u001b[A\n",
      "Validation DataLoader 0:  14%|█▉            | 435/3084 [00:02<00:12, 215.51it/s]\u001b[A\n",
      "Validation DataLoader 0:  14%|█▉            | 436/3084 [00:02<00:12, 215.52it/s]\u001b[A\n",
      "Validation DataLoader 0:  14%|█▉            | 437/3084 [00:02<00:12, 215.52it/s]\u001b[A\n",
      "Validation DataLoader 0:  14%|█▉            | 438/3084 [00:02<00:12, 215.56it/s]\u001b[A\n",
      "Validation DataLoader 0:  14%|█▉            | 439/3084 [00:02<00:12, 215.61it/s]\u001b[A\n",
      "Validation DataLoader 0:  14%|█▉            | 440/3084 [00:02<00:12, 215.56it/s]\u001b[A\n",
      "Validation DataLoader 0:  14%|██            | 441/3084 [00:02<00:12, 215.59it/s]\u001b[A\n",
      "Validation DataLoader 0:  14%|██            | 442/3084 [00:02<00:12, 215.63it/s]\u001b[A\n",
      "Validation DataLoader 0:  14%|██            | 443/3084 [00:02<00:12, 215.66it/s]\u001b[A\n",
      "Validation DataLoader 0:  14%|██            | 444/3084 [00:02<00:12, 215.70it/s]\u001b[A\n",
      "Validation DataLoader 0:  14%|██            | 445/3084 [00:02<00:12, 215.71it/s]\u001b[A\n",
      "Validation DataLoader 0:  14%|██            | 446/3084 [00:02<00:12, 215.74it/s]\u001b[A\n",
      "Validation DataLoader 0:  14%|██            | 447/3084 [00:02<00:12, 215.75it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██            | 448/3084 [00:02<00:12, 215.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██            | 449/3084 [00:02<00:12, 215.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██            | 450/3084 [00:02<00:12, 215.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██            | 451/3084 [00:02<00:12, 215.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██            | 452/3084 [00:02<00:12, 215.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██            | 453/3084 [00:02<00:12, 215.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██            | 454/3084 [00:02<00:12, 215.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██            | 455/3084 [00:02<00:12, 215.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██            | 456/3084 [00:02<00:12, 215.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██            | 457/3084 [00:02<00:12, 216.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██            | 458/3084 [00:02<00:12, 216.07it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██            | 459/3084 [00:02<00:12, 216.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██            | 460/3084 [00:02<00:12, 216.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██            | 461/3084 [00:02<00:12, 216.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██            | 462/3084 [00:02<00:12, 216.20it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██            | 463/3084 [00:02<00:12, 216.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██            | 464/3084 [00:02<00:12, 216.26it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██            | 465/3084 [00:02<00:12, 216.30it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██            | 466/3084 [00:02<00:12, 216.33it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██            | 467/3084 [00:02<00:12, 216.28it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██            | 468/3084 [00:02<00:12, 216.30it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▏           | 469/3084 [00:02<00:12, 216.32it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▏           | 470/3084 [00:02<00:12, 216.33it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▏           | 471/3084 [00:02<00:12, 216.36it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▏           | 472/3084 [00:02<00:12, 216.31it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▏           | 473/3084 [00:02<00:12, 216.35it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▏           | 474/3084 [00:02<00:12, 216.39it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▏           | 475/3084 [00:02<00:12, 216.41it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▏           | 476/3084 [00:02<00:12, 216.44it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▏           | 477/3084 [00:02<00:12, 216.47it/s]\u001b[A\n",
      "Validation DataLoader 0:  15%|██▏           | 478/3084 [00:02<00:12, 216.51it/s]\u001b[A\n",
      "Validation DataLoader 0:  16%|██▏           | 479/3084 [00:02<00:12, 216.56it/s]\u001b[A\n",
      "Validation DataLoader 0:  16%|██▏           | 480/3084 [00:02<00:12, 216.59it/s]\u001b[A\n",
      "Validation DataLoader 0:  16%|██▏           | 481/3084 [00:02<00:12, 216.62it/s]\u001b[A\n",
      "Validation DataLoader 0:  16%|██▏           | 482/3084 [00:02<00:12, 216.66it/s]\u001b[A\n",
      "Validation DataLoader 0:  16%|██▏           | 483/3084 [00:02<00:12, 216.69it/s]\u001b[A\n",
      "Validation DataLoader 0:  16%|██▏           | 484/3084 [00:02<00:11, 216.73it/s]\u001b[A\n",
      "Validation DataLoader 0:  16%|██▏           | 485/3084 [00:02<00:11, 216.76it/s]\u001b[A\n",
      "Validation DataLoader 0:  16%|██▏           | 486/3084 [00:02<00:11, 216.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  16%|██▏           | 487/3084 [00:02<00:11, 216.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  16%|██▏           | 488/3084 [00:02<00:11, 216.86it/s]\u001b[A\n",
      "Validation DataLoader 0:  16%|██▏           | 489/3084 [00:02<00:11, 216.90it/s]\u001b[A\n",
      "Validation DataLoader 0:  16%|██▏           | 490/3084 [00:02<00:11, 216.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  16%|██▏           | 491/3084 [00:02<00:11, 216.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  16%|██▏           | 492/3084 [00:02<00:11, 216.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  16%|██▏           | 493/3084 [00:02<00:11, 217.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  16%|██▏           | 494/3084 [00:02<00:11, 217.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  16%|██▏           | 495/3084 [00:02<00:11, 217.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  16%|██▎           | 496/3084 [00:02<00:11, 217.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  16%|██▎           | 497/3084 [00:02<00:11, 217.07it/s]\u001b[A\n",
      "Validation DataLoader 0:  16%|██▎           | 498/3084 [00:02<00:11, 217.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  16%|██▎           | 499/3084 [00:02<00:11, 217.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  16%|██▎           | 500/3084 [00:02<00:11, 217.09it/s]\u001b[A\n",
      "Validation DataLoader 0:  16%|██▎           | 501/3084 [00:02<00:11, 217.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  16%|██▎           | 502/3084 [00:02<00:11, 217.14it/s]\u001b[A\n",
      "Validation DataLoader 0:  16%|██▎           | 503/3084 [00:02<00:11, 217.18it/s]\u001b[A\n",
      "Validation DataLoader 0:  16%|██▎           | 504/3084 [00:02<00:11, 217.14it/s]\u001b[A\n",
      "Validation DataLoader 0:  16%|██▎           | 505/3084 [00:02<00:11, 217.18it/s]\u001b[A\n",
      "Validation DataLoader 0:  16%|██▎           | 506/3084 [00:02<00:11, 217.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  16%|██▎           | 507/3084 [00:02<00:11, 217.25it/s]\u001b[A\n",
      "Validation DataLoader 0:  16%|██▎           | 508/3084 [00:02<00:11, 217.28it/s]\u001b[A\n",
      "Validation DataLoader 0:  17%|██▎           | 509/3084 [00:02<00:11, 217.32it/s]\u001b[A\n",
      "Validation DataLoader 0:  17%|██▎           | 510/3084 [00:02<00:11, 217.35it/s]\u001b[A\n",
      "Validation DataLoader 0:  17%|██▎           | 511/3084 [00:02<00:11, 217.38it/s]\u001b[A\n",
      "Validation DataLoader 0:  17%|██▎           | 512/3084 [00:02<00:11, 217.41it/s]\u001b[A\n",
      "Validation DataLoader 0:  17%|██▎           | 513/3084 [00:02<00:11, 217.44it/s]\u001b[A\n",
      "Validation DataLoader 0:  17%|██▎           | 514/3084 [00:02<00:11, 217.48it/s]\u001b[A\n",
      "Validation DataLoader 0:  17%|██▎           | 515/3084 [00:02<00:11, 217.51it/s]\u001b[A\n",
      "Validation DataLoader 0:  17%|██▎           | 516/3084 [00:02<00:11, 217.53it/s]\u001b[A\n",
      "Validation DataLoader 0:  17%|██▎           | 517/3084 [00:02<00:11, 217.56it/s]\u001b[A\n",
      "Validation DataLoader 0:  17%|██▎           | 518/3084 [00:02<00:11, 217.59it/s]\u001b[A\n",
      "Validation DataLoader 0:  17%|██▎           | 519/3084 [00:02<00:11, 217.62it/s]\u001b[A\n",
      "Validation DataLoader 0:  17%|██▎           | 520/3084 [00:02<00:11, 217.63it/s]\u001b[A\n",
      "Validation DataLoader 0:  17%|██▎           | 521/3084 [00:02<00:11, 217.66it/s]\u001b[A\n",
      "Validation DataLoader 0:  17%|██▎           | 522/3084 [00:02<00:11, 217.70it/s]\u001b[A\n",
      "Validation DataLoader 0:  17%|██▎           | 523/3084 [00:02<00:11, 217.74it/s]\u001b[A\n",
      "Validation DataLoader 0:  17%|██▍           | 524/3084 [00:02<00:11, 217.76it/s]\u001b[A\n",
      "Validation DataLoader 0:  17%|██▍           | 525/3084 [00:02<00:11, 217.74it/s]\u001b[A\n",
      "Validation DataLoader 0:  17%|██▍           | 526/3084 [00:02<00:11, 217.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  17%|██▍           | 527/3084 [00:02<00:11, 217.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  17%|██▍           | 528/3084 [00:02<00:11, 217.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  17%|██▍           | 529/3084 [00:02<00:11, 217.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  17%|██▍           | 530/3084 [00:02<00:11, 217.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  17%|██▍           | 531/3084 [00:02<00:11, 217.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  17%|██▍           | 532/3084 [00:02<00:11, 217.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  17%|██▍           | 533/3084 [00:02<00:11, 217.90it/s]\u001b[A\n",
      "Validation DataLoader 0:  17%|██▍           | 534/3084 [00:02<00:11, 217.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  17%|██▍           | 535/3084 [00:02<00:11, 217.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  17%|██▍           | 536/3084 [00:02<00:11, 217.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  17%|██▍           | 537/3084 [00:02<00:11, 217.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  17%|██▍           | 538/3084 [00:02<00:11, 217.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  17%|██▍           | 539/3084 [00:02<00:11, 217.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  18%|██▍           | 540/3084 [00:02<00:11, 218.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  18%|██▍           | 541/3084 [00:02<00:11, 218.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  18%|██▍           | 542/3084 [00:02<00:11, 218.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  18%|██▍           | 543/3084 [00:02<00:11, 218.07it/s]\u001b[A\n",
      "Validation DataLoader 0:  18%|██▍           | 544/3084 [00:02<00:11, 218.09it/s]\u001b[A\n",
      "Validation DataLoader 0:  18%|██▍           | 545/3084 [00:02<00:11, 218.12it/s]\u001b[A\n",
      "Validation DataLoader 0:  18%|██▍           | 546/3084 [00:02<00:11, 218.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  18%|██▍           | 547/3084 [00:02<00:11, 218.18it/s]\u001b[A\n",
      "Validation DataLoader 0:  18%|██▍           | 548/3084 [00:02<00:11, 218.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  18%|██▍           | 549/3084 [00:02<00:11, 218.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  18%|██▍           | 550/3084 [00:02<00:11, 218.26it/s]\u001b[A\n",
      "Validation DataLoader 0:  18%|██▌           | 551/3084 [00:02<00:11, 218.29it/s]\u001b[A\n",
      "Validation DataLoader 0:  18%|██▌           | 552/3084 [00:02<00:11, 218.31it/s]\u001b[A\n",
      "Validation DataLoader 0:  18%|██▌           | 553/3084 [00:02<00:11, 218.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  18%|██▌           | 554/3084 [00:02<00:11, 218.37it/s]\u001b[A\n",
      "Validation DataLoader 0:  18%|██▌           | 555/3084 [00:02<00:11, 218.41it/s]\u001b[A\n",
      "Validation DataLoader 0:  18%|██▌           | 556/3084 [00:02<00:11, 218.44it/s]\u001b[A\n",
      "Validation DataLoader 0:  18%|██▌           | 557/3084 [00:02<00:11, 218.46it/s]\u001b[A\n",
      "Validation DataLoader 0:  18%|██▌           | 558/3084 [00:02<00:11, 218.49it/s]\u001b[A\n",
      "Validation DataLoader 0:  18%|██▌           | 559/3084 [00:02<00:11, 218.51it/s]\u001b[A\n",
      "Validation DataLoader 0:  18%|██▌           | 560/3084 [00:02<00:11, 218.54it/s]\u001b[A\n",
      "Validation DataLoader 0:  18%|██▌           | 561/3084 [00:02<00:11, 218.56it/s]\u001b[A\n",
      "Validation DataLoader 0:  18%|██▌           | 562/3084 [00:02<00:11, 218.59it/s]\u001b[A\n",
      "Validation DataLoader 0:  18%|██▌           | 563/3084 [00:02<00:11, 218.55it/s]\u001b[A\n",
      "Validation DataLoader 0:  18%|██▌           | 564/3084 [00:02<00:11, 218.59it/s]\u001b[A\n",
      "Validation DataLoader 0:  18%|██▌           | 565/3084 [00:02<00:11, 218.60it/s]\u001b[A\n",
      "Validation DataLoader 0:  18%|██▌           | 566/3084 [00:02<00:11, 218.62it/s]\u001b[A\n",
      "Validation DataLoader 0:  18%|██▌           | 567/3084 [00:02<00:11, 218.65it/s]\u001b[A\n",
      "Validation DataLoader 0:  18%|██▌           | 568/3084 [00:02<00:11, 218.61it/s]\u001b[A\n",
      "Validation DataLoader 0:  18%|██▌           | 569/3084 [00:02<00:11, 218.63it/s]\u001b[A\n",
      "Validation DataLoader 0:  18%|██▌           | 570/3084 [00:02<00:11, 218.65it/s]\u001b[A\n",
      "Validation DataLoader 0:  19%|██▌           | 571/3084 [00:02<00:11, 218.68it/s]\u001b[A\n",
      "Validation DataLoader 0:  19%|██▌           | 572/3084 [00:02<00:11, 218.70it/s]\u001b[A\n",
      "Validation DataLoader 0:  19%|██▌           | 573/3084 [00:02<00:11, 218.73it/s]\u001b[A\n",
      "Validation DataLoader 0:  19%|██▌           | 574/3084 [00:02<00:11, 218.75it/s]\u001b[A\n",
      "Validation DataLoader 0:  19%|██▌           | 575/3084 [00:02<00:11, 218.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  19%|██▌           | 576/3084 [00:02<00:11, 218.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  19%|██▌           | 577/3084 [00:02<00:11, 218.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  19%|██▌           | 578/3084 [00:02<00:11, 218.86it/s]\u001b[A\n",
      "Validation DataLoader 0:  19%|██▋           | 579/3084 [00:02<00:11, 218.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  19%|██▋           | 580/3084 [00:02<00:11, 218.90it/s]\u001b[A\n",
      "Validation DataLoader 0:  19%|██▋           | 581/3084 [00:02<00:11, 218.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  19%|██▋           | 582/3084 [00:02<00:11, 218.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  19%|██▋           | 583/3084 [00:02<00:11, 218.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  19%|██▋           | 584/3084 [00:02<00:11, 219.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  19%|██▋           | 585/3084 [00:02<00:11, 219.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  19%|██▋           | 586/3084 [00:02<00:11, 219.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  19%|██▋           | 587/3084 [00:02<00:11, 219.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  19%|██▋           | 588/3084 [00:02<00:11, 219.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  19%|██▋           | 589/3084 [00:02<00:11, 219.07it/s]\u001b[A\n",
      "Validation DataLoader 0:  19%|██▋           | 590/3084 [00:02<00:11, 219.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  19%|██▋           | 591/3084 [00:02<00:11, 219.12it/s]\u001b[A\n",
      "Validation DataLoader 0:  19%|██▋           | 592/3084 [00:02<00:11, 219.14it/s]\u001b[A\n",
      "Validation DataLoader 0:  19%|██▋           | 593/3084 [00:02<00:11, 219.16it/s]\u001b[A\n",
      "Validation DataLoader 0:  19%|██▋           | 594/3084 [00:02<00:11, 219.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  19%|██▋           | 595/3084 [00:02<00:11, 219.16it/s]\u001b[A\n",
      "Validation DataLoader 0:  19%|██▋           | 596/3084 [00:02<00:11, 219.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  19%|██▋           | 597/3084 [00:02<00:11, 219.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  19%|██▋           | 598/3084 [00:02<00:11, 219.24it/s]\u001b[A\n",
      "Validation DataLoader 0:  19%|██▋           | 599/3084 [00:02<00:11, 219.28it/s]\u001b[A\n",
      "Validation DataLoader 0:  19%|██▋           | 600/3084 [00:02<00:11, 219.24it/s]\u001b[A\n",
      "Validation DataLoader 0:  19%|██▋           | 601/3084 [00:02<00:11, 219.27it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██▋           | 602/3084 [00:02<00:11, 219.28it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██▋           | 603/3084 [00:02<00:11, 219.29it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██▋           | 604/3084 [00:02<00:11, 219.31it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██▋           | 605/3084 [00:02<00:11, 219.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██▊           | 606/3084 [00:02<00:11, 219.36it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██▊           | 607/3084 [00:02<00:11, 219.38it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██▊           | 608/3084 [00:02<00:11, 219.41it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██▊           | 609/3084 [00:02<00:11, 219.43it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██▊           | 610/3084 [00:02<00:11, 219.45it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██▊           | 611/3084 [00:02<00:11, 219.48it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██▊           | 612/3084 [00:02<00:11, 219.51it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██▊           | 613/3084 [00:02<00:11, 219.53it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██▊           | 614/3084 [00:02<00:11, 219.56it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██▊           | 615/3084 [00:02<00:11, 219.58it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██▊           | 616/3084 [00:02<00:11, 219.61it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██▊           | 617/3084 [00:02<00:11, 219.64it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██▊           | 618/3084 [00:02<00:11, 219.59it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██▊           | 619/3084 [00:02<00:11, 219.62it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██▊           | 620/3084 [00:02<00:11, 219.63it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██▊           | 621/3084 [00:02<00:11, 219.66it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██▊           | 622/3084 [00:02<00:11, 219.68it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██▊           | 623/3084 [00:02<00:11, 219.70it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██▊           | 624/3084 [00:02<00:11, 219.72it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██▊           | 625/3084 [00:02<00:11, 219.75it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██▊           | 626/3084 [00:02<00:11, 219.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██▊           | 627/3084 [00:02<00:11, 219.73it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██▊           | 628/3084 [00:02<00:11, 219.76it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██▊           | 629/3084 [00:02<00:11, 219.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██▊           | 630/3084 [00:02<00:11, 219.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██▊           | 631/3084 [00:02<00:11, 219.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  20%|██▊           | 632/3084 [00:02<00:11, 219.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  21%|██▊           | 633/3084 [00:02<00:11, 219.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  21%|██▉           | 634/3084 [00:02<00:11, 219.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  21%|██▉           | 635/3084 [00:02<00:11, 219.86it/s]\u001b[A\n",
      "Validation DataLoader 0:  21%|██▉           | 636/3084 [00:02<00:11, 219.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  21%|██▉           | 637/3084 [00:02<00:11, 219.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  21%|██▉           | 638/3084 [00:02<00:11, 219.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  21%|██▉           | 639/3084 [00:02<00:11, 219.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  21%|██▉           | 640/3084 [00:02<00:11, 219.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  21%|██▉           | 641/3084 [00:02<00:11, 220.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  21%|██▉           | 642/3084 [00:02<00:11, 220.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  21%|██▉           | 643/3084 [00:02<00:11, 220.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  21%|██▉           | 644/3084 [00:02<00:11, 220.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  21%|██▉           | 645/3084 [00:02<00:11, 220.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  21%|██▉           | 646/3084 [00:02<00:11, 220.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  21%|██▉           | 647/3084 [00:02<00:11, 220.08it/s]\u001b[A\n",
      "Validation DataLoader 0:  21%|██▉           | 648/3084 [00:02<00:11, 220.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  21%|██▉           | 649/3084 [00:02<00:11, 220.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  21%|██▉           | 650/3084 [00:02<00:11, 220.07it/s]\u001b[A\n",
      "Validation DataLoader 0:  21%|██▉           | 651/3084 [00:02<00:11, 220.09it/s]\u001b[A\n",
      "Validation DataLoader 0:  21%|██▉           | 652/3084 [00:02<00:11, 220.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  21%|██▉           | 653/3084 [00:02<00:11, 220.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  21%|██▉           | 654/3084 [00:02<00:11, 220.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  21%|██▉           | 655/3084 [00:02<00:11, 220.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  21%|██▉           | 656/3084 [00:02<00:11, 220.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  21%|██▉           | 657/3084 [00:02<00:11, 220.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  21%|██▉           | 658/3084 [00:02<00:11, 220.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  21%|██▉           | 659/3084 [00:02<00:11, 220.20it/s]\u001b[A\n",
      "Validation DataLoader 0:  21%|██▉           | 660/3084 [00:02<00:11, 220.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  21%|███           | 661/3084 [00:03<00:11, 220.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  21%|███           | 662/3084 [00:03<00:10, 220.25it/s]\u001b[A\n",
      "Validation DataLoader 0:  21%|███           | 663/3084 [00:03<00:10, 220.27it/s]\u001b[A\n",
      "Validation DataLoader 0:  22%|███           | 664/3084 [00:03<00:10, 220.24it/s]\u001b[A\n",
      "Validation DataLoader 0:  22%|███           | 665/3084 [00:03<00:10, 220.26it/s]\u001b[A\n",
      "Validation DataLoader 0:  22%|███           | 666/3084 [00:03<00:10, 220.27it/s]\u001b[A\n",
      "Validation DataLoader 0:  22%|███           | 667/3084 [00:03<00:10, 220.28it/s]\u001b[A\n",
      "Validation DataLoader 0:  22%|███           | 668/3084 [00:03<00:10, 220.29it/s]\u001b[A\n",
      "Validation DataLoader 0:  22%|███           | 669/3084 [00:03<00:10, 220.30it/s]\u001b[A\n",
      "Validation DataLoader 0:  22%|███           | 670/3084 [00:03<00:10, 220.32it/s]\u001b[A\n",
      "Validation DataLoader 0:  22%|███           | 671/3084 [00:03<00:10, 220.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  22%|███           | 672/3084 [00:03<00:10, 220.36it/s]\u001b[A\n",
      "Validation DataLoader 0:  22%|███           | 673/3084 [00:03<00:10, 220.36it/s]\u001b[A\n",
      "Validation DataLoader 0:  22%|███           | 674/3084 [00:03<00:10, 220.38it/s]\u001b[A\n",
      "Validation DataLoader 0:  22%|███           | 675/3084 [00:03<00:10, 220.41it/s]\u001b[A\n",
      "Validation DataLoader 0:  22%|███           | 676/3084 [00:03<00:10, 220.43it/s]\u001b[A\n",
      "Validation DataLoader 0:  22%|███           | 677/3084 [00:03<00:10, 220.45it/s]\u001b[A\n",
      "Validation DataLoader 0:  22%|███           | 678/3084 [00:03<00:10, 220.47it/s]\u001b[A\n",
      "Validation DataLoader 0:  22%|███           | 679/3084 [00:03<00:10, 220.49it/s]\u001b[A\n",
      "Validation DataLoader 0:  22%|███           | 680/3084 [00:03<00:10, 220.51it/s]\u001b[A\n",
      "Validation DataLoader 0:  22%|███           | 681/3084 [00:03<00:10, 220.53it/s]\u001b[A\n",
      "Validation DataLoader 0:  22%|███           | 682/3084 [00:03<00:10, 220.50it/s]\u001b[A\n",
      "Validation DataLoader 0:  22%|███           | 683/3084 [00:03<00:10, 220.52it/s]\u001b[A\n",
      "Validation DataLoader 0:  22%|███           | 684/3084 [00:03<00:10, 220.54it/s]\u001b[A\n",
      "Validation DataLoader 0:  22%|███           | 685/3084 [00:03<00:10, 220.55it/s]\u001b[A\n",
      "Validation DataLoader 0:  22%|███           | 686/3084 [00:03<00:10, 220.56it/s]\u001b[A\n",
      "Validation DataLoader 0:  22%|███           | 687/3084 [00:03<00:10, 220.57it/s]\u001b[A\n",
      "Validation DataLoader 0:  22%|███           | 688/3084 [00:03<00:10, 220.58it/s]\u001b[A\n",
      "Validation DataLoader 0:  22%|███▏          | 689/3084 [00:03<00:10, 220.60it/s]\u001b[A\n",
      "Validation DataLoader 0:  22%|███▏          | 690/3084 [00:03<00:10, 220.61it/s]\u001b[A\n",
      "Validation DataLoader 0:  22%|███▏          | 691/3084 [00:03<00:10, 220.57it/s]\u001b[A\n",
      "Validation DataLoader 0:  22%|███▏          | 692/3084 [00:03<00:10, 220.59it/s]\u001b[A\n",
      "Validation DataLoader 0:  22%|███▏          | 693/3084 [00:03<00:10, 220.59it/s]\u001b[A\n",
      "Validation DataLoader 0:  23%|███▏          | 694/3084 [00:03<00:10, 220.60it/s]\u001b[A\n",
      "Validation DataLoader 0:  23%|███▏          | 695/3084 [00:03<00:10, 220.62it/s]\u001b[A\n",
      "Validation DataLoader 0:  23%|███▏          | 696/3084 [00:03<00:10, 220.58it/s]\u001b[A\n",
      "Validation DataLoader 0:  23%|███▏          | 697/3084 [00:03<00:10, 220.59it/s]\u001b[A\n",
      "Validation DataLoader 0:  23%|███▏          | 698/3084 [00:03<00:10, 220.60it/s]\u001b[A\n",
      "Validation DataLoader 0:  23%|███▏          | 699/3084 [00:03<00:10, 220.61it/s]\u001b[A\n",
      "Validation DataLoader 0:  23%|███▏          | 700/3084 [00:03<00:10, 220.59it/s]\u001b[A\n",
      "Validation DataLoader 0:  23%|███▏          | 701/3084 [00:03<00:10, 220.60it/s]\u001b[A\n",
      "Validation DataLoader 0:  23%|███▏          | 702/3084 [00:03<00:10, 220.62it/s]\u001b[A\n",
      "Validation DataLoader 0:  23%|███▏          | 703/3084 [00:03<00:10, 220.63it/s]\u001b[A\n",
      "Validation DataLoader 0:  23%|███▏          | 704/3084 [00:03<00:10, 220.65it/s]\u001b[A\n",
      "Validation DataLoader 0:  23%|███▏          | 705/3084 [00:03<00:10, 220.65it/s]\u001b[A\n",
      "Validation DataLoader 0:  23%|███▏          | 706/3084 [00:03<00:10, 220.67it/s]\u001b[A\n",
      "Validation DataLoader 0:  23%|███▏          | 707/3084 [00:03<00:10, 220.69it/s]\u001b[A\n",
      "Validation DataLoader 0:  23%|███▏          | 708/3084 [00:03<00:10, 220.71it/s]\u001b[A\n",
      "Validation DataLoader 0:  23%|███▏          | 709/3084 [00:03<00:10, 220.73it/s]\u001b[A\n",
      "Validation DataLoader 0:  23%|███▏          | 710/3084 [00:03<00:10, 220.76it/s]\u001b[A\n",
      "Validation DataLoader 0:  23%|███▏          | 711/3084 [00:03<00:10, 220.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  23%|███▏          | 712/3084 [00:03<00:10, 220.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  23%|███▏          | 713/3084 [00:03<00:10, 220.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  23%|███▏          | 714/3084 [00:03<00:10, 220.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  23%|███▏          | 715/3084 [00:03<00:10, 220.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  23%|███▎          | 716/3084 [00:03<00:10, 220.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  23%|███▎          | 717/3084 [00:03<00:10, 220.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  23%|███▎          | 718/3084 [00:03<00:10, 220.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  23%|███▎          | 719/3084 [00:03<00:10, 220.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  23%|███▎          | 720/3084 [00:03<00:10, 220.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  23%|███▎          | 721/3084 [00:03<00:10, 220.86it/s]\u001b[A\n",
      "Validation DataLoader 0:  23%|███▎          | 722/3084 [00:03<00:10, 220.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  23%|███▎          | 723/3084 [00:03<00:10, 220.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  23%|███▎          | 724/3084 [00:03<00:10, 220.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  24%|███▎          | 725/3084 [00:03<00:10, 220.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  24%|███▎          | 726/3084 [00:03<00:10, 220.86it/s]\u001b[A\n",
      "Validation DataLoader 0:  24%|███▎          | 727/3084 [00:03<00:10, 220.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  24%|███▎          | 728/3084 [00:03<00:10, 220.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  24%|███▎          | 729/3084 [00:03<00:10, 220.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  24%|███▎          | 730/3084 [00:03<00:10, 220.86it/s]\u001b[A\n",
      "Validation DataLoader 0:  24%|███▎          | 731/3084 [00:03<00:10, 220.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  24%|███▎          | 732/3084 [00:03<00:10, 220.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  24%|███▎          | 733/3084 [00:03<00:10, 220.90it/s]\u001b[A\n",
      "Validation DataLoader 0:  24%|███▎          | 734/3084 [00:03<00:10, 220.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  24%|███▎          | 735/3084 [00:03<00:10, 220.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  24%|███▎          | 736/3084 [00:03<00:10, 220.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  24%|███▎          | 737/3084 [00:03<00:10, 220.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  24%|███▎          | 738/3084 [00:03<00:10, 220.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  24%|███▎          | 739/3084 [00:03<00:10, 221.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  24%|███▎          | 740/3084 [00:03<00:10, 221.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  24%|███▎          | 741/3084 [00:03<00:10, 221.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  24%|███▎          | 742/3084 [00:03<00:10, 221.07it/s]\u001b[A\n",
      "Validation DataLoader 0:  24%|███▎          | 743/3084 [00:03<00:10, 221.09it/s]\u001b[A\n",
      "Validation DataLoader 0:  24%|███▍          | 744/3084 [00:03<00:10, 221.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  24%|███▍          | 745/3084 [00:03<00:10, 221.12it/s]\u001b[A\n",
      "Validation DataLoader 0:  24%|███▍          | 746/3084 [00:03<00:10, 221.08it/s]\u001b[A\n",
      "Validation DataLoader 0:  24%|███▍          | 747/3084 [00:03<00:10, 221.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  24%|███▍          | 748/3084 [00:03<00:10, 221.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  24%|███▍          | 749/3084 [00:03<00:10, 221.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  24%|███▍          | 750/3084 [00:03<00:10, 221.12it/s]\u001b[A\n",
      "Validation DataLoader 0:  24%|███▍          | 751/3084 [00:03<00:10, 221.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  24%|███▍          | 752/3084 [00:03<00:10, 221.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  24%|███▍          | 753/3084 [00:03<00:10, 221.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  24%|███▍          | 754/3084 [00:03<00:10, 221.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  24%|███▍          | 755/3084 [00:03<00:10, 221.14it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|███▍          | 756/3084 [00:03<00:10, 221.16it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|███▍          | 757/3084 [00:03<00:10, 221.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|███▍          | 758/3084 [00:03<00:10, 221.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|███▍          | 759/3084 [00:03<00:10, 221.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|███▍          | 760/3084 [00:03<00:10, 221.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|███▍          | 761/3084 [00:03<00:10, 221.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|███▍          | 762/3084 [00:03<00:10, 221.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|███▍          | 763/3084 [00:03<00:10, 221.24it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|███▍          | 764/3084 [00:03<00:10, 221.26it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|███▍          | 765/3084 [00:03<00:10, 221.28it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|███▍          | 766/3084 [00:03<00:10, 221.29it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|███▍          | 767/3084 [00:03<00:10, 221.30it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|███▍          | 768/3084 [00:03<00:10, 221.30it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|███▍          | 769/3084 [00:03<00:10, 221.32it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|███▍          | 770/3084 [00:03<00:10, 221.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|███▌          | 771/3084 [00:03<00:10, 221.36it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|███▌          | 772/3084 [00:03<00:10, 221.38it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|███▌          | 773/3084 [00:03<00:10, 221.39it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|███▌          | 774/3084 [00:03<00:10, 221.41it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|███▌          | 775/3084 [00:03<00:10, 221.43it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|███▌          | 776/3084 [00:03<00:10, 221.44it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|███▌          | 777/3084 [00:03<00:10, 221.46it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|███▌          | 778/3084 [00:03<00:10, 221.43it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|███▌          | 779/3084 [00:03<00:10, 221.44it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|███▌          | 780/3084 [00:03<00:10, 221.45it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|███▌          | 781/3084 [00:03<00:10, 221.46it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|███▌          | 782/3084 [00:03<00:10, 221.47it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|███▌          | 783/3084 [00:03<00:10, 221.49it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|███▌          | 784/3084 [00:03<00:10, 221.50it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|███▌          | 785/3084 [00:03<00:10, 221.52it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|███▌          | 786/3084 [00:03<00:10, 221.54it/s]\u001b[A\n",
      "Validation DataLoader 0:  26%|███▌          | 787/3084 [00:03<00:10, 221.50it/s]\u001b[A\n",
      "Validation DataLoader 0:  26%|███▌          | 788/3084 [00:03<00:10, 221.51it/s]\u001b[A\n",
      "Validation DataLoader 0:  26%|███▌          | 789/3084 [00:03<00:10, 221.52it/s]\u001b[A\n",
      "Validation DataLoader 0:  26%|███▌          | 790/3084 [00:03<00:10, 221.52it/s]\u001b[A\n",
      "Validation DataLoader 0:  26%|███▌          | 791/3084 [00:03<00:10, 221.53it/s]\u001b[A\n",
      "Validation DataLoader 0:  26%|███▌          | 792/3084 [00:03<00:10, 221.51it/s]\u001b[A\n",
      "Validation DataLoader 0:  26%|███▌          | 793/3084 [00:03<00:10, 221.52it/s]\u001b[A\n",
      "Validation DataLoader 0:  26%|███▌          | 794/3084 [00:03<00:10, 221.53it/s]\u001b[A\n",
      "Validation DataLoader 0:  26%|███▌          | 795/3084 [00:03<00:10, 221.55it/s]\u001b[A\n",
      "Validation DataLoader 0:  26%|███▌          | 796/3084 [00:03<00:10, 221.57it/s]\u001b[A\n",
      "Validation DataLoader 0:  26%|███▌          | 797/3084 [00:03<00:10, 221.58it/s]\u001b[A\n",
      "Validation DataLoader 0:  26%|███▌          | 798/3084 [00:03<00:10, 221.60it/s]\u001b[A\n",
      "Validation DataLoader 0:  26%|███▋          | 799/3084 [00:03<00:10, 221.61it/s]\u001b[A\n",
      "Validation DataLoader 0:  26%|███▋          | 800/3084 [00:03<00:10, 221.63it/s]\u001b[A\n",
      "Validation DataLoader 0:  26%|███▋          | 801/3084 [00:03<00:10, 221.65it/s]\u001b[A\n",
      "Validation DataLoader 0:  26%|███▋          | 802/3084 [00:03<00:10, 221.66it/s]\u001b[A\n",
      "Validation DataLoader 0:  26%|███▋          | 803/3084 [00:03<00:10, 221.68it/s]\u001b[A\n",
      "Validation DataLoader 0:  26%|███▋          | 804/3084 [00:03<00:10, 221.70it/s]\u001b[A\n",
      "Validation DataLoader 0:  26%|███▋          | 805/3084 [00:03<00:10, 221.71it/s]\u001b[A\n",
      "Validation DataLoader 0:  26%|███▋          | 806/3084 [00:03<00:10, 221.73it/s]\u001b[A\n",
      "Validation DataLoader 0:  26%|███▋          | 807/3084 [00:03<00:10, 221.75it/s]\u001b[A\n",
      "Validation DataLoader 0:  26%|███▋          | 808/3084 [00:03<00:10, 221.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  26%|███▋          | 809/3084 [00:03<00:10, 221.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  26%|███▋          | 810/3084 [00:03<00:10, 221.76it/s]\u001b[A\n",
      "Validation DataLoader 0:  26%|███▋          | 811/3084 [00:03<00:10, 221.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  26%|███▋          | 812/3084 [00:03<00:10, 221.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  26%|███▋          | 813/3084 [00:03<00:10, 221.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  26%|███▋          | 814/3084 [00:03<00:10, 221.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  26%|███▋          | 815/3084 [00:03<00:10, 221.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  26%|███▋          | 816/3084 [00:03<00:10, 221.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  26%|███▋          | 817/3084 [00:03<00:10, 221.86it/s]\u001b[A\n",
      "Validation DataLoader 0:  27%|███▋          | 818/3084 [00:03<00:10, 221.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  27%|███▋          | 819/3084 [00:03<00:10, 221.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  27%|███▋          | 820/3084 [00:03<00:10, 221.86it/s]\u001b[A\n",
      "Validation DataLoader 0:  27%|███▋          | 821/3084 [00:03<00:10, 221.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  27%|███▋          | 822/3084 [00:03<00:10, 221.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  27%|███▋          | 823/3084 [00:03<00:10, 221.90it/s]\u001b[A\n",
      "Validation DataLoader 0:  27%|███▋          | 824/3084 [00:03<00:10, 221.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  27%|███▋          | 825/3084 [00:03<00:10, 221.90it/s]\u001b[A\n",
      "Validation DataLoader 0:  27%|███▋          | 826/3084 [00:03<00:10, 221.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  27%|███▊          | 827/3084 [00:03<00:10, 221.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  27%|███▊          | 828/3084 [00:03<00:10, 221.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  27%|███▊          | 829/3084 [00:03<00:10, 221.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  27%|███▊          | 830/3084 [00:03<00:10, 221.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  27%|███▊          | 831/3084 [00:03<00:10, 221.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  27%|███▊          | 832/3084 [00:03<00:10, 221.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  27%|███▊          | 833/3084 [00:03<00:10, 221.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  27%|███▊          | 834/3084 [00:03<00:10, 222.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  27%|███▊          | 835/3084 [00:03<00:10, 222.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  27%|███▊          | 836/3084 [00:03<00:10, 222.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  27%|███▊          | 837/3084 [00:03<00:10, 222.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  27%|███▊          | 838/3084 [00:03<00:10, 222.07it/s]\u001b[A\n",
      "Validation DataLoader 0:  27%|███▊          | 839/3084 [00:03<00:10, 222.09it/s]\u001b[A\n",
      "Validation DataLoader 0:  27%|███▊          | 840/3084 [00:03<00:10, 222.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  27%|███▊          | 841/3084 [00:03<00:10, 222.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  27%|███▊          | 842/3084 [00:03<00:10, 222.08it/s]\u001b[A\n",
      "Validation DataLoader 0:  27%|███▊          | 843/3084 [00:03<00:10, 222.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  27%|███▊          | 844/3084 [00:03<00:10, 222.12it/s]\u001b[A\n",
      "Validation DataLoader 0:  27%|███▊          | 845/3084 [00:03<00:10, 222.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  27%|███▊          | 846/3084 [00:03<00:10, 222.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  27%|███▊          | 847/3084 [00:03<00:10, 222.16it/s]\u001b[A\n",
      "Validation DataLoader 0:  27%|███▊          | 848/3084 [00:03<00:10, 222.18it/s]\u001b[A\n",
      "Validation DataLoader 0:  28%|███▊          | 849/3084 [00:03<00:10, 222.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  28%|███▊          | 850/3084 [00:03<00:10, 222.20it/s]\u001b[A\n",
      "Validation DataLoader 0:  28%|███▊          | 851/3084 [00:03<00:10, 222.18it/s]\u001b[A\n",
      "Validation DataLoader 0:  28%|███▊          | 852/3084 [00:03<00:10, 222.20it/s]\u001b[A\n",
      "Validation DataLoader 0:  28%|███▊          | 853/3084 [00:03<00:10, 222.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  28%|███▉          | 854/3084 [00:03<00:10, 222.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  28%|███▉          | 855/3084 [00:03<00:10, 222.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  28%|███▉          | 856/3084 [00:03<00:10, 222.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  28%|███▉          | 857/3084 [00:03<00:10, 222.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  28%|███▉          | 858/3084 [00:03<00:10, 222.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  28%|███▉          | 859/3084 [00:03<00:10, 222.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  28%|███▉          | 860/3084 [00:03<00:10, 222.24it/s]\u001b[A\n",
      "Validation DataLoader 0:  28%|███▉          | 861/3084 [00:03<00:10, 222.25it/s]\u001b[A\n",
      "Validation DataLoader 0:  28%|███▉          | 862/3084 [00:03<00:09, 222.26it/s]\u001b[A\n",
      "Validation DataLoader 0:  28%|███▉          | 863/3084 [00:03<00:09, 222.27it/s]\u001b[A\n",
      "Validation DataLoader 0:  28%|███▉          | 864/3084 [00:03<00:09, 222.29it/s]\u001b[A\n",
      "Validation DataLoader 0:  28%|███▉          | 865/3084 [00:03<00:09, 222.30it/s]\u001b[A\n",
      "Validation DataLoader 0:  28%|███▉          | 866/3084 [00:03<00:09, 222.32it/s]\u001b[A\n",
      "Validation DataLoader 0:  28%|███▉          | 867/3084 [00:03<00:09, 222.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  28%|███▉          | 868/3084 [00:03<00:09, 222.36it/s]\u001b[A\n",
      "Validation DataLoader 0:  28%|███▉          | 869/3084 [00:03<00:09, 222.37it/s]\u001b[A\n",
      "Validation DataLoader 0:  28%|███▉          | 870/3084 [00:03<00:09, 222.39it/s]\u001b[A\n",
      "Validation DataLoader 0:  28%|███▉          | 871/3084 [00:03<00:09, 222.40it/s]\u001b[A\n",
      "Validation DataLoader 0:  28%|███▉          | 872/3084 [00:03<00:09, 222.42it/s]\u001b[A\n",
      "Validation DataLoader 0:  28%|███▉          | 873/3084 [00:03<00:09, 222.44it/s]\u001b[A\n",
      "Validation DataLoader 0:  28%|███▉          | 874/3084 [00:03<00:09, 222.41it/s]\u001b[A\n",
      "Validation DataLoader 0:  28%|███▉          | 875/3084 [00:03<00:09, 222.43it/s]\u001b[A\n",
      "Validation DataLoader 0:  28%|███▉          | 876/3084 [00:03<00:09, 222.44it/s]\u001b[A\n",
      "Validation DataLoader 0:  28%|███▉          | 877/3084 [00:03<00:09, 222.46it/s]\u001b[A\n",
      "Validation DataLoader 0:  28%|███▉          | 878/3084 [00:03<00:09, 222.47it/s]\u001b[A\n",
      "Validation DataLoader 0:  29%|███▉          | 879/3084 [00:03<00:09, 222.49it/s]\u001b[A\n",
      "Validation DataLoader 0:  29%|███▉          | 880/3084 [00:03<00:09, 222.50it/s]\u001b[A\n",
      "Validation DataLoader 0:  29%|███▉          | 881/3084 [00:03<00:09, 222.51it/s]\u001b[A\n",
      "Validation DataLoader 0:  29%|████          | 882/3084 [00:03<00:09, 222.52it/s]\u001b[A\n",
      "Validation DataLoader 0:  29%|████          | 883/3084 [00:03<00:09, 222.50it/s]\u001b[A\n",
      "Validation DataLoader 0:  29%|████          | 884/3084 [00:03<00:09, 222.51it/s]\u001b[A\n",
      "Validation DataLoader 0:  29%|████          | 885/3084 [00:03<00:09, 222.52it/s]\u001b[A\n",
      "Validation DataLoader 0:  29%|████          | 886/3084 [00:03<00:09, 222.53it/s]\u001b[A\n",
      "Validation DataLoader 0:  29%|████          | 887/3084 [00:03<00:09, 222.54it/s]\u001b[A\n",
      "Validation DataLoader 0:  29%|████          | 888/3084 [00:03<00:09, 222.51it/s]\u001b[A\n",
      "Validation DataLoader 0:  29%|████          | 889/3084 [00:03<00:09, 222.52it/s]\u001b[A\n",
      "Validation DataLoader 0:  29%|████          | 890/3084 [00:03<00:09, 222.53it/s]\u001b[A\n",
      "Validation DataLoader 0:  29%|████          | 891/3084 [00:04<00:09, 222.54it/s]\u001b[A\n",
      "Validation DataLoader 0:  29%|████          | 892/3084 [00:04<00:09, 222.55it/s]\u001b[A\n",
      "Validation DataLoader 0:  29%|████          | 893/3084 [00:04<00:09, 222.56it/s]\u001b[A\n",
      "Validation DataLoader 0:  29%|████          | 894/3084 [00:04<00:09, 222.56it/s]\u001b[A\n",
      "Validation DataLoader 0:  29%|████          | 895/3084 [00:04<00:09, 222.57it/s]\u001b[A\n",
      "Validation DataLoader 0:  29%|████          | 896/3084 [00:04<00:09, 222.59it/s]\u001b[A\n",
      "Validation DataLoader 0:  29%|████          | 897/3084 [00:04<00:09, 222.60it/s]\u001b[A\n",
      "Validation DataLoader 0:  29%|████          | 898/3084 [00:04<00:09, 222.61it/s]\u001b[A\n",
      "Validation DataLoader 0:  29%|████          | 899/3084 [00:04<00:09, 222.63it/s]\u001b[A\n",
      "Validation DataLoader 0:  29%|████          | 900/3084 [00:04<00:09, 222.64it/s]\u001b[A\n",
      "Validation DataLoader 0:  29%|████          | 901/3084 [00:04<00:09, 222.65it/s]\u001b[A\n",
      "Validation DataLoader 0:  29%|████          | 902/3084 [00:04<00:09, 222.63it/s]\u001b[A\n",
      "Validation DataLoader 0:  29%|████          | 903/3084 [00:04<00:09, 222.56it/s]\u001b[A\n",
      "Validation DataLoader 0:  29%|████          | 904/3084 [00:04<00:09, 222.50it/s]\u001b[A\n",
      "Validation DataLoader 0:  29%|████          | 905/3084 [00:04<00:09, 222.44it/s]\u001b[A\n",
      "Validation DataLoader 0:  29%|████          | 906/3084 [00:04<00:09, 222.38it/s]\u001b[A\n",
      "Validation DataLoader 0:  29%|████          | 907/3084 [00:04<00:09, 222.31it/s]\u001b[A\n",
      "Validation DataLoader 0:  29%|████          | 908/3084 [00:04<00:09, 222.25it/s]\u001b[A\n",
      "Validation DataLoader 0:  29%|████▏         | 909/3084 [00:04<00:09, 222.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|████▏         | 910/3084 [00:04<00:09, 222.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|████▏         | 911/3084 [00:04<00:09, 222.07it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|████▏         | 912/3084 [00:04<00:09, 222.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|████▏         | 913/3084 [00:04<00:09, 222.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|████▏         | 914/3084 [00:04<00:09, 222.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|████▏         | 915/3084 [00:04<00:09, 221.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|████▏         | 916/3084 [00:04<00:09, 221.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|████▏         | 917/3084 [00:04<00:09, 221.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|████▏         | 918/3084 [00:04<00:09, 221.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|████▏         | 919/3084 [00:04<00:09, 221.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|████▏         | 920/3084 [00:04<00:09, 221.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|████▏         | 921/3084 [00:04<00:09, 221.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|████▏         | 922/3084 [00:04<00:09, 221.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|████▏         | 923/3084 [00:04<00:09, 221.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|████▏         | 924/3084 [00:04<00:09, 221.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|████▏         | 925/3084 [00:04<00:09, 221.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|████▏         | 926/3084 [00:04<00:09, 221.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|████▏         | 927/3084 [00:04<00:09, 221.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|████▏         | 928/3084 [00:04<00:09, 222.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|████▏         | 929/3084 [00:04<00:09, 222.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|████▏         | 930/3084 [00:04<00:09, 222.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|████▏         | 931/3084 [00:04<00:09, 222.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|████▏         | 932/3084 [00:04<00:09, 222.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|████▏         | 933/3084 [00:04<00:09, 222.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|████▏         | 934/3084 [00:04<00:09, 222.07it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|████▏         | 935/3084 [00:04<00:09, 222.08it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|████▏         | 936/3084 [00:04<00:09, 222.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|████▎         | 937/3084 [00:04<00:09, 222.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|████▎         | 938/3084 [00:04<00:09, 222.08it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|████▎         | 939/3084 [00:04<00:09, 222.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  30%|████▎         | 940/3084 [00:04<00:09, 222.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  31%|████▎         | 941/3084 [00:04<00:09, 222.12it/s]\u001b[A\n",
      "Validation DataLoader 0:  31%|████▎         | 942/3084 [00:04<00:09, 222.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  31%|████▎         | 943/3084 [00:04<00:09, 222.12it/s]\u001b[A\n",
      "Validation DataLoader 0:  31%|████▎         | 944/3084 [00:04<00:09, 222.12it/s]\u001b[A\n",
      "Validation DataLoader 0:  31%|████▎         | 945/3084 [00:04<00:09, 222.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  31%|████▎         | 946/3084 [00:04<00:09, 222.14it/s]\u001b[A\n",
      "Validation DataLoader 0:  31%|████▎         | 947/3084 [00:04<00:09, 222.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  31%|████▎         | 948/3084 [00:04<00:09, 222.12it/s]\u001b[A\n",
      "Validation DataLoader 0:  31%|████▎         | 949/3084 [00:04<00:09, 222.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  31%|████▎         | 950/3084 [00:04<00:09, 222.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  31%|████▎         | 951/3084 [00:04<00:09, 222.14it/s]\u001b[A\n",
      "Validation DataLoader 0:  31%|████▎         | 952/3084 [00:04<00:09, 222.16it/s]\u001b[A\n",
      "Validation DataLoader 0:  31%|████▎         | 953/3084 [00:04<00:09, 222.16it/s]\u001b[A\n",
      "Validation DataLoader 0:  31%|████▎         | 954/3084 [00:04<00:09, 222.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  31%|████▎         | 955/3084 [00:04<00:09, 222.18it/s]\u001b[A\n",
      "Validation DataLoader 0:  31%|████▎         | 956/3084 [00:04<00:09, 222.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  31%|████▎         | 957/3084 [00:04<00:09, 222.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  31%|████▎         | 958/3084 [00:04<00:09, 222.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  31%|████▎         | 959/3084 [00:04<00:09, 222.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  31%|████▎         | 960/3084 [00:04<00:09, 222.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  31%|████▎         | 961/3084 [00:04<00:09, 222.24it/s]\u001b[A\n",
      "Validation DataLoader 0:  31%|████▎         | 962/3084 [00:04<00:09, 222.25it/s]\u001b[A\n",
      "Validation DataLoader 0:  31%|████▎         | 963/3084 [00:04<00:09, 222.26it/s]\u001b[A\n",
      "Validation DataLoader 0:  31%|████▍         | 964/3084 [00:04<00:09, 222.27it/s]\u001b[A\n",
      "Validation DataLoader 0:  31%|████▍         | 965/3084 [00:04<00:09, 222.28it/s]\u001b[A\n",
      "Validation DataLoader 0:  31%|████▍         | 966/3084 [00:04<00:09, 222.30it/s]\u001b[A\n",
      "Validation DataLoader 0:  31%|████▍         | 967/3084 [00:04<00:09, 222.31it/s]\u001b[A\n",
      "Validation DataLoader 0:  31%|████▍         | 968/3084 [00:04<00:09, 222.31it/s]\u001b[A\n",
      "Validation DataLoader 0:  31%|████▍         | 969/3084 [00:04<00:09, 222.32it/s]\u001b[A\n",
      "Validation DataLoader 0:  31%|████▍         | 970/3084 [00:04<00:09, 222.30it/s]\u001b[A\n",
      "Validation DataLoader 0:  31%|████▍         | 971/3084 [00:04<00:09, 222.30it/s]\u001b[A\n",
      "Validation DataLoader 0:  32%|████▍         | 972/3084 [00:04<00:09, 222.31it/s]\u001b[A\n",
      "Validation DataLoader 0:  32%|████▍         | 973/3084 [00:04<00:09, 222.32it/s]\u001b[A\n",
      "Validation DataLoader 0:  32%|████▍         | 974/3084 [00:04<00:09, 222.33it/s]\u001b[A\n",
      "Validation DataLoader 0:  32%|████▍         | 975/3084 [00:04<00:09, 222.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  32%|████▍         | 976/3084 [00:04<00:09, 222.35it/s]\u001b[A\n",
      "Validation DataLoader 0:  32%|████▍         | 977/3084 [00:04<00:09, 222.36it/s]\u001b[A\n",
      "Validation DataLoader 0:  32%|████▍         | 978/3084 [00:04<00:09, 222.37it/s]\u001b[A\n",
      "Validation DataLoader 0:  32%|████▍         | 979/3084 [00:04<00:09, 222.35it/s]\u001b[A\n",
      "Validation DataLoader 0:  32%|████▍         | 980/3084 [00:04<00:09, 222.32it/s]\u001b[A\n",
      "Validation DataLoader 0:  32%|████▍         | 981/3084 [00:04<00:09, 222.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  32%|████▍         | 982/3084 [00:04<00:09, 222.35it/s]\u001b[A\n",
      "Validation DataLoader 0:  32%|████▍         | 983/3084 [00:04<00:09, 222.36it/s]\u001b[A\n",
      "Validation DataLoader 0:  32%|████▍         | 984/3084 [00:04<00:09, 222.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  32%|████▍         | 985/3084 [00:04<00:09, 222.35it/s]\u001b[A\n",
      "Validation DataLoader 0:  32%|████▍         | 986/3084 [00:04<00:09, 222.36it/s]\u001b[A\n",
      "Validation DataLoader 0:  32%|████▍         | 987/3084 [00:04<00:09, 222.37it/s]\u001b[A\n",
      "Validation DataLoader 0:  32%|████▍         | 988/3084 [00:04<00:09, 222.38it/s]\u001b[A\n",
      "Validation DataLoader 0:  32%|████▍         | 989/3084 [00:04<00:09, 222.39it/s]\u001b[A\n",
      "Validation DataLoader 0:  32%|████▍         | 990/3084 [00:04<00:09, 222.41it/s]\u001b[A\n",
      "Validation DataLoader 0:  32%|████▍         | 991/3084 [00:04<00:09, 222.42it/s]\u001b[A\n",
      "Validation DataLoader 0:  32%|████▌         | 992/3084 [00:04<00:09, 222.44it/s]\u001b[A\n",
      "Validation DataLoader 0:  32%|████▌         | 993/3084 [00:04<00:09, 222.45it/s]\u001b[A\n",
      "Validation DataLoader 0:  32%|████▌         | 994/3084 [00:04<00:09, 222.46it/s]\u001b[A\n",
      "Validation DataLoader 0:  32%|████▌         | 995/3084 [00:04<00:09, 222.48it/s]\u001b[A\n",
      "Validation DataLoader 0:  32%|████▌         | 996/3084 [00:04<00:09, 222.49it/s]\u001b[A\n",
      "Validation DataLoader 0:  32%|████▌         | 997/3084 [00:04<00:09, 222.51it/s]\u001b[A\n",
      "Validation DataLoader 0:  32%|████▌         | 998/3084 [00:04<00:09, 222.53it/s]\u001b[A\n",
      "Validation DataLoader 0:  32%|████▌         | 999/3084 [00:04<00:09, 222.54it/s]\u001b[A\n",
      "Validation DataLoader 0:  32%|████▏        | 1000/3084 [00:04<00:09, 222.55it/s]\u001b[A\n",
      "Validation DataLoader 0:  32%|████▏        | 1001/3084 [00:04<00:09, 222.57it/s]\u001b[A\n",
      "Validation DataLoader 0:  32%|████▏        | 1002/3084 [00:04<00:09, 222.54it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|████▏        | 1003/3084 [00:04<00:09, 222.56it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|████▏        | 1004/3084 [00:04<00:09, 222.57it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|████▏        | 1005/3084 [00:04<00:09, 222.58it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|████▏        | 1006/3084 [00:04<00:09, 222.59it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|████▏        | 1007/3084 [00:04<00:09, 222.61it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|████▏        | 1008/3084 [00:04<00:09, 222.62it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|████▎        | 1009/3084 [00:04<00:09, 222.63it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|████▎        | 1010/3084 [00:04<00:09, 222.64it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|████▎        | 1011/3084 [00:04<00:09, 222.61it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|████▎        | 1012/3084 [00:04<00:09, 222.59it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|████▎        | 1013/3084 [00:04<00:09, 222.60it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|████▎        | 1014/3084 [00:04<00:09, 222.61it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|████▎        | 1015/3084 [00:04<00:09, 222.62it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|████▎        | 1016/3084 [00:04<00:09, 222.60it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|████▎        | 1017/3084 [00:04<00:09, 222.62it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|████▎        | 1018/3084 [00:04<00:09, 222.63it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|████▎        | 1019/3084 [00:04<00:09, 222.64it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|████▎        | 1020/3084 [00:04<00:09, 222.64it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|████▎        | 1021/3084 [00:04<00:09, 222.65it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|████▎        | 1022/3084 [00:04<00:09, 222.66it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|████▎        | 1023/3084 [00:04<00:09, 222.68it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|████▎        | 1024/3084 [00:04<00:09, 222.69it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|████▎        | 1025/3084 [00:04<00:09, 222.70it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|████▎        | 1026/3084 [00:04<00:09, 222.72it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|████▎        | 1027/3084 [00:04<00:09, 222.73it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|████▎        | 1028/3084 [00:04<00:09, 222.74it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|████▎        | 1029/3084 [00:04<00:09, 222.75it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|████▎        | 1030/3084 [00:04<00:09, 222.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|████▎        | 1031/3084 [00:04<00:09, 222.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|████▎        | 1032/3084 [00:04<00:09, 222.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  33%|████▎        | 1033/3084 [00:04<00:09, 222.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  34%|████▎        | 1034/3084 [00:04<00:09, 222.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  34%|████▎        | 1035/3084 [00:04<00:09, 222.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  34%|████▎        | 1036/3084 [00:04<00:09, 222.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  34%|████▎        | 1037/3084 [00:04<00:09, 222.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  34%|████▍        | 1038/3084 [00:04<00:09, 222.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  34%|████▍        | 1039/3084 [00:04<00:09, 222.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  34%|████▍        | 1040/3084 [00:04<00:09, 222.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  34%|████▍        | 1041/3084 [00:04<00:09, 222.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  34%|████▍        | 1042/3084 [00:04<00:09, 222.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  34%|████▍        | 1043/3084 [00:04<00:09, 222.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  34%|████▍        | 1044/3084 [00:04<00:09, 222.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  34%|████▍        | 1045/3084 [00:04<00:09, 222.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  34%|████▍        | 1046/3084 [00:04<00:09, 222.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  34%|████▍        | 1047/3084 [00:04<00:09, 222.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  34%|████▍        | 1048/3084 [00:04<00:09, 222.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  34%|████▍        | 1049/3084 [00:04<00:09, 222.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  34%|████▍        | 1050/3084 [00:04<00:09, 222.86it/s]\u001b[A\n",
      "Validation DataLoader 0:  34%|████▍        | 1051/3084 [00:04<00:09, 222.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  34%|████▍        | 1052/3084 [00:04<00:09, 222.89it/s]\u001b[A\n",
      "Validation DataLoader 0:  34%|████▍        | 1053/3084 [00:04<00:09, 222.90it/s]\u001b[A\n",
      "Validation DataLoader 0:  34%|████▍        | 1054/3084 [00:04<00:09, 222.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  34%|████▍        | 1055/3084 [00:04<00:09, 222.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  34%|████▍        | 1056/3084 [00:04<00:09, 222.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  34%|████▍        | 1057/3084 [00:04<00:09, 222.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  34%|████▍        | 1058/3084 [00:04<00:09, 222.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  34%|████▍        | 1059/3084 [00:04<00:09, 222.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  34%|████▍        | 1060/3084 [00:04<00:09, 222.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  34%|████▍        | 1061/3084 [00:04<00:09, 222.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  34%|████▍        | 1062/3084 [00:04<00:09, 222.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  34%|████▍        | 1063/3084 [00:04<00:09, 223.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|████▍        | 1064/3084 [00:04<00:09, 223.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|████▍        | 1065/3084 [00:04<00:09, 223.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|████▍        | 1066/3084 [00:04<00:09, 223.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|████▍        | 1067/3084 [00:04<00:09, 223.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|████▌        | 1068/3084 [00:04<00:09, 223.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|████▌        | 1069/3084 [00:04<00:09, 223.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|████▌        | 1070/3084 [00:04<00:09, 223.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|████▌        | 1071/3084 [00:04<00:09, 223.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|████▌        | 1072/3084 [00:04<00:09, 223.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|████▌        | 1073/3084 [00:04<00:09, 223.07it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|████▌        | 1074/3084 [00:04<00:09, 223.08it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|████▌        | 1075/3084 [00:04<00:09, 223.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|████▌        | 1076/3084 [00:04<00:09, 223.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|████▌        | 1077/3084 [00:04<00:08, 223.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|████▌        | 1078/3084 [00:04<00:08, 223.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|████▌        | 1079/3084 [00:04<00:08, 223.07it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|████▌        | 1080/3084 [00:04<00:08, 223.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|████▌        | 1081/3084 [00:04<00:08, 223.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|████▌        | 1082/3084 [00:04<00:08, 223.07it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|████▌        | 1083/3084 [00:04<00:08, 223.07it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|████▌        | 1084/3084 [00:04<00:08, 223.08it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|████▌        | 1085/3084 [00:04<00:08, 223.09it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|████▌        | 1086/3084 [00:04<00:08, 223.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|████▌        | 1087/3084 [00:04<00:08, 223.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|████▌        | 1088/3084 [00:04<00:08, 223.12it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|████▌        | 1089/3084 [00:04<00:08, 223.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|████▌        | 1090/3084 [00:04<00:08, 223.12it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|████▌        | 1091/3084 [00:04<00:08, 223.14it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|████▌        | 1092/3084 [00:04<00:08, 223.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|████▌        | 1093/3084 [00:04<00:08, 223.16it/s]\u001b[A\n",
      "Validation DataLoader 0:  35%|████▌        | 1094/3084 [00:04<00:08, 223.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  36%|████▌        | 1095/3084 [00:04<00:08, 223.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  36%|████▌        | 1096/3084 [00:04<00:08, 223.20it/s]\u001b[A\n",
      "Validation DataLoader 0:  36%|████▌        | 1097/3084 [00:04<00:08, 223.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  36%|████▋        | 1098/3084 [00:04<00:08, 223.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  36%|████▋        | 1099/3084 [00:04<00:08, 223.20it/s]\u001b[A\n",
      "Validation DataLoader 0:  36%|████▋        | 1100/3084 [00:04<00:08, 223.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  36%|████▋        | 1101/3084 [00:04<00:08, 223.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  36%|████▋        | 1102/3084 [00:04<00:08, 223.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  36%|████▋        | 1103/3084 [00:04<00:08, 223.24it/s]\u001b[A\n",
      "Validation DataLoader 0:  36%|████▋        | 1104/3084 [00:04<00:08, 223.25it/s]\u001b[A\n",
      "Validation DataLoader 0:  36%|████▋        | 1105/3084 [00:04<00:08, 223.26it/s]\u001b[A\n",
      "Validation DataLoader 0:  36%|████▋        | 1106/3084 [00:04<00:08, 223.27it/s]\u001b[A\n",
      "Validation DataLoader 0:  36%|████▋        | 1107/3084 [00:04<00:08, 223.25it/s]\u001b[A\n",
      "Validation DataLoader 0:  36%|████▋        | 1108/3084 [00:04<00:08, 223.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  36%|████▋        | 1109/3084 [00:04<00:08, 223.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  36%|████▋        | 1110/3084 [00:04<00:08, 223.20it/s]\u001b[A\n",
      "Validation DataLoader 0:  36%|████▋        | 1111/3084 [00:04<00:08, 223.18it/s]\u001b[A\n",
      "Validation DataLoader 0:  36%|████▋        | 1112/3084 [00:04<00:08, 223.16it/s]\u001b[A\n",
      "Validation DataLoader 0:  36%|████▋        | 1113/3084 [00:04<00:08, 223.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  36%|████▋        | 1114/3084 [00:04<00:08, 223.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  36%|████▋        | 1115/3084 [00:04<00:08, 223.18it/s]\u001b[A\n",
      "Validation DataLoader 0:  36%|████▋        | 1116/3084 [00:05<00:08, 223.18it/s]\u001b[A\n",
      "Validation DataLoader 0:  36%|████▋        | 1117/3084 [00:05<00:08, 223.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  36%|████▋        | 1118/3084 [00:05<00:08, 223.20it/s]\u001b[A\n",
      "Validation DataLoader 0:  36%|████▋        | 1119/3084 [00:05<00:08, 223.20it/s]\u001b[A\n",
      "Validation DataLoader 0:  36%|████▋        | 1120/3084 [00:05<00:08, 223.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  36%|████▋        | 1121/3084 [00:05<00:08, 223.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  36%|████▋        | 1122/3084 [00:05<00:08, 223.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  36%|████▋        | 1123/3084 [00:05<00:08, 223.24it/s]\u001b[A\n",
      "Validation DataLoader 0:  36%|████▋        | 1124/3084 [00:05<00:08, 223.25it/s]\u001b[A\n",
      "Validation DataLoader 0:  36%|████▋        | 1125/3084 [00:05<00:08, 223.26it/s]\u001b[A\n",
      "Validation DataLoader 0:  37%|████▋        | 1126/3084 [00:05<00:08, 223.27it/s]\u001b[A\n",
      "Validation DataLoader 0:  37%|████▊        | 1127/3084 [00:05<00:08, 223.29it/s]\u001b[A\n",
      "Validation DataLoader 0:  37%|████▊        | 1128/3084 [00:05<00:08, 223.30it/s]\u001b[A\n",
      "Validation DataLoader 0:  37%|████▊        | 1129/3084 [00:05<00:08, 223.31it/s]\u001b[A\n",
      "Validation DataLoader 0:  37%|████▊        | 1130/3084 [00:05<00:08, 223.32it/s]\u001b[A\n",
      "Validation DataLoader 0:  37%|████▊        | 1131/3084 [00:05<00:08, 223.33it/s]\u001b[A\n",
      "Validation DataLoader 0:  37%|████▊        | 1132/3084 [00:05<00:08, 223.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  37%|████▊        | 1133/3084 [00:05<00:08, 223.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  37%|████▊        | 1134/3084 [00:05<00:08, 223.35it/s]\u001b[A\n",
      "Validation DataLoader 0:  37%|████▊        | 1135/3084 [00:05<00:08, 223.36it/s]\u001b[A\n",
      "Validation DataLoader 0:  37%|████▊        | 1136/3084 [00:05<00:08, 223.37it/s]\u001b[A\n",
      "Validation DataLoader 0:  37%|████▊        | 1137/3084 [00:05<00:08, 223.38it/s]\u001b[A\n",
      "Validation DataLoader 0:  37%|████▊        | 1138/3084 [00:05<00:08, 223.39it/s]\u001b[A\n",
      "Validation DataLoader 0:  37%|████▊        | 1139/3084 [00:05<00:08, 223.37it/s]\u001b[A\n",
      "Validation DataLoader 0:  37%|████▊        | 1140/3084 [00:05<00:08, 223.38it/s]\u001b[A\n",
      "Validation DataLoader 0:  37%|████▊        | 1141/3084 [00:05<00:08, 223.39it/s]\u001b[A\n",
      "Validation DataLoader 0:  37%|████▊        | 1142/3084 [00:05<00:08, 223.40it/s]\u001b[A\n",
      "Validation DataLoader 0:  37%|████▊        | 1143/3084 [00:05<00:08, 223.41it/s]\u001b[A\n",
      "Validation DataLoader 0:  37%|████▊        | 1144/3084 [00:05<00:08, 223.39it/s]\u001b[A\n",
      "Validation DataLoader 0:  37%|████▊        | 1145/3084 [00:05<00:08, 223.40it/s]\u001b[A\n",
      "Validation DataLoader 0:  37%|████▊        | 1146/3084 [00:05<00:08, 223.40it/s]\u001b[A\n",
      "Validation DataLoader 0:  37%|████▊        | 1147/3084 [00:05<00:08, 223.41it/s]\u001b[A\n",
      "Validation DataLoader 0:  37%|████▊        | 1148/3084 [00:05<00:08, 223.42it/s]\u001b[A\n",
      "Validation DataLoader 0:  37%|████▊        | 1149/3084 [00:05<00:08, 223.43it/s]\u001b[A\n",
      "Validation DataLoader 0:  37%|████▊        | 1150/3084 [00:05<00:08, 223.43it/s]\u001b[A\n",
      "Validation DataLoader 0:  37%|████▊        | 1151/3084 [00:05<00:08, 223.44it/s]\u001b[A\n",
      "Validation DataLoader 0:  37%|████▊        | 1152/3084 [00:05<00:08, 223.46it/s]\u001b[A\n",
      "Validation DataLoader 0:  37%|████▊        | 1153/3084 [00:05<00:08, 223.47it/s]\u001b[A\n",
      "Validation DataLoader 0:  37%|████▊        | 1154/3084 [00:05<00:08, 223.48it/s]\u001b[A\n",
      "Validation DataLoader 0:  37%|████▊        | 1155/3084 [00:05<00:08, 223.49it/s]\u001b[A\n",
      "Validation DataLoader 0:  37%|████▊        | 1156/3084 [00:05<00:08, 223.50it/s]\u001b[A\n",
      "Validation DataLoader 0:  38%|████▉        | 1157/3084 [00:05<00:08, 223.51it/s]\u001b[A\n",
      "Validation DataLoader 0:  38%|████▉        | 1158/3084 [00:05<00:08, 223.52it/s]\u001b[A\n",
      "Validation DataLoader 0:  38%|████▉        | 1159/3084 [00:05<00:08, 223.53it/s]\u001b[A\n",
      "Validation DataLoader 0:  38%|████▉        | 1160/3084 [00:05<00:08, 223.54it/s]\u001b[A\n",
      "Validation DataLoader 0:  38%|████▉        | 1161/3084 [00:05<00:08, 223.55it/s]\u001b[A\n",
      "Validation DataLoader 0:  38%|████▉        | 1162/3084 [00:05<00:08, 223.56it/s]\u001b[A\n",
      "Validation DataLoader 0:  38%|████▉        | 1163/3084 [00:05<00:08, 223.57it/s]\u001b[A\n",
      "Validation DataLoader 0:  38%|████▉        | 1164/3084 [00:05<00:08, 223.58it/s]\u001b[A\n",
      "Validation DataLoader 0:  38%|████▉        | 1165/3084 [00:05<00:08, 223.59it/s]\u001b[A\n",
      "Validation DataLoader 0:  38%|████▉        | 1166/3084 [00:05<00:08, 223.60it/s]\u001b[A\n",
      "Validation DataLoader 0:  38%|████▉        | 1167/3084 [00:05<00:08, 223.61it/s]\u001b[A\n",
      "Validation DataLoader 0:  38%|████▉        | 1168/3084 [00:05<00:08, 223.62it/s]\u001b[A\n",
      "Validation DataLoader 0:  38%|████▉        | 1169/3084 [00:05<00:08, 223.64it/s]\u001b[A\n",
      "Validation DataLoader 0:  38%|████▉        | 1170/3084 [00:05<00:08, 223.65it/s]\u001b[A\n",
      "Validation DataLoader 0:  38%|████▉        | 1171/3084 [00:05<00:08, 223.62it/s]\u001b[A\n",
      "Validation DataLoader 0:  38%|████▉        | 1172/3084 [00:05<00:08, 223.40it/s]\u001b[A\n",
      "Validation DataLoader 0:  38%|████▉        | 1173/3084 [00:05<00:08, 223.39it/s]\u001b[A\n",
      "Validation DataLoader 0:  38%|████▉        | 1174/3084 [00:05<00:08, 223.40it/s]\u001b[A\n",
      "Validation DataLoader 0:  38%|████▉        | 1175/3084 [00:05<00:08, 223.38it/s]\u001b[A\n",
      "Validation DataLoader 0:  38%|████▉        | 1176/3084 [00:05<00:08, 223.39it/s]\u001b[A\n",
      "Validation DataLoader 0:  38%|████▉        | 1177/3084 [00:05<00:08, 223.40it/s]\u001b[A\n",
      "Validation DataLoader 0:  38%|████▉        | 1178/3084 [00:05<00:08, 223.40it/s]\u001b[A\n",
      "Validation DataLoader 0:  38%|████▉        | 1179/3084 [00:05<00:08, 223.42it/s]\u001b[A\n",
      "Validation DataLoader 0:  38%|████▉        | 1180/3084 [00:05<00:08, 223.43it/s]\u001b[A\n",
      "Validation DataLoader 0:  38%|████▉        | 1181/3084 [00:05<00:08, 223.43it/s]\u001b[A\n",
      "Validation DataLoader 0:  38%|████▉        | 1182/3084 [00:05<00:08, 223.44it/s]\u001b[A\n",
      "Validation DataLoader 0:  38%|████▉        | 1183/3084 [00:05<00:08, 223.45it/s]\u001b[A\n",
      "Validation DataLoader 0:  38%|████▉        | 1184/3084 [00:05<00:08, 223.46it/s]\u001b[A\n",
      "Validation DataLoader 0:  38%|████▉        | 1185/3084 [00:05<00:08, 223.47it/s]\u001b[A\n",
      "Validation DataLoader 0:  38%|████▉        | 1186/3084 [00:05<00:08, 223.47it/s]\u001b[A\n",
      "Validation DataLoader 0:  38%|█████        | 1187/3084 [00:05<00:08, 223.48it/s]\u001b[A\n",
      "Validation DataLoader 0:  39%|█████        | 1188/3084 [00:05<00:08, 223.48it/s]\u001b[A\n",
      "Validation DataLoader 0:  39%|█████        | 1189/3084 [00:05<00:08, 223.47it/s]\u001b[A\n",
      "Validation DataLoader 0:  39%|█████        | 1190/3084 [00:05<00:08, 223.48it/s]\u001b[A\n",
      "Validation DataLoader 0:  39%|█████        | 1191/3084 [00:05<00:08, 223.49it/s]\u001b[A\n",
      "Validation DataLoader 0:  39%|█████        | 1192/3084 [00:05<00:08, 223.50it/s]\u001b[A\n",
      "Validation DataLoader 0:  39%|█████        | 1193/3084 [00:05<00:08, 223.51it/s]\u001b[A\n",
      "Validation DataLoader 0:  39%|█████        | 1194/3084 [00:05<00:08, 223.52it/s]\u001b[A\n",
      "Validation DataLoader 0:  39%|█████        | 1195/3084 [00:05<00:08, 223.53it/s]\u001b[A\n",
      "Validation DataLoader 0:  39%|█████        | 1196/3084 [00:05<00:08, 223.54it/s]\u001b[A\n",
      "Validation DataLoader 0:  39%|█████        | 1197/3084 [00:05<00:08, 223.53it/s]\u001b[A\n",
      "Validation DataLoader 0:  39%|█████        | 1198/3084 [00:05<00:08, 223.54it/s]\u001b[A\n",
      "Validation DataLoader 0:  39%|█████        | 1199/3084 [00:05<00:08, 223.55it/s]\u001b[A\n",
      "Validation DataLoader 0:  39%|█████        | 1200/3084 [00:05<00:08, 223.56it/s]\u001b[A\n",
      "Validation DataLoader 0:  39%|█████        | 1201/3084 [00:05<00:08, 223.57it/s]\u001b[A\n",
      "Validation DataLoader 0:  39%|█████        | 1202/3084 [00:05<00:08, 223.58it/s]\u001b[A\n",
      "Validation DataLoader 0:  39%|█████        | 1203/3084 [00:05<00:08, 223.59it/s]\u001b[A\n",
      "Validation DataLoader 0:  39%|█████        | 1204/3084 [00:05<00:08, 223.61it/s]\u001b[A\n",
      "Validation DataLoader 0:  39%|█████        | 1205/3084 [00:05<00:08, 223.62it/s]\u001b[A\n",
      "Validation DataLoader 0:  39%|█████        | 1206/3084 [00:05<00:08, 223.63it/s]\u001b[A\n",
      "Validation DataLoader 0:  39%|█████        | 1207/3084 [00:05<00:08, 223.61it/s]\u001b[A\n",
      "Validation DataLoader 0:  39%|█████        | 1208/3084 [00:05<00:08, 223.63it/s]\u001b[A\n",
      "Validation DataLoader 0:  39%|█████        | 1209/3084 [00:05<00:08, 223.63it/s]\u001b[A\n",
      "Validation DataLoader 0:  39%|█████        | 1210/3084 [00:05<00:08, 223.64it/s]\u001b[A\n",
      "Validation DataLoader 0:  39%|█████        | 1211/3084 [00:05<00:08, 223.65it/s]\u001b[A\n",
      "Validation DataLoader 0:  39%|█████        | 1212/3084 [00:05<00:08, 223.66it/s]\u001b[A\n",
      "Validation DataLoader 0:  39%|█████        | 1213/3084 [00:05<00:08, 223.66it/s]\u001b[A\n",
      "Validation DataLoader 0:  39%|█████        | 1214/3084 [00:05<00:08, 223.67it/s]\u001b[A\n",
      "Validation DataLoader 0:  39%|█████        | 1215/3084 [00:05<00:08, 223.67it/s]\u001b[A\n",
      "Validation DataLoader 0:  39%|█████▏       | 1216/3084 [00:05<00:08, 223.69it/s]\u001b[A\n",
      "Validation DataLoader 0:  39%|█████▏       | 1217/3084 [00:05<00:08, 223.69it/s]\u001b[A\n",
      "Validation DataLoader 0:  39%|█████▏       | 1218/3084 [00:05<00:08, 223.70it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|█████▏       | 1219/3084 [00:05<00:08, 223.71it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|█████▏       | 1220/3084 [00:05<00:08, 223.71it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|█████▏       | 1221/3084 [00:05<00:08, 223.70it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|█████▏       | 1222/3084 [00:05<00:08, 223.71it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|█████▏       | 1223/3084 [00:05<00:08, 223.72it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|█████▏       | 1224/3084 [00:05<00:08, 223.73it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|█████▏       | 1225/3084 [00:05<00:08, 223.73it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|█████▏       | 1226/3084 [00:05<00:08, 223.75it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|█████▏       | 1227/3084 [00:05<00:08, 223.76it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|█████▏       | 1228/3084 [00:05<00:08, 223.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|█████▏       | 1229/3084 [00:05<00:08, 223.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|█████▏       | 1230/3084 [00:05<00:08, 223.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|█████▏       | 1231/3084 [00:05<00:08, 223.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|█████▏       | 1232/3084 [00:05<00:08, 223.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|█████▏       | 1233/3084 [00:05<00:08, 223.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|█████▏       | 1234/3084 [00:05<00:08, 223.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|█████▏       | 1235/3084 [00:05<00:08, 223.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|█████▏       | 1236/3084 [00:05<00:08, 223.86it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|█████▏       | 1237/3084 [00:05<00:08, 223.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|█████▏       | 1238/3084 [00:05<00:08, 223.89it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|█████▏       | 1239/3084 [00:05<00:08, 223.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|█████▏       | 1240/3084 [00:05<00:08, 223.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|█████▏       | 1241/3084 [00:05<00:08, 223.89it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|█████▏       | 1242/3084 [00:05<00:08, 223.90it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|█████▏       | 1243/3084 [00:05<00:08, 223.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|█████▏       | 1244/3084 [00:05<00:08, 223.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|█████▏       | 1245/3084 [00:05<00:08, 223.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|█████▎       | 1246/3084 [00:05<00:08, 223.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|█████▎       | 1247/3084 [00:05<00:08, 223.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|█████▎       | 1248/3084 [00:05<00:08, 223.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  40%|█████▎       | 1249/3084 [00:05<00:08, 223.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  41%|█████▎       | 1250/3084 [00:05<00:08, 223.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  41%|█████▎       | 1251/3084 [00:05<00:08, 223.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  41%|█████▎       | 1252/3084 [00:05<00:08, 223.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  41%|█████▎       | 1253/3084 [00:05<00:08, 223.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  41%|█████▎       | 1254/3084 [00:05<00:08, 223.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  41%|█████▎       | 1255/3084 [00:05<00:08, 223.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  41%|█████▎       | 1256/3084 [00:05<00:08, 224.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  41%|█████▎       | 1257/3084 [00:05<00:08, 224.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  41%|█████▎       | 1258/3084 [00:05<00:08, 224.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  41%|█████▎       | 1259/3084 [00:05<00:08, 224.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  41%|█████▎       | 1260/3084 [00:05<00:08, 224.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  41%|█████▎       | 1261/3084 [00:05<00:08, 224.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  41%|█████▎       | 1262/3084 [00:05<00:08, 224.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  41%|█████▎       | 1263/3084 [00:05<00:08, 224.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  41%|█████▎       | 1264/3084 [00:05<00:08, 224.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  41%|█████▎       | 1265/3084 [00:05<00:08, 224.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  41%|█████▎       | 1266/3084 [00:05<00:08, 224.07it/s]\u001b[A\n",
      "Validation DataLoader 0:  41%|█████▎       | 1267/3084 [00:05<00:08, 224.08it/s]\u001b[A\n",
      "Validation DataLoader 0:  41%|█████▎       | 1268/3084 [00:05<00:08, 224.08it/s]\u001b[A\n",
      "Validation DataLoader 0:  41%|█████▎       | 1269/3084 [00:05<00:08, 224.09it/s]\u001b[A\n",
      "Validation DataLoader 0:  41%|█████▎       | 1270/3084 [00:05<00:08, 224.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  41%|█████▎       | 1271/3084 [00:05<00:08, 224.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  41%|█████▎       | 1272/3084 [00:05<00:08, 224.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  41%|█████▎       | 1273/3084 [00:05<00:08, 224.12it/s]\u001b[A\n",
      "Validation DataLoader 0:  41%|█████▎       | 1274/3084 [00:05<00:08, 224.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  41%|█████▎       | 1275/3084 [00:05<00:08, 224.14it/s]\u001b[A\n",
      "Validation DataLoader 0:  41%|█████▍       | 1276/3084 [00:05<00:08, 224.14it/s]\u001b[A\n",
      "Validation DataLoader 0:  41%|█████▍       | 1277/3084 [00:05<00:08, 224.14it/s]\u001b[A\n",
      "Validation DataLoader 0:  41%|█████▍       | 1278/3084 [00:05<00:08, 224.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  41%|█████▍       | 1279/3084 [00:05<00:08, 224.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  42%|█████▍       | 1280/3084 [00:05<00:08, 224.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  42%|█████▍       | 1281/3084 [00:05<00:08, 224.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  42%|█████▍       | 1282/3084 [00:05<00:08, 224.14it/s]\u001b[A\n",
      "Validation DataLoader 0:  42%|█████▍       | 1283/3084 [00:05<00:08, 224.14it/s]\u001b[A\n",
      "Validation DataLoader 0:  42%|█████▍       | 1284/3084 [00:05<00:08, 224.14it/s]\u001b[A\n",
      "Validation DataLoader 0:  42%|█████▍       | 1285/3084 [00:05<00:08, 224.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  42%|█████▍       | 1286/3084 [00:05<00:08, 224.16it/s]\u001b[A\n",
      "Validation DataLoader 0:  42%|█████▍       | 1287/3084 [00:05<00:08, 224.18it/s]\u001b[A\n",
      "Validation DataLoader 0:  42%|█████▍       | 1288/3084 [00:05<00:08, 224.18it/s]\u001b[A\n",
      "Validation DataLoader 0:  42%|█████▍       | 1289/3084 [00:05<00:08, 224.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  42%|█████▍       | 1290/3084 [00:05<00:08, 224.20it/s]\u001b[A\n",
      "Validation DataLoader 0:  42%|█████▍       | 1291/3084 [00:05<00:07, 224.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  42%|█████▍       | 1292/3084 [00:05<00:07, 224.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  42%|█████▍       | 1293/3084 [00:05<00:07, 224.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  42%|█████▍       | 1294/3084 [00:05<00:07, 224.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  42%|█████▍       | 1295/3084 [00:05<00:07, 224.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  42%|█████▍       | 1296/3084 [00:05<00:07, 224.24it/s]\u001b[A\n",
      "Validation DataLoader 0:  42%|█████▍       | 1297/3084 [00:05<00:07, 224.25it/s]\u001b[A\n",
      "Validation DataLoader 0:  42%|█████▍       | 1298/3084 [00:05<00:07, 224.25it/s]\u001b[A\n",
      "Validation DataLoader 0:  42%|█████▍       | 1299/3084 [00:05<00:07, 224.26it/s]\u001b[A\n",
      "Validation DataLoader 0:  42%|█████▍       | 1300/3084 [00:05<00:07, 224.27it/s]\u001b[A\n",
      "Validation DataLoader 0:  42%|█████▍       | 1301/3084 [00:05<00:07, 224.28it/s]\u001b[A\n",
      "Validation DataLoader 0:  42%|█████▍       | 1302/3084 [00:05<00:07, 224.29it/s]\u001b[A\n",
      "Validation DataLoader 0:  42%|█████▍       | 1303/3084 [00:05<00:07, 224.30it/s]\u001b[A\n",
      "Validation DataLoader 0:  42%|█████▍       | 1304/3084 [00:05<00:07, 224.31it/s]\u001b[A\n",
      "Validation DataLoader 0:  42%|█████▌       | 1305/3084 [00:05<00:07, 224.32it/s]\u001b[A\n",
      "Validation DataLoader 0:  42%|█████▌       | 1306/3084 [00:05<00:07, 224.32it/s]\u001b[A\n",
      "Validation DataLoader 0:  42%|█████▌       | 1307/3084 [00:05<00:07, 224.32it/s]\u001b[A\n",
      "Validation DataLoader 0:  42%|█████▌       | 1308/3084 [00:05<00:07, 224.33it/s]\u001b[A\n",
      "Validation DataLoader 0:  42%|█████▌       | 1309/3084 [00:05<00:07, 224.33it/s]\u001b[A\n",
      "Validation DataLoader 0:  42%|█████▌       | 1310/3084 [00:05<00:07, 224.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  43%|█████▌       | 1311/3084 [00:05<00:07, 224.35it/s]\u001b[A\n",
      "Validation DataLoader 0:  43%|█████▌       | 1312/3084 [00:05<00:07, 224.33it/s]\u001b[A\n",
      "Validation DataLoader 0:  43%|█████▌       | 1313/3084 [00:05<00:07, 224.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  43%|█████▌       | 1314/3084 [00:05<00:07, 224.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  43%|█████▌       | 1315/3084 [00:05<00:07, 224.18it/s]\u001b[A\n",
      "Validation DataLoader 0:  43%|█████▌       | 1316/3084 [00:05<00:07, 224.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  43%|█████▌       | 1317/3084 [00:05<00:07, 224.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  43%|█████▌       | 1318/3084 [00:05<00:07, 224.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  43%|█████▌       | 1319/3084 [00:05<00:07, 224.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  43%|█████▌       | 1320/3084 [00:05<00:07, 224.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  43%|█████▌       | 1321/3084 [00:05<00:07, 224.24it/s]\u001b[A\n",
      "Validation DataLoader 0:  43%|█████▌       | 1322/3084 [00:05<00:07, 224.26it/s]\u001b[A\n",
      "Validation DataLoader 0:  43%|█████▌       | 1323/3084 [00:05<00:07, 224.27it/s]\u001b[A\n",
      "Validation DataLoader 0:  43%|█████▌       | 1324/3084 [00:05<00:07, 224.28it/s]\u001b[A\n",
      "Validation DataLoader 0:  43%|█████▌       | 1325/3084 [00:05<00:07, 224.28it/s]\u001b[A\n",
      "Validation DataLoader 0:  43%|█████▌       | 1326/3084 [00:05<00:07, 224.29it/s]\u001b[A\n",
      "Validation DataLoader 0:  43%|█████▌       | 1327/3084 [00:05<00:07, 224.30it/s]\u001b[A\n",
      "Validation DataLoader 0:  43%|█████▌       | 1328/3084 [00:05<00:07, 224.31it/s]\u001b[A\n",
      "Validation DataLoader 0:  43%|█████▌       | 1329/3084 [00:05<00:07, 224.32it/s]\u001b[A\n",
      "Validation DataLoader 0:  43%|█████▌       | 1330/3084 [00:05<00:07, 224.33it/s]\u001b[A\n",
      "Validation DataLoader 0:  43%|█████▌       | 1331/3084 [00:05<00:07, 224.33it/s]\u001b[A\n",
      "Validation DataLoader 0:  43%|█████▌       | 1332/3084 [00:05<00:07, 224.35it/s]\u001b[A\n",
      "Validation DataLoader 0:  43%|█████▌       | 1333/3084 [00:05<00:07, 224.33it/s]\u001b[A\n",
      "Validation DataLoader 0:  43%|█████▌       | 1334/3084 [00:05<00:07, 224.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  43%|█████▋       | 1335/3084 [00:05<00:07, 224.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  43%|█████▋       | 1336/3084 [00:05<00:07, 224.35it/s]\u001b[A\n",
      "Validation DataLoader 0:  43%|█████▋       | 1337/3084 [00:05<00:07, 224.36it/s]\u001b[A\n",
      "Validation DataLoader 0:  43%|█████▋       | 1338/3084 [00:05<00:07, 224.37it/s]\u001b[A\n",
      "Validation DataLoader 0:  43%|█████▋       | 1339/3084 [00:05<00:07, 224.38it/s]\u001b[A\n",
      "Validation DataLoader 0:  43%|█████▋       | 1340/3084 [00:05<00:07, 224.38it/s]\u001b[A\n",
      "Validation DataLoader 0:  43%|█████▋       | 1341/3084 [00:05<00:07, 224.39it/s]\u001b[A\n",
      "Validation DataLoader 0:  44%|█████▋       | 1342/3084 [00:05<00:07, 224.40it/s]\u001b[A\n",
      "Validation DataLoader 0:  44%|█████▋       | 1343/3084 [00:05<00:07, 224.41it/s]\u001b[A\n",
      "Validation DataLoader 0:  44%|█████▋       | 1344/3084 [00:05<00:07, 224.39it/s]\u001b[A\n",
      "Validation DataLoader 0:  44%|█████▋       | 1345/3084 [00:05<00:07, 224.39it/s]\u001b[A\n",
      "Validation DataLoader 0:  44%|█████▋       | 1346/3084 [00:05<00:07, 224.40it/s]\u001b[A\n",
      "Validation DataLoader 0:  44%|█████▋       | 1347/3084 [00:06<00:07, 224.41it/s]\u001b[A\n",
      "Validation DataLoader 0:  44%|█████▋       | 1348/3084 [00:06<00:07, 224.41it/s]\u001b[A\n",
      "Validation DataLoader 0:  44%|█████▋       | 1349/3084 [00:06<00:07, 224.42it/s]\u001b[A\n",
      "Validation DataLoader 0:  44%|█████▋       | 1350/3084 [00:06<00:07, 224.43it/s]\u001b[A\n",
      "Validation DataLoader 0:  44%|█████▋       | 1351/3084 [00:06<00:07, 224.44it/s]\u001b[A\n",
      "Validation DataLoader 0:  44%|█████▋       | 1352/3084 [00:06<00:07, 224.45it/s]\u001b[A\n",
      "Validation DataLoader 0:  44%|█████▋       | 1353/3084 [00:06<00:07, 224.46it/s]\u001b[A\n",
      "Validation DataLoader 0:  44%|█████▋       | 1354/3084 [00:06<00:07, 224.47it/s]\u001b[A\n",
      "Validation DataLoader 0:  44%|█████▋       | 1355/3084 [00:06<00:07, 224.48it/s]\u001b[A\n",
      "Validation DataLoader 0:  44%|█████▋       | 1356/3084 [00:06<00:07, 224.49it/s]\u001b[A\n",
      "Validation DataLoader 0:  44%|█████▋       | 1357/3084 [00:06<00:07, 224.49it/s]\u001b[A\n",
      "Validation DataLoader 0:  44%|█████▋       | 1358/3084 [00:06<00:07, 224.50it/s]\u001b[A\n",
      "Validation DataLoader 0:  44%|█████▋       | 1359/3084 [00:06<00:07, 224.50it/s]\u001b[A\n",
      "Validation DataLoader 0:  44%|█████▋       | 1360/3084 [00:06<00:07, 224.51it/s]\u001b[A\n",
      "Validation DataLoader 0:  44%|█████▋       | 1361/3084 [00:06<00:07, 224.52it/s]\u001b[A\n",
      "Validation DataLoader 0:  44%|█████▋       | 1362/3084 [00:06<00:07, 224.52it/s]\u001b[A\n",
      "Validation DataLoader 0:  44%|█████▋       | 1363/3084 [00:06<00:07, 224.53it/s]\u001b[A\n",
      "Validation DataLoader 0:  44%|█████▋       | 1364/3084 [00:06<00:07, 224.54it/s]\u001b[A\n",
      "Validation DataLoader 0:  44%|█████▊       | 1365/3084 [00:06<00:07, 224.52it/s]\u001b[A\n",
      "Validation DataLoader 0:  44%|█████▊       | 1366/3084 [00:06<00:07, 224.53it/s]\u001b[A\n",
      "Validation DataLoader 0:  44%|█████▊       | 1367/3084 [00:06<00:07, 224.54it/s]\u001b[A\n",
      "Validation DataLoader 0:  44%|█████▊       | 1368/3084 [00:06<00:07, 224.55it/s]\u001b[A\n",
      "Validation DataLoader 0:  44%|█████▊       | 1369/3084 [00:06<00:07, 224.55it/s]\u001b[A\n",
      "Validation DataLoader 0:  44%|█████▊       | 1370/3084 [00:06<00:07, 224.56it/s]\u001b[A\n",
      "Validation DataLoader 0:  44%|█████▊       | 1371/3084 [00:06<00:07, 224.58it/s]\u001b[A\n",
      "Validation DataLoader 0:  44%|█████▊       | 1372/3084 [00:06<00:07, 224.59it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|█████▊       | 1373/3084 [00:06<00:07, 224.59it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|█████▊       | 1374/3084 [00:06<00:07, 224.60it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|█████▊       | 1375/3084 [00:06<00:07, 224.61it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|█████▊       | 1376/3084 [00:06<00:07, 224.59it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|█████▊       | 1377/3084 [00:06<00:07, 224.59it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|█████▊       | 1378/3084 [00:06<00:07, 224.60it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|█████▊       | 1379/3084 [00:06<00:07, 224.60it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|█████▊       | 1380/3084 [00:06<00:07, 224.61it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|█████▊       | 1381/3084 [00:06<00:07, 224.62it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|█████▊       | 1382/3084 [00:06<00:07, 224.63it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|█████▊       | 1383/3084 [00:06<00:07, 224.64it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|█████▊       | 1384/3084 [00:06<00:07, 224.64it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|█████▊       | 1385/3084 [00:06<00:07, 224.65it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|█████▊       | 1386/3084 [00:06<00:07, 224.66it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|█████▊       | 1387/3084 [00:06<00:07, 224.67it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|█████▊       | 1388/3084 [00:06<00:07, 224.68it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|█████▊       | 1389/3084 [00:06<00:07, 224.69it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|█████▊       | 1390/3084 [00:06<00:07, 224.69it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|█████▊       | 1391/3084 [00:06<00:07, 224.70it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|█████▊       | 1392/3084 [00:06<00:07, 224.71it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|█████▊       | 1393/3084 [00:06<00:07, 224.71it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|█████▉       | 1394/3084 [00:06<00:07, 224.72it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|█████▉       | 1395/3084 [00:06<00:07, 224.73it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|█████▉       | 1396/3084 [00:06<00:07, 224.74it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|█████▉       | 1397/3084 [00:06<00:07, 224.72it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|█████▉       | 1398/3084 [00:06<00:07, 224.72it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|█████▉       | 1399/3084 [00:06<00:07, 224.73it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|█████▉       | 1400/3084 [00:06<00:07, 224.74it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|█████▉       | 1401/3084 [00:06<00:07, 224.75it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|█████▉       | 1402/3084 [00:06<00:07, 224.76it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|█████▉       | 1403/3084 [00:06<00:07, 224.76it/s]\u001b[A\n",
      "Validation DataLoader 0:  46%|█████▉       | 1404/3084 [00:06<00:07, 224.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  46%|█████▉       | 1405/3084 [00:06<00:07, 224.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  46%|█████▉       | 1406/3084 [00:06<00:07, 224.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  46%|█████▉       | 1407/3084 [00:06<00:07, 224.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  46%|█████▉       | 1408/3084 [00:06<00:07, 224.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  46%|█████▉       | 1409/3084 [00:06<00:07, 224.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  46%|█████▉       | 1410/3084 [00:06<00:07, 224.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  46%|█████▉       | 1411/3084 [00:06<00:07, 224.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  46%|█████▉       | 1412/3084 [00:06<00:07, 224.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  46%|█████▉       | 1413/3084 [00:06<00:07, 224.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  46%|█████▉       | 1414/3084 [00:06<00:07, 224.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  46%|█████▉       | 1415/3084 [00:06<00:07, 224.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  46%|█████▉       | 1416/3084 [00:06<00:07, 224.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  46%|█████▉       | 1417/3084 [00:06<00:07, 224.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  46%|█████▉       | 1418/3084 [00:06<00:07, 224.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  46%|█████▉       | 1419/3084 [00:06<00:07, 224.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  46%|█████▉       | 1420/3084 [00:06<00:07, 224.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  46%|█████▉       | 1421/3084 [00:06<00:07, 224.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  46%|█████▉       | 1422/3084 [00:06<00:07, 224.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  46%|█████▉       | 1423/3084 [00:06<00:07, 224.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  46%|██████       | 1424/3084 [00:06<00:07, 224.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  46%|██████       | 1425/3084 [00:06<00:07, 224.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  46%|██████       | 1426/3084 [00:06<00:07, 224.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  46%|██████       | 1427/3084 [00:06<00:07, 224.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  46%|██████       | 1428/3084 [00:06<00:07, 224.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  46%|██████       | 1429/3084 [00:06<00:07, 224.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  46%|██████       | 1430/3084 [00:06<00:07, 224.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  46%|██████       | 1431/3084 [00:06<00:07, 224.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  46%|██████       | 1432/3084 [00:06<00:07, 224.86it/s]\u001b[A\n",
      "Validation DataLoader 0:  46%|██████       | 1433/3084 [00:06<00:07, 224.86it/s]\u001b[A\n",
      "Validation DataLoader 0:  46%|██████       | 1434/3084 [00:06<00:07, 224.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  47%|██████       | 1435/3084 [00:06<00:07, 224.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  47%|██████       | 1436/3084 [00:06<00:07, 224.89it/s]\u001b[A\n",
      "Validation DataLoader 0:  47%|██████       | 1437/3084 [00:06<00:07, 224.89it/s]\u001b[A\n",
      "Validation DataLoader 0:  47%|██████       | 1438/3084 [00:06<00:07, 224.90it/s]\u001b[A\n",
      "Validation DataLoader 0:  47%|██████       | 1439/3084 [00:06<00:07, 224.90it/s]\u001b[A\n",
      "Validation DataLoader 0:  47%|██████       | 1440/3084 [00:06<00:07, 224.89it/s]\u001b[A\n",
      "Validation DataLoader 0:  47%|██████       | 1441/3084 [00:06<00:07, 224.89it/s]\u001b[A\n",
      "Validation DataLoader 0:  47%|██████       | 1442/3084 [00:06<00:07, 224.89it/s]\u001b[A\n",
      "Validation DataLoader 0:  47%|██████       | 1443/3084 [00:06<00:07, 224.90it/s]\u001b[A\n",
      "Validation DataLoader 0:  47%|██████       | 1444/3084 [00:06<00:07, 224.90it/s]\u001b[A\n",
      "Validation DataLoader 0:  47%|██████       | 1445/3084 [00:06<00:07, 224.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  47%|██████       | 1446/3084 [00:06<00:07, 224.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  47%|██████       | 1447/3084 [00:06<00:07, 224.90it/s]\u001b[A\n",
      "Validation DataLoader 0:  47%|██████       | 1448/3084 [00:06<00:07, 224.90it/s]\u001b[A\n",
      "Validation DataLoader 0:  47%|██████       | 1449/3084 [00:06<00:07, 224.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  47%|██████       | 1450/3084 [00:06<00:07, 224.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  47%|██████       | 1451/3084 [00:06<00:07, 224.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  47%|██████       | 1452/3084 [00:06<00:07, 224.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  47%|██████       | 1453/3084 [00:06<00:07, 224.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  47%|██████▏      | 1454/3084 [00:06<00:07, 224.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  47%|██████▏      | 1455/3084 [00:06<00:07, 224.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  47%|██████▏      | 1456/3084 [00:06<00:07, 224.66it/s]\u001b[A\n",
      "Validation DataLoader 0:  47%|██████▏      | 1457/3084 [00:06<00:07, 224.61it/s]\u001b[A\n",
      "Validation DataLoader 0:  47%|██████▏      | 1458/3084 [00:06<00:07, 224.62it/s]\u001b[A\n",
      "Validation DataLoader 0:  47%|██████▏      | 1459/3084 [00:06<00:07, 224.62it/s]\u001b[A\n",
      "Validation DataLoader 0:  47%|██████▏      | 1460/3084 [00:06<00:07, 224.63it/s]\u001b[A\n",
      "Validation DataLoader 0:  47%|██████▏      | 1461/3084 [00:06<00:07, 224.63it/s]\u001b[A\n",
      "Validation DataLoader 0:  47%|██████▏      | 1462/3084 [00:06<00:07, 224.63it/s]\u001b[A\n",
      "Validation DataLoader 0:  47%|██████▏      | 1463/3084 [00:06<00:07, 224.64it/s]\u001b[A\n",
      "Validation DataLoader 0:  47%|██████▏      | 1464/3084 [00:06<00:07, 224.65it/s]\u001b[A\n",
      "Validation DataLoader 0:  48%|██████▏      | 1465/3084 [00:06<00:07, 224.65it/s]\u001b[A\n",
      "Validation DataLoader 0:  48%|██████▏      | 1466/3084 [00:06<00:07, 224.66it/s]\u001b[A\n",
      "Validation DataLoader 0:  48%|██████▏      | 1467/3084 [00:06<00:07, 224.66it/s]\u001b[A\n",
      "Validation DataLoader 0:  48%|██████▏      | 1468/3084 [00:06<00:07, 224.67it/s]\u001b[A\n",
      "Validation DataLoader 0:  48%|██████▏      | 1469/3084 [00:06<00:07, 224.67it/s]\u001b[A\n",
      "Validation DataLoader 0:  48%|██████▏      | 1470/3084 [00:06<00:07, 224.68it/s]\u001b[A\n",
      "Validation DataLoader 0:  48%|██████▏      | 1471/3084 [00:06<00:07, 224.68it/s]\u001b[A\n",
      "Validation DataLoader 0:  48%|██████▏      | 1472/3084 [00:06<00:07, 224.69it/s]\u001b[A\n",
      "Validation DataLoader 0:  48%|██████▏      | 1473/3084 [00:06<00:07, 224.69it/s]\u001b[A\n",
      "Validation DataLoader 0:  48%|██████▏      | 1474/3084 [00:06<00:07, 224.69it/s]\u001b[A\n",
      "Validation DataLoader 0:  48%|██████▏      | 1475/3084 [00:06<00:07, 224.70it/s]\u001b[A\n",
      "Validation DataLoader 0:  48%|██████▏      | 1476/3084 [00:06<00:07, 224.70it/s]\u001b[A\n",
      "Validation DataLoader 0:  48%|██████▏      | 1477/3084 [00:06<00:07, 224.71it/s]\u001b[A\n",
      "Validation DataLoader 0:  48%|██████▏      | 1478/3084 [00:06<00:07, 224.71it/s]\u001b[A\n",
      "Validation DataLoader 0:  48%|██████▏      | 1479/3084 [00:06<00:07, 224.72it/s]\u001b[A\n",
      "Validation DataLoader 0:  48%|██████▏      | 1480/3084 [00:06<00:07, 224.73it/s]\u001b[A\n",
      "Validation DataLoader 0:  48%|██████▏      | 1481/3084 [00:06<00:07, 224.73it/s]\u001b[A\n",
      "Validation DataLoader 0:  48%|██████▏      | 1482/3084 [00:06<00:07, 224.74it/s]\u001b[A\n",
      "Validation DataLoader 0:  48%|██████▎      | 1483/3084 [00:06<00:07, 224.74it/s]\u001b[A\n",
      "Validation DataLoader 0:  48%|██████▎      | 1484/3084 [00:06<00:07, 224.75it/s]\u001b[A\n",
      "Validation DataLoader 0:  48%|██████▎      | 1485/3084 [00:06<00:07, 224.76it/s]\u001b[A\n",
      "Validation DataLoader 0:  48%|██████▎      | 1486/3084 [00:06<00:07, 224.76it/s]\u001b[A\n",
      "Validation DataLoader 0:  48%|██████▎      | 1487/3084 [00:06<00:07, 224.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  48%|██████▎      | 1488/3084 [00:06<00:07, 224.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  48%|██████▎      | 1489/3084 [00:06<00:07, 224.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  48%|██████▎      | 1490/3084 [00:06<00:07, 224.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  48%|██████▎      | 1491/3084 [00:06<00:07, 224.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  48%|██████▎      | 1492/3084 [00:06<00:07, 224.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  48%|██████▎      | 1493/3084 [00:06<00:07, 224.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  48%|██████▎      | 1494/3084 [00:06<00:07, 224.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  48%|██████▎      | 1495/3084 [00:06<00:07, 224.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  49%|██████▎      | 1496/3084 [00:06<00:07, 224.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  49%|██████▎      | 1497/3084 [00:06<00:07, 224.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  49%|██████▎      | 1498/3084 [00:06<00:07, 224.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  49%|██████▎      | 1499/3084 [00:06<00:07, 224.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  49%|██████▎      | 1500/3084 [00:06<00:07, 224.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  49%|██████▎      | 1501/3084 [00:06<00:07, 224.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  49%|██████▎      | 1502/3084 [00:06<00:07, 224.86it/s]\u001b[A\n",
      "Validation DataLoader 0:  49%|██████▎      | 1503/3084 [00:06<00:07, 224.86it/s]\u001b[A\n",
      "Validation DataLoader 0:  49%|██████▎      | 1504/3084 [00:06<00:07, 224.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  49%|██████▎      | 1505/3084 [00:06<00:07, 224.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  49%|██████▎      | 1506/3084 [00:06<00:07, 224.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  49%|██████▎      | 1507/3084 [00:06<00:07, 224.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  49%|██████▎      | 1508/3084 [00:06<00:07, 224.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  49%|██████▎      | 1509/3084 [00:06<00:07, 224.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  49%|██████▎      | 1510/3084 [00:06<00:06, 224.89it/s]\u001b[A\n",
      "Validation DataLoader 0:  49%|██████▎      | 1511/3084 [00:06<00:06, 224.90it/s]\u001b[A\n",
      "Validation DataLoader 0:  49%|██████▎      | 1512/3084 [00:06<00:06, 224.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  49%|██████▍      | 1513/3084 [00:06<00:06, 224.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  49%|██████▍      | 1514/3084 [00:06<00:06, 224.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  49%|██████▍      | 1515/3084 [00:06<00:06, 224.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  49%|██████▍      | 1516/3084 [00:06<00:06, 224.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  49%|██████▍      | 1517/3084 [00:06<00:06, 224.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  49%|██████▍      | 1518/3084 [00:06<00:06, 224.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  49%|██████▍      | 1519/3084 [00:06<00:06, 224.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  49%|██████▍      | 1520/3084 [00:06<00:06, 224.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  49%|██████▍      | 1521/3084 [00:06<00:06, 224.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  49%|██████▍      | 1522/3084 [00:06<00:06, 224.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  49%|██████▍      | 1523/3084 [00:06<00:06, 224.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  49%|██████▍      | 1524/3084 [00:06<00:06, 224.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  49%|██████▍      | 1525/3084 [00:06<00:06, 224.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  49%|██████▍      | 1526/3084 [00:06<00:06, 224.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████▍      | 1527/3084 [00:06<00:06, 224.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████▍      | 1528/3084 [00:06<00:06, 225.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████▍      | 1529/3084 [00:06<00:06, 225.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████▍      | 1530/3084 [00:06<00:06, 225.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████▍      | 1531/3084 [00:06<00:06, 225.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████▍      | 1532/3084 [00:06<00:06, 225.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████▍      | 1533/3084 [00:06<00:06, 225.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████▍      | 1534/3084 [00:06<00:06, 225.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████▍      | 1535/3084 [00:06<00:06, 225.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████▍      | 1536/3084 [00:06<00:06, 225.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████▍      | 1537/3084 [00:06<00:06, 225.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████▍      | 1538/3084 [00:06<00:06, 225.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████▍      | 1539/3084 [00:06<00:06, 225.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████▍      | 1540/3084 [00:06<00:06, 225.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████▍      | 1541/3084 [00:06<00:06, 225.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████▌      | 1542/3084 [00:06<00:06, 225.07it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████▌      | 1543/3084 [00:06<00:06, 225.08it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████▌      | 1544/3084 [00:06<00:06, 225.08it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████▌      | 1545/3084 [00:06<00:06, 225.09it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████▌      | 1546/3084 [00:06<00:06, 225.09it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████▌      | 1547/3084 [00:06<00:06, 225.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████▌      | 1548/3084 [00:06<00:06, 225.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████▌      | 1549/3084 [00:06<00:06, 225.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████▌      | 1550/3084 [00:06<00:06, 225.12it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████▌      | 1551/3084 [00:06<00:06, 225.12it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████▌      | 1552/3084 [00:06<00:06, 225.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████▌      | 1553/3084 [00:06<00:06, 225.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████▌      | 1554/3084 [00:06<00:06, 225.14it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████▌      | 1555/3084 [00:06<00:06, 225.14it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████▌      | 1556/3084 [00:06<00:06, 225.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|██████▌      | 1557/3084 [00:06<00:06, 225.14it/s]\u001b[A\n",
      "Validation DataLoader 0:  51%|██████▌      | 1558/3084 [00:06<00:06, 225.14it/s]\u001b[A\n",
      "Validation DataLoader 0:  51%|██████▌      | 1559/3084 [00:06<00:06, 225.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  51%|██████▌      | 1560/3084 [00:06<00:06, 225.16it/s]\u001b[A\n",
      "Validation DataLoader 0:  51%|██████▌      | 1561/3084 [00:06<00:06, 225.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  51%|██████▌      | 1562/3084 [00:06<00:06, 225.18it/s]\u001b[A\n",
      "Validation DataLoader 0:  51%|██████▌      | 1563/3084 [00:06<00:06, 225.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  51%|██████▌      | 1564/3084 [00:06<00:06, 225.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  51%|██████▌      | 1565/3084 [00:06<00:06, 225.20it/s]\u001b[A\n",
      "Validation DataLoader 0:  51%|██████▌      | 1566/3084 [00:06<00:06, 225.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  51%|██████▌      | 1567/3084 [00:06<00:06, 225.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  51%|██████▌      | 1568/3084 [00:06<00:06, 225.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  51%|██████▌      | 1569/3084 [00:06<00:06, 225.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  51%|██████▌      | 1570/3084 [00:06<00:06, 225.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  51%|██████▌      | 1571/3084 [00:06<00:06, 225.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  51%|██████▋      | 1572/3084 [00:06<00:06, 225.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  51%|██████▋      | 1573/3084 [00:06<00:06, 225.24it/s]\u001b[A\n",
      "Validation DataLoader 0:  51%|██████▋      | 1574/3084 [00:06<00:06, 225.25it/s]\u001b[A\n",
      "Validation DataLoader 0:  51%|██████▋      | 1575/3084 [00:06<00:06, 225.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  51%|██████▋      | 1576/3084 [00:06<00:06, 225.24it/s]\u001b[A\n",
      "Validation DataLoader 0:  51%|██████▋      | 1577/3084 [00:07<00:06, 225.26it/s]\u001b[A\n",
      "Validation DataLoader 0:  51%|██████▋      | 1578/3084 [00:07<00:06, 225.27it/s]\u001b[A\n",
      "Validation DataLoader 0:  51%|██████▋      | 1579/3084 [00:07<00:06, 225.28it/s]\u001b[A\n",
      "Validation DataLoader 0:  51%|██████▋      | 1580/3084 [00:07<00:06, 225.29it/s]\u001b[A\n",
      "Validation DataLoader 0:  51%|██████▋      | 1581/3084 [00:07<00:06, 225.30it/s]\u001b[A\n",
      "Validation DataLoader 0:  51%|██████▋      | 1582/3084 [00:07<00:06, 225.31it/s]\u001b[A\n",
      "Validation DataLoader 0:  51%|██████▋      | 1583/3084 [00:07<00:06, 225.31it/s]\u001b[A\n",
      "Validation DataLoader 0:  51%|██████▋      | 1584/3084 [00:07<00:06, 225.32it/s]\u001b[A\n",
      "Validation DataLoader 0:  51%|██████▋      | 1585/3084 [00:07<00:06, 225.33it/s]\u001b[A\n",
      "Validation DataLoader 0:  51%|██████▋      | 1586/3084 [00:07<00:06, 225.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  51%|██████▋      | 1587/3084 [00:07<00:06, 225.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  51%|██████▋      | 1588/3084 [00:07<00:06, 225.35it/s]\u001b[A\n",
      "Validation DataLoader 0:  52%|██████▋      | 1589/3084 [00:07<00:06, 225.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  52%|██████▋      | 1590/3084 [00:07<00:06, 225.35it/s]\u001b[A\n",
      "Validation DataLoader 0:  52%|██████▋      | 1591/3084 [00:07<00:06, 225.36it/s]\u001b[A\n",
      "Validation DataLoader 0:  52%|██████▋      | 1592/3084 [00:07<00:06, 225.37it/s]\u001b[A\n",
      "Validation DataLoader 0:  52%|██████▋      | 1593/3084 [00:07<00:06, 225.38it/s]\u001b[A\n",
      "Validation DataLoader 0:  52%|██████▋      | 1594/3084 [00:07<00:06, 225.39it/s]\u001b[A\n",
      "Validation DataLoader 0:  52%|██████▋      | 1595/3084 [00:07<00:06, 225.40it/s]\u001b[A\n",
      "Validation DataLoader 0:  52%|██████▋      | 1596/3084 [00:07<00:06, 225.41it/s]\u001b[A\n",
      "Validation DataLoader 0:  52%|██████▋      | 1597/3084 [00:07<00:06, 225.41it/s]\u001b[A\n",
      "Validation DataLoader 0:  52%|██████▋      | 1598/3084 [00:07<00:06, 225.42it/s]\u001b[A\n",
      "Validation DataLoader 0:  52%|██████▋      | 1599/3084 [00:07<00:06, 225.43it/s]\u001b[A\n",
      "Validation DataLoader 0:  52%|██████▋      | 1600/3084 [00:07<00:06, 225.42it/s]\u001b[A\n",
      "Validation DataLoader 0:  52%|██████▋      | 1601/3084 [00:07<00:06, 225.42it/s]\u001b[A\n",
      "Validation DataLoader 0:  52%|██████▊      | 1602/3084 [00:07<00:06, 225.43it/s]\u001b[A\n",
      "Validation DataLoader 0:  52%|██████▊      | 1603/3084 [00:07<00:06, 225.44it/s]\u001b[A\n",
      "Validation DataLoader 0:  52%|██████▊      | 1604/3084 [00:07<00:06, 225.44it/s]\u001b[A\n",
      "Validation DataLoader 0:  52%|██████▊      | 1605/3084 [00:07<00:06, 225.45it/s]\u001b[A\n",
      "Validation DataLoader 0:  52%|██████▊      | 1606/3084 [00:07<00:06, 225.45it/s]\u001b[A\n",
      "Validation DataLoader 0:  52%|██████▊      | 1607/3084 [00:07<00:06, 225.44it/s]\u001b[A\n",
      "Validation DataLoader 0:  52%|██████▊      | 1608/3084 [00:07<00:06, 225.45it/s]\u001b[A\n",
      "Validation DataLoader 0:  52%|██████▊      | 1609/3084 [00:07<00:06, 225.46it/s]\u001b[A\n",
      "Validation DataLoader 0:  52%|██████▊      | 1610/3084 [00:07<00:06, 225.47it/s]\u001b[A\n",
      "Validation DataLoader 0:  52%|██████▊      | 1611/3084 [00:07<00:06, 225.48it/s]\u001b[A\n",
      "Validation DataLoader 0:  52%|██████▊      | 1612/3084 [00:07<00:06, 225.49it/s]\u001b[A\n",
      "Validation DataLoader 0:  52%|██████▊      | 1613/3084 [00:07<00:06, 225.50it/s]\u001b[A\n",
      "Validation DataLoader 0:  52%|██████▊      | 1614/3084 [00:07<00:06, 225.50it/s]\u001b[A\n",
      "Validation DataLoader 0:  52%|██████▊      | 1615/3084 [00:07<00:06, 225.51it/s]\u001b[A\n",
      "Validation DataLoader 0:  52%|██████▊      | 1616/3084 [00:07<00:06, 225.52it/s]\u001b[A\n",
      "Validation DataLoader 0:  52%|██████▊      | 1617/3084 [00:07<00:06, 225.53it/s]\u001b[A\n",
      "Validation DataLoader 0:  52%|██████▊      | 1618/3084 [00:07<00:06, 225.54it/s]\u001b[A\n",
      "Validation DataLoader 0:  52%|██████▊      | 1619/3084 [00:07<00:06, 225.55it/s]\u001b[A\n",
      "Validation DataLoader 0:  53%|██████▊      | 1620/3084 [00:07<00:06, 225.56it/s]\u001b[A\n",
      "Validation DataLoader 0:  53%|██████▊      | 1621/3084 [00:07<00:06, 225.54it/s]\u001b[A\n",
      "Validation DataLoader 0:  53%|██████▊      | 1622/3084 [00:07<00:06, 225.55it/s]\u001b[A\n",
      "Validation DataLoader 0:  53%|██████▊      | 1623/3084 [00:07<00:06, 225.56it/s]\u001b[A\n",
      "Validation DataLoader 0:  53%|██████▊      | 1624/3084 [00:07<00:06, 225.57it/s]\u001b[A\n",
      "Validation DataLoader 0:  53%|██████▊      | 1625/3084 [00:07<00:06, 225.58it/s]\u001b[A\n",
      "Validation DataLoader 0:  53%|██████▊      | 1626/3084 [00:07<00:06, 225.58it/s]\u001b[A\n",
      "Validation DataLoader 0:  53%|██████▊      | 1627/3084 [00:07<00:06, 225.59it/s]\u001b[A\n",
      "Validation DataLoader 0:  53%|██████▊      | 1628/3084 [00:07<00:06, 225.60it/s]\u001b[A\n",
      "Validation DataLoader 0:  53%|██████▊      | 1629/3084 [00:07<00:06, 225.61it/s]\u001b[A\n",
      "Validation DataLoader 0:  53%|██████▊      | 1630/3084 [00:07<00:06, 225.62it/s]\u001b[A\n",
      "Validation DataLoader 0:  53%|██████▉      | 1631/3084 [00:07<00:06, 225.63it/s]\u001b[A\n",
      "Validation DataLoader 0:  53%|██████▉      | 1632/3084 [00:07<00:06, 225.62it/s]\u001b[A\n",
      "Validation DataLoader 0:  53%|██████▉      | 1633/3084 [00:07<00:06, 225.62it/s]\u001b[A\n",
      "Validation DataLoader 0:  53%|██████▉      | 1634/3084 [00:07<00:06, 225.62it/s]\u001b[A\n",
      "Validation DataLoader 0:  53%|██████▉      | 1635/3084 [00:07<00:06, 225.63it/s]\u001b[A\n",
      "Validation DataLoader 0:  53%|██████▉      | 1636/3084 [00:07<00:06, 225.63it/s]\u001b[A\n",
      "Validation DataLoader 0:  53%|██████▉      | 1637/3084 [00:07<00:06, 225.64it/s]\u001b[A\n",
      "Validation DataLoader 0:  53%|██████▉      | 1638/3084 [00:07<00:06, 225.65it/s]\u001b[A\n",
      "Validation DataLoader 0:  53%|██████▉      | 1639/3084 [00:07<00:06, 225.63it/s]\u001b[A\n",
      "Validation DataLoader 0:  53%|██████▉      | 1640/3084 [00:07<00:06, 225.64it/s]\u001b[A\n",
      "Validation DataLoader 0:  53%|██████▉      | 1641/3084 [00:07<00:06, 225.65it/s]\u001b[A\n",
      "Validation DataLoader 0:  53%|██████▉      | 1642/3084 [00:07<00:06, 225.66it/s]\u001b[A\n",
      "Validation DataLoader 0:  53%|██████▉      | 1643/3084 [00:07<00:06, 225.67it/s]\u001b[A\n",
      "Validation DataLoader 0:  53%|██████▉      | 1644/3084 [00:07<00:06, 225.67it/s]\u001b[A\n",
      "Validation DataLoader 0:  53%|██████▉      | 1645/3084 [00:07<00:06, 225.68it/s]\u001b[A\n",
      "Validation DataLoader 0:  53%|██████▉      | 1646/3084 [00:07<00:06, 225.69it/s]\u001b[A\n",
      "Validation DataLoader 0:  53%|██████▉      | 1647/3084 [00:07<00:06, 225.70it/s]\u001b[A\n",
      "Validation DataLoader 0:  53%|██████▉      | 1648/3084 [00:07<00:06, 225.70it/s]\u001b[A\n",
      "Validation DataLoader 0:  53%|██████▉      | 1649/3084 [00:07<00:06, 225.71it/s]\u001b[A\n",
      "Validation DataLoader 0:  54%|██████▉      | 1650/3084 [00:07<00:06, 225.71it/s]\u001b[A\n",
      "Validation DataLoader 0:  54%|██████▉      | 1651/3084 [00:07<00:06, 225.72it/s]\u001b[A\n",
      "Validation DataLoader 0:  54%|██████▉      | 1652/3084 [00:07<00:06, 225.73it/s]\u001b[A\n",
      "Validation DataLoader 0:  54%|██████▉      | 1653/3084 [00:07<00:06, 225.72it/s]\u001b[A\n",
      "Validation DataLoader 0:  54%|██████▉      | 1654/3084 [00:07<00:06, 225.72it/s]\u001b[A\n",
      "Validation DataLoader 0:  54%|██████▉      | 1655/3084 [00:07<00:06, 225.73it/s]\u001b[A\n",
      "Validation DataLoader 0:  54%|██████▉      | 1656/3084 [00:07<00:06, 225.74it/s]\u001b[A\n",
      "Validation DataLoader 0:  54%|██████▉      | 1657/3084 [00:07<00:06, 225.75it/s]\u001b[A\n",
      "Validation DataLoader 0:  54%|██████▉      | 1658/3084 [00:07<00:06, 225.76it/s]\u001b[A\n",
      "Validation DataLoader 0:  54%|██████▉      | 1659/3084 [00:07<00:06, 225.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  54%|██████▉      | 1660/3084 [00:07<00:06, 225.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  54%|███████      | 1661/3084 [00:07<00:06, 225.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  54%|███████      | 1662/3084 [00:07<00:06, 225.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  54%|███████      | 1663/3084 [00:07<00:06, 225.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  54%|███████      | 1664/3084 [00:07<00:06, 225.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  54%|███████      | 1665/3084 [00:07<00:06, 225.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  54%|███████      | 1666/3084 [00:07<00:06, 225.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  54%|███████      | 1667/3084 [00:07<00:06, 225.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  54%|███████      | 1668/3084 [00:07<00:06, 225.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  54%|███████      | 1669/3084 [00:07<00:06, 225.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  54%|███████      | 1670/3084 [00:07<00:06, 225.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  54%|███████      | 1671/3084 [00:07<00:06, 225.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  54%|███████      | 1672/3084 [00:07<00:06, 225.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  54%|███████      | 1673/3084 [00:07<00:06, 225.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  54%|███████      | 1674/3084 [00:07<00:06, 225.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  54%|███████      | 1675/3084 [00:07<00:06, 225.86it/s]\u001b[A\n",
      "Validation DataLoader 0:  54%|███████      | 1676/3084 [00:07<00:06, 225.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  54%|███████      | 1677/3084 [00:07<00:06, 225.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  54%|███████      | 1678/3084 [00:07<00:06, 225.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  54%|███████      | 1679/3084 [00:07<00:06, 225.89it/s]\u001b[A\n",
      "Validation DataLoader 0:  54%|███████      | 1680/3084 [00:07<00:06, 225.90it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|███████      | 1681/3084 [00:07<00:06, 225.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|███████      | 1682/3084 [00:07<00:06, 225.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|███████      | 1683/3084 [00:07<00:06, 225.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|███████      | 1684/3084 [00:07<00:06, 225.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|███████      | 1685/3084 [00:07<00:06, 225.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|███████      | 1686/3084 [00:07<00:06, 225.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|███████      | 1687/3084 [00:07<00:06, 225.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|███████      | 1688/3084 [00:07<00:06, 225.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|███████      | 1689/3084 [00:07<00:06, 225.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|███████      | 1690/3084 [00:07<00:06, 225.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|███████▏     | 1691/3084 [00:07<00:06, 225.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|███████▏     | 1692/3084 [00:07<00:06, 225.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|███████▏     | 1693/3084 [00:07<00:06, 226.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|███████▏     | 1694/3084 [00:07<00:06, 226.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|███████▏     | 1695/3084 [00:07<00:06, 226.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|███████▏     | 1696/3084 [00:07<00:06, 226.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|███████▏     | 1697/3084 [00:07<00:06, 225.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|███████▏     | 1698/3084 [00:07<00:06, 225.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|███████▏     | 1699/3084 [00:07<00:06, 225.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|███████▏     | 1700/3084 [00:07<00:06, 225.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|███████▏     | 1701/3084 [00:07<00:06, 225.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|███████▏     | 1702/3084 [00:07<00:06, 225.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|███████▏     | 1703/3084 [00:07<00:06, 225.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|███████▏     | 1704/3084 [00:07<00:06, 225.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|███████▏     | 1705/3084 [00:07<00:06, 225.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|███████▏     | 1706/3084 [00:07<00:06, 225.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|███████▏     | 1707/3084 [00:07<00:06, 225.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|███████▏     | 1708/3084 [00:07<00:06, 225.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|███████▏     | 1709/3084 [00:07<00:06, 225.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|███████▏     | 1710/3084 [00:07<00:06, 225.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|███████▏     | 1711/3084 [00:07<00:06, 225.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  56%|███████▏     | 1712/3084 [00:07<00:06, 225.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  56%|███████▏     | 1713/3084 [00:07<00:06, 225.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  56%|███████▏     | 1714/3084 [00:07<00:06, 225.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  56%|███████▏     | 1715/3084 [00:07<00:06, 225.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  56%|███████▏     | 1716/3084 [00:07<00:06, 225.75it/s]\u001b[A\n",
      "Validation DataLoader 0:  56%|███████▏     | 1717/3084 [00:07<00:06, 225.76it/s]\u001b[A\n",
      "Validation DataLoader 0:  56%|███████▏     | 1718/3084 [00:07<00:06, 225.76it/s]\u001b[A\n",
      "Validation DataLoader 0:  56%|███████▏     | 1719/3084 [00:07<00:06, 225.76it/s]\u001b[A\n",
      "Validation DataLoader 0:  56%|███████▎     | 1720/3084 [00:07<00:06, 225.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  56%|███████▎     | 1721/3084 [00:07<00:06, 225.76it/s]\u001b[A\n",
      "Validation DataLoader 0:  56%|███████▎     | 1722/3084 [00:07<00:06, 225.76it/s]\u001b[A\n",
      "Validation DataLoader 0:  56%|███████▎     | 1723/3084 [00:07<00:06, 225.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  56%|███████▎     | 1724/3084 [00:07<00:06, 225.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  56%|███████▎     | 1725/3084 [00:07<00:06, 225.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  56%|███████▎     | 1726/3084 [00:07<00:06, 225.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  56%|███████▎     | 1727/3084 [00:07<00:06, 225.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  56%|███████▎     | 1728/3084 [00:07<00:06, 225.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  56%|███████▎     | 1729/3084 [00:07<00:06, 225.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  56%|███████▎     | 1730/3084 [00:07<00:05, 225.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  56%|███████▎     | 1731/3084 [00:07<00:05, 225.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  56%|███████▎     | 1732/3084 [00:07<00:05, 225.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  56%|███████▎     | 1733/3084 [00:07<00:05, 225.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  56%|███████▎     | 1734/3084 [00:07<00:05, 225.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  56%|███████▎     | 1735/3084 [00:07<00:05, 225.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  56%|███████▎     | 1736/3084 [00:07<00:05, 225.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  56%|███████▎     | 1737/3084 [00:07<00:05, 225.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  56%|███████▎     | 1738/3084 [00:07<00:05, 225.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  56%|███████▎     | 1739/3084 [00:07<00:05, 225.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  56%|███████▎     | 1740/3084 [00:07<00:05, 225.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  56%|███████▎     | 1741/3084 [00:07<00:05, 225.66it/s]\u001b[A\n",
      "Validation DataLoader 0:  56%|███████▎     | 1742/3084 [00:07<00:05, 225.64it/s]\u001b[A\n",
      "Validation DataLoader 0:  57%|███████▎     | 1743/3084 [00:07<00:05, 225.64it/s]\u001b[A\n",
      "Validation DataLoader 0:  57%|███████▎     | 1744/3084 [00:07<00:05, 225.64it/s]\u001b[A\n",
      "Validation DataLoader 0:  57%|███████▎     | 1745/3084 [00:07<00:05, 225.64it/s]\u001b[A\n",
      "Validation DataLoader 0:  57%|███████▎     | 1746/3084 [00:07<00:05, 225.65it/s]\u001b[A\n",
      "Validation DataLoader 0:  57%|███████▎     | 1747/3084 [00:07<00:05, 225.63it/s]\u001b[A\n",
      "Validation DataLoader 0:  57%|███████▎     | 1748/3084 [00:07<00:05, 225.63it/s]\u001b[A\n",
      "Validation DataLoader 0:  57%|███████▎     | 1749/3084 [00:07<00:05, 225.64it/s]\u001b[A\n",
      "Validation DataLoader 0:  57%|███████▍     | 1750/3084 [00:07<00:05, 225.64it/s]\u001b[A\n",
      "Validation DataLoader 0:  57%|███████▍     | 1751/3084 [00:07<00:05, 225.64it/s]\u001b[A\n",
      "Validation DataLoader 0:  57%|███████▍     | 1752/3084 [00:07<00:05, 225.65it/s]\u001b[A\n",
      "Validation DataLoader 0:  57%|███████▍     | 1753/3084 [00:07<00:05, 225.65it/s]\u001b[A\n",
      "Validation DataLoader 0:  57%|███████▍     | 1754/3084 [00:07<00:05, 225.65it/s]\u001b[A\n",
      "Validation DataLoader 0:  57%|███████▍     | 1755/3084 [00:07<00:05, 225.65it/s]\u001b[A\n",
      "Validation DataLoader 0:  57%|███████▍     | 1756/3084 [00:07<00:05, 225.65it/s]\u001b[A\n",
      "Validation DataLoader 0:  57%|███████▍     | 1757/3084 [00:07<00:05, 225.66it/s]\u001b[A\n",
      "Validation DataLoader 0:  57%|███████▍     | 1758/3084 [00:07<00:05, 225.66it/s]\u001b[A\n",
      "Validation DataLoader 0:  57%|███████▍     | 1759/3084 [00:07<00:05, 225.66it/s]\u001b[A\n",
      "Validation DataLoader 0:  57%|███████▍     | 1760/3084 [00:07<00:05, 225.67it/s]\u001b[A\n",
      "Validation DataLoader 0:  57%|███████▍     | 1761/3084 [00:07<00:05, 225.67it/s]\u001b[A\n",
      "Validation DataLoader 0:  57%|███████▍     | 1762/3084 [00:07<00:05, 225.67it/s]\u001b[A\n",
      "Validation DataLoader 0:  57%|███████▍     | 1763/3084 [00:07<00:05, 225.67it/s]\u001b[A\n",
      "Validation DataLoader 0:  57%|███████▍     | 1764/3084 [00:07<00:05, 225.67it/s]\u001b[A\n",
      "Validation DataLoader 0:  57%|███████▍     | 1765/3084 [00:07<00:05, 225.68it/s]\u001b[A\n",
      "Validation DataLoader 0:  57%|███████▍     | 1766/3084 [00:07<00:05, 225.66it/s]\u001b[A\n",
      "Validation DataLoader 0:  57%|███████▍     | 1767/3084 [00:07<00:05, 225.66it/s]\u001b[A\n",
      "Validation DataLoader 0:  57%|███████▍     | 1768/3084 [00:07<00:05, 225.67it/s]\u001b[A\n",
      "Validation DataLoader 0:  57%|███████▍     | 1769/3084 [00:07<00:05, 225.67it/s]\u001b[A\n",
      "Validation DataLoader 0:  57%|███████▍     | 1770/3084 [00:07<00:05, 225.67it/s]\u001b[A\n",
      "Validation DataLoader 0:  57%|███████▍     | 1771/3084 [00:07<00:05, 225.68it/s]\u001b[A\n",
      "Validation DataLoader 0:  57%|███████▍     | 1772/3084 [00:07<00:05, 225.68it/s]\u001b[A\n",
      "Validation DataLoader 0:  57%|███████▍     | 1773/3084 [00:07<00:05, 225.68it/s]\u001b[A\n",
      "Validation DataLoader 0:  58%|███████▍     | 1774/3084 [00:07<00:05, 225.69it/s]\u001b[A\n",
      "Validation DataLoader 0:  58%|███████▍     | 1775/3084 [00:07<00:05, 225.69it/s]\u001b[A\n",
      "Validation DataLoader 0:  58%|███████▍     | 1776/3084 [00:07<00:05, 225.69it/s]\u001b[A\n",
      "Validation DataLoader 0:  58%|███████▍     | 1777/3084 [00:07<00:05, 225.69it/s]\u001b[A\n",
      "Validation DataLoader 0:  58%|███████▍     | 1778/3084 [00:07<00:05, 225.69it/s]\u001b[A\n",
      "Validation DataLoader 0:  58%|███████▍     | 1779/3084 [00:07<00:05, 225.67it/s]\u001b[A\n",
      "Validation DataLoader 0:  58%|███████▌     | 1780/3084 [00:07<00:05, 225.68it/s]\u001b[A\n",
      "Validation DataLoader 0:  58%|███████▌     | 1781/3084 [00:07<00:05, 225.68it/s]\u001b[A\n",
      "Validation DataLoader 0:  58%|███████▌     | 1782/3084 [00:07<00:05, 225.68it/s]\u001b[A\n",
      "Validation DataLoader 0:  58%|███████▌     | 1783/3084 [00:07<00:05, 225.69it/s]\u001b[A\n",
      "Validation DataLoader 0:  58%|███████▌     | 1784/3084 [00:07<00:05, 225.69it/s]\u001b[A\n",
      "Validation DataLoader 0:  58%|███████▌     | 1785/3084 [00:07<00:05, 225.69it/s]\u001b[A\n",
      "Validation DataLoader 0:  58%|███████▌     | 1786/3084 [00:07<00:05, 225.70it/s]\u001b[A\n",
      "Validation DataLoader 0:  58%|███████▌     | 1787/3084 [00:07<00:05, 225.70it/s]\u001b[A\n",
      "Validation DataLoader 0:  58%|███████▌     | 1788/3084 [00:07<00:05, 225.70it/s]\u001b[A\n",
      "Validation DataLoader 0:  58%|███████▌     | 1789/3084 [00:07<00:05, 225.70it/s]\u001b[A\n",
      "Validation DataLoader 0:  58%|███████▌     | 1790/3084 [00:07<00:05, 225.70it/s]\u001b[A\n",
      "Validation DataLoader 0:  58%|███████▌     | 1791/3084 [00:07<00:05, 225.70it/s]\u001b[A\n",
      "Validation DataLoader 0:  58%|███████▌     | 1792/3084 [00:07<00:05, 225.71it/s]\u001b[A\n",
      "Validation DataLoader 0:  58%|███████▌     | 1793/3084 [00:07<00:05, 225.71it/s]\u001b[A\n",
      "Validation DataLoader 0:  58%|███████▌     | 1794/3084 [00:07<00:05, 225.71it/s]\u001b[A\n",
      "Validation DataLoader 0:  58%|███████▌     | 1795/3084 [00:07<00:05, 225.71it/s]\u001b[A\n",
      "Validation DataLoader 0:  58%|███████▌     | 1796/3084 [00:07<00:05, 225.72it/s]\u001b[A\n",
      "Validation DataLoader 0:  58%|███████▌     | 1797/3084 [00:07<00:05, 225.72it/s]\u001b[A\n",
      "Validation DataLoader 0:  58%|███████▌     | 1798/3084 [00:07<00:05, 225.70it/s]\u001b[A\n",
      "Validation DataLoader 0:  58%|███████▌     | 1799/3084 [00:07<00:05, 225.71it/s]\u001b[A\n",
      "Validation DataLoader 0:  58%|███████▌     | 1800/3084 [00:07<00:05, 225.71it/s]\u001b[A\n",
      "Validation DataLoader 0:  58%|███████▌     | 1801/3084 [00:07<00:05, 225.71it/s]\u001b[A\n",
      "Validation DataLoader 0:  58%|███████▌     | 1802/3084 [00:07<00:05, 225.71it/s]\u001b[A\n",
      "Validation DataLoader 0:  58%|███████▌     | 1803/3084 [00:07<00:05, 225.71it/s]\u001b[A\n",
      "Validation DataLoader 0:  58%|███████▌     | 1804/3084 [00:07<00:05, 225.71it/s]\u001b[A\n",
      "Validation DataLoader 0:  59%|███████▌     | 1805/3084 [00:07<00:05, 225.72it/s]\u001b[A\n",
      "Validation DataLoader 0:  59%|███████▌     | 1806/3084 [00:08<00:05, 225.72it/s]\u001b[A\n",
      "Validation DataLoader 0:  59%|███████▌     | 1807/3084 [00:08<00:05, 225.72it/s]\u001b[A\n",
      "Validation DataLoader 0:  59%|███████▌     | 1808/3084 [00:08<00:05, 225.72it/s]\u001b[A\n",
      "Validation DataLoader 0:  59%|███████▋     | 1809/3084 [00:08<00:05, 225.73it/s]\u001b[A\n",
      "Validation DataLoader 0:  59%|███████▋     | 1810/3084 [00:08<00:05, 225.73it/s]\u001b[A\n",
      "Validation DataLoader 0:  59%|███████▋     | 1811/3084 [00:08<00:05, 225.71it/s]\u001b[A\n",
      "Validation DataLoader 0:  59%|███████▋     | 1812/3084 [00:08<00:05, 225.72it/s]\u001b[A\n",
      "Validation DataLoader 0:  59%|███████▋     | 1813/3084 [00:08<00:05, 225.72it/s]\u001b[A\n",
      "Validation DataLoader 0:  59%|███████▋     | 1814/3084 [00:08<00:05, 225.72it/s]\u001b[A\n",
      "Validation DataLoader 0:  59%|███████▋     | 1815/3084 [00:08<00:05, 225.73it/s]\u001b[A\n",
      "Validation DataLoader 0:  59%|███████▋     | 1816/3084 [00:08<00:05, 225.73it/s]\u001b[A\n",
      "Validation DataLoader 0:  59%|███████▋     | 1817/3084 [00:08<00:05, 225.73it/s]\u001b[A\n",
      "Validation DataLoader 0:  59%|███████▋     | 1818/3084 [00:08<00:05, 225.74it/s]\u001b[A\n",
      "Validation DataLoader 0:  59%|███████▋     | 1819/3084 [00:08<00:05, 225.74it/s]\u001b[A\n",
      "Validation DataLoader 0:  59%|███████▋     | 1820/3084 [00:08<00:05, 225.74it/s]\u001b[A\n",
      "Validation DataLoader 0:  59%|███████▋     | 1821/3084 [00:08<00:05, 225.74it/s]\u001b[A\n",
      "Validation DataLoader 0:  59%|███████▋     | 1822/3084 [00:08<00:05, 225.75it/s]\u001b[A\n",
      "Validation DataLoader 0:  59%|███████▋     | 1823/3084 [00:08<00:05, 225.75it/s]\u001b[A\n",
      "Validation DataLoader 0:  59%|███████▋     | 1824/3084 [00:08<00:05, 225.75it/s]\u001b[A\n",
      "Validation DataLoader 0:  59%|███████▋     | 1825/3084 [00:08<00:05, 225.75it/s]\u001b[A\n",
      "Validation DataLoader 0:  59%|███████▋     | 1826/3084 [00:08<00:05, 225.76it/s]\u001b[A\n",
      "Validation DataLoader 0:  59%|███████▋     | 1827/3084 [00:08<00:05, 225.76it/s]\u001b[A\n",
      "Validation DataLoader 0:  59%|███████▋     | 1828/3084 [00:08<00:05, 225.76it/s]\u001b[A\n",
      "Validation DataLoader 0:  59%|███████▋     | 1829/3084 [00:08<00:05, 225.76it/s]\u001b[A\n",
      "Validation DataLoader 0:  59%|███████▋     | 1830/3084 [00:08<00:05, 225.74it/s]\u001b[A\n",
      "Validation DataLoader 0:  59%|███████▋     | 1831/3084 [00:08<00:05, 225.75it/s]\u001b[A\n",
      "Validation DataLoader 0:  59%|███████▋     | 1832/3084 [00:08<00:05, 225.75it/s]\u001b[A\n",
      "Validation DataLoader 0:  59%|███████▋     | 1833/3084 [00:08<00:05, 225.75it/s]\u001b[A\n",
      "Validation DataLoader 0:  59%|███████▋     | 1834/3084 [00:08<00:05, 225.76it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|███████▋     | 1835/3084 [00:08<00:05, 225.76it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|███████▋     | 1836/3084 [00:08<00:05, 225.76it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|███████▋     | 1837/3084 [00:08<00:05, 225.76it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|███████▋     | 1838/3084 [00:08<00:05, 225.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|███████▊     | 1839/3084 [00:08<00:05, 225.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|███████▊     | 1840/3084 [00:08<00:05, 225.76it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|███████▊     | 1841/3084 [00:08<00:05, 225.76it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|███████▊     | 1842/3084 [00:08<00:05, 225.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|███████▊     | 1843/3084 [00:08<00:05, 225.75it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|███████▊     | 1844/3084 [00:08<00:05, 225.75it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|███████▊     | 1845/3084 [00:08<00:05, 225.76it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|███████▊     | 1846/3084 [00:08<00:05, 225.76it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|███████▊     | 1847/3084 [00:08<00:05, 225.76it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|███████▊     | 1848/3084 [00:08<00:05, 225.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|███████▊     | 1849/3084 [00:08<00:05, 225.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|███████▊     | 1850/3084 [00:08<00:05, 225.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|███████▊     | 1851/3084 [00:08<00:05, 225.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|███████▊     | 1852/3084 [00:08<00:05, 225.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|███████▊     | 1853/3084 [00:08<00:05, 225.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|███████▊     | 1854/3084 [00:08<00:05, 225.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|███████▊     | 1855/3084 [00:08<00:05, 225.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|███████▊     | 1856/3084 [00:08<00:05, 225.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|███████▊     | 1857/3084 [00:08<00:05, 225.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|███████▊     | 1858/3084 [00:08<00:05, 225.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|███████▊     | 1859/3084 [00:08<00:05, 225.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|███████▊     | 1860/3084 [00:08<00:05, 225.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|███████▊     | 1861/3084 [00:08<00:05, 225.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|███████▊     | 1862/3084 [00:08<00:05, 225.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|███████▊     | 1863/3084 [00:08<00:05, 225.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|███████▊     | 1864/3084 [00:08<00:05, 225.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  60%|███████▊     | 1865/3084 [00:08<00:05, 225.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  61%|███████▊     | 1866/3084 [00:08<00:05, 225.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  61%|███████▊     | 1867/3084 [00:08<00:05, 225.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  61%|███████▊     | 1868/3084 [00:08<00:05, 225.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  61%|███████▉     | 1869/3084 [00:08<00:05, 225.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  61%|███████▉     | 1870/3084 [00:08<00:05, 225.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  61%|███████▉     | 1871/3084 [00:08<00:05, 225.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  61%|███████▉     | 1872/3084 [00:08<00:05, 225.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  61%|███████▉     | 1873/3084 [00:08<00:05, 225.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  61%|███████▉     | 1874/3084 [00:08<00:05, 225.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  61%|███████▉     | 1875/3084 [00:08<00:05, 225.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  61%|███████▉     | 1876/3084 [00:08<00:05, 225.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  61%|███████▉     | 1877/3084 [00:08<00:05, 225.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  61%|███████▉     | 1878/3084 [00:08<00:05, 225.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  61%|███████▉     | 1879/3084 [00:08<00:05, 225.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  61%|███████▉     | 1880/3084 [00:08<00:05, 225.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  61%|███████▉     | 1881/3084 [00:08<00:05, 225.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  61%|███████▉     | 1882/3084 [00:08<00:05, 225.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  61%|███████▉     | 1883/3084 [00:08<00:05, 225.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  61%|███████▉     | 1884/3084 [00:08<00:05, 225.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  61%|███████▉     | 1885/3084 [00:08<00:05, 225.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  61%|███████▉     | 1886/3084 [00:08<00:05, 225.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  61%|███████▉     | 1887/3084 [00:08<00:05, 225.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  61%|███████▉     | 1888/3084 [00:08<00:05, 225.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  61%|███████▉     | 1889/3084 [00:08<00:05, 225.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  61%|███████▉     | 1890/3084 [00:08<00:05, 225.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  61%|███████▉     | 1891/3084 [00:08<00:05, 225.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  61%|███████▉     | 1892/3084 [00:08<00:05, 225.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  61%|███████▉     | 1893/3084 [00:08<00:05, 225.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  61%|███████▉     | 1894/3084 [00:08<00:05, 225.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  61%|███████▉     | 1895/3084 [00:08<00:05, 225.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  61%|███████▉     | 1896/3084 [00:08<00:05, 225.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  62%|███████▉     | 1897/3084 [00:08<00:05, 225.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  62%|████████     | 1898/3084 [00:08<00:05, 225.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  62%|████████     | 1899/3084 [00:08<00:05, 225.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  62%|████████     | 1900/3084 [00:08<00:05, 225.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  62%|████████     | 1901/3084 [00:08<00:05, 225.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  62%|████████     | 1902/3084 [00:08<00:05, 225.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  62%|████████     | 1903/3084 [00:08<00:05, 225.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  62%|████████     | 1904/3084 [00:08<00:05, 225.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  62%|████████     | 1905/3084 [00:08<00:05, 225.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  62%|████████     | 1906/3084 [00:08<00:05, 225.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  62%|████████     | 1907/3084 [00:08<00:05, 225.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  62%|████████     | 1908/3084 [00:08<00:05, 225.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  62%|████████     | 1909/3084 [00:08<00:05, 225.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  62%|████████     | 1910/3084 [00:08<00:05, 225.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  62%|████████     | 1911/3084 [00:08<00:05, 225.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  62%|████████     | 1912/3084 [00:08<00:05, 225.86it/s]\u001b[A\n",
      "Validation DataLoader 0:  62%|████████     | 1913/3084 [00:08<00:05, 225.86it/s]\u001b[A\n",
      "Validation DataLoader 0:  62%|████████     | 1914/3084 [00:08<00:05, 225.86it/s]\u001b[A\n",
      "Validation DataLoader 0:  62%|████████     | 1915/3084 [00:08<00:05, 225.86it/s]\u001b[A\n",
      "Validation DataLoader 0:  62%|████████     | 1916/3084 [00:08<00:05, 225.86it/s]\u001b[A\n",
      "Validation DataLoader 0:  62%|████████     | 1917/3084 [00:08<00:05, 225.86it/s]\u001b[A\n",
      "Validation DataLoader 0:  62%|████████     | 1918/3084 [00:08<00:05, 225.86it/s]\u001b[A\n",
      "Validation DataLoader 0:  62%|████████     | 1919/3084 [00:08<00:05, 225.86it/s]\u001b[A\n",
      "Validation DataLoader 0:  62%|████████     | 1920/3084 [00:08<00:05, 225.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  62%|████████     | 1921/3084 [00:08<00:05, 225.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  62%|████████     | 1922/3084 [00:08<00:05, 225.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  62%|████████     | 1923/3084 [00:08<00:05, 225.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  62%|████████     | 1924/3084 [00:08<00:05, 225.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  62%|████████     | 1925/3084 [00:08<00:05, 225.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  62%|████████     | 1926/3084 [00:08<00:05, 225.86it/s]\u001b[A\n",
      "Validation DataLoader 0:  62%|████████     | 1927/3084 [00:08<00:05, 225.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  63%|████████▏    | 1928/3084 [00:08<00:05, 225.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  63%|████████▏    | 1929/3084 [00:08<00:05, 225.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  63%|████████▏    | 1930/3084 [00:08<00:05, 225.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  63%|████████▏    | 1931/3084 [00:08<00:05, 225.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  63%|████████▏    | 1932/3084 [00:08<00:05, 225.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  63%|████████▏    | 1933/3084 [00:08<00:05, 225.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  63%|████████▏    | 1934/3084 [00:08<00:05, 225.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  63%|████████▏    | 1935/3084 [00:08<00:05, 225.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  63%|████████▏    | 1936/3084 [00:08<00:05, 225.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  63%|████████▏    | 1937/3084 [00:08<00:05, 225.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  63%|████████▏    | 1938/3084 [00:08<00:05, 225.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  63%|████████▏    | 1939/3084 [00:08<00:05, 225.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  63%|████████▏    | 1940/3084 [00:08<00:05, 225.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  63%|████████▏    | 1941/3084 [00:08<00:05, 225.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  63%|████████▏    | 1942/3084 [00:08<00:05, 225.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  63%|████████▏    | 1943/3084 [00:08<00:05, 225.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  63%|████████▏    | 1944/3084 [00:08<00:05, 225.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  63%|████████▏    | 1945/3084 [00:08<00:05, 225.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  63%|████████▏    | 1946/3084 [00:08<00:05, 225.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  63%|████████▏    | 1947/3084 [00:08<00:05, 225.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  63%|████████▏    | 1948/3084 [00:08<00:05, 225.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  63%|████████▏    | 1949/3084 [00:08<00:05, 225.86it/s]\u001b[A\n",
      "Validation DataLoader 0:  63%|████████▏    | 1950/3084 [00:08<00:05, 225.86it/s]\u001b[A\n",
      "Validation DataLoader 0:  63%|████████▏    | 1951/3084 [00:08<00:05, 225.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  63%|████████▏    | 1952/3084 [00:08<00:05, 225.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  63%|████████▏    | 1953/3084 [00:08<00:05, 225.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  63%|████████▏    | 1954/3084 [00:08<00:05, 225.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  63%|████████▏    | 1955/3084 [00:08<00:04, 225.89it/s]\u001b[A\n",
      "Validation DataLoader 0:  63%|████████▏    | 1956/3084 [00:08<00:04, 225.89it/s]\u001b[A\n",
      "Validation DataLoader 0:  63%|████████▏    | 1957/3084 [00:08<00:04, 225.90it/s]\u001b[A\n",
      "Validation DataLoader 0:  63%|████████▎    | 1958/3084 [00:08<00:04, 225.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  64%|████████▎    | 1959/3084 [00:08<00:04, 225.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  64%|████████▎    | 1960/3084 [00:08<00:04, 225.75it/s]\u001b[A\n",
      "Validation DataLoader 0:  64%|████████▎    | 1961/3084 [00:08<00:04, 225.74it/s]\u001b[A\n",
      "Validation DataLoader 0:  64%|████████▎    | 1962/3084 [00:08<00:04, 225.74it/s]\u001b[A\n",
      "Validation DataLoader 0:  64%|████████▎    | 1963/3084 [00:08<00:04, 225.74it/s]\u001b[A\n",
      "Validation DataLoader 0:  64%|████████▎    | 1964/3084 [00:08<00:04, 225.74it/s]\u001b[A\n",
      "Validation DataLoader 0:  64%|████████▎    | 1965/3084 [00:08<00:04, 225.74it/s]\u001b[A\n",
      "Validation DataLoader 0:  64%|████████▎    | 1966/3084 [00:08<00:04, 225.74it/s]\u001b[A\n",
      "Validation DataLoader 0:  64%|████████▎    | 1967/3084 [00:08<00:04, 225.74it/s]\u001b[A\n",
      "Validation DataLoader 0:  64%|████████▎    | 1968/3084 [00:08<00:04, 225.74it/s]\u001b[A\n",
      "Validation DataLoader 0:  64%|████████▎    | 1969/3084 [00:08<00:04, 225.75it/s]\u001b[A\n",
      "Validation DataLoader 0:  64%|████████▎    | 1970/3084 [00:08<00:04, 225.75it/s]\u001b[A\n",
      "Validation DataLoader 0:  64%|████████▎    | 1971/3084 [00:08<00:04, 225.76it/s]\u001b[A\n",
      "Validation DataLoader 0:  64%|████████▎    | 1972/3084 [00:08<00:04, 225.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  64%|████████▎    | 1973/3084 [00:08<00:04, 225.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  64%|████████▎    | 1974/3084 [00:08<00:04, 225.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  64%|████████▎    | 1975/3084 [00:08<00:04, 225.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  64%|████████▎    | 1976/3084 [00:08<00:04, 225.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  64%|████████▎    | 1977/3084 [00:08<00:04, 225.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  64%|████████▎    | 1978/3084 [00:08<00:04, 225.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  64%|████████▎    | 1979/3084 [00:08<00:04, 225.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  64%|████████▎    | 1980/3084 [00:08<00:04, 225.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  64%|████████▎    | 1981/3084 [00:08<00:04, 225.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  64%|████████▎    | 1982/3084 [00:08<00:04, 225.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  64%|████████▎    | 1983/3084 [00:08<00:04, 225.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  64%|████████▎    | 1984/3084 [00:08<00:04, 225.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  64%|████████▎    | 1985/3084 [00:08<00:04, 225.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  64%|████████▎    | 1986/3084 [00:08<00:04, 225.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  64%|████████▍    | 1987/3084 [00:08<00:04, 225.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  64%|████████▍    | 1988/3084 [00:08<00:04, 225.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  64%|████████▍    | 1989/3084 [00:08<00:04, 225.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|████████▍    | 1990/3084 [00:08<00:04, 225.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|████████▍    | 1991/3084 [00:08<00:04, 225.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|████████▍    | 1992/3084 [00:08<00:04, 225.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|████████▍    | 1993/3084 [00:08<00:04, 225.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|████████▍    | 1994/3084 [00:08<00:04, 225.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|████████▍    | 1995/3084 [00:08<00:04, 225.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|████████▍    | 1996/3084 [00:08<00:04, 225.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|████████▍    | 1997/3084 [00:08<00:04, 225.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|████████▍    | 1998/3084 [00:08<00:04, 225.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|████████▍    | 1999/3084 [00:08<00:04, 225.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|████████▍    | 2000/3084 [00:08<00:04, 225.86it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|████████▍    | 2001/3084 [00:08<00:04, 225.86it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|████████▍    | 2002/3084 [00:08<00:04, 225.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|████████▍    | 2003/3084 [00:08<00:04, 225.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|████████▍    | 2004/3084 [00:08<00:04, 225.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|████████▍    | 2005/3084 [00:08<00:04, 225.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|████████▍    | 2006/3084 [00:08<00:04, 225.89it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|████████▍    | 2007/3084 [00:08<00:04, 225.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|████████▍    | 2008/3084 [00:08<00:04, 225.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|████████▍    | 2009/3084 [00:08<00:04, 225.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|████████▍    | 2010/3084 [00:08<00:04, 225.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|████████▍    | 2011/3084 [00:08<00:04, 225.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|████████▍    | 2012/3084 [00:08<00:04, 225.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|████████▍    | 2013/3084 [00:08<00:04, 225.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|████████▍    | 2014/3084 [00:08<00:04, 225.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|████████▍    | 2015/3084 [00:08<00:04, 225.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|████████▍    | 2016/3084 [00:08<00:04, 225.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|████████▌    | 2017/3084 [00:08<00:04, 225.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|████████▌    | 2018/3084 [00:08<00:04, 225.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|████████▌    | 2019/3084 [00:08<00:04, 225.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  65%|████████▌    | 2020/3084 [00:08<00:04, 225.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  66%|████████▌    | 2021/3084 [00:08<00:04, 225.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  66%|████████▌    | 2022/3084 [00:08<00:04, 225.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  66%|████████▌    | 2023/3084 [00:08<00:04, 225.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  66%|████████▌    | 2024/3084 [00:08<00:04, 225.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  66%|████████▌    | 2025/3084 [00:08<00:04, 225.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  66%|████████▌    | 2026/3084 [00:08<00:04, 225.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  66%|████████▌    | 2027/3084 [00:08<00:04, 225.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  66%|████████▌    | 2028/3084 [00:08<00:04, 225.76it/s]\u001b[A\n",
      "Validation DataLoader 0:  66%|████████▌    | 2029/3084 [00:08<00:04, 225.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  66%|████████▌    | 2030/3084 [00:08<00:04, 225.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  66%|████████▌    | 2031/3084 [00:08<00:04, 225.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  66%|████████▌    | 2032/3084 [00:09<00:04, 225.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  66%|████████▌    | 2033/3084 [00:09<00:04, 225.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  66%|████████▌    | 2034/3084 [00:09<00:04, 225.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  66%|████████▌    | 2035/3084 [00:09<00:04, 225.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  66%|████████▌    | 2036/3084 [00:09<00:04, 225.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  66%|████████▌    | 2037/3084 [00:09<00:04, 225.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  66%|████████▌    | 2038/3084 [00:09<00:04, 225.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  66%|████████▌    | 2039/3084 [00:09<00:04, 225.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  66%|████████▌    | 2040/3084 [00:09<00:04, 225.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  66%|████████▌    | 2041/3084 [00:09<00:04, 225.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  66%|████████▌    | 2042/3084 [00:09<00:04, 225.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  66%|████████▌    | 2043/3084 [00:09<00:04, 225.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  66%|████████▌    | 2044/3084 [00:09<00:04, 225.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  66%|████████▌    | 2045/3084 [00:09<00:04, 225.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  66%|████████▌    | 2046/3084 [00:09<00:04, 225.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  66%|████████▋    | 2047/3084 [00:09<00:04, 225.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  66%|████████▋    | 2048/3084 [00:09<00:04, 225.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  66%|████████▋    | 2049/3084 [00:09<00:04, 225.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  66%|████████▋    | 2050/3084 [00:09<00:04, 225.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|████████▋    | 2051/3084 [00:09<00:04, 225.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|████████▋    | 2052/3084 [00:09<00:04, 225.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|████████▋    | 2053/3084 [00:09<00:04, 225.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|████████▋    | 2054/3084 [00:09<00:04, 225.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|████████▋    | 2055/3084 [00:09<00:04, 225.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|████████▋    | 2056/3084 [00:09<00:04, 225.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|████████▋    | 2057/3084 [00:09<00:04, 225.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|████████▋    | 2058/3084 [00:09<00:04, 225.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|████████▋    | 2059/3084 [00:09<00:04, 225.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|████████▋    | 2060/3084 [00:09<00:04, 225.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|████████▋    | 2061/3084 [00:09<00:04, 225.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|████████▋    | 2062/3084 [00:09<00:04, 225.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|████████▋    | 2063/3084 [00:09<00:04, 225.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|████████▋    | 2064/3084 [00:09<00:04, 225.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|████████▋    | 2065/3084 [00:09<00:04, 225.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|████████▋    | 2066/3084 [00:09<00:04, 225.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|████████▋    | 2067/3084 [00:09<00:04, 225.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|████████▋    | 2068/3084 [00:09<00:04, 225.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|████████▋    | 2069/3084 [00:09<00:04, 225.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|████████▋    | 2070/3084 [00:09<00:04, 225.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|████████▋    | 2071/3084 [00:09<00:04, 225.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|████████▋    | 2072/3084 [00:09<00:04, 225.86it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|████████▋    | 2073/3084 [00:09<00:04, 225.86it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|████████▋    | 2074/3084 [00:09<00:04, 225.86it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|████████▋    | 2075/3084 [00:09<00:04, 225.86it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|████████▊    | 2076/3084 [00:09<00:04, 225.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|████████▊    | 2077/3084 [00:09<00:04, 225.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|████████▊    | 2078/3084 [00:09<00:04, 225.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|████████▊    | 2079/3084 [00:09<00:04, 225.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|████████▊    | 2080/3084 [00:09<00:04, 225.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  67%|████████▊    | 2081/3084 [00:09<00:04, 225.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  68%|████████▊    | 2082/3084 [00:09<00:04, 225.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  68%|████████▊    | 2083/3084 [00:09<00:04, 225.89it/s]\u001b[A\n",
      "Validation DataLoader 0:  68%|████████▊    | 2084/3084 [00:09<00:04, 225.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  68%|████████▊    | 2085/3084 [00:09<00:04, 225.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  68%|████████▊    | 2086/3084 [00:09<00:04, 225.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  68%|████████▊    | 2087/3084 [00:09<00:04, 225.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  68%|████████▊    | 2088/3084 [00:09<00:04, 225.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  68%|████████▊    | 2089/3084 [00:09<00:04, 225.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  68%|████████▊    | 2090/3084 [00:09<00:04, 225.89it/s]\u001b[A\n",
      "Validation DataLoader 0:  68%|████████▊    | 2091/3084 [00:09<00:04, 225.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  68%|████████▊    | 2092/3084 [00:09<00:04, 225.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  68%|████████▊    | 2093/3084 [00:09<00:04, 225.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  68%|████████▊    | 2094/3084 [00:09<00:04, 225.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  68%|████████▊    | 2095/3084 [00:09<00:04, 225.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  68%|████████▊    | 2096/3084 [00:09<00:04, 225.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  68%|████████▊    | 2097/3084 [00:09<00:04, 225.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  68%|████████▊    | 2098/3084 [00:09<00:04, 225.89it/s]\u001b[A\n",
      "Validation DataLoader 0:  68%|████████▊    | 2099/3084 [00:09<00:04, 225.89it/s]\u001b[A\n",
      "Validation DataLoader 0:  68%|████████▊    | 2100/3084 [00:09<00:04, 225.89it/s]\u001b[A\n",
      "Validation DataLoader 0:  68%|████████▊    | 2101/3084 [00:09<00:04, 225.90it/s]\u001b[A\n",
      "Validation DataLoader 0:  68%|████████▊    | 2102/3084 [00:09<00:04, 225.90it/s]\u001b[A\n",
      "Validation DataLoader 0:  68%|████████▊    | 2103/3084 [00:09<00:04, 225.90it/s]\u001b[A\n",
      "Validation DataLoader 0:  68%|████████▊    | 2104/3084 [00:09<00:04, 225.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  68%|████████▊    | 2105/3084 [00:09<00:04, 225.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  68%|████████▉    | 2106/3084 [00:09<00:04, 225.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  68%|████████▉    | 2107/3084 [00:09<00:04, 225.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  68%|████████▉    | 2108/3084 [00:09<00:04, 225.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  68%|████████▉    | 2109/3084 [00:09<00:04, 225.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  68%|████████▉    | 2110/3084 [00:09<00:04, 225.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  68%|████████▉    | 2111/3084 [00:09<00:04, 225.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  68%|████████▉    | 2112/3084 [00:09<00:04, 225.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  69%|████████▉    | 2113/3084 [00:09<00:04, 225.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  69%|████████▉    | 2114/3084 [00:09<00:04, 225.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  69%|████████▉    | 2115/3084 [00:09<00:04, 225.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  69%|████████▉    | 2116/3084 [00:09<00:04, 225.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  69%|████████▉    | 2117/3084 [00:09<00:04, 225.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  69%|████████▉    | 2118/3084 [00:09<00:04, 225.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  69%|████████▉    | 2119/3084 [00:09<00:04, 225.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  69%|████████▉    | 2120/3084 [00:09<00:04, 225.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  69%|████████▉    | 2121/3084 [00:09<00:04, 225.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  69%|████████▉    | 2122/3084 [00:09<00:04, 225.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  69%|████████▉    | 2123/3084 [00:09<00:04, 225.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  69%|████████▉    | 2124/3084 [00:09<00:04, 225.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  69%|████████▉    | 2125/3084 [00:09<00:04, 225.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  69%|████████▉    | 2126/3084 [00:09<00:04, 225.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  69%|████████▉    | 2127/3084 [00:09<00:04, 225.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  69%|████████▉    | 2128/3084 [00:09<00:04, 225.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  69%|████████▉    | 2129/3084 [00:09<00:04, 225.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  69%|████████▉    | 2130/3084 [00:09<00:04, 225.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  69%|████████▉    | 2131/3084 [00:09<00:04, 225.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  69%|████████▉    | 2132/3084 [00:09<00:04, 225.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  69%|████████▉    | 2133/3084 [00:09<00:04, 225.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  69%|████████▉    | 2134/3084 [00:09<00:04, 225.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  69%|████████▉    | 2135/3084 [00:09<00:04, 225.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  69%|█████████    | 2136/3084 [00:09<00:04, 225.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  69%|█████████    | 2137/3084 [00:09<00:04, 225.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  69%|█████████    | 2138/3084 [00:09<00:04, 225.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  69%|█████████    | 2139/3084 [00:09<00:04, 225.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  69%|█████████    | 2140/3084 [00:09<00:04, 225.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  69%|█████████    | 2141/3084 [00:09<00:04, 225.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  69%|█████████    | 2142/3084 [00:09<00:04, 225.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  69%|█████████    | 2143/3084 [00:09<00:04, 225.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|█████████    | 2144/3084 [00:09<00:04, 225.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|█████████    | 2145/3084 [00:09<00:04, 225.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|█████████    | 2146/3084 [00:09<00:04, 225.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|█████████    | 2147/3084 [00:09<00:04, 225.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|█████████    | 2148/3084 [00:09<00:04, 225.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|█████████    | 2149/3084 [00:09<00:04, 225.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|█████████    | 2150/3084 [00:09<00:04, 225.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|█████████    | 2151/3084 [00:09<00:04, 225.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|█████████    | 2152/3084 [00:09<00:04, 225.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|█████████    | 2153/3084 [00:09<00:04, 225.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|█████████    | 2154/3084 [00:09<00:04, 225.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|█████████    | 2155/3084 [00:09<00:04, 225.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|█████████    | 2156/3084 [00:09<00:04, 225.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|█████████    | 2157/3084 [00:09<00:04, 225.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|█████████    | 2158/3084 [00:09<00:04, 225.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|█████████    | 2159/3084 [00:09<00:04, 225.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|█████████    | 2160/3084 [00:09<00:04, 225.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|█████████    | 2161/3084 [00:09<00:04, 225.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|█████████    | 2162/3084 [00:09<00:04, 225.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|█████████    | 2163/3084 [00:09<00:04, 225.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|█████████    | 2164/3084 [00:09<00:04, 225.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|█████████▏   | 2165/3084 [00:09<00:04, 226.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|█████████▏   | 2166/3084 [00:09<00:04, 226.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|█████████▏   | 2167/3084 [00:09<00:04, 226.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|█████████▏   | 2168/3084 [00:09<00:04, 226.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|█████████▏   | 2169/3084 [00:09<00:04, 226.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|█████████▏   | 2170/3084 [00:09<00:04, 226.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|█████████▏   | 2171/3084 [00:09<00:04, 226.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|█████████▏   | 2172/3084 [00:09<00:04, 226.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|█████████▏   | 2173/3084 [00:09<00:04, 226.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  70%|█████████▏   | 2174/3084 [00:09<00:04, 226.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  71%|█████████▏   | 2175/3084 [00:09<00:04, 226.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  71%|█████████▏   | 2176/3084 [00:09<00:04, 226.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  71%|█████████▏   | 2177/3084 [00:09<00:04, 226.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  71%|█████████▏   | 2178/3084 [00:09<00:04, 226.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  71%|█████████▏   | 2179/3084 [00:09<00:04, 226.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  71%|█████████▏   | 2180/3084 [00:09<00:03, 226.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  71%|█████████▏   | 2181/3084 [00:09<00:03, 226.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  71%|█████████▏   | 2182/3084 [00:09<00:03, 226.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  71%|█████████▏   | 2183/3084 [00:09<00:03, 226.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  71%|█████████▏   | 2184/3084 [00:09<00:03, 226.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  71%|█████████▏   | 2185/3084 [00:09<00:03, 226.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  71%|█████████▏   | 2186/3084 [00:09<00:03, 226.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  71%|█████████▏   | 2187/3084 [00:09<00:03, 226.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  71%|█████████▏   | 2188/3084 [00:09<00:03, 226.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  71%|█████████▏   | 2189/3084 [00:09<00:03, 226.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  71%|█████████▏   | 2190/3084 [00:09<00:03, 226.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  71%|█████████▏   | 2191/3084 [00:09<00:03, 226.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  71%|█████████▏   | 2192/3084 [00:09<00:03, 226.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  71%|█████████▏   | 2193/3084 [00:09<00:03, 226.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  71%|█████████▏   | 2194/3084 [00:09<00:03, 226.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  71%|█████████▎   | 2195/3084 [00:09<00:03, 226.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  71%|█████████▎   | 2196/3084 [00:09<00:03, 226.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  71%|█████████▎   | 2197/3084 [00:09<00:03, 226.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  71%|█████████▎   | 2198/3084 [00:09<00:03, 226.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  71%|█████████▎   | 2199/3084 [00:09<00:03, 226.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  71%|█████████▎   | 2200/3084 [00:09<00:03, 226.07it/s]\u001b[A\n",
      "Validation DataLoader 0:  71%|█████████▎   | 2201/3084 [00:09<00:03, 226.07it/s]\u001b[A\n",
      "Validation DataLoader 0:  71%|█████████▎   | 2202/3084 [00:09<00:03, 226.07it/s]\u001b[A\n",
      "Validation DataLoader 0:  71%|█████████▎   | 2203/3084 [00:09<00:03, 226.08it/s]\u001b[A\n",
      "Validation DataLoader 0:  71%|█████████▎   | 2204/3084 [00:09<00:03, 226.08it/s]\u001b[A\n",
      "Validation DataLoader 0:  71%|█████████▎   | 2205/3084 [00:09<00:03, 226.08it/s]\u001b[A\n",
      "Validation DataLoader 0:  72%|█████████▎   | 2206/3084 [00:09<00:03, 226.09it/s]\u001b[A\n",
      "Validation DataLoader 0:  72%|█████████▎   | 2207/3084 [00:09<00:03, 226.09it/s]\u001b[A\n",
      "Validation DataLoader 0:  72%|█████████▎   | 2208/3084 [00:09<00:03, 226.09it/s]\u001b[A\n",
      "Validation DataLoader 0:  72%|█████████▎   | 2209/3084 [00:09<00:03, 226.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  72%|█████████▎   | 2210/3084 [00:09<00:03, 226.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  72%|█████████▎   | 2211/3084 [00:09<00:03, 226.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  72%|█████████▎   | 2212/3084 [00:09<00:03, 226.09it/s]\u001b[A\n",
      "Validation DataLoader 0:  72%|█████████▎   | 2213/3084 [00:09<00:03, 226.09it/s]\u001b[A\n",
      "Validation DataLoader 0:  72%|█████████▎   | 2214/3084 [00:09<00:03, 226.09it/s]\u001b[A\n",
      "Validation DataLoader 0:  72%|█████████▎   | 2215/3084 [00:09<00:03, 226.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  72%|█████████▎   | 2216/3084 [00:09<00:03, 226.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  72%|█████████▎   | 2217/3084 [00:09<00:03, 226.09it/s]\u001b[A\n",
      "Validation DataLoader 0:  72%|█████████▎   | 2218/3084 [00:09<00:03, 226.09it/s]\u001b[A\n",
      "Validation DataLoader 0:  72%|█████████▎   | 2219/3084 [00:09<00:03, 226.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  72%|█████████▎   | 2220/3084 [00:09<00:03, 226.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  72%|█████████▎   | 2221/3084 [00:09<00:03, 226.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  72%|█████████▎   | 2222/3084 [00:09<00:03, 226.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  72%|█████████▎   | 2223/3084 [00:09<00:03, 226.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  72%|█████████▎   | 2224/3084 [00:09<00:03, 226.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  72%|█████████▍   | 2225/3084 [00:09<00:03, 226.12it/s]\u001b[A\n",
      "Validation DataLoader 0:  72%|█████████▍   | 2226/3084 [00:09<00:03, 226.12it/s]\u001b[A\n",
      "Validation DataLoader 0:  72%|█████████▍   | 2227/3084 [00:09<00:03, 226.12it/s]\u001b[A\n",
      "Validation DataLoader 0:  72%|█████████▍   | 2228/3084 [00:09<00:03, 226.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  72%|█████████▍   | 2229/3084 [00:09<00:03, 226.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  72%|█████████▍   | 2230/3084 [00:09<00:03, 226.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  72%|█████████▍   | 2231/3084 [00:09<00:03, 226.14it/s]\u001b[A\n",
      "Validation DataLoader 0:  72%|█████████▍   | 2232/3084 [00:09<00:03, 226.14it/s]\u001b[A\n",
      "Validation DataLoader 0:  72%|█████████▍   | 2233/3084 [00:09<00:03, 226.14it/s]\u001b[A\n",
      "Validation DataLoader 0:  72%|█████████▍   | 2234/3084 [00:09<00:03, 226.14it/s]\u001b[A\n",
      "Validation DataLoader 0:  72%|█████████▍   | 2235/3084 [00:09<00:03, 226.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  73%|█████████▍   | 2236/3084 [00:09<00:03, 226.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  73%|█████████▍   | 2237/3084 [00:09<00:03, 226.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  73%|█████████▍   | 2238/3084 [00:09<00:03, 226.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  73%|█████████▍   | 2239/3084 [00:09<00:03, 226.16it/s]\u001b[A\n",
      "Validation DataLoader 0:  73%|█████████▍   | 2240/3084 [00:09<00:03, 226.16it/s]\u001b[A\n",
      "Validation DataLoader 0:  73%|█████████▍   | 2241/3084 [00:09<00:03, 226.16it/s]\u001b[A\n",
      "Validation DataLoader 0:  73%|█████████▍   | 2242/3084 [00:09<00:03, 226.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  73%|█████████▍   | 2243/3084 [00:09<00:03, 226.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  73%|█████████▍   | 2244/3084 [00:09<00:03, 226.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  73%|█████████▍   | 2245/3084 [00:09<00:03, 226.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  73%|█████████▍   | 2246/3084 [00:09<00:03, 226.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  73%|█████████▍   | 2247/3084 [00:09<00:03, 226.16it/s]\u001b[A\n",
      "Validation DataLoader 0:  73%|█████████▍   | 2248/3084 [00:09<00:03, 226.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  73%|█████████▍   | 2249/3084 [00:09<00:03, 226.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  73%|█████████▍   | 2250/3084 [00:09<00:03, 226.16it/s]\u001b[A\n",
      "Validation DataLoader 0:  73%|█████████▍   | 2251/3084 [00:09<00:03, 226.16it/s]\u001b[A\n",
      "Validation DataLoader 0:  73%|█████████▍   | 2252/3084 [00:09<00:03, 226.16it/s]\u001b[A\n",
      "Validation DataLoader 0:  73%|█████████▍   | 2253/3084 [00:09<00:03, 226.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  73%|█████████▌   | 2254/3084 [00:09<00:03, 226.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  73%|█████████▌   | 2255/3084 [00:09<00:03, 226.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  73%|█████████▌   | 2256/3084 [00:09<00:03, 226.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  73%|█████████▌   | 2257/3084 [00:09<00:03, 226.18it/s]\u001b[A\n",
      "Validation DataLoader 0:  73%|█████████▌   | 2258/3084 [00:09<00:03, 226.18it/s]\u001b[A\n",
      "Validation DataLoader 0:  73%|█████████▌   | 2259/3084 [00:09<00:03, 226.18it/s]\u001b[A\n",
      "Validation DataLoader 0:  73%|█████████▌   | 2260/3084 [00:09<00:03, 226.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  73%|█████████▌   | 2261/3084 [00:09<00:03, 226.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  73%|█████████▌   | 2262/3084 [00:10<00:03, 226.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  73%|█████████▌   | 2263/3084 [00:10<00:03, 226.20it/s]\u001b[A\n",
      "Validation DataLoader 0:  73%|█████████▌   | 2264/3084 [00:10<00:03, 226.20it/s]\u001b[A\n",
      "Validation DataLoader 0:  73%|█████████▌   | 2265/3084 [00:10<00:03, 226.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  73%|█████████▌   | 2266/3084 [00:10<00:03, 226.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  74%|█████████▌   | 2267/3084 [00:10<00:03, 226.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  74%|█████████▌   | 2268/3084 [00:10<00:03, 226.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  74%|█████████▌   | 2269/3084 [00:10<00:03, 226.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  74%|█████████▌   | 2270/3084 [00:10<00:03, 226.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  74%|█████████▌   | 2271/3084 [00:10<00:03, 226.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  74%|█████████▌   | 2272/3084 [00:10<00:03, 226.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  74%|█████████▌   | 2273/3084 [00:10<00:03, 226.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  74%|█████████▌   | 2274/3084 [00:10<00:03, 226.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  74%|█████████▌   | 2275/3084 [00:10<00:03, 226.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  74%|█████████▌   | 2276/3084 [00:10<00:03, 226.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  74%|█████████▌   | 2277/3084 [00:10<00:03, 226.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  74%|█████████▌   | 2278/3084 [00:10<00:03, 226.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  74%|█████████▌   | 2279/3084 [00:10<00:03, 226.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  74%|█████████▌   | 2280/3084 [00:10<00:03, 226.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  74%|█████████▌   | 2281/3084 [00:10<00:03, 226.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  74%|█████████▌   | 2282/3084 [00:10<00:03, 226.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  74%|█████████▌   | 2283/3084 [00:10<00:03, 226.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  74%|█████████▋   | 2284/3084 [00:10<00:03, 226.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  74%|█████████▋   | 2285/3084 [00:10<00:03, 226.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  74%|█████████▋   | 2286/3084 [00:10<00:03, 226.23it/s]\u001b[A\n",
      "Validation DataLoader 0:  74%|█████████▋   | 2287/3084 [00:10<00:03, 226.24it/s]\u001b[A\n",
      "Validation DataLoader 0:  74%|█████████▋   | 2288/3084 [00:10<00:03, 226.24it/s]\u001b[A\n",
      "Validation DataLoader 0:  74%|█████████▋   | 2289/3084 [00:10<00:03, 226.24it/s]\u001b[A\n",
      "Validation DataLoader 0:  74%|█████████▋   | 2290/3084 [00:10<00:03, 226.24it/s]\u001b[A\n",
      "Validation DataLoader 0:  74%|█████████▋   | 2291/3084 [00:10<00:03, 226.25it/s]\u001b[A\n",
      "Validation DataLoader 0:  74%|█████████▋   | 2292/3084 [00:10<00:03, 226.25it/s]\u001b[A\n",
      "Validation DataLoader 0:  74%|█████████▋   | 2293/3084 [00:10<00:03, 226.25it/s]\u001b[A\n",
      "Validation DataLoader 0:  74%|█████████▋   | 2294/3084 [00:10<00:03, 226.26it/s]\u001b[A\n",
      "Validation DataLoader 0:  74%|█████████▋   | 2295/3084 [00:10<00:03, 226.26it/s]\u001b[A\n",
      "Validation DataLoader 0:  74%|█████████▋   | 2296/3084 [00:10<00:03, 226.26it/s]\u001b[A\n",
      "Validation DataLoader 0:  74%|█████████▋   | 2297/3084 [00:10<00:03, 226.26it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████▋   | 2298/3084 [00:10<00:03, 226.27it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████▋   | 2299/3084 [00:10<00:03, 226.27it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████▋   | 2300/3084 [00:10<00:03, 226.27it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████▋   | 2301/3084 [00:10<00:03, 226.27it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████▋   | 2302/3084 [00:10<00:03, 226.28it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████▋   | 2303/3084 [00:10<00:03, 226.28it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████▋   | 2304/3084 [00:10<00:03, 226.28it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████▋   | 2305/3084 [00:10<00:03, 226.28it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████▋   | 2306/3084 [00:10<00:03, 226.29it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████▋   | 2307/3084 [00:10<00:03, 226.29it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████▋   | 2308/3084 [00:10<00:03, 226.27it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████▋   | 2309/3084 [00:10<00:03, 226.28it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████▋   | 2310/3084 [00:10<00:03, 226.28it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████▋   | 2311/3084 [00:10<00:03, 226.28it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████▋   | 2312/3084 [00:10<00:03, 226.28it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████▊   | 2313/3084 [00:10<00:03, 226.28it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████▊   | 2314/3084 [00:10<00:03, 226.28it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████▊   | 2315/3084 [00:10<00:03, 226.29it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████▊   | 2316/3084 [00:10<00:03, 226.29it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████▊   | 2317/3084 [00:10<00:03, 226.29it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████▊   | 2318/3084 [00:10<00:03, 226.30it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████▊   | 2319/3084 [00:10<00:03, 226.30it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████▊   | 2320/3084 [00:10<00:03, 226.30it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████▊   | 2321/3084 [00:10<00:03, 226.30it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████▊   | 2322/3084 [00:10<00:03, 226.31it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████▊   | 2323/3084 [00:10<00:03, 226.31it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████▊   | 2324/3084 [00:10<00:03, 226.31it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████▊   | 2325/3084 [00:10<00:03, 226.31it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████▊   | 2326/3084 [00:10<00:03, 226.32it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████▊   | 2327/3084 [00:10<00:03, 226.32it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|█████████▊   | 2328/3084 [00:10<00:03, 226.32it/s]\u001b[A\n",
      "Validation DataLoader 0:  76%|█████████▊   | 2329/3084 [00:10<00:03, 226.33it/s]\u001b[A\n",
      "Validation DataLoader 0:  76%|█████████▊   | 2330/3084 [00:10<00:03, 226.33it/s]\u001b[A\n",
      "Validation DataLoader 0:  76%|█████████▊   | 2331/3084 [00:10<00:03, 226.33it/s]\u001b[A\n",
      "Validation DataLoader 0:  76%|█████████▊   | 2332/3084 [00:10<00:03, 226.33it/s]\u001b[A\n",
      "Validation DataLoader 0:  76%|█████████▊   | 2333/3084 [00:10<00:03, 226.33it/s]\u001b[A\n",
      "Validation DataLoader 0:  76%|█████████▊   | 2334/3084 [00:10<00:03, 226.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  76%|█████████▊   | 2335/3084 [00:10<00:03, 226.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  76%|█████████▊   | 2336/3084 [00:10<00:03, 226.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  76%|█████████▊   | 2337/3084 [00:10<00:03, 226.35it/s]\u001b[A\n",
      "Validation DataLoader 0:  76%|█████████▊   | 2338/3084 [00:10<00:03, 226.35it/s]\u001b[A\n",
      "Validation DataLoader 0:  76%|█████████▊   | 2339/3084 [00:10<00:03, 226.35it/s]\u001b[A\n",
      "Validation DataLoader 0:  76%|█████████▊   | 2340/3084 [00:10<00:03, 226.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  76%|█████████▊   | 2341/3084 [00:10<00:03, 226.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  76%|█████████▊   | 2342/3084 [00:10<00:03, 226.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  76%|█████████▉   | 2343/3084 [00:10<00:03, 226.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  76%|█████████▉   | 2344/3084 [00:10<00:03, 226.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  76%|█████████▉   | 2345/3084 [00:10<00:03, 226.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  76%|█████████▉   | 2346/3084 [00:10<00:03, 226.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  76%|█████████▉   | 2347/3084 [00:10<00:03, 226.35it/s]\u001b[A\n",
      "Validation DataLoader 0:  76%|█████████▉   | 2348/3084 [00:10<00:03, 226.35it/s]\u001b[A\n",
      "Validation DataLoader 0:  76%|█████████▉   | 2349/3084 [00:10<00:03, 226.35it/s]\u001b[A\n",
      "Validation DataLoader 0:  76%|█████████▉   | 2350/3084 [00:10<00:03, 226.35it/s]\u001b[A\n",
      "Validation DataLoader 0:  76%|█████████▉   | 2351/3084 [00:10<00:03, 226.35it/s]\u001b[A\n",
      "Validation DataLoader 0:  76%|█████████▉   | 2352/3084 [00:10<00:03, 226.35it/s]\u001b[A\n",
      "Validation DataLoader 0:  76%|█████████▉   | 2353/3084 [00:10<00:03, 226.36it/s]\u001b[A\n",
      "Validation DataLoader 0:  76%|█████████▉   | 2354/3084 [00:10<00:03, 226.36it/s]\u001b[A\n",
      "Validation DataLoader 0:  76%|█████████▉   | 2355/3084 [00:10<00:03, 226.36it/s]\u001b[A\n",
      "Validation DataLoader 0:  76%|█████████▉   | 2356/3084 [00:10<00:03, 226.37it/s]\u001b[A\n",
      "Validation DataLoader 0:  76%|█████████▉   | 2357/3084 [00:10<00:03, 226.37it/s]\u001b[A\n",
      "Validation DataLoader 0:  76%|█████████▉   | 2358/3084 [00:10<00:03, 226.37it/s]\u001b[A\n",
      "Validation DataLoader 0:  76%|█████████▉   | 2359/3084 [00:10<00:03, 226.37it/s]\u001b[A\n",
      "Validation DataLoader 0:  77%|█████████▉   | 2360/3084 [00:10<00:03, 226.38it/s]\u001b[A\n",
      "Validation DataLoader 0:  77%|█████████▉   | 2361/3084 [00:10<00:03, 226.38it/s]\u001b[A\n",
      "Validation DataLoader 0:  77%|█████████▉   | 2362/3084 [00:10<00:03, 226.38it/s]\u001b[A\n",
      "Validation DataLoader 0:  77%|█████████▉   | 2363/3084 [00:10<00:03, 226.39it/s]\u001b[A\n",
      "Validation DataLoader 0:  77%|█████████▉   | 2364/3084 [00:10<00:03, 226.39it/s]\u001b[A\n",
      "Validation DataLoader 0:  77%|█████████▉   | 2365/3084 [00:10<00:03, 226.40it/s]\u001b[A\n",
      "Validation DataLoader 0:  77%|█████████▉   | 2366/3084 [00:10<00:03, 226.38it/s]\u001b[A\n",
      "Validation DataLoader 0:  77%|█████████▉   | 2367/3084 [00:10<00:03, 226.39it/s]\u001b[A\n",
      "Validation DataLoader 0:  77%|█████████▉   | 2368/3084 [00:10<00:03, 226.38it/s]\u001b[A\n",
      "Validation DataLoader 0:  77%|█████████▉   | 2369/3084 [00:10<00:03, 226.38it/s]\u001b[A\n",
      "Validation DataLoader 0:  77%|█████████▉   | 2370/3084 [00:10<00:03, 226.39it/s]\u001b[A\n",
      "Validation DataLoader 0:  77%|█████████▉   | 2371/3084 [00:10<00:03, 226.39it/s]\u001b[A\n",
      "Validation DataLoader 0:  77%|█████████▉   | 2372/3084 [00:10<00:03, 226.39it/s]\u001b[A\n",
      "Validation DataLoader 0:  77%|██████████   | 2373/3084 [00:10<00:03, 226.39it/s]\u001b[A\n",
      "Validation DataLoader 0:  77%|██████████   | 2374/3084 [00:10<00:03, 226.40it/s]\u001b[A\n",
      "Validation DataLoader 0:  77%|██████████   | 2375/3084 [00:10<00:03, 226.40it/s]\u001b[A\n",
      "Validation DataLoader 0:  77%|██████████   | 2376/3084 [00:10<00:03, 226.40it/s]\u001b[A\n",
      "Validation DataLoader 0:  77%|██████████   | 2377/3084 [00:10<00:03, 226.40it/s]\u001b[A\n",
      "Validation DataLoader 0:  77%|██████████   | 2378/3084 [00:10<00:03, 226.40it/s]\u001b[A\n",
      "Validation DataLoader 0:  77%|██████████   | 2379/3084 [00:10<00:03, 226.39it/s]\u001b[A\n",
      "Validation DataLoader 0:  77%|██████████   | 2380/3084 [00:10<00:03, 226.39it/s]\u001b[A\n",
      "Validation DataLoader 0:  77%|██████████   | 2381/3084 [00:10<00:03, 226.39it/s]\u001b[A\n",
      "Validation DataLoader 0:  77%|██████████   | 2382/3084 [00:10<00:03, 226.40it/s]\u001b[A\n",
      "Validation DataLoader 0:  77%|██████████   | 2383/3084 [00:10<00:03, 226.40it/s]\u001b[A\n",
      "Validation DataLoader 0:  77%|██████████   | 2384/3084 [00:10<00:03, 226.40it/s]\u001b[A\n",
      "Validation DataLoader 0:  77%|██████████   | 2385/3084 [00:10<00:03, 226.41it/s]\u001b[A\n",
      "Validation DataLoader 0:  77%|██████████   | 2386/3084 [00:10<00:03, 226.41it/s]\u001b[A\n",
      "Validation DataLoader 0:  77%|██████████   | 2387/3084 [00:10<00:03, 226.42it/s]\u001b[A\n",
      "Validation DataLoader 0:  77%|██████████   | 2388/3084 [00:10<00:03, 226.42it/s]\u001b[A\n",
      "Validation DataLoader 0:  77%|██████████   | 2389/3084 [00:10<00:03, 226.43it/s]\u001b[A\n",
      "Validation DataLoader 0:  77%|██████████   | 2390/3084 [00:10<00:03, 226.43it/s]\u001b[A\n",
      "Validation DataLoader 0:  78%|██████████   | 2391/3084 [00:10<00:03, 226.44it/s]\u001b[A\n",
      "Validation DataLoader 0:  78%|██████████   | 2392/3084 [00:10<00:03, 226.44it/s]\u001b[A\n",
      "Validation DataLoader 0:  78%|██████████   | 2393/3084 [00:10<00:03, 226.45it/s]\u001b[A\n",
      "Validation DataLoader 0:  78%|██████████   | 2394/3084 [00:10<00:03, 226.45it/s]\u001b[A\n",
      "Validation DataLoader 0:  78%|██████████   | 2395/3084 [00:10<00:03, 226.45it/s]\u001b[A\n",
      "Validation DataLoader 0:  78%|██████████   | 2396/3084 [00:10<00:03, 226.46it/s]\u001b[A\n",
      "Validation DataLoader 0:  78%|██████████   | 2397/3084 [00:10<00:03, 226.46it/s]\u001b[A\n",
      "Validation DataLoader 0:  78%|██████████   | 2398/3084 [00:10<00:03, 226.45it/s]\u001b[A\n",
      "Validation DataLoader 0:  78%|██████████   | 2399/3084 [00:10<00:03, 226.46it/s]\u001b[A\n",
      "Validation DataLoader 0:  78%|██████████   | 2400/3084 [00:10<00:03, 226.46it/s]\u001b[A\n",
      "Validation DataLoader 0:  78%|██████████   | 2401/3084 [00:10<00:03, 226.46it/s]\u001b[A\n",
      "Validation DataLoader 0:  78%|██████████▏  | 2402/3084 [00:10<00:03, 226.46it/s]\u001b[A\n",
      "Validation DataLoader 0:  78%|██████████▏  | 2403/3084 [00:10<00:03, 226.46it/s]\u001b[A\n",
      "Validation DataLoader 0:  78%|██████████▏  | 2404/3084 [00:10<00:03, 226.47it/s]\u001b[A\n",
      "Validation DataLoader 0:  78%|██████████▏  | 2405/3084 [00:10<00:02, 226.47it/s]\u001b[A\n",
      "Validation DataLoader 0:  78%|██████████▏  | 2406/3084 [00:10<00:02, 226.47it/s]\u001b[A\n",
      "Validation DataLoader 0:  78%|██████████▏  | 2407/3084 [00:10<00:02, 226.47it/s]\u001b[A\n",
      "Validation DataLoader 0:  78%|██████████▏  | 2408/3084 [00:10<00:02, 226.47it/s]\u001b[A\n",
      "Validation DataLoader 0:  78%|██████████▏  | 2409/3084 [00:10<00:02, 226.47it/s]\u001b[A\n",
      "Validation DataLoader 0:  78%|██████████▏  | 2410/3084 [00:10<00:02, 226.48it/s]\u001b[A\n",
      "Validation DataLoader 0:  78%|██████████▏  | 2411/3084 [00:10<00:02, 226.46it/s]\u001b[A\n",
      "Validation DataLoader 0:  78%|██████████▏  | 2412/3084 [00:10<00:02, 226.46it/s]\u001b[A\n",
      "Validation DataLoader 0:  78%|██████████▏  | 2413/3084 [00:10<00:02, 226.46it/s]\u001b[A\n",
      "Validation DataLoader 0:  78%|██████████▏  | 2414/3084 [00:10<00:02, 226.47it/s]\u001b[A\n",
      "Validation DataLoader 0:  78%|██████████▏  | 2415/3084 [00:10<00:02, 226.47it/s]\u001b[A\n",
      "Validation DataLoader 0:  78%|██████████▏  | 2416/3084 [00:10<00:02, 226.47it/s]\u001b[A\n",
      "Validation DataLoader 0:  78%|██████████▏  | 2417/3084 [00:10<00:02, 226.47it/s]\u001b[A\n",
      "Validation DataLoader 0:  78%|██████████▏  | 2418/3084 [00:10<00:02, 226.47it/s]\u001b[A\n",
      "Validation DataLoader 0:  78%|██████████▏  | 2419/3084 [00:10<00:02, 226.48it/s]\u001b[A\n",
      "Validation DataLoader 0:  78%|██████████▏  | 2420/3084 [00:10<00:02, 226.48it/s]\u001b[A\n",
      "Validation DataLoader 0:  79%|██████████▏  | 2421/3084 [00:10<00:02, 226.49it/s]\u001b[A\n",
      "Validation DataLoader 0:  79%|██████████▏  | 2422/3084 [00:10<00:02, 226.49it/s]\u001b[A\n",
      "Validation DataLoader 0:  79%|██████████▏  | 2423/3084 [00:10<00:02, 226.49it/s]\u001b[A\n",
      "Validation DataLoader 0:  79%|██████████▏  | 2424/3084 [00:10<00:02, 226.50it/s]\u001b[A\n",
      "Validation DataLoader 0:  79%|██████████▏  | 2425/3084 [00:10<00:02, 226.50it/s]\u001b[A\n",
      "Validation DataLoader 0:  79%|██████████▏  | 2426/3084 [00:10<00:02, 226.51it/s]\u001b[A\n",
      "Validation DataLoader 0:  79%|██████████▏  | 2427/3084 [00:10<00:02, 226.51it/s]\u001b[A\n",
      "Validation DataLoader 0:  79%|██████████▏  | 2428/3084 [00:10<00:02, 226.51it/s]\u001b[A\n",
      "Validation DataLoader 0:  79%|██████████▏  | 2429/3084 [00:10<00:02, 226.52it/s]\u001b[A\n",
      "Validation DataLoader 0:  79%|██████████▏  | 2430/3084 [00:10<00:02, 226.50it/s]\u001b[A\n",
      "Validation DataLoader 0:  79%|██████████▏  | 2431/3084 [00:10<00:02, 226.51it/s]\u001b[A\n",
      "Validation DataLoader 0:  79%|██████████▎  | 2432/3084 [00:10<00:02, 226.51it/s]\u001b[A\n",
      "Validation DataLoader 0:  79%|██████████▎  | 2433/3084 [00:10<00:02, 226.51it/s]\u001b[A\n",
      "Validation DataLoader 0:  79%|██████████▎  | 2434/3084 [00:10<00:02, 226.52it/s]\u001b[A\n",
      "Validation DataLoader 0:  79%|██████████▎  | 2435/3084 [00:10<00:02, 226.52it/s]\u001b[A\n",
      "Validation DataLoader 0:  79%|██████████▎  | 2436/3084 [00:10<00:02, 226.52it/s]\u001b[A\n",
      "Validation DataLoader 0:  79%|██████████▎  | 2437/3084 [00:10<00:02, 226.52it/s]\u001b[A\n",
      "Validation DataLoader 0:  79%|██████████▎  | 2438/3084 [00:10<00:02, 226.52it/s]\u001b[A\n",
      "Validation DataLoader 0:  79%|██████████▎  | 2439/3084 [00:10<00:02, 226.52it/s]\u001b[A\n",
      "Validation DataLoader 0:  79%|██████████▎  | 2440/3084 [00:10<00:02, 226.53it/s]\u001b[A\n",
      "Validation DataLoader 0:  79%|██████████▎  | 2441/3084 [00:10<00:02, 226.53it/s]\u001b[A\n",
      "Validation DataLoader 0:  79%|██████████▎  | 2442/3084 [00:10<00:02, 226.53it/s]\u001b[A\n",
      "Validation DataLoader 0:  79%|██████████▎  | 2443/3084 [00:10<00:02, 226.52it/s]\u001b[A\n",
      "Validation DataLoader 0:  79%|██████████▎  | 2444/3084 [00:10<00:02, 226.52it/s]\u001b[A\n",
      "Validation DataLoader 0:  79%|██████████▎  | 2445/3084 [00:10<00:02, 226.52it/s]\u001b[A\n",
      "Validation DataLoader 0:  79%|██████████▎  | 2446/3084 [00:10<00:02, 226.52it/s]\u001b[A\n",
      "Validation DataLoader 0:  79%|██████████▎  | 2447/3084 [00:10<00:02, 226.53it/s]\u001b[A\n",
      "Validation DataLoader 0:  79%|██████████▎  | 2448/3084 [00:10<00:02, 226.53it/s]\u001b[A\n",
      "Validation DataLoader 0:  79%|██████████▎  | 2449/3084 [00:10<00:02, 226.53it/s]\u001b[A\n",
      "Validation DataLoader 0:  79%|██████████▎  | 2450/3084 [00:10<00:02, 226.54it/s]\u001b[A\n",
      "Validation DataLoader 0:  79%|██████████▎  | 2451/3084 [00:10<00:02, 226.54it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████▎  | 2452/3084 [00:10<00:02, 226.55it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████▎  | 2453/3084 [00:10<00:02, 226.55it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████▎  | 2454/3084 [00:10<00:02, 226.56it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████▎  | 2455/3084 [00:10<00:02, 226.56it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████▎  | 2456/3084 [00:10<00:02, 226.57it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████▎  | 2457/3084 [00:10<00:02, 226.57it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████▎  | 2458/3084 [00:10<00:02, 226.57it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████▎  | 2459/3084 [00:10<00:02, 226.58it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████▎  | 2460/3084 [00:10<00:02, 226.58it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████▎  | 2461/3084 [00:10<00:02, 226.58it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████▍  | 2462/3084 [00:10<00:02, 226.57it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████▍  | 2463/3084 [00:10<00:02, 226.58it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████▍  | 2464/3084 [00:10<00:02, 226.58it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████▍  | 2465/3084 [00:10<00:02, 226.58it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████▍  | 2466/3084 [00:10<00:02, 226.58it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████▍  | 2467/3084 [00:10<00:02, 226.58it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████▍  | 2468/3084 [00:10<00:02, 226.59it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████▍  | 2469/3084 [00:10<00:02, 226.58it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████▍  | 2470/3084 [00:10<00:02, 226.58it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████▍  | 2471/3084 [00:10<00:02, 226.58it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████▍  | 2472/3084 [00:10<00:02, 226.59it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████▍  | 2473/3084 [00:10<00:02, 226.59it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████▍  | 2474/3084 [00:10<00:02, 226.59it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████▍  | 2475/3084 [00:10<00:02, 226.59it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████▍  | 2476/3084 [00:10<00:02, 226.59it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████▍  | 2477/3084 [00:10<00:02, 226.59it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████▍  | 2478/3084 [00:10<00:02, 226.60it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████▍  | 2479/3084 [00:10<00:02, 226.60it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████▍  | 2480/3084 [00:10<00:02, 226.60it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████▍  | 2481/3084 [00:10<00:02, 226.60it/s]\u001b[A\n",
      "Validation DataLoader 0:  80%|██████████▍  | 2482/3084 [00:10<00:02, 226.61it/s]\u001b[A\n",
      "Validation DataLoader 0:  81%|██████████▍  | 2483/3084 [00:10<00:02, 226.61it/s]\u001b[A\n",
      "Validation DataLoader 0:  81%|██████████▍  | 2484/3084 [00:10<00:02, 226.61it/s]\u001b[A\n",
      "Validation DataLoader 0:  81%|██████████▍  | 2485/3084 [00:10<00:02, 226.61it/s]\u001b[A\n",
      "Validation DataLoader 0:  81%|██████████▍  | 2486/3084 [00:10<00:02, 226.61it/s]\u001b[A\n",
      "Validation DataLoader 0:  81%|██████████▍  | 2487/3084 [00:10<00:02, 226.62it/s]\u001b[A\n",
      "Validation DataLoader 0:  81%|██████████▍  | 2488/3084 [00:10<00:02, 226.62it/s]\u001b[A\n",
      "Validation DataLoader 0:  81%|██████████▍  | 2489/3084 [00:10<00:02, 226.63it/s]\u001b[A\n",
      "Validation DataLoader 0:  81%|██████████▍  | 2490/3084 [00:10<00:02, 226.63it/s]\u001b[A\n",
      "Validation DataLoader 0:  81%|██████████▌  | 2491/3084 [00:10<00:02, 226.63it/s]\u001b[A\n",
      "Validation DataLoader 0:  81%|██████████▌  | 2492/3084 [00:10<00:02, 226.64it/s]\u001b[A\n",
      "Validation DataLoader 0:  81%|██████████▌  | 2493/3084 [00:10<00:02, 226.64it/s]\u001b[A\n",
      "Validation DataLoader 0:  81%|██████████▌  | 2494/3084 [00:11<00:02, 226.63it/s]\u001b[A\n",
      "Validation DataLoader 0:  81%|██████████▌  | 2495/3084 [00:11<00:02, 226.63it/s]\u001b[A\n",
      "Validation DataLoader 0:  81%|██████████▌  | 2496/3084 [00:11<00:02, 226.63it/s]\u001b[A\n",
      "Validation DataLoader 0:  81%|██████████▌  | 2497/3084 [00:11<00:02, 226.64it/s]\u001b[A\n",
      "Validation DataLoader 0:  81%|██████████▌  | 2498/3084 [00:11<00:02, 226.64it/s]\u001b[A\n",
      "Validation DataLoader 0:  81%|██████████▌  | 2499/3084 [00:11<00:02, 226.64it/s]\u001b[A\n",
      "Validation DataLoader 0:  81%|██████████▌  | 2500/3084 [00:11<00:02, 226.64it/s]\u001b[A\n",
      "Validation DataLoader 0:  81%|██████████▌  | 2501/3084 [00:11<00:02, 226.64it/s]\u001b[A\n",
      "Validation DataLoader 0:  81%|██████████▌  | 2502/3084 [00:11<00:02, 226.65it/s]\u001b[A\n",
      "Validation DataLoader 0:  81%|██████████▌  | 2503/3084 [00:11<00:02, 226.65it/s]\u001b[A\n",
      "Validation DataLoader 0:  81%|██████████▌  | 2504/3084 [00:11<00:02, 226.65it/s]\u001b[A\n",
      "Validation DataLoader 0:  81%|██████████▌  | 2505/3084 [00:11<00:02, 226.65it/s]\u001b[A\n",
      "Validation DataLoader 0:  81%|██████████▌  | 2506/3084 [00:11<00:02, 226.65it/s]\u001b[A\n",
      "Validation DataLoader 0:  81%|██████████▌  | 2507/3084 [00:11<00:02, 226.66it/s]\u001b[A\n",
      "Validation DataLoader 0:  81%|██████████▌  | 2508/3084 [00:11<00:02, 226.66it/s]\u001b[A\n",
      "Validation DataLoader 0:  81%|██████████▌  | 2509/3084 [00:11<00:02, 226.66it/s]\u001b[A\n",
      "Validation DataLoader 0:  81%|██████████▌  | 2510/3084 [00:11<00:02, 226.66it/s]\u001b[A\n",
      "Validation DataLoader 0:  81%|██████████▌  | 2511/3084 [00:11<00:02, 226.67it/s]\u001b[A\n",
      "Validation DataLoader 0:  81%|██████████▌  | 2512/3084 [00:11<00:02, 226.67it/s]\u001b[A\n",
      "Validation DataLoader 0:  81%|██████████▌  | 2513/3084 [00:11<00:02, 226.67it/s]\u001b[A\n",
      "Validation DataLoader 0:  82%|██████████▌  | 2514/3084 [00:11<00:02, 226.67it/s]\u001b[A\n",
      "Validation DataLoader 0:  82%|██████████▌  | 2515/3084 [00:11<00:02, 226.67it/s]\u001b[A\n",
      "Validation DataLoader 0:  82%|██████████▌  | 2516/3084 [00:11<00:02, 226.68it/s]\u001b[A\n",
      "Validation DataLoader 0:  82%|██████████▌  | 2517/3084 [00:11<00:02, 226.68it/s]\u001b[A\n",
      "Validation DataLoader 0:  82%|██████████▌  | 2518/3084 [00:11<00:02, 226.68it/s]\u001b[A\n",
      "Validation DataLoader 0:  82%|██████████▌  | 2519/3084 [00:11<00:02, 226.68it/s]\u001b[A\n",
      "Validation DataLoader 0:  82%|██████████▌  | 2520/3084 [00:11<00:02, 226.68it/s]\u001b[A\n",
      "Validation DataLoader 0:  82%|██████████▋  | 2521/3084 [00:11<00:02, 226.69it/s]\u001b[A\n",
      "Validation DataLoader 0:  82%|██████████▋  | 2522/3084 [00:11<00:02, 226.69it/s]\u001b[A\n",
      "Validation DataLoader 0:  82%|██████████▋  | 2523/3084 [00:11<00:02, 226.69it/s]\u001b[A\n",
      "Validation DataLoader 0:  82%|██████████▋  | 2524/3084 [00:11<00:02, 226.69it/s]\u001b[A\n",
      "Validation DataLoader 0:  82%|██████████▋  | 2525/3084 [00:11<00:02, 226.70it/s]\u001b[A\n",
      "Validation DataLoader 0:  82%|██████████▋  | 2526/3084 [00:11<00:02, 226.69it/s]\u001b[A\n",
      "Validation DataLoader 0:  82%|██████████▋  | 2527/3084 [00:11<00:02, 226.69it/s]\u001b[A\n",
      "Validation DataLoader 0:  82%|██████████▋  | 2528/3084 [00:11<00:02, 226.69it/s]\u001b[A\n",
      "Validation DataLoader 0:  82%|██████████▋  | 2529/3084 [00:11<00:02, 226.70it/s]\u001b[A\n",
      "Validation DataLoader 0:  82%|██████████▋  | 2530/3084 [00:11<00:02, 226.70it/s]\u001b[A\n",
      "Validation DataLoader 0:  82%|██████████▋  | 2531/3084 [00:11<00:02, 226.70it/s]\u001b[A\n",
      "Validation DataLoader 0:  82%|██████████▋  | 2532/3084 [00:11<00:02, 226.70it/s]\u001b[A\n",
      "Validation DataLoader 0:  82%|██████████▋  | 2533/3084 [00:11<00:02, 226.70it/s]\u001b[A\n",
      "Validation DataLoader 0:  82%|██████████▋  | 2534/3084 [00:11<00:02, 226.70it/s]\u001b[A\n",
      "Validation DataLoader 0:  82%|██████████▋  | 2535/3084 [00:11<00:02, 226.70it/s]\u001b[A\n",
      "Validation DataLoader 0:  82%|██████████▋  | 2536/3084 [00:11<00:02, 226.71it/s]\u001b[A\n",
      "Validation DataLoader 0:  82%|██████████▋  | 2537/3084 [00:11<00:02, 226.71it/s]\u001b[A\n",
      "Validation DataLoader 0:  82%|██████████▋  | 2538/3084 [00:11<00:02, 226.71it/s]\u001b[A\n",
      "Validation DataLoader 0:  82%|██████████▋  | 2539/3084 [00:11<00:02, 226.71it/s]\u001b[A\n",
      "Validation DataLoader 0:  82%|██████████▋  | 2540/3084 [00:11<00:02, 226.72it/s]\u001b[A\n",
      "Validation DataLoader 0:  82%|██████████▋  | 2541/3084 [00:11<00:02, 226.72it/s]\u001b[A\n",
      "Validation DataLoader 0:  82%|██████████▋  | 2542/3084 [00:11<00:02, 226.72it/s]\u001b[A\n",
      "Validation DataLoader 0:  82%|██████████▋  | 2543/3084 [00:11<00:02, 226.72it/s]\u001b[A\n",
      "Validation DataLoader 0:  82%|██████████▋  | 2544/3084 [00:11<00:02, 226.72it/s]\u001b[A\n",
      "Validation DataLoader 0:  83%|██████████▋  | 2545/3084 [00:11<00:02, 226.72it/s]\u001b[A\n",
      "Validation DataLoader 0:  83%|██████████▋  | 2546/3084 [00:11<00:02, 226.73it/s]\u001b[A\n",
      "Validation DataLoader 0:  83%|██████████▋  | 2547/3084 [00:11<00:02, 226.73it/s]\u001b[A\n",
      "Validation DataLoader 0:  83%|██████████▋  | 2548/3084 [00:11<00:02, 226.73it/s]\u001b[A\n",
      "Validation DataLoader 0:  83%|██████████▋  | 2549/3084 [00:11<00:02, 226.73it/s]\u001b[A\n",
      "Validation DataLoader 0:  83%|██████████▋  | 2550/3084 [00:11<00:02, 226.74it/s]\u001b[A\n",
      "Validation DataLoader 0:  83%|██████████▊  | 2551/3084 [00:11<00:02, 226.74it/s]\u001b[A\n",
      "Validation DataLoader 0:  83%|██████████▊  | 2552/3084 [00:11<00:02, 226.75it/s]\u001b[A\n",
      "Validation DataLoader 0:  83%|██████████▊  | 2553/3084 [00:11<00:02, 226.75it/s]\u001b[A\n",
      "Validation DataLoader 0:  83%|██████████▊  | 2554/3084 [00:11<00:02, 226.76it/s]\u001b[A\n",
      "Validation DataLoader 0:  83%|██████████▊  | 2555/3084 [00:11<00:02, 226.76it/s]\u001b[A\n",
      "Validation DataLoader 0:  83%|██████████▊  | 2556/3084 [00:11<00:02, 226.76it/s]\u001b[A\n",
      "Validation DataLoader 0:  83%|██████████▊  | 2557/3084 [00:11<00:02, 226.76it/s]\u001b[A\n",
      "Validation DataLoader 0:  83%|██████████▊  | 2558/3084 [00:11<00:02, 226.75it/s]\u001b[A\n",
      "Validation DataLoader 0:  83%|██████████▊  | 2559/3084 [00:11<00:02, 226.76it/s]\u001b[A\n",
      "Validation DataLoader 0:  83%|██████████▊  | 2560/3084 [00:11<00:02, 226.76it/s]\u001b[A\n",
      "Validation DataLoader 0:  83%|██████████▊  | 2561/3084 [00:11<00:02, 226.76it/s]\u001b[A\n",
      "Validation DataLoader 0:  83%|██████████▊  | 2562/3084 [00:11<00:02, 226.76it/s]\u001b[A\n",
      "Validation DataLoader 0:  83%|██████████▊  | 2563/3084 [00:11<00:02, 226.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  83%|██████████▊  | 2564/3084 [00:11<00:02, 226.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  83%|██████████▊  | 2565/3084 [00:11<00:02, 226.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  83%|██████████▊  | 2566/3084 [00:11<00:02, 226.77it/s]\u001b[A\n",
      "Validation DataLoader 0:  83%|██████████▊  | 2567/3084 [00:11<00:02, 226.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  83%|██████████▊  | 2568/3084 [00:11<00:02, 226.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  83%|██████████▊  | 2569/3084 [00:11<00:02, 226.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  83%|██████████▊  | 2570/3084 [00:11<00:02, 226.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  83%|██████████▊  | 2571/3084 [00:11<00:02, 226.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  83%|██████████▊  | 2572/3084 [00:11<00:02, 226.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  83%|██████████▊  | 2573/3084 [00:11<00:02, 226.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  83%|██████████▊  | 2574/3084 [00:11<00:02, 226.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  83%|██████████▊  | 2575/3084 [00:11<00:02, 226.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  84%|██████████▊  | 2576/3084 [00:11<00:02, 226.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  84%|██████████▊  | 2577/3084 [00:11<00:02, 226.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  84%|██████████▊  | 2578/3084 [00:11<00:02, 226.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  84%|██████████▊  | 2579/3084 [00:11<00:02, 226.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  84%|██████████▉  | 2580/3084 [00:11<00:02, 226.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  84%|██████████▉  | 2581/3084 [00:11<00:02, 226.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  84%|██████████▉  | 2582/3084 [00:11<00:02, 226.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  84%|██████████▉  | 2583/3084 [00:11<00:02, 226.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  84%|██████████▉  | 2584/3084 [00:11<00:02, 226.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  84%|██████████▉  | 2585/3084 [00:11<00:02, 226.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  84%|██████████▉  | 2586/3084 [00:11<00:02, 226.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  84%|██████████▉  | 2587/3084 [00:11<00:02, 226.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  84%|██████████▉  | 2588/3084 [00:11<00:02, 226.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  84%|██████████▉  | 2589/3084 [00:11<00:02, 226.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  84%|██████████▉  | 2590/3084 [00:11<00:02, 226.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  84%|██████████▉  | 2591/3084 [00:11<00:02, 226.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  84%|██████████▉  | 2592/3084 [00:11<00:02, 226.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  84%|██████████▉  | 2593/3084 [00:11<00:02, 226.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  84%|██████████▉  | 2594/3084 [00:11<00:02, 226.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  84%|██████████▉  | 2595/3084 [00:11<00:02, 226.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  84%|██████████▉  | 2596/3084 [00:11<00:02, 226.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  84%|██████████▉  | 2597/3084 [00:11<00:02, 226.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  84%|██████████▉  | 2598/3084 [00:11<00:02, 226.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  84%|██████████▉  | 2599/3084 [00:11<00:02, 226.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  84%|██████████▉  | 2600/3084 [00:11<00:02, 226.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  84%|██████████▉  | 2601/3084 [00:11<00:02, 226.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  84%|██████████▉  | 2602/3084 [00:11<00:02, 226.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  84%|██████████▉  | 2603/3084 [00:11<00:02, 226.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  84%|██████████▉  | 2604/3084 [00:11<00:02, 226.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  84%|██████████▉  | 2605/3084 [00:11<00:02, 226.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|██████████▉  | 2606/3084 [00:11<00:02, 226.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|██████████▉  | 2607/3084 [00:11<00:02, 226.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|██████████▉  | 2608/3084 [00:11<00:02, 226.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|██████████▉  | 2609/3084 [00:11<00:02, 226.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████  | 2610/3084 [00:11<00:02, 226.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████  | 2611/3084 [00:11<00:02, 226.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████  | 2612/3084 [00:11<00:02, 226.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████  | 2613/3084 [00:11<00:02, 226.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████  | 2614/3084 [00:11<00:02, 226.86it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████  | 2615/3084 [00:11<00:02, 226.86it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████  | 2616/3084 [00:11<00:02, 226.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████  | 2617/3084 [00:11<00:02, 226.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████  | 2618/3084 [00:11<00:02, 226.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████  | 2619/3084 [00:11<00:02, 226.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████  | 2620/3084 [00:11<00:02, 226.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████  | 2621/3084 [00:11<00:02, 226.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████  | 2622/3084 [00:11<00:02, 226.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████  | 2623/3084 [00:11<00:02, 226.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████  | 2624/3084 [00:11<00:02, 226.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████  | 2625/3084 [00:11<00:02, 226.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████  | 2626/3084 [00:11<00:02, 226.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████  | 2627/3084 [00:11<00:02, 226.89it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████  | 2628/3084 [00:11<00:02, 226.89it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████  | 2629/3084 [00:11<00:02, 226.89it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████  | 2630/3084 [00:11<00:02, 226.90it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████  | 2631/3084 [00:11<00:01, 226.90it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████  | 2632/3084 [00:11<00:01, 226.90it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████  | 2633/3084 [00:11<00:01, 226.90it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████  | 2634/3084 [00:11<00:01, 226.90it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████  | 2635/3084 [00:11<00:01, 226.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  85%|███████████  | 2636/3084 [00:11<00:01, 226.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  86%|███████████  | 2637/3084 [00:11<00:01, 226.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  86%|███████████  | 2638/3084 [00:11<00:01, 226.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  86%|███████████  | 2639/3084 [00:11<00:01, 226.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  86%|███████████▏ | 2640/3084 [00:11<00:01, 226.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  86%|███████████▏ | 2641/3084 [00:11<00:01, 226.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  86%|███████████▏ | 2642/3084 [00:11<00:01, 226.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  86%|███████████▏ | 2643/3084 [00:11<00:01, 226.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  86%|███████████▏ | 2644/3084 [00:11<00:01, 226.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  86%|███████████▏ | 2645/3084 [00:11<00:01, 226.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  86%|███████████▏ | 2646/3084 [00:11<00:01, 226.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  86%|███████████▏ | 2647/3084 [00:11<00:01, 226.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  86%|███████████▏ | 2648/3084 [00:11<00:01, 226.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  86%|███████████▏ | 2649/3084 [00:11<00:01, 226.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  86%|███████████▏ | 2650/3084 [00:11<00:01, 226.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  86%|███████████▏ | 2651/3084 [00:11<00:01, 226.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  86%|███████████▏ | 2652/3084 [00:11<00:01, 226.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  86%|███████████▏ | 2653/3084 [00:11<00:01, 226.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  86%|███████████▏ | 2654/3084 [00:11<00:01, 226.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  86%|███████████▏ | 2655/3084 [00:11<00:01, 226.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  86%|███████████▏ | 2656/3084 [00:11<00:01, 226.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  86%|███████████▏ | 2657/3084 [00:11<00:01, 226.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  86%|███████████▏ | 2658/3084 [00:11<00:01, 226.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  86%|███████████▏ | 2659/3084 [00:11<00:01, 226.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  86%|███████████▏ | 2660/3084 [00:11<00:01, 226.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  86%|███████████▏ | 2661/3084 [00:11<00:01, 226.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  86%|███████████▏ | 2662/3084 [00:11<00:01, 226.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  86%|███████████▏ | 2663/3084 [00:11<00:01, 226.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  86%|███████████▏ | 2664/3084 [00:11<00:01, 226.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  86%|███████████▏ | 2665/3084 [00:11<00:01, 226.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  86%|███████████▏ | 2666/3084 [00:11<00:01, 226.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  86%|███████████▏ | 2667/3084 [00:11<00:01, 226.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  87%|███████████▏ | 2668/3084 [00:11<00:01, 226.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  87%|███████████▎ | 2669/3084 [00:11<00:01, 226.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  87%|███████████▎ | 2670/3084 [00:11<00:01, 226.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  87%|███████████▎ | 2671/3084 [00:11<00:01, 226.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  87%|███████████▎ | 2672/3084 [00:11<00:01, 226.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  87%|███████████▎ | 2673/3084 [00:11<00:01, 226.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  87%|███████████▎ | 2674/3084 [00:11<00:01, 226.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  87%|███████████▎ | 2675/3084 [00:11<00:01, 226.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  87%|███████████▎ | 2676/3084 [00:11<00:01, 226.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  87%|███████████▎ | 2677/3084 [00:11<00:01, 227.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  87%|███████████▎ | 2678/3084 [00:11<00:01, 227.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  87%|███████████▎ | 2679/3084 [00:11<00:01, 227.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  87%|███████████▎ | 2680/3084 [00:11<00:01, 227.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  87%|███████████▎ | 2681/3084 [00:11<00:01, 227.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  87%|███████████▎ | 2682/3084 [00:11<00:01, 227.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  87%|███████████▎ | 2683/3084 [00:11<00:01, 227.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  87%|███████████▎ | 2684/3084 [00:11<00:01, 227.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  87%|███████████▎ | 2685/3084 [00:11<00:01, 227.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  87%|███████████▎ | 2686/3084 [00:11<00:01, 227.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  87%|███████████▎ | 2687/3084 [00:11<00:01, 227.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  87%|███████████▎ | 2688/3084 [00:11<00:01, 227.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  87%|███████████▎ | 2689/3084 [00:11<00:01, 227.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  87%|███████████▎ | 2690/3084 [00:11<00:01, 227.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  87%|███████████▎ | 2691/3084 [00:11<00:01, 226.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  87%|███████████▎ | 2692/3084 [00:11<00:01, 226.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  87%|███████████▎ | 2693/3084 [00:11<00:01, 226.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  87%|███████████▎ | 2694/3084 [00:11<00:01, 226.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  87%|███████████▎ | 2695/3084 [00:11<00:01, 226.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  87%|███████████▎ | 2696/3084 [00:11<00:01, 226.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  87%|███████████▎ | 2697/3084 [00:11<00:01, 226.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  87%|███████████▎ | 2698/3084 [00:11<00:01, 226.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  88%|███████████▍ | 2699/3084 [00:11<00:01, 226.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  88%|███████████▍ | 2700/3084 [00:11<00:01, 226.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  88%|███████████▍ | 2701/3084 [00:11<00:01, 226.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  88%|███████████▍ | 2702/3084 [00:11<00:01, 226.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  88%|███████████▍ | 2703/3084 [00:11<00:01, 226.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  88%|███████████▍ | 2704/3084 [00:11<00:01, 226.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  88%|███████████▍ | 2705/3084 [00:11<00:01, 226.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  88%|███████████▍ | 2706/3084 [00:11<00:01, 226.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  88%|███████████▍ | 2707/3084 [00:11<00:01, 226.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  88%|███████████▍ | 2708/3084 [00:11<00:01, 226.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  88%|███████████▍ | 2709/3084 [00:11<00:01, 226.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  88%|███████████▍ | 2710/3084 [00:11<00:01, 226.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  88%|███████████▍ | 2711/3084 [00:11<00:01, 226.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  88%|███████████▍ | 2712/3084 [00:11<00:01, 226.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  88%|███████████▍ | 2713/3084 [00:11<00:01, 226.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  88%|███████████▍ | 2714/3084 [00:11<00:01, 226.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  88%|███████████▍ | 2715/3084 [00:11<00:01, 226.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  88%|███████████▍ | 2716/3084 [00:11<00:01, 226.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  88%|███████████▍ | 2717/3084 [00:11<00:01, 226.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  88%|███████████▍ | 2718/3084 [00:11<00:01, 226.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  88%|███████████▍ | 2719/3084 [00:11<00:01, 226.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  88%|███████████▍ | 2720/3084 [00:11<00:01, 226.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  88%|███████████▍ | 2721/3084 [00:11<00:01, 226.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  88%|███████████▍ | 2722/3084 [00:11<00:01, 226.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  88%|███████████▍ | 2723/3084 [00:12<00:01, 226.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  88%|███████████▍ | 2724/3084 [00:12<00:01, 226.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  88%|███████████▍ | 2725/3084 [00:12<00:01, 226.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  88%|███████████▍ | 2726/3084 [00:12<00:01, 226.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  88%|███████████▍ | 2727/3084 [00:12<00:01, 226.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  88%|███████████▍ | 2728/3084 [00:12<00:01, 226.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  88%|███████████▌ | 2729/3084 [00:12<00:01, 226.83it/s]\u001b[A\n",
      "Validation DataLoader 0:  89%|███████████▌ | 2730/3084 [00:12<00:01, 226.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  89%|███████████▌ | 2731/3084 [00:12<00:01, 226.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  89%|███████████▌ | 2732/3084 [00:12<00:01, 226.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  89%|███████████▌ | 2733/3084 [00:12<00:01, 226.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  89%|███████████▌ | 2734/3084 [00:12<00:01, 226.84it/s]\u001b[A\n",
      "Validation DataLoader 0:  89%|███████████▌ | 2735/3084 [00:12<00:01, 226.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  89%|███████████▌ | 2736/3084 [00:12<00:01, 226.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  89%|███████████▌ | 2737/3084 [00:12<00:01, 226.85it/s]\u001b[A\n",
      "Validation DataLoader 0:  89%|███████████▌ | 2738/3084 [00:12<00:01, 226.86it/s]\u001b[A\n",
      "Validation DataLoader 0:  89%|███████████▌ | 2739/3084 [00:12<00:01, 226.86it/s]\u001b[A\n",
      "Validation DataLoader 0:  89%|███████████▌ | 2740/3084 [00:12<00:01, 226.86it/s]\u001b[A\n",
      "Validation DataLoader 0:  89%|███████████▌ | 2741/3084 [00:12<00:01, 226.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  89%|███████████▌ | 2742/3084 [00:12<00:01, 226.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  89%|███████████▌ | 2743/3084 [00:12<00:01, 226.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  89%|███████████▌ | 2744/3084 [00:12<00:01, 226.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  89%|███████████▌ | 2745/3084 [00:12<00:01, 226.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  89%|███████████▌ | 2746/3084 [00:12<00:01, 226.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  89%|███████████▌ | 2747/3084 [00:12<00:01, 226.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  89%|███████████▌ | 2748/3084 [00:12<00:01, 226.89it/s]\u001b[A\n",
      "Validation DataLoader 0:  89%|███████████▌ | 2749/3084 [00:12<00:01, 226.89it/s]\u001b[A\n",
      "Validation DataLoader 0:  89%|███████████▌ | 2750/3084 [00:12<00:01, 226.89it/s]\u001b[A\n",
      "Validation DataLoader 0:  89%|███████████▌ | 2751/3084 [00:12<00:01, 226.89it/s]\u001b[A\n",
      "Validation DataLoader 0:  89%|███████████▌ | 2752/3084 [00:12<00:01, 226.89it/s]\u001b[A\n",
      "Validation DataLoader 0:  89%|███████████▌ | 2753/3084 [00:12<00:01, 226.89it/s]\u001b[A\n",
      "Validation DataLoader 0:  89%|███████████▌ | 2754/3084 [00:12<00:01, 226.90it/s]\u001b[A\n",
      "Validation DataLoader 0:  89%|███████████▌ | 2755/3084 [00:12<00:01, 226.90it/s]\u001b[A\n",
      "Validation DataLoader 0:  89%|███████████▌ | 2756/3084 [00:12<00:01, 226.88it/s]\u001b[A\n",
      "Validation DataLoader 0:  89%|███████████▌ | 2757/3084 [00:12<00:01, 226.89it/s]\u001b[A\n",
      "Validation DataLoader 0:  89%|███████████▋ | 2758/3084 [00:12<00:01, 226.89it/s]\u001b[A\n",
      "Validation DataLoader 0:  89%|███████████▋ | 2759/3084 [00:12<00:01, 226.89it/s]\u001b[A\n",
      "Validation DataLoader 0:  89%|███████████▋ | 2760/3084 [00:12<00:01, 226.89it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|███████████▋ | 2761/3084 [00:12<00:01, 226.89it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|███████████▋ | 2762/3084 [00:12<00:01, 226.89it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|███████████▋ | 2763/3084 [00:12<00:01, 226.89it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|███████████▋ | 2764/3084 [00:12<00:01, 226.89it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|███████████▋ | 2765/3084 [00:12<00:01, 226.89it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|███████████▋ | 2766/3084 [00:12<00:01, 226.90it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|███████████▋ | 2767/3084 [00:12<00:01, 226.90it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|███████████▋ | 2768/3084 [00:12<00:01, 226.90it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|███████████▋ | 2769/3084 [00:12<00:01, 226.90it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|███████████▋ | 2770/3084 [00:12<00:01, 226.90it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|███████████▋ | 2771/3084 [00:12<00:01, 226.90it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|███████████▋ | 2772/3084 [00:12<00:01, 226.90it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|███████████▋ | 2773/3084 [00:12<00:01, 226.90it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|███████████▋ | 2774/3084 [00:12<00:01, 226.90it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|███████████▋ | 2775/3084 [00:12<00:01, 226.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|███████████▋ | 2776/3084 [00:12<00:01, 226.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|███████████▋ | 2777/3084 [00:12<00:01, 226.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|███████████▋ | 2778/3084 [00:12<00:01, 226.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|███████████▋ | 2779/3084 [00:12<00:01, 226.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|███████████▋ | 2780/3084 [00:12<00:01, 226.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|███████████▋ | 2781/3084 [00:12<00:01, 226.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|███████████▋ | 2782/3084 [00:12<00:01, 226.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|███████████▋ | 2783/3084 [00:12<00:01, 226.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|███████████▋ | 2784/3084 [00:12<00:01, 226.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|███████████▋ | 2785/3084 [00:12<00:01, 226.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|███████████▋ | 2786/3084 [00:12<00:01, 226.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|███████████▋ | 2787/3084 [00:12<00:01, 226.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|███████████▊ | 2788/3084 [00:12<00:01, 226.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|███████████▊ | 2789/3084 [00:12<00:01, 226.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|███████████▊ | 2790/3084 [00:12<00:01, 226.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|███████████▊ | 2791/3084 [00:12<00:01, 226.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  91%|███████████▊ | 2792/3084 [00:12<00:01, 226.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  91%|███████████▊ | 2793/3084 [00:12<00:01, 226.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  91%|███████████▊ | 2794/3084 [00:12<00:01, 226.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  91%|███████████▊ | 2795/3084 [00:12<00:01, 226.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  91%|███████████▊ | 2796/3084 [00:12<00:01, 226.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  91%|███████████▊ | 2797/3084 [00:12<00:01, 226.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  91%|███████████▊ | 2798/3084 [00:12<00:01, 226.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  91%|███████████▊ | 2799/3084 [00:12<00:01, 226.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  91%|███████████▊ | 2800/3084 [00:12<00:01, 226.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  91%|███████████▊ | 2801/3084 [00:12<00:01, 226.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  91%|███████████▊ | 2802/3084 [00:12<00:01, 226.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  91%|███████████▊ | 2803/3084 [00:12<00:01, 226.92it/s]\u001b[A\n",
      "Validation DataLoader 0:  91%|███████████▊ | 2804/3084 [00:12<00:01, 226.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  91%|███████████▊ | 2805/3084 [00:12<00:01, 226.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  91%|███████████▊ | 2806/3084 [00:12<00:01, 226.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  91%|███████████▊ | 2807/3084 [00:12<00:01, 226.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  91%|███████████▊ | 2808/3084 [00:12<00:01, 226.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  91%|███████████▊ | 2809/3084 [00:12<00:01, 226.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  91%|███████████▊ | 2810/3084 [00:12<00:01, 226.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  91%|███████████▊ | 2811/3084 [00:12<00:01, 226.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  91%|███████████▊ | 2812/3084 [00:12<00:01, 226.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  91%|███████████▊ | 2813/3084 [00:12<00:01, 226.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  91%|███████████▊ | 2814/3084 [00:12<00:01, 226.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  91%|███████████▊ | 2815/3084 [00:12<00:01, 226.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  91%|███████████▊ | 2816/3084 [00:12<00:01, 226.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  91%|███████████▊ | 2817/3084 [00:12<00:01, 226.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  91%|███████████▉ | 2818/3084 [00:12<00:01, 226.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  91%|███████████▉ | 2819/3084 [00:12<00:01, 226.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  91%|███████████▉ | 2820/3084 [00:12<00:01, 226.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  91%|███████████▉ | 2821/3084 [00:12<00:01, 226.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  92%|███████████▉ | 2822/3084 [00:12<00:01, 226.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  92%|███████████▉ | 2823/3084 [00:12<00:01, 226.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  92%|███████████▉ | 2824/3084 [00:12<00:01, 226.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  92%|███████████▉ | 2825/3084 [00:12<00:01, 226.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  92%|███████████▉ | 2826/3084 [00:12<00:01, 226.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  92%|███████████▉ | 2827/3084 [00:12<00:01, 226.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  92%|███████████▉ | 2828/3084 [00:12<00:01, 226.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  92%|███████████▉ | 2829/3084 [00:12<00:01, 226.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  92%|███████████▉ | 2830/3084 [00:12<00:01, 226.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  92%|███████████▉ | 2831/3084 [00:12<00:01, 226.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  92%|███████████▉ | 2832/3084 [00:12<00:01, 226.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  92%|███████████▉ | 2833/3084 [00:12<00:01, 226.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  92%|███████████▉ | 2834/3084 [00:12<00:01, 226.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  92%|███████████▉ | 2835/3084 [00:12<00:01, 226.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  92%|███████████▉ | 2836/3084 [00:12<00:01, 226.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  92%|███████████▉ | 2837/3084 [00:12<00:01, 226.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  92%|███████████▉ | 2838/3084 [00:12<00:01, 226.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  92%|███████████▉ | 2839/3084 [00:12<00:01, 226.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  92%|███████████▉ | 2840/3084 [00:12<00:01, 227.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  92%|███████████▉ | 2841/3084 [00:12<00:01, 227.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  92%|███████████▉ | 2842/3084 [00:12<00:01, 227.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  92%|███████████▉ | 2843/3084 [00:12<00:01, 227.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  92%|███████████▉ | 2844/3084 [00:12<00:01, 227.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  92%|███████████▉ | 2845/3084 [00:12<00:01, 227.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  92%|███████████▉ | 2846/3084 [00:12<00:01, 227.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  92%|████████████ | 2847/3084 [00:12<00:01, 227.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  92%|████████████ | 2848/3084 [00:12<00:01, 227.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  92%|████████████ | 2849/3084 [00:12<00:01, 227.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  92%|████████████ | 2850/3084 [00:12<00:01, 227.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  92%|████████████ | 2851/3084 [00:12<00:01, 227.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  92%|████████████ | 2852/3084 [00:12<00:01, 227.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  93%|████████████ | 2853/3084 [00:12<00:01, 227.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  93%|████████████ | 2854/3084 [00:12<00:01, 227.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  93%|████████████ | 2855/3084 [00:12<00:01, 227.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  93%|████████████ | 2856/3084 [00:12<00:01, 227.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  93%|████████████ | 2857/3084 [00:12<00:00, 227.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  93%|████████████ | 2858/3084 [00:12<00:00, 227.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  93%|████████████ | 2859/3084 [00:12<00:00, 227.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  93%|████████████ | 2860/3084 [00:12<00:00, 227.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  93%|████████████ | 2861/3084 [00:12<00:00, 227.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  93%|████████████ | 2862/3084 [00:12<00:00, 227.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  93%|████████████ | 2863/3084 [00:12<00:00, 227.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  93%|████████████ | 2864/3084 [00:12<00:00, 227.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  93%|████████████ | 2865/3084 [00:12<00:00, 227.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  93%|████████████ | 2866/3084 [00:12<00:00, 227.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  93%|████████████ | 2867/3084 [00:12<00:00, 227.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  93%|████████████ | 2868/3084 [00:12<00:00, 227.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  93%|████████████ | 2869/3084 [00:12<00:00, 227.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  93%|████████████ | 2870/3084 [00:12<00:00, 227.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  93%|████████████ | 2871/3084 [00:12<00:00, 227.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  93%|████████████ | 2872/3084 [00:12<00:00, 227.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  93%|████████████ | 2873/3084 [00:12<00:00, 227.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  93%|████████████ | 2874/3084 [00:12<00:00, 227.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  93%|████████████ | 2875/3084 [00:12<00:00, 227.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  93%|████████████ | 2876/3084 [00:12<00:00, 227.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  93%|████████████▏| 2877/3084 [00:12<00:00, 227.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  93%|████████████▏| 2878/3084 [00:12<00:00, 227.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  93%|████████████▏| 2879/3084 [00:12<00:00, 227.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  93%|████████████▏| 2880/3084 [00:12<00:00, 227.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  93%|████████████▏| 2881/3084 [00:12<00:00, 227.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  93%|████████████▏| 2882/3084 [00:12<00:00, 227.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  93%|████████████▏| 2883/3084 [00:12<00:00, 227.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  94%|████████████▏| 2884/3084 [00:12<00:00, 227.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  94%|████████████▏| 2885/3084 [00:12<00:00, 227.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  94%|████████████▏| 2886/3084 [00:12<00:00, 227.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  94%|████████████▏| 2887/3084 [00:12<00:00, 227.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  94%|████████████▏| 2888/3084 [00:12<00:00, 227.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  94%|████████████▏| 2889/3084 [00:12<00:00, 227.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  94%|████████████▏| 2890/3084 [00:12<00:00, 227.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  94%|████████████▏| 2891/3084 [00:12<00:00, 227.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  94%|████████████▏| 2892/3084 [00:12<00:00, 227.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  94%|████████████▏| 2893/3084 [00:12<00:00, 227.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  94%|████████████▏| 2894/3084 [00:12<00:00, 227.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  94%|████████████▏| 2895/3084 [00:12<00:00, 227.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  94%|████████████▏| 2896/3084 [00:12<00:00, 227.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  94%|████████████▏| 2897/3084 [00:12<00:00, 227.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  94%|████████████▏| 2898/3084 [00:12<00:00, 227.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  94%|████████████▏| 2899/3084 [00:12<00:00, 227.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  94%|████████████▏| 2900/3084 [00:12<00:00, 227.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  94%|████████████▏| 2901/3084 [00:12<00:00, 227.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  94%|████████████▏| 2902/3084 [00:12<00:00, 227.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  94%|████████████▏| 2903/3084 [00:12<00:00, 227.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  94%|████████████▏| 2904/3084 [00:12<00:00, 227.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  94%|████████████▏| 2905/3084 [00:12<00:00, 227.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  94%|████████████▏| 2906/3084 [00:12<00:00, 227.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  94%|████████████▎| 2907/3084 [00:12<00:00, 227.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  94%|████████████▎| 2908/3084 [00:12<00:00, 227.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  94%|████████████▎| 2909/3084 [00:12<00:00, 227.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  94%|████████████▎| 2910/3084 [00:12<00:00, 227.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  94%|████████████▎| 2911/3084 [00:12<00:00, 227.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  94%|████████████▎| 2912/3084 [00:12<00:00, 227.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  94%|████████████▎| 2913/3084 [00:12<00:00, 227.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  94%|████████████▎| 2914/3084 [00:12<00:00, 227.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|████████████▎| 2915/3084 [00:12<00:00, 227.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|████████████▎| 2916/3084 [00:12<00:00, 227.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|████████████▎| 2917/3084 [00:12<00:00, 227.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|████████████▎| 2918/3084 [00:12<00:00, 227.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|████████████▎| 2919/3084 [00:12<00:00, 227.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|████████████▎| 2920/3084 [00:12<00:00, 227.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|████████████▎| 2921/3084 [00:12<00:00, 227.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|████████████▎| 2922/3084 [00:12<00:00, 227.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|████████████▎| 2923/3084 [00:12<00:00, 227.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|████████████▎| 2924/3084 [00:12<00:00, 227.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|████████████▎| 2925/3084 [00:12<00:00, 227.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|████████████▎| 2926/3084 [00:12<00:00, 227.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|████████████▎| 2927/3084 [00:12<00:00, 227.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|████████████▎| 2928/3084 [00:12<00:00, 227.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|████████████▎| 2929/3084 [00:12<00:00, 227.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|████████████▎| 2930/3084 [00:12<00:00, 227.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|████████████▎| 2931/3084 [00:12<00:00, 227.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|████████████▎| 2932/3084 [00:12<00:00, 227.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|████████████▎| 2933/3084 [00:12<00:00, 227.07it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|████████████▎| 2934/3084 [00:12<00:00, 227.07it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|████████████▎| 2935/3084 [00:12<00:00, 227.07it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|████████████▍| 2936/3084 [00:12<00:00, 227.07it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|████████████▍| 2937/3084 [00:12<00:00, 227.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|████████████▍| 2938/3084 [00:12<00:00, 227.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|████████████▍| 2939/3084 [00:12<00:00, 226.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|████████████▍| 2940/3084 [00:12<00:00, 226.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|████████████▍| 2941/3084 [00:12<00:00, 226.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|████████████▍| 2942/3084 [00:12<00:00, 226.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|████████████▍| 2943/3084 [00:12<00:00, 226.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|████████████▍| 2944/3084 [00:12<00:00, 226.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  95%|████████████▍| 2945/3084 [00:12<00:00, 226.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  96%|████████████▍| 2946/3084 [00:12<00:00, 227.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  96%|████████████▍| 2947/3084 [00:12<00:00, 227.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  96%|████████████▍| 2948/3084 [00:12<00:00, 227.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  96%|████████████▍| 2949/3084 [00:12<00:00, 227.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  96%|████████████▍| 2950/3084 [00:12<00:00, 227.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  96%|████████████▍| 2951/3084 [00:13<00:00, 227.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  96%|████████████▍| 2952/3084 [00:13<00:00, 227.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  96%|████████████▍| 2953/3084 [00:13<00:00, 227.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  96%|████████████▍| 2954/3084 [00:13<00:00, 227.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  96%|████████████▍| 2955/3084 [00:13<00:00, 227.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  96%|████████████▍| 2956/3084 [00:13<00:00, 227.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  96%|████████████▍| 2957/3084 [00:13<00:00, 227.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  96%|████████████▍| 2958/3084 [00:13<00:00, 227.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  96%|████████████▍| 2959/3084 [00:13<00:00, 227.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  96%|████████████▍| 2960/3084 [00:13<00:00, 227.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  96%|████████████▍| 2961/3084 [00:13<00:00, 227.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  96%|████████████▍| 2962/3084 [00:13<00:00, 227.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  96%|████████████▍| 2963/3084 [00:13<00:00, 227.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  96%|████████████▍| 2964/3084 [00:13<00:00, 227.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  96%|████████████▍| 2965/3084 [00:13<00:00, 227.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  96%|████████████▌| 2966/3084 [00:13<00:00, 227.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  96%|████████████▌| 2967/3084 [00:13<00:00, 227.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  96%|████████████▌| 2968/3084 [00:13<00:00, 226.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  96%|████████████▌| 2969/3084 [00:13<00:00, 226.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  96%|████████████▌| 2970/3084 [00:13<00:00, 226.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  96%|████████████▌| 2971/3084 [00:13<00:00, 226.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  96%|████████████▌| 2972/3084 [00:13<00:00, 226.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  96%|████████████▌| 2973/3084 [00:13<00:00, 226.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  96%|████████████▌| 2974/3084 [00:13<00:00, 226.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  96%|████████████▌| 2975/3084 [00:13<00:00, 226.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  96%|████████████▌| 2976/3084 [00:13<00:00, 226.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  97%|████████████▌| 2977/3084 [00:13<00:00, 226.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  97%|████████████▌| 2978/3084 [00:13<00:00, 226.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  97%|████████████▌| 2979/3084 [00:13<00:00, 226.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  97%|████████████▌| 2980/3084 [00:13<00:00, 226.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  97%|████████████▌| 2981/3084 [00:13<00:00, 226.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  97%|████████████▌| 2982/3084 [00:13<00:00, 226.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  97%|████████████▌| 2983/3084 [00:13<00:00, 226.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  97%|████████████▌| 2984/3084 [00:13<00:00, 226.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  97%|████████████▌| 2985/3084 [00:13<00:00, 226.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  97%|████████████▌| 2986/3084 [00:13<00:00, 226.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  97%|████████████▌| 2987/3084 [00:13<00:00, 226.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  97%|████████████▌| 2988/3084 [00:13<00:00, 226.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  97%|████████████▌| 2989/3084 [00:13<00:00, 226.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  97%|████████████▌| 2990/3084 [00:13<00:00, 226.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  97%|████████████▌| 2991/3084 [00:13<00:00, 226.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  97%|████████████▌| 2992/3084 [00:13<00:00, 226.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  97%|████████████▌| 2993/3084 [00:13<00:00, 226.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  97%|████████████▌| 2994/3084 [00:13<00:00, 226.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  97%|████████████▌| 2995/3084 [00:13<00:00, 226.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  97%|████████████▋| 2996/3084 [00:13<00:00, 226.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  97%|████████████▋| 2997/3084 [00:13<00:00, 226.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  97%|████████████▋| 2998/3084 [00:13<00:00, 226.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  97%|████████████▋| 2999/3084 [00:13<00:00, 226.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  97%|████████████▋| 3000/3084 [00:13<00:00, 226.97it/s]\u001b[A\n",
      "Validation DataLoader 0:  97%|████████████▋| 3001/3084 [00:13<00:00, 226.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  97%|████████████▋| 3002/3084 [00:13<00:00, 226.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  97%|████████████▋| 3003/3084 [00:13<00:00, 226.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  97%|████████████▋| 3004/3084 [00:13<00:00, 226.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  97%|████████████▋| 3005/3084 [00:13<00:00, 226.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  97%|████████████▋| 3006/3084 [00:13<00:00, 226.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  98%|████████████▋| 3007/3084 [00:13<00:00, 226.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  98%|████████████▋| 3008/3084 [00:13<00:00, 226.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  98%|████████████▋| 3009/3084 [00:13<00:00, 227.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  98%|████████████▋| 3010/3084 [00:13<00:00, 227.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  98%|████████████▋| 3011/3084 [00:13<00:00, 227.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  98%|████████████▋| 3012/3084 [00:13<00:00, 227.00it/s]\u001b[A\n",
      "Validation DataLoader 0:  98%|████████████▋| 3013/3084 [00:13<00:00, 227.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  98%|████████████▋| 3014/3084 [00:13<00:00, 227.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  98%|████████████▋| 3015/3084 [00:13<00:00, 227.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  98%|████████████▋| 3016/3084 [00:13<00:00, 227.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  98%|████████████▋| 3017/3084 [00:13<00:00, 227.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  98%|████████████▋| 3018/3084 [00:13<00:00, 227.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  98%|████████████▋| 3019/3084 [00:13<00:00, 227.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  98%|████████████▋| 3020/3084 [00:13<00:00, 227.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  98%|████████████▋| 3021/3084 [00:13<00:00, 227.02it/s]\u001b[A\n",
      "Validation DataLoader 0:  98%|████████████▋| 3022/3084 [00:13<00:00, 227.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  98%|████████████▋| 3023/3084 [00:13<00:00, 227.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  98%|████████████▋| 3024/3084 [00:13<00:00, 227.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  98%|████████████▊| 3025/3084 [00:13<00:00, 227.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  98%|████████████▊| 3026/3084 [00:13<00:00, 227.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  98%|████████████▊| 3027/3084 [00:13<00:00, 227.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  98%|████████████▊| 3028/3084 [00:13<00:00, 227.05it/s]\u001b[A\n",
      "Validation DataLoader 0:  98%|████████████▊| 3029/3084 [00:13<00:00, 227.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  98%|████████████▊| 3030/3084 [00:13<00:00, 227.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  98%|████████████▊| 3031/3084 [00:13<00:00, 227.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  98%|████████████▊| 3032/3084 [00:13<00:00, 227.07it/s]\u001b[A\n",
      "Validation DataLoader 0:  98%|████████████▊| 3033/3084 [00:13<00:00, 227.07it/s]\u001b[A\n",
      "Validation DataLoader 0:  98%|████████████▊| 3034/3084 [00:13<00:00, 227.08it/s]\u001b[A\n",
      "Validation DataLoader 0:  98%|████████████▊| 3035/3084 [00:13<00:00, 227.08it/s]\u001b[A\n",
      "Validation DataLoader 0:  98%|████████████▊| 3036/3084 [00:13<00:00, 227.08it/s]\u001b[A\n",
      "Validation DataLoader 0:  98%|████████████▊| 3037/3084 [00:13<00:00, 227.09it/s]\u001b[A\n",
      "Validation DataLoader 0:  99%|████████████▊| 3038/3084 [00:13<00:00, 227.09it/s]\u001b[A\n",
      "Validation DataLoader 0:  99%|████████████▊| 3039/3084 [00:13<00:00, 227.09it/s]\u001b[A\n",
      "Validation DataLoader 0:  99%|████████████▊| 3040/3084 [00:13<00:00, 227.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  99%|████████████▊| 3041/3084 [00:13<00:00, 227.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  99%|████████████▊| 3042/3084 [00:13<00:00, 227.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  99%|████████████▊| 3043/3084 [00:13<00:00, 227.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  99%|████████████▊| 3044/3084 [00:13<00:00, 227.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  99%|████████████▊| 3045/3084 [00:13<00:00, 227.12it/s]\u001b[A\n",
      "Validation DataLoader 0:  99%|████████████▊| 3046/3084 [00:13<00:00, 227.12it/s]\u001b[A\n",
      "Validation DataLoader 0:  99%|████████████▊| 3047/3084 [00:13<00:00, 227.12it/s]\u001b[A\n",
      "Validation DataLoader 0:  99%|████████████▊| 3048/3084 [00:13<00:00, 227.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  99%|████████████▊| 3049/3084 [00:13<00:00, 227.13it/s]\u001b[A\n",
      "Validation DataLoader 0:  99%|████████████▊| 3050/3084 [00:13<00:00, 227.14it/s]\u001b[A\n",
      "Validation DataLoader 0:  99%|████████████▊| 3051/3084 [00:13<00:00, 227.14it/s]\u001b[A\n",
      "Validation DataLoader 0:  99%|████████████▊| 3052/3084 [00:13<00:00, 227.14it/s]\u001b[A\n",
      "Validation DataLoader 0:  99%|████████████▊| 3053/3084 [00:13<00:00, 227.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  99%|████████████▊| 3054/3084 [00:13<00:00, 227.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  99%|████████████▉| 3055/3084 [00:13<00:00, 227.16it/s]\u001b[A\n",
      "Validation DataLoader 0:  99%|████████████▉| 3056/3084 [00:13<00:00, 227.16it/s]\u001b[A\n",
      "Validation DataLoader 0:  99%|████████████▉| 3057/3084 [00:13<00:00, 227.16it/s]\u001b[A\n",
      "Validation DataLoader 0:  99%|████████████▉| 3058/3084 [00:13<00:00, 227.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  99%|████████████▉| 3059/3084 [00:13<00:00, 227.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  99%|████████████▉| 3060/3084 [00:13<00:00, 227.18it/s]\u001b[A\n",
      "Validation DataLoader 0:  99%|████████████▉| 3061/3084 [00:13<00:00, 227.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  99%|████████████▉| 3062/3084 [00:13<00:00, 227.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  99%|████████████▉| 3063/3084 [00:13<00:00, 227.20it/s]\u001b[A\n",
      "Validation DataLoader 0:  99%|████████████▉| 3064/3084 [00:13<00:00, 227.20it/s]\u001b[A\n",
      "Validation DataLoader 0:  99%|████████████▉| 3065/3084 [00:13<00:00, 227.20it/s]\u001b[A\n",
      "Validation DataLoader 0:  99%|████████████▉| 3066/3084 [00:13<00:00, 227.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  99%|████████████▉| 3067/3084 [00:13<00:00, 227.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  99%|████████████▉| 3068/3084 [00:13<00:00, 227.22it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████▉| 3069/3084 [00:13<00:00, 227.22it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████▉| 3070/3084 [00:13<00:00, 227.23it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████▉| 3071/3084 [00:13<00:00, 227.23it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████▉| 3072/3084 [00:13<00:00, 227.23it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████▉| 3073/3084 [00:13<00:00, 227.24it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████▉| 3074/3084 [00:13<00:00, 227.24it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████▉| 3075/3084 [00:13<00:00, 227.24it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████▉| 3076/3084 [00:13<00:00, 227.25it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████▉| 3077/3084 [00:13<00:00, 227.25it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████▉| 3078/3084 [00:13<00:00, 227.26it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████▉| 3079/3084 [00:13<00:00, 227.26it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████▉| 3080/3084 [00:13<00:00, 227.27it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████▉| 3081/3084 [00:13<00:00, 227.27it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████▉| 3082/3084 [00:13<00:00, 227.27it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|████████████▉| 3083/3084 [00:13<00:00, 227.28it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|█████████████| 3084/3084 [00:13<00:00, 227.28it/s]\u001b[A\n",
      "Epoch 1:  84%|▊| 2593/3084 [00:25<00:04, 101.45it/s, v_num=3, train_acc_step=0.7^CA\n",
      "/opt/conda/envs/mase/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mFine Tuning Complete\u001b[0m\n",
      "I0318 12:29:01.091728 139887962613568 fine_tune.py:121] Fine Tuning Complete\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mQuantized graph histogram:\u001b[0m\n",
      "I0318 12:29:01.113227 139887962613568 summary.py:84] Quantized graph histogram:\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "| Original type   | OP           |   Total |   Changed |   Unchanged |\n",
      "|-----------------+--------------+---------+-----------+-------------|\n",
      "| BatchNorm1d     | batch_norm1d |       4 |         0 |           4 |\n",
      "| Linear          | linear       |       3 |         3 |           0 |\n",
      "| ReLU            | relu         |       4 |         0 |           4 |\n",
      "| output          | output       |       1 |         0 |           1 |\n",
      "| x               | placeholder  |       1 |         0 |           1 |\u001b[0m\n",
      "I0318 12:29:01.114112 139887962613568 summary.py:85] \n",
      "| Original type   | OP           |   Total |   Changed |   Unchanged |\n",
      "|-----------------+--------------+---------+-----------+-------------|\n",
      "| BatchNorm1d     | batch_norm1d |       4 |         0 |           4 |\n",
      "| Linear          | linear       |       3 |         3 |           0 |\n",
      "| ReLU            | relu         |       4 |         0 |           4 |\n",
      "| output          | output       |       1 |         0 |           1 |\n",
      "| x               | placeholder  |       1 |         0 |           1 |\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "I0318 12:29:01.117386 139887962613568 quantize.py:129] Converting PyTorch model to ONNX...\n"
     ]
    }
   ],
   "source": [
    "!ch transform --config ../../../machop/configs/tensorrt/jsc_toy_INT8_quantization_by_type.toml --load {JSC_CHECKPOINT_PATH} --load-type pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, `FP16` acheives a slighty higher test accuracy and a slightly lower latency (~10%) from that of INT8 quantization as expected. Now lets try a more complicated model - `vgg7`.\n",
    "\n",
    "## Section 3. Type-wise Mixed Precision on Larger Model\n",
    "We will now quantize `vgg7` which includes both convolutional and linear layers, however for this demonstration we want to quantize all layer types except the linear layers.\n",
    "\n",
    "In this case, we set:\n",
    "\n",
    "- The `by` parameter to `type`\n",
    "- The `quantize` parameter to true for `passes.tensorrt_quantize.conv2d.config` and `precision` parameter to 'INT8'.\n",
    "- The `input` and `weight` quantize axis for the conv2d layers.\n",
    "- The default `passes.tensorrt_quantize.default.config` to false. \n",
    "\n",
    "During the TensorRT quantization, the model's conv2d layers will be converted to an INT8 fake quantized form, whilst the linear layers are kept to their default 'FP16'. Calibration of the conv2d layers will be undergone and fine tuning.  \n",
    "\n",
    "You may either download a pretrained model [here](https://imperiallondon-my.sharepoint.com/:f:/g/personal/zz7522_ic_ac_uk/Emh3VT7Q_qRFmnp8kDrcgDoBwGUuzLwwKNtX8ZAt368jJQ?e=gsKONa), otherwise train it yourself as shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ch train --config ../../../machop/configs/tensorrt/vgg7_FP16_quantization_by_type.toml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now load the checkpoint in and quantize the model and compare it to the unquantized version as we did in [Section 1.5](#section-15-performance-analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG_CHECKPOINT_PATH = \"../../../mase_output/vgg7-pre-trained/test-accu-0.9332.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: ch: command not found\n"
     ]
    }
   ],
   "source": [
    "!ch transform --config ../../../machop/configs/tensorrt/vgg7_INT8_quantization_by_type.toml --load {VGG_CHECKPOINT_PATH} --load-type pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 4. Layer-wise Mixed Precision\n",
    "\n",
    "So far we have strictly quantized either in INT8 or FP16. Now, we will show how to conduct layerwise mixed precision using the same `vgg7` model. In this case we will show how for instance, layer 0 and 1 can be set to FP16, while layer 2 and 3 can be INT8 quantized. \n",
    "\n",
    "For this, we set:\n",
    "- The `by` parameter to `name`\n",
    "- The `precision` to 'FP16' for `passes.tensorrt_quantize.feature_layers_0.config and passes.tensorrt_quantize.feature_layers_1.config`\n",
    "- The `precision` to 'INT8' for `passes.tensorrt_quantize.feature_layers_0.config and passes.tensorrt_quantize.feature_layers_1.config`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/mase/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-18 11:38:55,375] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mSet logging level to info\u001b[0m\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0318 11:38:56.826868 139779632510784 logger.py:44] Set logging level to info\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import toml\n",
    "from copy import copy, deepcopy\n",
    "\n",
    "# Figure out the correct path\n",
    "machop_path = Path(\".\").resolve().parent.parent.parent /\"machop\"\n",
    "assert machop_path.exists(), \"Failed to find machop at: {}\".format(machop_path)\n",
    "sys.path.append(str(machop_path))\n",
    "\n",
    "# Add directory to the PATH so that chop can be called\n",
    "new_path = \"../../../machop\"\n",
    "full_path = os.path.abspath(new_path)\n",
    "os.environ['PATH'] += os.pathsep + full_path\n",
    "\n",
    "from chop.tools.utils import to_numpy_if_tensor\n",
    "from chop.tools.logger import set_logging_verbosity\n",
    "from chop.tools import get_cf_args, get_dummy_input\n",
    "from chop.passes.graph.utils import deepcopy_mase_graph\n",
    "from chop.tools.get_input import InputGenerator\n",
    "from chop.tools.checkpoint_load import load_model\n",
    "from chop.ir import MaseGraph\n",
    "from chop.models import get_model_info, get_model, get_tokenizer\n",
    "from chop.dataset import MaseDataModule, get_dataset_info\n",
    "from chop.passes.graph.transforms import metadata_value_type_cast_transform_pass\n",
    "from chop.passes.graph import (\n",
    "    summarize_quantization_analysis_pass,\n",
    "    add_common_metadata_analysis_pass,\n",
    "    init_metadata_analysis_pass,\n",
    "    add_software_metadata_analysis_pass,\n",
    "    tensorrt_calibrate_transform_pass,\n",
    "    tensorrt_fake_quantize_transform_pass,\n",
    "    tensorrt_fine_tune_transform_pass,\n",
    "    tensorrt_engine_interface_pass,\n",
    "    tensorrt_analysis_pass,\n",
    "    )\n",
    "\n",
    "set_logging_verbosity(\"info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Path to your TOML file\n",
    "toml_file_path = '../../../machop/configs/tensorrt/vgg7_layerwise_mixed_precision.toml'\n",
    "\n",
    "# Reading TOML file and converting it into a Python dictionary\n",
    "with open(toml_file_path, 'r') as toml_file:\n",
    "    pass_args = toml.load(toml_file)\n",
    "\n",
    "# Extract the 'passes.tensorrt_quantize' section and its children\n",
    "tensorrt_quantize_config = pass_args.get('passes', {}).get('tensorrt_quantize', {})\n",
    "# Extract the 'passes.tensorrt_analysis' section and its children\n",
    "tensorrt_analysis_config = pass_args.get('passes', {}).get('tensorrt_analysis', {})\n",
    "\n",
    "# Load the basics in\n",
    "model_name = pass_args['model']\n",
    "dataset_name = pass_args['dataset']\n",
    "max_epochs = pass_args['max_epochs']\n",
    "batch_size = pass_args['batch_size']\n",
    "learning_rate = pass_args['learning_rate']\n",
    "accelerator = pass_args['accelerator']\n",
    "\n",
    "data_module = MaseDataModule(\n",
    "    name=dataset_name,\n",
    "    batch_size=batch_size,\n",
    "    model_name=model_name,\n",
    "    num_workers=0,\n",
    ")\n",
    "data_module.prepare_data()\n",
    "data_module.setup()\n",
    "\n",
    "# Add the data_module and other necessary information to the configs\n",
    "configs = [tensorrt_quantize_config, tensorrt_analysis_config]\n",
    "for config in configs:\n",
    "    config['task'] = pass_args['task']\n",
    "    config['batch_size'] = pass_args['batch_size']\n",
    "    config['model'] = pass_args['model']\n",
    "    config['data_module'] = data_module\n",
    "    config['accelerator'] = 'cuda' if pass_args['accelerator'] == 'gpu' else pass_args['accelerator']\n",
    "    if config['accelerator'] == 'gpu':\n",
    "        os.environ['CUDA_MODULE_LOADING'] = 'LAZY'\n",
    "\n",
    "model_info = get_model_info(model_name)\n",
    "model = get_model(\n",
    "    model_name,\n",
    "    task=\"cls\",\n",
    "    dataset_info=data_module.dataset_info,\n",
    "    pretrained=False)\n",
    "\n",
    "\n",
    "input_generator = InputGenerator(\n",
    "    data_module=data_module,\n",
    "    model_info=model_info,\n",
    "    task=\"cls\",\n",
    "    which_dataloader=\"train\",\n",
    ")\n",
    "\n",
    "# generate the mase graph and initialize node metadata\n",
    "mg = MaseGraph(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from ../../../mase_output/vgg7-pre-trained/test-accu-0.9332.ckpt\u001b[0m\n",
      "I0318 11:23:31.613022 140342552557376 checkpoint_load.py:85] Loaded pytorch lightning checkpoint from ../../../mase_output/vgg7-pre-trained/test-accu-0.9332.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Load in the trained checkpoint - change this accordingly\n",
    "VGG_CHECKPOINT_PATH = \"../../../mase_output/vgg7-pre-trained/test-accu-0.9332.ckpt\"\n",
    "\n",
    "model = load_model(load_name=VGG_CHECKPOINT_PATH, load_type=\"pl\", model=model)\n",
    "\n",
    "# Initiate metadata\n",
    "dummy_in = next(iter(input_generator))\n",
    "_ = model(**dummy_in)\n",
    "mg, _ = init_metadata_analysis_pass(mg, None)\n",
    "\n",
    "mg_original = deepcopy_mase_graph(mg)\n",
    "\n",
    "mg, _ = add_common_metadata_analysis_pass(mg, {\"dummy_in\": dummy_in})\n",
    "mg, _ = add_software_metadata_analysis_pass(mg, None)\n",
    "mg, _ = metadata_value_type_cast_transform_pass(mg, pass_args={\"fn\": to_numpy_if_tensor})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis\u001b[0m\n",
      "I0318 09:55:37.107798 140195009255232 analysis.py:214] Starting transformation analysis\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results vgg7:\n",
      "+------------------------------+-------------+\n",
      "|            Metric            |    Value    |\n",
      "+------------------------------+-------------+\n",
      "|    Average Test Accuracy     |   0.91967   |\n",
      "|      Average Precision       |   0.92315   |\n",
      "|        Average Recall        |   0.92362   |\n",
      "|       Average F1 Score       |   0.92326   |\n",
      "|         Average Loss         |   0.23674   |\n",
      "|       Average Latency        |  28.123 ms  |\n",
      "|   Average GPU Power Usage    |  100.17 W   |\n",
      "| Inference Energy Consumption | 0.78256 mWh |\n",
      "+------------------------------+-------------+\u001b[0m\n",
      "I0318 09:55:40.969246 140195009255232 analysis.py:330] \n",
      "Results vgg7:\n",
      "+------------------------------+-------------+\n",
      "|            Metric            |    Value    |\n",
      "+------------------------------+-------------+\n",
      "|    Average Test Accuracy     |   0.91967   |\n",
      "|      Average Precision       |   0.92315   |\n",
      "|        Average Recall        |   0.92362   |\n",
      "|       Average F1 Score       |   0.92326   |\n",
      "|         Average Loss         |   0.23674   |\n",
      "|       Average Latency        |  28.123 ms  |\n",
      "|   Average GPU Power Usage    |  100.17 W   |\n",
      "| Inference Energy Consumption | 0.78256 mWh |\n",
      "+------------------------------+-------------+\n"
     ]
    }
   ],
   "source": [
    "_, _ = tensorrt_analysis_pass(mg, pass_args=tensorrt_analysis_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mApplying fake quantization to PyTorch model...\u001b[0m\n",
      "I0318 11:28:17.732462 140342552557376 utils.py:199] Applying fake quantization to PyTorch model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mFake quantization applied to PyTorch model.\u001b[0m\n",
      "I0318 11:28:18.571809 140342552557376 utils.py:224] Fake quantization applied to PyTorch model.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting calibration of the model in PyTorch...\u001b[0m\n",
      "I0318 11:28:18.574708 140342552557376 calibrate.py:91] Starting calibration of the model in PyTorch...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "I0318 11:28:18.593663 140342552557376 calibrate.py:100] Disabling Quantization and Enabling Calibration\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "I0318 11:28:18.595410 140342552557376 calibrate.py:100] Disabling Quantization and Enabling Calibration\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "I0318 11:28:18.596705 140342552557376 calibrate.py:100] Disabling Quantization and Enabling Calibration\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "I0318 11:28:18.597985 140342552557376 calibrate.py:100] Disabling Quantization and Enabling Calibration\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "I0318 11:28:18.599245 140342552557376 calibrate.py:100] Disabling Quantization and Enabling Calibration\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "I0318 11:28:18.600471 140342552557376 calibrate.py:100] Disabling Quantization and Enabling Calibration\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "I0318 11:28:18.601733 140342552557376 calibrate.py:100] Disabling Quantization and Enabling Calibration\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "I0318 11:28:18.602964 140342552557376 calibrate.py:100] Disabling Quantization and Enabling Calibration\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "I0318 11:28:18.605333 140342552557376 calibrate.py:100] Disabling Quantization and Enabling Calibration\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "I0318 11:28:18.606415 140342552557376 calibrate.py:100] Disabling Quantization and Enabling Calibration\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "I0318 11:28:18.607586 140342552557376 calibrate.py:100] Disabling Quantization and Enabling Calibration\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "I0318 11:28:18.608670 140342552557376 calibrate.py:100] Disabling Quantization and Enabling Calibration\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "I0318 11:28:18.609715 140342552557376 calibrate.py:100] Disabling Quantization and Enabling Calibration\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "I0318 11:28:18.610790 140342552557376 calibrate.py:100] Disabling Quantization and Enabling Calibration\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "I0318 11:28:18.611837 140342552557376 calibrate.py:100] Disabling Quantization and Enabling Calibration\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "I0318 11:28:18.612829 140342552557376 calibrate.py:100] Disabling Quantization and Enabling Calibration\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "I0318 11:28:21.197682 140342552557376 calibrate.py:121] Enabling Quantization and Disabling Calibration\n",
      "W0318 11:28:21.199681 140342552557376 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "I0318 11:28:21.200521 140342552557376 calibrate.py:121] Enabling Quantization and Disabling Calibration\n",
      "W0318 11:28:21.201774 140342552557376 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "I0318 11:28:21.202453 140342552557376 calibrate.py:121] Enabling Quantization and Disabling Calibration\n",
      "W0318 11:28:21.203719 140342552557376 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "I0318 11:28:21.204330 140342552557376 calibrate.py:121] Enabling Quantization and Disabling Calibration\n",
      "W0318 11:28:21.205599 140342552557376 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "I0318 11:28:21.206325 140342552557376 calibrate.py:121] Enabling Quantization and Disabling Calibration\n",
      "W0318 11:28:21.207642 140342552557376 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "I0318 11:28:21.208199 140342552557376 calibrate.py:121] Enabling Quantization and Disabling Calibration\n",
      "W0318 11:28:21.209242 140342552557376 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "I0318 11:28:21.209810 140342552557376 calibrate.py:121] Enabling Quantization and Disabling Calibration\n",
      "W0318 11:28:21.210819 140342552557376 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "I0318 11:28:21.211365 140342552557376 calibrate.py:121] Enabling Quantization and Disabling Calibration\n",
      "W0318 11:28:21.212429 140342552557376 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "I0318 11:28:21.212999 140342552557376 calibrate.py:121] Enabling Quantization and Disabling Calibration\n",
      "W0318 11:28:21.214085 140342552557376 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "I0318 11:28:21.214655 140342552557376 calibrate.py:121] Enabling Quantization and Disabling Calibration\n",
      "W0318 11:28:21.215662 140342552557376 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "I0318 11:28:21.216244 140342552557376 calibrate.py:121] Enabling Quantization and Disabling Calibration\n",
      "W0318 11:28:21.217268 140342552557376 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "I0318 11:28:21.217990 140342552557376 calibrate.py:121] Enabling Quantization and Disabling Calibration\n",
      "W0318 11:28:21.219000 140342552557376 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "I0318 11:28:21.219562 140342552557376 calibrate.py:121] Enabling Quantization and Disabling Calibration\n",
      "W0318 11:28:21.220567 140342552557376 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "I0318 11:28:21.221132 140342552557376 calibrate.py:121] Enabling Quantization and Disabling Calibration\n",
      "W0318 11:28:21.222173 140342552557376 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "I0318 11:28:21.222737 140342552557376 calibrate.py:121] Enabling Quantization and Disabling Calibration\n",
      "W0318 11:28:21.223725 140342552557376 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "I0318 11:28:21.224255 140342552557376 calibrate.py:121] Enabling Quantization and Disabling Calibration\n",
      "W0318 11:28:21.225344 140342552557376 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "W0318 11:28:21.243050 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0318 11:28:21.243606 140342552557376 tensor_quantizer.py:239] Call .cuda() if running on GPU after loading calibrated amax.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.3._input_quantizer       : TensorQuantizer(8bit fake per-tensor amax=3.3064 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:21.244405 140342552557376 calibrate.py:79] feature_layers.3._input_quantizer       : TensorQuantizer(8bit fake per-tensor amax=3.3064 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:21.246361 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.3._weight_quantizer      : TensorQuantizer(8bit fake per-tensor amax=0.2366 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:21.247056 140342552557376 calibrate.py:79] feature_layers.3._weight_quantizer      : TensorQuantizer(8bit fake per-tensor amax=0.2366 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:21.248930 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.7._input_quantizer       : TensorQuantizer(8bit fake per-tensor amax=1.8229 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:21.249636 140342552557376 calibrate.py:79] feature_layers.7._input_quantizer       : TensorQuantizer(8bit fake per-tensor amax=1.8229 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:21.251572 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.7._weight_quantizer      : TensorQuantizer(8bit fake per-tensor amax=0.2296 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:21.252292 140342552557376 calibrate.py:79] feature_layers.7._weight_quantizer      : TensorQuantizer(8bit fake per-tensor amax=0.2296 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:21.253920 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.10._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=1.4558 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:21.254510 140342552557376 calibrate.py:79] feature_layers.10._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=1.4558 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:21.256041 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.10._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.2080 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:21.256649 140342552557376 calibrate.py:79] feature_layers.10._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.2080 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:21.258250 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.14._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=1.9219 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:21.258848 140342552557376 calibrate.py:79] feature_layers.14._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=1.9219 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:21.260337 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.14._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.2013 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:21.260950 140342552557376 calibrate.py:79] feature_layers.14._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.2013 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:21.262467 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.17._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=1.6114 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:21.263044 140342552557376 calibrate.py:79] feature_layers.17._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=1.6114 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:21.264503 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.17._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.1879 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:21.265105 140342552557376 calibrate.py:79] feature_layers.17._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.1879 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:21.266860 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mclassifier.0._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=2.3207 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:21.267887 140342552557376 calibrate.py:79] classifier.0._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=2.3207 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:21.269870 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mclassifier.0._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.0907 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:21.270471 140342552557376 calibrate.py:79] classifier.0._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.0907 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:21.271997 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mclassifier.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=9.7149 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:21.272617 140342552557376 calibrate.py:79] classifier.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=9.7149 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:21.274109 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mclassifier.2._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.0590 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:21.274774 140342552557376 calibrate.py:79] classifier.2._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.0590 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:21.276411 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlast_layer._input_quantizer             : TensorQuantizer(8bit fake per-tensor amax=7.4151 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:21.277001 140342552557376 calibrate.py:79] last_layer._input_quantizer             : TensorQuantizer(8bit fake per-tensor amax=7.4151 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:21.278594 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlast_layer._weight_quantizer            : TensorQuantizer(8bit fake per-tensor amax=0.1019 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:21.279222 140342552557376 calibrate.py:79] last_layer._weight_quantizer            : TensorQuantizer(8bit fake per-tensor amax=0.1019 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPerforming post calibration analysis for calibrator percentile_99.0...\u001b[0m\n",
      "I0318 11:28:21.282034 140342552557376 calibrate.py:53] Performing post calibration analysis for calibrator percentile_99.0...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis\u001b[0m\n",
      "I0318 11:28:21.283648 140342552557376 analysis.py:214] Starting transformation analysis\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results vgg7:\n",
      "+------------------------------+------------+\n",
      "|            Metric            |   Value    |\n",
      "+------------------------------+------------+\n",
      "|    Average Test Accuracy     |  0.86901   |\n",
      "|      Average Precision       |  0.87585   |\n",
      "|        Average Recall        |  0.87477   |\n",
      "|       Average F1 Score       |  0.87472   |\n",
      "|         Average Loss         |   0.6701   |\n",
      "|       Average Latency        | 39.118 ms  |\n",
      "|   Average GPU Power Usage    |  96.331 W  |\n",
      "| Inference Energy Consumption | 1.0467 mWh |\n",
      "+------------------------------+------------+\u001b[0m\n",
      "I0318 11:28:25.935484 140342552557376 analysis.py:330] \n",
      "Results vgg7:\n",
      "+------------------------------+------------+\n",
      "|            Metric            |   Value    |\n",
      "+------------------------------+------------+\n",
      "|    Average Test Accuracy     |  0.86901   |\n",
      "|      Average Precision       |  0.87585   |\n",
      "|        Average Recall        |  0.87477   |\n",
      "|       Average F1 Score       |  0.87472   |\n",
      "|         Average Loss         |   0.6701   |\n",
      "|       Average Latency        | 39.118 ms  |\n",
      "|   Average GPU Power Usage    |  96.331 W  |\n",
      "| Inference Energy Consumption | 1.0467 mWh |\n",
      "+------------------------------+------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPost calibration analysis complete.\u001b[0m\n",
      "I0318 11:28:25.938501 140342552557376 calibrate.py:66] Post calibration analysis complete.\n",
      "W0318 11:28:25.940452 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.3._input_quantizer       : TensorQuantizer(8bit fake per-tensor amax=6.0252 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:25.941426 140342552557376 calibrate.py:79] feature_layers.3._input_quantizer       : TensorQuantizer(8bit fake per-tensor amax=6.0252 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:25.943193 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.3._weight_quantizer      : TensorQuantizer(8bit fake per-tensor amax=0.3704 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:25.943901 140342552557376 calibrate.py:79] feature_layers.3._weight_quantizer      : TensorQuantizer(8bit fake per-tensor amax=0.3704 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:25.945704 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.7._input_quantizer       : TensorQuantizer(8bit fake per-tensor amax=3.3006 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:25.946482 140342552557376 calibrate.py:79] feature_layers.7._input_quantizer       : TensorQuantizer(8bit fake per-tensor amax=3.3006 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:25.949194 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.7._weight_quantizer      : TensorQuantizer(8bit fake per-tensor amax=0.3621 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:25.950498 140342552557376 calibrate.py:79] feature_layers.7._weight_quantizer      : TensorQuantizer(8bit fake per-tensor amax=0.3621 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:25.952027 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.10._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=2.4138 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:25.952803 140342552557376 calibrate.py:79] feature_layers.10._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=2.4138 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:25.954279 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.10._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.2821 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:25.955048 140342552557376 calibrate.py:79] feature_layers.10._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.2821 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:25.956552 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.14._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=2.9919 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:25.957344 140342552557376 calibrate.py:79] feature_layers.14._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=2.9919 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:25.958792 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.14._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.2734 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:25.959579 140342552557376 calibrate.py:79] feature_layers.14._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.2734 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:25.961067 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.17._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=2.7116 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:25.961866 140342552557376 calibrate.py:79] feature_layers.17._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=2.7116 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:25.963307 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.17._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.2519 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:25.964072 140342552557376 calibrate.py:79] feature_layers.17._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.2519 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:25.965596 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mclassifier.0._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=4.0080 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:25.966368 140342552557376 calibrate.py:79] classifier.0._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=4.0080 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:25.967808 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mclassifier.0._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.1603 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:25.968582 140342552557376 calibrate.py:79] classifier.0._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.1603 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:25.970146 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mclassifier.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=37.9196 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:25.970953 140342552557376 calibrate.py:79] classifier.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=37.9196 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:25.972397 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mclassifier.2._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.1175 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:25.973172 140342552557376 calibrate.py:79] classifier.2._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.1175 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:25.974653 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlast_layer._input_quantizer             : TensorQuantizer(8bit fake per-tensor amax=18.9375 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:25.975427 140342552557376 calibrate.py:79] last_layer._input_quantizer             : TensorQuantizer(8bit fake per-tensor amax=18.9375 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:25.976882 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlast_layer._weight_quantizer            : TensorQuantizer(8bit fake per-tensor amax=0.1626 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:25.977659 140342552557376 calibrate.py:79] last_layer._weight_quantizer            : TensorQuantizer(8bit fake per-tensor amax=0.1626 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPerforming post calibration analysis for calibrator percentile_99.9...\u001b[0m\n",
      "I0318 11:28:25.980097 140342552557376 calibrate.py:53] Performing post calibration analysis for calibrator percentile_99.9...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis\u001b[0m\n",
      "I0318 11:28:25.981252 140342552557376 analysis.py:214] Starting transformation analysis\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results vgg7:\n",
      "+------------------------------+------------+\n",
      "|            Metric            |   Value    |\n",
      "+------------------------------+------------+\n",
      "| Average Validation Accuracy  |  0.91902   |\n",
      "|      Average Precision       |  0.92231   |\n",
      "|        Average Recall        |  0.92259   |\n",
      "|       Average F1 Score       |  0.92233   |\n",
      "|         Average Loss         |  0.23545   |\n",
      "|       Average Latency        | 38.241 ms  |\n",
      "|   Average GPU Power Usage    |  98.32 W   |\n",
      "| Inference Energy Consumption | 1.0444 mWh |\n",
      "+------------------------------+------------+\u001b[0m\n",
      "I0318 11:28:30.514988 140342552557376 analysis.py:330] \n",
      "Results vgg7:\n",
      "+------------------------------+------------+\n",
      "|            Metric            |   Value    |\n",
      "+------------------------------+------------+\n",
      "| Average Validation Accuracy  |  0.91902   |\n",
      "|      Average Precision       |  0.92231   |\n",
      "|        Average Recall        |  0.92259   |\n",
      "|       Average F1 Score       |  0.92233   |\n",
      "|         Average Loss         |  0.23545   |\n",
      "|       Average Latency        | 38.241 ms  |\n",
      "|   Average GPU Power Usage    |  98.32 W   |\n",
      "| Inference Energy Consumption | 1.0444 mWh |\n",
      "+------------------------------+------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPost calibration analysis complete.\u001b[0m\n",
      "I0318 11:28:30.517491 140342552557376 calibrate.py:66] Post calibration analysis complete.\n",
      "W0318 11:28:30.519387 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.3._input_quantizer       : TensorQuantizer(8bit fake per-tensor amax=8.8229 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:30.520300 140342552557376 calibrate.py:79] feature_layers.3._input_quantizer       : TensorQuantizer(8bit fake per-tensor amax=8.8229 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:30.521599 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.3._weight_quantizer      : TensorQuantizer(8bit fake per-tensor amax=0.4801 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:30.522299 140342552557376 calibrate.py:79] feature_layers.3._weight_quantizer      : TensorQuantizer(8bit fake per-tensor amax=0.4801 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:30.523626 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.7._input_quantizer       : TensorQuantizer(8bit fake per-tensor amax=4.6778 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:30.524185 140342552557376 calibrate.py:79] feature_layers.7._input_quantizer       : TensorQuantizer(8bit fake per-tensor amax=4.6778 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:30.525709 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.7._weight_quantizer      : TensorQuantizer(8bit fake per-tensor amax=0.5323 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:30.526466 140342552557376 calibrate.py:79] feature_layers.7._weight_quantizer      : TensorQuantizer(8bit fake per-tensor amax=0.5323 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:30.527942 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.10._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=3.4064 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:30.528787 140342552557376 calibrate.py:79] feature_layers.10._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=3.4064 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:30.530232 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.10._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.3551 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:30.530984 140342552557376 calibrate.py:79] feature_layers.10._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.3551 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:30.532467 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.14._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=4.1424 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:30.533243 140342552557376 calibrate.py:79] feature_layers.14._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=4.1424 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:30.534674 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.14._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.3452 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:30.535426 140342552557376 calibrate.py:79] feature_layers.14._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.3452 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:30.536897 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.17._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=3.9340 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:30.537687 140342552557376 calibrate.py:79] feature_layers.17._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=3.9340 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:30.539270 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.17._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.3140 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:30.539996 140342552557376 calibrate.py:79] feature_layers.17._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.3140 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:30.541348 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mclassifier.0._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=6.0178 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:30.542055 140342552557376 calibrate.py:79] classifier.0._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=6.0178 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:30.543355 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mclassifier.0._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.2223 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:30.544059 140342552557376 calibrate.py:79] classifier.0._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.2223 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:30.545431 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mclassifier.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=78.4245 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:30.545994 140342552557376 calibrate.py:79] classifier.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=78.4245 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:30.547391 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mclassifier.2._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.1688 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:30.548099 140342552557376 calibrate.py:79] classifier.2._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.1688 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:30.549457 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlast_layer._input_quantizer             : TensorQuantizer(8bit fake per-tensor amax=34.5309 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:30.550158 140342552557376 calibrate.py:79] last_layer._input_quantizer             : TensorQuantizer(8bit fake per-tensor amax=34.5309 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:30.551448 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlast_layer._weight_quantizer            : TensorQuantizer(8bit fake per-tensor amax=0.2025 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:30.552142 140342552557376 calibrate.py:79] last_layer._weight_quantizer            : TensorQuantizer(8bit fake per-tensor amax=0.2025 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPerforming post calibration analysis for calibrator percentile_99.99...\u001b[0m\n",
      "I0318 11:28:30.554086 140342552557376 calibrate.py:53] Performing post calibration analysis for calibrator percentile_99.99...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis\u001b[0m\n",
      "I0318 11:28:30.555100 140342552557376 analysis.py:214] Starting transformation analysis\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results vgg7:\n",
      "+------------------------------+------------+\n",
      "|            Metric            |   Value    |\n",
      "+------------------------------+------------+\n",
      "| Average Validation Accuracy  |   0.9199   |\n",
      "|      Average Precision       |  0.92349   |\n",
      "|        Average Recall        |  0.92397   |\n",
      "|       Average F1 Score       |   0.9236   |\n",
      "|         Average Loss         |  0.23618   |\n",
      "|       Average Latency        | 37.764 ms  |\n",
      "|   Average GPU Power Usage    |  99.221 W  |\n",
      "| Inference Energy Consumption | 1.0408 mWh |\n",
      "+------------------------------+------------+\u001b[0m\n",
      "I0318 11:28:35.070010 140342552557376 analysis.py:330] \n",
      "Results vgg7:\n",
      "+------------------------------+------------+\n",
      "|            Metric            |   Value    |\n",
      "+------------------------------+------------+\n",
      "| Average Validation Accuracy  |   0.9199   |\n",
      "|      Average Precision       |  0.92349   |\n",
      "|        Average Recall        |  0.92397   |\n",
      "|       Average F1 Score       |   0.9236   |\n",
      "|         Average Loss         |  0.23618   |\n",
      "|       Average Latency        | 37.764 ms  |\n",
      "|   Average GPU Power Usage    |  99.221 W  |\n",
      "| Inference Energy Consumption | 1.0408 mWh |\n",
      "+------------------------------+------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPost calibration analysis complete.\u001b[0m\n",
      "I0318 11:28:35.072438 140342552557376 calibrate.py:66] Post calibration analysis complete.\n",
      "W0318 11:28:36.382215 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.3._input_quantizer       : TensorQuantizer(8bit fake per-tensor amax=10.5813 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:36.383707 140342552557376 calibrate.py:79] feature_layers.3._input_quantizer       : TensorQuantizer(8bit fake per-tensor amax=10.5813 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:37.369438 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.3._weight_quantizer      : TensorQuantizer(8bit fake per-tensor amax=0.4989 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:37.370501 140342552557376 calibrate.py:79] feature_layers.3._weight_quantizer      : TensorQuantizer(8bit fake per-tensor amax=0.4989 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:38.678205 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.7._input_quantizer       : TensorQuantizer(8bit fake per-tensor amax=5.2901 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:38.679295 140342552557376 calibrate.py:79] feature_layers.7._input_quantizer       : TensorQuantizer(8bit fake per-tensor amax=5.2901 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:39.667615 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.7._weight_quantizer      : TensorQuantizer(8bit fake per-tensor amax=0.5739 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:39.668674 140342552557376 calibrate.py:79] feature_layers.7._weight_quantizer      : TensorQuantizer(8bit fake per-tensor amax=0.5739 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:40.903185 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.10._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=4.2021 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:40.904335 140342552557376 calibrate.py:79] feature_layers.10._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=4.2021 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:41.893523 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.10._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.3685 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:41.894849 140342552557376 calibrate.py:79] feature_layers.10._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.3685 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:43.172208 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.14._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=5.1101 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:43.173320 140342552557376 calibrate.py:79] feature_layers.14._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=5.1101 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:44.170346 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.14._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.3645 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:44.171500 140342552557376 calibrate.py:79] feature_layers.14._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.3645 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:45.174597 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.17._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=5.6426 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:45.175661 140342552557376 calibrate.py:79] feature_layers.17._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=5.6426 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:46.172044 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.17._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.3202 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:46.173436 140342552557376 calibrate.py:79] feature_layers.17._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.3202 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:47.473207 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mclassifier.0._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=7.3163 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:47.474412 140342552557376 calibrate.py:79] classifier.0._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=7.3163 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:48.464096 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mclassifier.0._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.2408 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:48.464964 140342552557376 calibrate.py:79] classifier.0._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.2408 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:49.517606 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mclassifier.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=152.1875 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:49.518703 140342552557376 calibrate.py:79] classifier.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=152.1875 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:50.509681 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mclassifier.2._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.1952 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:50.510785 140342552557376 calibrate.py:79] classifier.2._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.1952 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:51.535877 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlast_layer._input_quantizer             : TensorQuantizer(8bit fake per-tensor amax=64.6092 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:51.537046 140342552557376 calibrate.py:79] last_layer._input_quantizer             : TensorQuantizer(8bit fake per-tensor amax=64.6092 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:52.531830 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlast_layer._weight_quantizer            : TensorQuantizer(8bit fake per-tensor amax=0.1997 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:52.532883 140342552557376 calibrate.py:79] last_layer._weight_quantizer            : TensorQuantizer(8bit fake per-tensor amax=0.1997 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPerforming post calibration analysis for calibrator mse...\u001b[0m\n",
      "I0318 11:28:52.535768 140342552557376 calibrate.py:53] Performing post calibration analysis for calibrator mse...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis\u001b[0m\n",
      "I0318 11:28:52.537053 140342552557376 analysis.py:214] Starting transformation analysis\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results vgg7:\n",
      "+------------------------------+------------+\n",
      "|            Metric            |   Value    |\n",
      "+------------------------------+------------+\n",
      "| Average Validation Accuracy  |  0.92009   |\n",
      "|      Average Precision       |  0.92368   |\n",
      "|        Average Recall        |  0.92408   |\n",
      "|       Average F1 Score       |  0.92378   |\n",
      "|         Average Loss         |  0.23669   |\n",
      "|       Average Latency        | 38.354 ms  |\n",
      "|   Average GPU Power Usage    |  97.465 W  |\n",
      "| Inference Energy Consumption | 1.0384 mWh |\n",
      "+------------------------------+------------+\u001b[0m\n",
      "I0318 11:28:57.087177 140342552557376 analysis.py:330] \n",
      "Results vgg7:\n",
      "+------------------------------+------------+\n",
      "|            Metric            |   Value    |\n",
      "+------------------------------+------------+\n",
      "| Average Validation Accuracy  |  0.92009   |\n",
      "|      Average Precision       |  0.92368   |\n",
      "|        Average Recall        |  0.92408   |\n",
      "|       Average F1 Score       |  0.92378   |\n",
      "|         Average Loss         |  0.23669   |\n",
      "|       Average Latency        | 38.354 ms  |\n",
      "|   Average GPU Power Usage    |  97.465 W  |\n",
      "| Inference Energy Consumption | 1.0384 mWh |\n",
      "+------------------------------+------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPost calibration analysis complete.\u001b[0m\n",
      "I0318 11:28:57.089607 140342552557376 calibrate.py:66] Post calibration analysis complete.\n",
      "W0318 11:29:04.151026 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.3._input_quantizer       : TensorQuantizer(8bit fake per-tensor amax=10.7260 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:29:04.152235 140342552557376 calibrate.py:79] feature_layers.3._input_quantizer       : TensorQuantizer(8bit fake per-tensor amax=10.7260 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:29:08.801714 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.3._weight_quantizer      : TensorQuantizer(8bit fake per-tensor amax=0.5427 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:29:08.802824 140342552557376 calibrate.py:79] feature_layers.3._weight_quantizer      : TensorQuantizer(8bit fake per-tensor amax=0.5427 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:29:16.188955 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.7._input_quantizer       : TensorQuantizer(8bit fake per-tensor amax=6.2438 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:29:16.190120 140342552557376 calibrate.py:79] feature_layers.7._input_quantizer       : TensorQuantizer(8bit fake per-tensor amax=6.2438 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:29:20.749375 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.7._weight_quantizer      : TensorQuantizer(8bit fake per-tensor amax=0.6185 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:29:20.750648 140342552557376 calibrate.py:79] feature_layers.7._weight_quantizer      : TensorQuantizer(8bit fake per-tensor amax=0.6185 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:29:27.322470 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.10._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=4.9095 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:29:27.324110 140342552557376 calibrate.py:79] feature_layers.10._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=4.9095 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:29:32.054767 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.10._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.4083 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:29:32.056291 140342552557376 calibrate.py:79] feature_layers.10._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.4083 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:29:39.190995 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.14._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=6.2019 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:29:39.192506 140342552557376 calibrate.py:79] feature_layers.14._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=6.2019 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:29:43.876971 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.14._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.4537 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:29:43.878366 140342552557376 calibrate.py:79] feature_layers.14._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.4537 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:29:48.624796 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.17._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=5.5843 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:29:48.626186 140342552557376 calibrate.py:79] feature_layers.17._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=5.5843 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:29:53.411544 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.17._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.3877 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:29:53.413097 140342552557376 calibrate.py:79] feature_layers.17._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.3877 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:30:00.302274 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mclassifier.0._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=8.3903 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:30:00.303872 140342552557376 calibrate.py:79] classifier.0._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=8.3903 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:30:04.989341 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mclassifier.0._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.2154 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:30:04.990899 140342552557376 calibrate.py:79] classifier.0._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.2154 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:30:09.949727 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mclassifier.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=155.0471 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:30:09.951436 140342552557376 calibrate.py:79] classifier.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=155.0471 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:30:14.412336 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mclassifier.2._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.1901 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:30:14.413735 140342552557376 calibrate.py:79] classifier.2._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.1901 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:30:19.174479 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlast_layer._input_quantizer             : TensorQuantizer(8bit fake per-tensor amax=62.1193 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:30:19.175708 140342552557376 calibrate.py:79] last_layer._input_quantizer             : TensorQuantizer(8bit fake per-tensor amax=62.1193 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:30:23.563438 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlast_layer._weight_quantizer            : TensorQuantizer(8bit fake per-tensor amax=0.2112 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:30:23.565157 140342552557376 calibrate.py:79] last_layer._weight_quantizer            : TensorQuantizer(8bit fake per-tensor amax=0.2112 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPerforming post calibration analysis for calibrator entropy...\u001b[0m\n",
      "I0318 11:30:23.567919 140342552557376 calibrate.py:53] Performing post calibration analysis for calibrator entropy...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis\u001b[0m\n",
      "I0318 11:30:23.569261 140342552557376 analysis.py:214] Starting transformation analysis\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results vgg7:\n",
      "+------------------------------+------------+\n",
      "|            Metric            |   Value    |\n",
      "+------------------------------+------------+\n",
      "| Average Validation Accuracy  |  0.91864   |\n",
      "|      Average Precision       |   0.9224   |\n",
      "|        Average Recall        |  0.92282   |\n",
      "|       Average F1 Score       |  0.92248   |\n",
      "|         Average Loss         |  0.23694   |\n",
      "|       Average Latency        |  38.88 ms  |\n",
      "|   Average GPU Power Usage    |  98.198 W  |\n",
      "| Inference Energy Consumption | 1.0605 mWh |\n",
      "+------------------------------+------------+\u001b[0m\n",
      "I0318 11:30:28.236583 140342552557376 analysis.py:330] \n",
      "Results vgg7:\n",
      "+------------------------------+------------+\n",
      "|            Metric            |   Value    |\n",
      "+------------------------------+------------+\n",
      "| Average Validation Accuracy  |  0.91864   |\n",
      "|      Average Precision       |   0.9224   |\n",
      "|        Average Recall        |  0.92282   |\n",
      "|       Average F1 Score       |  0.92248   |\n",
      "|         Average Loss         |  0.23694   |\n",
      "|       Average Latency        |  38.88 ms  |\n",
      "|   Average GPU Power Usage    |  98.198 W  |\n",
      "| Inference Energy Consumption | 1.0605 mWh |\n",
      "+------------------------------+------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPost calibration analysis complete.\u001b[0m\n",
      "I0318 11:30:28.238457 140342552557376 calibrate.py:66] Post calibration analysis complete.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mSucceeded in calibrating the model in PyTorch!\u001b[0m\n",
      "I0318 11:30:28.239268 140342552557376 calibrate.py:159] Succeeded in calibrating the model in PyTorch!\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting Fine Tuning...\u001b[0m\n",
      "I0318 11:30:28.245524 140342552557376 fine_tune.py:62] Starting Fine Tuning...\n",
      "I0318 11:30:58.501808 140342552557376 rank_zero.py:64] GPU available: True (cuda), used: True\n",
      "I0318 11:30:58.536208 140342552557376 rank_zero.py:64] TPU available: False, using: 0 TPU cores\n",
      "I0318 11:30:58.536926 140342552557376 rank_zero.py:64] IPU available: False, using: 0 IPUs\n",
      "I0318 11:30:58.537610 140342552557376 rank_zero.py:64] HPU available: False, using: 0 HPUs\n",
      "I0318 11:30:58.554492 140342552557376 rank_zero.py:64] You are using a CUDA device ('NVIDIA GeForce RTX 3070') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0318 11:31:02.771356 140342552557376 cuda.py:61] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "I0318 11:31:02.798513 140342552557376 model_summary.py:94] \n",
      "  | Name      | Type               | Params\n",
      "-------------------------------------------------\n",
      "0 | model     | GraphModule        | 14.0 M\n",
      "1 | loss_fn   | CrossEntropyLoss   | 0     \n",
      "2 | acc_train | MulticlassAccuracy | 0     \n",
      "3 | loss_val  | MeanMetric         | 0     \n",
      "4 | loss_test | MeanMetric         | 0     \n",
      "-------------------------------------------------\n",
      "14.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "14.0 M    Total params\n",
      "56.118    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/mase/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/mase/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 196/196 [00:58<00:00,  3.37it/s, v_num=1, train_acc_step=0.875, val_acc_epoch=0.896, val_loss_epoch=0.219]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0318 11:33:01.304579 140342552557376 rank_zero.py:64] `Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 196/196 [00:58<00:00,  3.35it/s, v_num=1, train_acc_step=0.875, val_acc_epoch=0.896, val_loss_epoch=0.219]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mFine Tuning Complete\u001b[0m\n",
      "I0318 11:33:01.409875 140342552557376 fine_tune.py:121] Fine Tuning Complete\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "I0318 11:33:01.418860 140342552557376 quantize.py:129] Converting PyTorch model to ONNX...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/mase/lib/python3.11/site-packages/pytorch_quantization/tensor_quant.py:363: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if min_amax < 0:\n",
      "/opt/conda/envs/mase/lib/python3.11/site-packages/pytorch_quantization/tensor_quant.py:366: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  max_bound = torch.tensor((2.0**(num_bits - 1 + int(unsigned))) - 1.0, device=amax.device)\n",
      "/opt/conda/envs/mase/lib/python3.11/site-packages/pytorch_quantization/tensor_quant.py:376: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if min_amax <= epsilon:  # Treat amax smaller than minimum representable of fp16 0\n",
      "/opt/conda/envs/mase/lib/python3.11/site-packages/pytorch_quantization/tensor_quant.py:382: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if min_amax <= epsilon:\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /root/mase/mase_output/tensorrt/quantization/onnx/2024_03_18/version_2/model.onnx\u001b[0m\n",
      "I0318 11:33:02.396777 140342552557376 quantize.py:152] ONNX Conversion Complete. Stored ONNX model to /root/mase/mase_output/tensorrt/quantization/onnx/2024_03_18/version_2/model.onnx\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "I0318 11:33:02.399959 140342552557376 quantize.py:55] Converting PyTorch model to TensorRT...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m mg, _ \u001b[38;5;241m=\u001b[39m tensorrt_calibrate_transform_pass(mg, pass_args\u001b[38;5;241m=\u001b[39mtensorrt_quantize_config)\n\u001b[1;32m      4\u001b[0m mg, _ \u001b[38;5;241m=\u001b[39m tensorrt_fine_tune_transform_pass(mg, pass_args\u001b[38;5;241m=\u001b[39mtensorrt_quantize_config)\n\u001b[0;32m----> 5\u001b[0m mg, meta \u001b[38;5;241m=\u001b[39m \u001b[43mtensorrt_engine_interface_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpass_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensorrt_quantize_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mase/machop/chop/passes/graph/transforms/tensorrt/quantize/quantize.py:20\u001b[0m, in \u001b[0;36mtensorrt_engine_interface_pass\u001b[0;34m(graph, pass_args)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtensorrt_engine_interface_pass\u001b[39m(graph, pass_args\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     19\u001b[0m     quantizer \u001b[38;5;241m=\u001b[39m Quantizer(pass_args)\n\u001b[0;32m---> 20\u001b[0m     trt_engine_path, onnx_path \u001b[38;5;241m=\u001b[39m \u001b[43mquantizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpytorch_to_trt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# link the model with graph\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     graph\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfx\u001b[38;5;241m.\u001b[39mGraphModule(graph\u001b[38;5;241m.\u001b[39mmodel, graph\u001b[38;5;241m.\u001b[39mfx_graph)\n",
      "File \u001b[0;32m~/mase/machop/chop/passes/graph/transforms/tensorrt/quantize/quantize.py:36\u001b[0m, in \u001b[0;36mQuantizer.pytorch_to_trt\u001b[0;34m(self, graph)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Model is first converted to ONNX format and then to TensorRT\u001b[39;00m\n\u001b[1;32m     35\u001b[0m ONNX_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpytorch_to_ONNX(graph\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[0;32m---> 36\u001b[0m TRT_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mONNX_to_TRT\u001b[49m\u001b[43m(\u001b[49m\u001b[43mONNX_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexport_TRT_model_summary(TRT_path)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m TRT_path, ONNX_path\n",
      "File \u001b[0;32m~/mase/machop/chop/passes/graph/transforms/tensorrt/quantize/quantize.py:61\u001b[0m, in \u001b[0;36mQuantizer.ONNX_to_TRT\u001b[0;34m(self, ONNX_path)\u001b[0m\n\u001b[1;32m     58\u001b[0m layer_wise_mixed_precision \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m check_for_value_in_dict(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mINT8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m check_for_value_in_dict(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFP16\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     60\u001b[0m TRT_LOGGER \u001b[38;5;241m=\u001b[39m trt\u001b[38;5;241m.\u001b[39mLogger(trt\u001b[38;5;241m.\u001b[39mLogger\u001b[38;5;241m.\u001b[39mWARNING)\n\u001b[0;32m---> 61\u001b[0m builder \u001b[38;5;241m=\u001b[39m \u001b[43mtrt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBuilder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTRT_LOGGER\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m network \u001b[38;5;241m=\u001b[39m builder\u001b[38;5;241m.\u001b[39mcreate_network(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m<<\u001b[39m \u001b[38;5;28mint\u001b[39m(trt\u001b[38;5;241m.\u001b[39mNetworkDefinitionCreationFlag\u001b[38;5;241m.\u001b[39mEXPLICIT_BATCH))\n\u001b[1;32m     63\u001b[0m parser \u001b[38;5;241m=\u001b[39m trt\u001b[38;5;241m.\u001b[39mOnnxParser(network, TRT_LOGGER)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mg, _ = tensorrt_fake_quantize_transform_pass(mg, pass_args=tensorrt_quantize_config)\n",
    "# summarize_quantization_analysis_pass(mg_original, mg)\n",
    "mg, _ = tensorrt_calibrate_transform_pass(mg, pass_args=tensorrt_quantize_config)\n",
    "mg, _ = tensorrt_fine_tune_transform_pass(mg, pass_args=tensorrt_quantize_config)\n",
    "mg, meta = tensorrt_engine_interface_pass(mg, pass_args=tensorrt_quantize_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ch transform --config ../../../machop/configs/tensorrt/vgg7_INT8_quantization_by_type.toml --load {VGG_CHECKPOINT_PATH} --load-type pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5. Language Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your TOML file\n",
    "toml_file_path = '../../../machop/configs/tensorrt/opt-125M_layerwise_mixed_precision_by_name.toml'\n",
    "\n",
    "# Reading TOML file and converting it into a Python dictionary\n",
    "with open(toml_file_path, 'r') as toml_file:\n",
    "    pass_args = toml.load(toml_file)\n",
    "\n",
    "# Extract the 'passes.tensorrt_quantize' section and its children\n",
    "tensorrt_quantize_config = pass_args.get('passes', {}).get('tensorrt_quantize', {})\n",
    "# Extract the 'passes.tensorrt_analysis' section and its children\n",
    "tensorrt_analysis_config = pass_args.get('passes', {}).get('tensorrt_analysis', {})\n",
    "\n",
    "# Load the basics in\n",
    "model_name = pass_args['model']\n",
    "dataset_name = pass_args['dataset']\n",
    "max_epochs = pass_args['max_epochs']\n",
    "batch_size = pass_args['batch_size']\n",
    "learning_rate = pass_args['learning_rate']\n",
    "accelerator = pass_args['accelerator']\n",
    "\n",
    "opt_tokenizer = get_tokenizer(\"facebook/opt-125m\")\n",
    "\n",
    "data_module = MaseDataModule(\n",
    "    name=dataset_name,\n",
    "    batch_size=batch_size,\n",
    "    model_name=model_name,\n",
    "    num_workers=os.cpu_count(),\n",
    "    max_token_len=128,\n",
    "    tokenizer=opt_tokenizer,\n",
    "    load_from_cache_file=True,\n",
    ")\n",
    "data_module.prepare_data()\n",
    "data_module.setup()\n",
    "\n",
    "# Add the data_module and other necessary information to the configs\n",
    "configs = [tensorrt_quantize_config, tensorrt_analysis_config]\n",
    "for config in configs:\n",
    "    config['task'] = pass_args['task']\n",
    "    config['batch_size'] = pass_args['batch_size']\n",
    "    config['model'] = pass_args['model']\n",
    "    config['data_module'] = data_module\n",
    "    config['accelerator'] = 'cuda' if pass_args['accelerator'] == 'gpu' else pass_args['accelerator']\n",
    "    if config['accelerator'] == 'gpu':\n",
    "        os.environ['CUDA_MODULE_LOADING'] = 'LAZY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_info = get_model_info(model_name)\n",
    "model = get_model(\n",
    "    \"facebook/opt-125m:patched\",\n",
    "    task=\"lm\",\n",
    "    dataset_info=get_dataset_info(\"wikitext2\"),\n",
    "    pretrained=True,\n",
    ")\n",
    "\n",
    "# Load in the trained checkpoint - change this accordingly\n",
    "# OPT125M_CHECKPOINT_PATH = \"../../../mase_output/jsc-toy_classification_jsc_2024-03-17/software/training_ckpts/best.ckpt\"\n",
    "# model = load_model(load_name=OPT125M_CHECKPOINT_PATH, load_type=\"pl\", model=model)\n",
    "\n",
    "model_info = get_model_info(\"facebook/opt-125m:patched\")\n",
    "cf_args = get_cf_args(model_info=model_info, task=\"lm\", model=model)\n",
    "\n",
    "mg = MaseGraph(model=model, cf_args=cf_args)\n",
    "\n",
    "# dummy_in = get_dummy_input(model_info, data_module=data_module, task=\"lm\")\n",
    "# if len(mg.model.additional_inputs) > 0:\n",
    "#     dummy_in = dummy_in | mg.model.additional_inputs\n",
    "\n",
    "# Initiate metadata\n",
    "mg, _ = init_metadata_analysis_pass(mg, pass_args=None)\n",
    "\n",
    "# # Before we begin, we will copy the original MaseGraph model to use for comparison during quantization analysis\n",
    "# mg_original = deepcopy_mase_graph(mg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _, _ = tensorrt_analysis_pass(mg, pass_args=tensorrt_analysis_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "I0318 08:54:47.010779 139760749061952 quantize.py:129] Converting PyTorch model to ONNX...\n",
      "ERROR:tornado.general:SEND Error: Host unreachable\n",
      "Traceback (most recent call last):\n",
      "  File \"_pydevd_bundle/pydevd_cython.pyx\", line 577, in _pydevd_bundle.pydevd_cython.PyDBFrame._handle_exception\n",
      "  File \"_pydevd_bundle/pydevd_cython.pyx\", line 312, in _pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\n",
      "  File \"/opt/conda/envs/mase/lib/python3.11/site-packages/debugpy/_vendored/pydevd/pydevd.py\", line 2070, in do_wait_suspend\n",
      "    keep_suspended = self._do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/envs/mase/lib/python3.11/site-packages/debugpy/_vendored/pydevd/pydevd.py\", line 2106, in _do_wait_suspend\n",
      "    time.sleep(0.01)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# mg, _ = tensorrt_fake_quantize_transform_pass(mg, pass_args=tensorrt_quantize_config)\n",
    "# summarize_quantization_analysis_pass(mg_original, mg)\n",
    "\n",
    "# mg, _ = tensorrt_calibrate_transform_pass(mg, pass_args=tensorrt_quantize_config)\n",
    "\n",
    "# mg, _ = tensorrt_fine_tune_transform_pass(mg, pass_args=tensorrt_quantize_config)\n",
    "\n",
    "mg, meta = tensorrt_engine_interface_pass(mg, pass_args=tensorrt_quantize_config)\n",
    "\n",
    "_, _ = tensorrt_analysis_pass(mg_original, pass_args=tensorrt_analysis_config)\n",
    "_, _ = tensorrt_analysis_pass(meta['trt_engine_path'], pass_args=tensorrt_analysis_config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
