{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome To the TensorRT Quantization Tutorial!\n",
    "\n",
    "This notebook is designed to show the features of the TensorRT passes integrated into MASE.\n",
    "\n",
    "## Section 1. INT8 Quantization\n",
    "Firstly, we will show you how to do a INT8 quantization of a simple model, `jsc-toy`, and compare the quantized model to the original model using the `Machop API`. The quantization process is split into the following stages, each using their own individual pass, and are explained in depth at each subsection:\n",
    "\n",
    "1. [Fake quantization](#section-11-fake-quantization): `tensorrt_fake_quantize_transform_pass`\n",
    "2. [Calibration](#sect): `tensorrt_calibrate_transform_pass`\n",
    "3. [Quantized Aware Training](#quantized-aware-training): `tensorrt_fine_tune_transform_pass`\n",
    "4. [Quantization](#quantization): `tensorrt_engine_interface_pass`\n",
    "5. [Analysis](#analysis): `tensorrt_analysis_pass`\n",
    "\n",
    "We start by loading in the required libraries and passes required for the notebook as well as ensuring the correct path is set for machop to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/mase/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-18 11:51:05,603] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mSet logging level to info\u001b[0m\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0318 11:51:07.062342 140129150785344 logger.py:44] Set logging level to info\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import toml\n",
    "from copy import copy, deepcopy\n",
    "\n",
    "# Figure out the correct path\n",
    "machop_path = Path(\".\").resolve().parent.parent.parent /\"machop\"\n",
    "assert machop_path.exists(), \"Failed to find machop at: {}\".format(machop_path)\n",
    "sys.path.append(str(machop_path))\n",
    "\n",
    "# Add directory to the PATH so that chop can be called\n",
    "new_path = \"../../../machop\"\n",
    "full_path = os.path.abspath(new_path)\n",
    "os.environ['PATH'] += os.pathsep + full_path\n",
    "\n",
    "from chop.tools.utils import to_numpy_if_tensor\n",
    "from chop.tools.logger import set_logging_verbosity\n",
    "from chop.tools import get_cf_args, get_dummy_input\n",
    "from chop.passes.graph.utils import deepcopy_mase_graph\n",
    "from chop.tools.get_input import InputGenerator\n",
    "from chop.tools.checkpoint_load import load_model\n",
    "from chop.ir import MaseGraph\n",
    "from chop.models import get_model_info, get_model, get_tokenizer\n",
    "from chop.dataset import MaseDataModule, get_dataset_info\n",
    "from chop.passes.graph.transforms import metadata_value_type_cast_transform_pass\n",
    "from chop.passes.graph import (\n",
    "    summarize_quantization_analysis_pass,\n",
    "    add_common_metadata_analysis_pass,\n",
    "    init_metadata_analysis_pass,\n",
    "    add_software_metadata_analysis_pass,\n",
    "    tensorrt_calibrate_transform_pass,\n",
    "    tensorrt_fake_quantize_transform_pass,\n",
    "    tensorrt_fine_tune_transform_pass,\n",
    "    tensorrt_engine_interface_pass,\n",
    "    tensorrt_analysis_pass,\n",
    "    )\n",
    "\n",
    "set_logging_verbosity(\"info\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we load in the toml file used for quantization. To view the configuration, click [here](../../machop/configs/tensorrt/jsc_toy_INT8_quantization_by_type.toml), or read the documentation on Mase [here]()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your TOML file\n",
    "toml_file_path = '../../../machop/configs/tensorrt/jsc_toy_INT8_quantization_by_type.toml'\n",
    "\n",
    "# Reading TOML file and converting it into a Python dictionary\n",
    "with open(toml_file_path, 'r') as toml_file:\n",
    "    pass_args = toml.load(toml_file)\n",
    "\n",
    "# Extract the 'passes.tensorrt_quantize' section and its children\n",
    "tensorrt_quantize_config = pass_args.get('passes', {}).get('tensorrt_quantize', {})\n",
    "# Extract the 'passes.tensorrt_analysis' section and its children\n",
    "tensorrt_analysis_config = pass_args.get('passes', {}).get('tensorrt_analysis', {})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then create a `MaseGraph` by loading in a model and training it using the toml configuration model arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the basics in\n",
    "model_name = pass_args['model']\n",
    "dataset_name = pass_args['dataset']\n",
    "max_epochs = pass_args['max_epochs']\n",
    "batch_size = pass_args['batch_size']\n",
    "learning_rate = pass_args['learning_rate']\n",
    "accelerator = pass_args['accelerator']\n",
    "\n",
    "data_module = MaseDataModule(\n",
    "    name=dataset_name,\n",
    "    batch_size=batch_size,\n",
    "    model_name=model_name,\n",
    "    num_workers=0,\n",
    ")\n",
    "data_module.prepare_data()\n",
    "data_module.setup()\n",
    "\n",
    "# Add the data_module and other necessary information to the configs\n",
    "configs = [tensorrt_quantize_config, tensorrt_analysis_config]\n",
    "for config in configs:\n",
    "    config['task'] = pass_args['task']\n",
    "    config['batch_size'] = pass_args['batch_size']\n",
    "    config['model'] = pass_args['model']\n",
    "    config['data_module'] = data_module\n",
    "    config['accelerator'] = 'cuda' if pass_args['accelerator'] == 'gpu' else pass_args['accelerator']\n",
    "    if config['accelerator'] == 'gpu':\n",
    "        os.environ['CUDA_MODULE_LOADING'] = 'LAZY'\n",
    "\n",
    "model_info = get_model_info(model_name)\n",
    "# quant_modules.initialize()\n",
    "model = get_model(\n",
    "    model_name,\n",
    "    task=\"cls\",\n",
    "    dataset_info=data_module.dataset_info,\n",
    "    pretrained=False)\n",
    "\n",
    "\n",
    "input_generator = InputGenerator(\n",
    "    data_module=data_module,\n",
    "    model_info=model_info,\n",
    "    task=\"cls\",\n",
    "    which_dataloader=\"train\",\n",
    ")\n",
    "\n",
    "# generate the mase graph and initialize node metadata\n",
    "mg = MaseGraph(model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we train the `jsc-toy` model using the machop `train` action with the config from the toml file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-18 11:44:36,191] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "INFO: Seed set to 0\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0318 11:44:37.795595 139634499045184 seed.py:54] Seed set to 0\n",
      "+-------------------------+------------------------+--------------+-----------------+------------------------+\n",
      "| Name                    |        Default         | Config. File | Manual Override |       Effective        |\n",
      "+-------------------------+------------------------+--------------+-----------------+------------------------+\n",
      "| task                    |     \u001b[38;5;8mclassification\u001b[0m     |     cls      |                 |          cls           |\n",
      "| load_name               |          None          |              |                 |          None          |\n",
      "| load_type               |           mz           |              |                 |           mz           |\n",
      "| batch_size              |          \u001b[38;5;8m128\u001b[0m           |     256      |                 |          256           |\n",
      "| to_debug                |         False          |              |                 |         False          |\n",
      "| log_level               |          info          |              |                 |          info          |\n",
      "| report_to               |      tensorboard       |              |                 |      tensorboard       |\n",
      "| seed                    |           0            |              |                 |           0            |\n",
      "| quant_config            |          None          |              |                 |          None          |\n",
      "| training_optimizer      |          adam          |              |                 |          adam          |\n",
      "| trainer_precision       |        16-mixed        |              |                 |        16-mixed        |\n",
      "| learning_rate           |         \u001b[38;5;8m1e-05\u001b[0m          |    0.001     |                 |         0.001          |\n",
      "| weight_decay            |           0            |              |                 |           0            |\n",
      "| max_epochs              |           \u001b[38;5;8m20\u001b[0m           |      10      |                 |           10           |\n",
      "| max_steps               |           -1           |              |                 |           -1           |\n",
      "| accumulate_grad_batches |           1            |              |                 |           1            |\n",
      "| log_every_n_steps       |           50           |              |                 |           50           |\n",
      "| num_workers             |           32           |              |                 |           32           |\n",
      "| num_devices             |           1            |              |                 |           1            |\n",
      "| num_nodes               |           1            |              |                 |           1            |\n",
      "| accelerator             |          \u001b[38;5;8mauto\u001b[0m          |     gpu      |                 |          gpu           |\n",
      "| strategy                |          auto          |              |                 |          auto          |\n",
      "| is_to_auto_requeue      |         False          |              |                 |         False          |\n",
      "| github_ci               |         False          |              |                 |         False          |\n",
      "| disable_dataset_cache   |         False          |              |                 |         False          |\n",
      "| target                  |  xcu250-figd2104-2L-e  |              |                 |  xcu250-figd2104-2L-e  |\n",
      "| num_targets             |          100           |              |                 |          100           |\n",
      "| is_pretrained           |         False          |              |                 |         False          |\n",
      "| max_token_len           |          512           |              |                 |          512           |\n",
      "| project_dir             | /root/mase/mase_output |              |                 | /root/mase/mase_output |\n",
      "| project                 |          None          |              |                 |          None          |\n",
      "| model                   |          \u001b[38;5;8mNone\u001b[0m          |   jsc-toy    |                 |        jsc-toy         |\n",
      "| dataset                 |          \u001b[38;5;8mNone\u001b[0m          |     jsc      |                 |          jsc           |\n",
      "| t_max                   |           20           |              |                 |           20           |\n",
      "| eta_min                 |         1e-06          |              |                 |         1e-06          |\n",
      "+-------------------------+------------------------+--------------+-----------------+------------------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mInitialising model 'jsc-toy'...\u001b[0m\n",
      "I0318 11:44:37.804295 139634499045184 cli.py:841] Initialising model 'jsc-toy'...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mInitialising dataset 'jsc'...\u001b[0m\n",
      "I0318 11:44:37.828583 139634499045184 cli.py:869] Initialising dataset 'jsc'...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mProject will be created at /root/mase/mase_output/jsc-toy_cls_jsc_2024-03-18\u001b[0m\n",
      "I0318 11:44:37.829264 139634499045184 cli.py:905] Project will be created at /root/mase/mase_output/jsc-toy_cls_jsc_2024-03-18\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTraining model 'jsc-toy'...\u001b[0m\n",
      "I0318 11:44:37.862516 139634499045184 cli.py:276] Training model 'jsc-toy'...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m##### WEIGHT DECAY ##### 0\u001b[0m\n",
      "I0318 11:44:37.863071 139634499045184 cli.py:320] ##### WEIGHT DECAY ##### 0\n",
      "INFO: Using 16bit Automatic Mixed Precision (AMP)\n",
      "I0318 11:44:37.943161 139634499045184 rank_zero.py:64] Using 16bit Automatic Mixed Precision (AMP)\n",
      "INFO: GPU available: True (cuda), used: True\n",
      "I0318 11:44:37.951574 139634499045184 rank_zero.py:64] GPU available: True (cuda), used: True\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "I0318 11:44:37.965183 139634499045184 rank_zero.py:64] TPU available: False, using: 0 TPU cores\n",
      "INFO: IPU available: False, using: 0 IPUs\n",
      "I0318 11:44:37.965238 139634499045184 rank_zero.py:64] IPU available: False, using: 0 IPUs\n",
      "INFO: HPU available: False, using: 0 HPUs\n",
      "I0318 11:44:37.965278 139634499045184 rank_zero.py:64] HPU available: False, using: 0 HPUs\n",
      "I0318 11:44:40.324936 139634499045184 cuda.py:61] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "I0318 11:44:40.413176 139634499045184 model_summary.py:94] \n",
      "  | Name      | Type               | Params\n",
      "-------------------------------------------------\n",
      "0 | model     | JSC_Toy            | 327   \n",
      "1 | loss_fn   | CrossEntropyLoss   | 0     \n",
      "2 | acc_train | MulticlassAccuracy | 0     \n",
      "3 | loss_val  | MeanMetric         | 0     \n",
      "4 | loss_test | MeanMetric         | 0     \n",
      "-------------------------------------------------\n",
      "327       Trainable params\n",
      "0         Non-trainable params\n",
      "327       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "Epoch 0: 100%|â–ˆ| 3084/3084 [00:21<00:00, 140.80it/s, v_num=0, train_acc_step=0.7\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                      | 0/3084 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                         | 0/3084 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                 | 1/3084 [00:00<04:57, 10.37it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "!ch train --config ../../../machop/configs/tensorrt/jsc_toy_INT8_quantization_by_type.toml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we load in the checkpoint. You will have to adjust this according to where it has been stored in the mase_output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from ../../../mase_output/jsc-toy-cls_jsc/best.ckpt\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0318 11:51:17.361118 140129150785344 checkpoint_load.py:85] Loaded pytorch lightning checkpoint from ../../../mase_output/jsc-toy-cls_jsc/best.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Load in the trained checkpoint - change this accordingly\n",
    "JSC_CHECKPOINT_PATH = \"../../../mase_output/jsc-toy-cls_jsc/best.ckpt\"\n",
    "\n",
    "model = load_model(load_name=JSC_CHECKPOINT_PATH, load_type=\"pl\", model=model)\n",
    "\n",
    "# Initiate metadata\n",
    "dummy_in = next(iter(input_generator))\n",
    "_ = model(**dummy_in)\n",
    "mg, _ = init_metadata_analysis_pass(mg, None)\n",
    "mg, _ = add_common_metadata_analysis_pass(mg, {\"dummy_in\": dummy_in})\n",
    "mg, _ = add_software_metadata_analysis_pass(mg, None)\n",
    "mg, _ = metadata_value_type_cast_transform_pass(mg, pass_args={\"fn\": to_numpy_if_tensor})\n",
    "\n",
    "# Before we begin, we will copy the original MaseGraph model to use for comparison during quantization analysis\n",
    "mg_original = deepcopy_mase_graph(mg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1.1 Fake Quantization\n",
    "\n",
    "Firstly, we fake quantize the module in order to perform calibration and fine tuning before actually quantizing - this is only used if we have INT8 calibration as other precisions are not currently supported within [pytorch-quantization](https://docs.nvidia.com/deeplearning/tensorrt/pytorch-quantization-toolkit/docs/index.html#) library.\n",
    "\n",
    "This is acheived through the `tensorrt_fake_quantize_transform_pass` which goes through the model, either by type or by name, replaces each layer appropriately to a fake quantized form if the `quantize` parameter is set in the default config (`passes.tensorrt_quantize.default.config`) or on a per name or type basis. \n",
    "\n",
    "Currently the quantizable layers are:\n",
    "- Linear\n",
    "- Conv1d, Conv2d, ConvNd \n",
    "- ConvTranspose1d, ConvTranspose2d, ConvTransposeNd \n",
    "- MaxPool1d, MaxPool2d, MaxPool3d\n",
    "- AvgPool1d, AvgPool2d, AvgPool3d\n",
    "- Clip (Tensor)\n",
    "- LSTM, LSTMCell\n",
    "\n",
    "To create a custom quantized module, click [here](https://docs.nvidia.com/deeplearning/tensorrt/pytorch-quantization-toolkit/docs/index.html#document-tutorials/creating_custom_quantized_modules).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mApplying fake quantization to PyTorch model...\u001b[0m\n",
      "I0318 11:52:10.653519 140129150785344 utils.py:167] Applying fake quantization to PyTorch model...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mFake quantization applied to PyTorch model.\u001b[0m\n",
      "I0318 11:52:11.059003 140129150785344 utils.py:192] Fake quantization applied to PyTorch model.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mQuantized graph histogram:\u001b[0m\n",
      "I0318 11:52:11.094833 140129150785344 summary.py:84] Quantized graph histogram:\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "| Original type   | OP           |   Total |   Changed |   Unchanged |\n",
      "|-----------------+--------------+---------+-----------+-------------|\n",
      "| BatchNorm1d     | batch_norm1d |       4 |         0 |           4 |\n",
      "| Linear          | linear       |       3 |         3 |           0 |\n",
      "| ReLU            | relu         |       4 |         0 |           4 |\n",
      "| output          | output       |       1 |         0 |           1 |\n",
      "| x               | placeholder  |       1 |         0 |           1 |\u001b[0m\n",
      "I0318 11:52:11.098179 140129150785344 summary.py:85] \n",
      "| Original type   | OP           |   Total |   Changed |   Unchanged |\n",
      "|-----------------+--------------+---------+-----------+-------------|\n",
      "| BatchNorm1d     | batch_norm1d |       4 |         0 |           4 |\n",
      "| Linear          | linear       |       3 |         3 |           0 |\n",
      "| ReLU            | relu         |       4 |         0 |           4 |\n",
      "| output          | output       |       1 |         0 |           1 |\n",
      "| x               | placeholder  |       1 |         0 |           1 |\n"
     ]
    }
   ],
   "source": [
    "mg, _ = tensorrt_fake_quantize_transform_pass(mg, pass_args=tensorrt_quantize_config)\n",
    "summarize_quantization_analysis_pass(mg_original, mg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see we have succesfully quantized all linear layers inside `jsc-toy`. See Section X for how to apply quantization layerwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1.2 Calibration\n",
    "\n",
    "Next, we perform calibration using the `tensorrt_calibrate_transform_pass`. Calibration is achieved by passing data samples to the quantizer and deciding the best amax for activations. \n",
    "\n",
    "Calibrators can be added as a search space parameter to examine the best performing calibrator. The calibrators have been included in the toml as follows.\n",
    "For example: `calibrators = [\"percentile\", \"mse\", \"entropy\"]`\n",
    "\n",
    "Note: \n",
    "- To use `percentile` calibration, a list of percentiles must be given\n",
    "- To use `max` calibration, the `histogram` weight and input calibrators must be removed and replaced with `max`. This will use global maximum absolute value to calibrate the model.\n",
    "- If `post_calibration_analysis` is set true the `tensorrt_analysis_pass` will be run for each calibrator tested to evaluate the most suitable calibrator for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting calibration of the model in PyTorch...\u001b[0m\n",
      "I0318 11:52:18.971756 140129150785344 calibrate.py:91] Starting calibration of the model in PyTorch...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "I0318 11:52:18.986147 140129150785344 calibrate.py:100] Disabling Quantization and Enabling Calibration\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "I0318 11:52:18.988298 140129150785344 calibrate.py:100] Disabling Quantization and Enabling Calibration\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "I0318 11:52:18.990240 140129150785344 calibrate.py:100] Disabling Quantization and Enabling Calibration\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "I0318 11:52:18.992076 140129150785344 calibrate.py:100] Disabling Quantization and Enabling Calibration\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "I0318 11:52:18.993931 140129150785344 calibrate.py:100] Disabling Quantization and Enabling Calibration\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "I0318 11:52:18.995384 140129150785344 calibrate.py:100] Disabling Quantization and Enabling Calibration\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "I0318 11:52:19.200505 140129150785344 calibrate.py:121] Enabling Quantization and Disabling Calibration\n",
      "W0318 11:52:19.202580 140129150785344 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "I0318 11:52:19.203527 140129150785344 calibrate.py:121] Enabling Quantization and Disabling Calibration\n",
      "W0318 11:52:19.205277 140129150785344 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "I0318 11:52:19.206042 140129150785344 calibrate.py:121] Enabling Quantization and Disabling Calibration\n",
      "W0318 11:52:19.207247 140129150785344 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "I0318 11:52:19.207888 140129150785344 calibrate.py:121] Enabling Quantization and Disabling Calibration\n",
      "W0318 11:52:19.209153 140129150785344 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "I0318 11:52:19.209818 140129150785344 calibrate.py:121] Enabling Quantization and Disabling Calibration\n",
      "W0318 11:52:19.211132 140129150785344 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "I0318 11:52:19.211847 140129150785344 calibrate.py:121] Enabling Quantization and Disabling Calibration\n",
      "W0318 11:52:19.213207 140129150785344 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "W0318 11:52:19.220771 140129150785344 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0318 11:52:19.221385 140129150785344 tensor_quantizer.py:239] Call .cuda() if running on GPU after loading calibrated amax.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=3.0128 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:52:19.222261 140129150785344 calibrate.py:79] seq_blocks.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=3.0128 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:52:19.224282 140129150785344 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.2._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.7247 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:52:19.225117 140129150785344 calibrate.py:79] seq_blocks.2._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.7247 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:52:19.227944 140129150785344 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.5._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=2.3860 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:52:19.228780 140129150785344 calibrate.py:79] seq_blocks.5._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=2.3860 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:52:19.231241 140129150785344 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.5._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5201 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:52:19.231870 140129150785344 calibrate.py:79] seq_blocks.5._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5201 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:52:19.233778 140129150785344 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.8._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=1.7416 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:52:19.234417 140129150785344 calibrate.py:79] seq_blocks.8._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=1.7416 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:52:19.236351 140129150785344 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.8._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5546 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:52:19.237002 140129150785344 calibrate.py:79] seq_blocks.8._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5546 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPerforming post calibration analysis for calibrator percentile_99.0...\u001b[0m\n",
      "I0318 11:52:19.239407 140129150785344 calibrate.py:53] Performing post calibration analysis for calibrator percentile_99.0...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis\u001b[0m\n",
      "I0318 11:52:19.240958 140129150785344 analysis.py:214] Starting transformation analysis\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results jsc-toy:\n",
      "+------------------------------+--------------+\n",
      "|            Metric            |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.72135    |\n",
      "|      Average Precision       |   0.73545    |\n",
      "|        Average Recall        |   0.71979    |\n",
      "|       Average F1 Score       |   0.72292    |\n",
      "|         Average Loss         |   0.80205    |\n",
      "|       Average Latency        |   3.33 ms    |\n",
      "|   Average GPU Power Usage    |   55.564 W   |\n",
      "| Inference Energy Consumption | 0.051397 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "I0318 11:52:26.934775 140129150785344 analysis.py:330] \n",
      "Results jsc-toy:\n",
      "+------------------------------+--------------+\n",
      "|            Metric            |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.72135    |\n",
      "|      Average Precision       |   0.73545    |\n",
      "|        Average Recall        |   0.71979    |\n",
      "|       Average F1 Score       |   0.72292    |\n",
      "|         Average Loss         |   0.80205    |\n",
      "|       Average Latency        |   3.33 ms    |\n",
      "|   Average GPU Power Usage    |   55.564 W   |\n",
      "| Inference Energy Consumption | 0.051397 mWh |\n",
      "+------------------------------+--------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPost calibration analysis complete.\u001b[0m\n",
      "I0318 11:52:26.938482 140129150785344 calibrate.py:66] Post calibration analysis complete.\n",
      "W0318 11:52:26.940514 140129150785344 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=4.2902 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:52:26.941511 140129150785344 calibrate.py:79] seq_blocks.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=4.2902 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:52:26.943309 140129150785344 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.2._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.7462 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:52:26.944329 140129150785344 calibrate.py:79] seq_blocks.2._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.7462 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:52:26.945902 140129150785344 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.5._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=3.9062 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:52:26.946619 140129150785344 calibrate.py:79] seq_blocks.5._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=3.9062 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:52:26.948084 140129150785344 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.5._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5201 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:52:26.948951 140129150785344 calibrate.py:79] seq_blocks.5._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5201 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:52:26.951983 140129150785344 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.8._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=2.2946 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:52:26.953216 140129150785344 calibrate.py:79] seq_blocks.8._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=2.2946 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:52:26.955915 140129150785344 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.8._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5546 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:52:26.957266 140129150785344 calibrate.py:79] seq_blocks.8._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5546 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPerforming post calibration analysis for calibrator percentile_99.9...\u001b[0m\n",
      "I0318 11:52:26.959598 140129150785344 calibrate.py:53] Performing post calibration analysis for calibrator percentile_99.9...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis\u001b[0m\n",
      "I0318 11:52:26.960746 140129150785344 analysis.py:214] Starting transformation analysis\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results jsc-toy:\n",
      "+------------------------------+--------------+\n",
      "|            Metric            |    Value     |\n",
      "+------------------------------+--------------+\n",
      "| Average Validation Accuracy  |   0.73239    |\n",
      "|      Average Precision       |   0.74542    |\n",
      "|        Average Recall        |   0.73063    |\n",
      "|       Average F1 Score       |   0.73398    |\n",
      "|         Average Loss         |   0.76669    |\n",
      "|       Average Latency        |  3.2573 ms   |\n",
      "|   Average GPU Power Usage    |   57.507 W   |\n",
      "| Inference Energy Consumption | 0.052033 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "I0318 11:52:33.902307 140129150785344 analysis.py:330] \n",
      "Results jsc-toy:\n",
      "+------------------------------+--------------+\n",
      "|            Metric            |    Value     |\n",
      "+------------------------------+--------------+\n",
      "| Average Validation Accuracy  |   0.73239    |\n",
      "|      Average Precision       |   0.74542    |\n",
      "|        Average Recall        |   0.73063    |\n",
      "|       Average F1 Score       |   0.73398    |\n",
      "|         Average Loss         |   0.76669    |\n",
      "|       Average Latency        |  3.2573 ms   |\n",
      "|   Average GPU Power Usage    |   57.507 W   |\n",
      "| Inference Energy Consumption | 0.052033 mWh |\n",
      "+------------------------------+--------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPost calibration analysis complete.\u001b[0m\n",
      "I0318 11:52:33.911842 140129150785344 calibrate.py:66] Post calibration analysis complete.\n",
      "W0318 11:52:33.914662 140129150785344 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=5.6476 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:52:33.915988 140129150785344 calibrate.py:79] seq_blocks.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=5.6476 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:52:33.918056 140129150785344 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.2._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.7462 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:52:33.918869 140129150785344 calibrate.py:79] seq_blocks.2._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.7462 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:52:33.920469 140129150785344 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.5._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=5.2123 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:52:33.921301 140129150785344 calibrate.py:79] seq_blocks.5._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=5.2123 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:52:33.922871 140129150785344 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.5._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5201 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:52:33.923691 140129150785344 calibrate.py:79] seq_blocks.5._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5201 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:52:33.925301 140129150785344 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.8._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=2.9248 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:52:33.926114 140129150785344 calibrate.py:79] seq_blocks.8._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=2.9248 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:52:33.927632 140129150785344 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.8._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5546 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:52:33.928440 140129150785344 calibrate.py:79] seq_blocks.8._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5546 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPerforming post calibration analysis for calibrator percentile_99.99...\u001b[0m\n",
      "I0318 11:52:33.930422 140129150785344 calibrate.py:53] Performing post calibration analysis for calibrator percentile_99.99...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis\u001b[0m\n",
      "I0318 11:52:33.931560 140129150785344 analysis.py:214] Starting transformation analysis\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results jsc-toy:\n",
      "+------------------------------+--------------+\n",
      "|            Metric            |    Value     |\n",
      "+------------------------------+--------------+\n",
      "| Average Validation Accuracy  |   0.73322    |\n",
      "|      Average Precision       |    0.7462    |\n",
      "|        Average Recall        |   0.73153    |\n",
      "|       Average F1 Score       |    0.7349    |\n",
      "|         Average Loss         |   0.76325    |\n",
      "|       Average Latency        |  3.2851 ms   |\n",
      "|   Average GPU Power Usage    |   57.504 W   |\n",
      "| Inference Energy Consumption | 0.052473 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "I0318 11:52:40.952058 140129150785344 analysis.py:330] \n",
      "Results jsc-toy:\n",
      "+------------------------------+--------------+\n",
      "|            Metric            |    Value     |\n",
      "+------------------------------+--------------+\n",
      "| Average Validation Accuracy  |   0.73322    |\n",
      "|      Average Precision       |    0.7462    |\n",
      "|        Average Recall        |   0.73153    |\n",
      "|       Average F1 Score       |    0.7349    |\n",
      "|         Average Loss         |   0.76325    |\n",
      "|       Average Latency        |  3.2851 ms   |\n",
      "|   Average GPU Power Usage    |   57.504 W   |\n",
      "| Inference Energy Consumption | 0.052473 mWh |\n",
      "+------------------------------+--------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPost calibration analysis complete.\u001b[0m\n",
      "I0318 11:52:40.954762 140129150785344 calibrate.py:66] Post calibration analysis complete.\n",
      "W0318 11:52:42.404549 140129150785344 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=7.2520 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:52:42.405567 140129150785344 calibrate.py:79] seq_blocks.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=7.2520 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:52:43.444594 140129150785344 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.2._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.7464 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:52:43.445366 140129150785344 calibrate.py:79] seq_blocks.2._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.7464 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:52:44.876339 140129150785344 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.5._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=6.2467 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:52:44.877133 140129150785344 calibrate.py:79] seq_blocks.5._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=6.2467 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:52:45.915652 140129150785344 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.5._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5179 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:52:45.916423 140129150785344 calibrate.py:79] seq_blocks.5._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5179 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:52:47.182084 140129150785344 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.8._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=3.1667 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:52:47.182881 140129150785344 calibrate.py:79] seq_blocks.8._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=3.1667 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:52:48.218744 140129150785344 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.8._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5531 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:52:48.219805 140129150785344 calibrate.py:79] seq_blocks.8._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5531 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPerforming post calibration analysis for calibrator mse...\u001b[0m\n",
      "I0318 11:52:48.221976 140129150785344 calibrate.py:53] Performing post calibration analysis for calibrator mse...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis\u001b[0m\n",
      "I0318 11:52:48.223003 140129150785344 analysis.py:214] Starting transformation analysis\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results jsc-toy:\n",
      "+------------------------------+--------------+\n",
      "|            Metric            |    Value     |\n",
      "+------------------------------+--------------+\n",
      "| Average Validation Accuracy  |   0.73288    |\n",
      "|      Average Precision       |   0.74547    |\n",
      "|        Average Recall        |   0.73127    |\n",
      "|       Average F1 Score       |   0.73454    |\n",
      "|         Average Loss         |   0.76504    |\n",
      "|       Average Latency        |   3.333 ms   |\n",
      "|   Average GPU Power Usage    |   57.744 W   |\n",
      "| Inference Energy Consumption | 0.053461 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "I0318 11:52:55.639227 140129150785344 analysis.py:330] \n",
      "Results jsc-toy:\n",
      "+------------------------------+--------------+\n",
      "|            Metric            |    Value     |\n",
      "+------------------------------+--------------+\n",
      "| Average Validation Accuracy  |   0.73288    |\n",
      "|      Average Precision       |   0.74547    |\n",
      "|        Average Recall        |   0.73127    |\n",
      "|       Average F1 Score       |   0.73454    |\n",
      "|         Average Loss         |   0.76504    |\n",
      "|       Average Latency        |   3.333 ms   |\n",
      "|   Average GPU Power Usage    |   57.744 W   |\n",
      "| Inference Energy Consumption | 0.053461 mWh |\n",
      "+------------------------------+--------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPost calibration analysis complete.\u001b[0m\n",
      "I0318 11:52:55.641868 140129150785344 calibrate.py:66] Post calibration analysis complete.\n",
      "W0318 11:53:03.151454 140129150785344 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=5.8408 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:53:03.152470 140129150785344 calibrate.py:79] seq_blocks.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=5.8408 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:53:06.453595 140129150785344 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.2._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.7465 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:53:06.454572 140129150785344 calibrate.py:79] seq_blocks.2._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.7465 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:53:13.467414 140129150785344 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.5._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=6.1224 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:53:13.468577 140129150785344 calibrate.py:79] seq_blocks.5._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=6.1224 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:53:16.683786 140129150785344 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.5._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5203 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:53:16.684908 140129150785344 calibrate.py:79] seq_blocks.5._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5203 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:53:22.960432 140129150785344 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.8._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=3.2948 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:53:22.961942 140129150785344 calibrate.py:79] seq_blocks.8._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=3.2948 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:53:26.095703 140129150785344 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.8._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5548 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:53:26.097137 140129150785344 calibrate.py:79] seq_blocks.8._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.5548 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPerforming post calibration analysis for calibrator entropy...\u001b[0m\n",
      "I0318 11:53:26.099242 140129150785344 calibrate.py:53] Performing post calibration analysis for calibrator entropy...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis\u001b[0m\n",
      "I0318 11:53:26.100685 140129150785344 analysis.py:214] Starting transformation analysis\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results jsc-toy:\n",
      "+------------------------------+--------------+\n",
      "|            Metric            |    Value     |\n",
      "+------------------------------+--------------+\n",
      "| Average Validation Accuracy  |   0.73333    |\n",
      "|      Average Precision       |   0.74622    |\n",
      "|        Average Recall        |   0.73161    |\n",
      "|       Average F1 Score       |   0.73496    |\n",
      "|         Average Loss         |   0.76394    |\n",
      "|       Average Latency        |  3.3796 ms   |\n",
      "|   Average GPU Power Usage    |   58.367 W   |\n",
      "| Inference Energy Consumption | 0.054794 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "I0318 11:53:33.269221 140129150785344 analysis.py:330] \n",
      "Results jsc-toy:\n",
      "+------------------------------+--------------+\n",
      "|            Metric            |    Value     |\n",
      "+------------------------------+--------------+\n",
      "| Average Validation Accuracy  |   0.73333    |\n",
      "|      Average Precision       |   0.74622    |\n",
      "|        Average Recall        |   0.73161    |\n",
      "|       Average F1 Score       |   0.73496    |\n",
      "|         Average Loss         |   0.76394    |\n",
      "|       Average Latency        |  3.3796 ms   |\n",
      "|   Average GPU Power Usage    |   58.367 W   |\n",
      "| Inference Energy Consumption | 0.054794 mWh |\n",
      "+------------------------------+--------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPost calibration analysis complete.\u001b[0m\n",
      "I0318 11:53:33.272923 140129150785344 calibrate.py:66] Post calibration analysis complete.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mSucceeded in calibrating the model in PyTorch!\u001b[0m\n",
      "I0318 11:53:33.274189 140129150785344 calibrate.py:159] Succeeded in calibrating the model in PyTorch!\n"
     ]
    }
   ],
   "source": [
    "mg, _ = tensorrt_calibrate_transform_pass(mg, pass_args=tensorrt_quantize_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results, the 99% `percentile` clips too many values during the amax calibration, comprimising the loss. However 99.99% demonstrates higher validation accuracy alongside `mse` and `entropy` for `jsc-toy`. For such a small model, the methods are not highly distinguished, however for larger models this calibration process will be important for ensuring the quantized model still performs well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1.3 Quantized Aware Training (QAT)\n",
    "\n",
    "The `tensorrt_fine_tune_transform_pass` is used to fine tune the quantized model. \n",
    "\n",
    "For QAT it is typical to employ 10% of the original training epochs, starting at 1% of the initial training learning rate, and a cosine annealing learning rate schedule that follows the decreasing half of a cosine period, down to 1% of the initial fine tuning learning rate (0.01% of the initial training learning rate). However this default can be overidden by setting the `epochs`, `initial_learning_rate` and `final_learning_rate` in `passes.tensorrt_quantize.fine_tune`.\n",
    "\n",
    "The fine tuned checkpoints are stored in the ckpts/fine_tuning folder:\n",
    "\n",
    "```\n",
    "mase_output\n",
    "â””â”€â”€ tensorrt\n",
    "    â””â”€â”€ quantization\n",
    "        â”œâ”€â”€ cache\n",
    "        â”œâ”€â”€ ckpts\n",
    "        â”‚   â””â”€â”€ fine_tuning\n",
    "        â”œâ”€â”€ json\n",
    "        â”œâ”€â”€ onnx\n",
    "        â””â”€â”€ trt\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting Fine Tuning...\u001b[0m\n",
      "I0318 11:53:39.080320 140129150785344 fine_tune.py:62] Starting Fine Tuning...\n",
      "I0318 11:53:39.378298 140129150785344 rank_zero.py:64] GPU available: True (cuda), used: True\n",
      "I0318 11:53:39.412764 140129150785344 rank_zero.py:64] TPU available: False, using: 0 TPU cores\n",
      "I0318 11:53:39.413215 140129150785344 rank_zero.py:64] IPU available: False, using: 0 IPUs\n",
      "I0318 11:53:39.413661 140129150785344 rank_zero.py:64] HPU available: False, using: 0 HPUs\n",
      "I0318 11:53:39.429783 140129150785344 rank_zero.py:64] You are using a CUDA device ('NVIDIA GeForce RTX 3070') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "I0318 11:53:41.737962 140129150785344 cuda.py:61] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "I0318 11:53:41.747797 140129150785344 model_summary.py:94] \n",
      "  | Name      | Type               | Params\n",
      "-------------------------------------------------\n",
      "0 | model     | GraphModule        | 327   \n",
      "1 | loss_fn   | CrossEntropyLoss   | 0     \n",
      "2 | acc_train | MulticlassAccuracy | 0     \n",
      "3 | loss_val  | MeanMetric         | 0     \n",
      "4 | loss_test | MeanMetric         | 0     \n",
      "-------------------------------------------------\n",
      "327       Trainable params\n",
      "0         Non-trainable params\n",
      "327       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/mase/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/mase/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3084/3084 [01:18<00:00, 39.42it/s, v_num=2, train_acc_step=0.745, val_acc_epoch=0.733, val_loss_epoch=0.750]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0318 11:56:17.983453 140129150785344 rank_zero.py:64] `Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3084/3084 [01:18<00:00, 39.41it/s, v_num=2, train_acc_step=0.745, val_acc_epoch=0.733, val_loss_epoch=0.750]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mFine Tuning Complete\u001b[0m\n",
      "I0318 11:56:17.996509 140129150785344 fine_tune.py:121] Fine Tuning Complete\n"
     ]
    }
   ],
   "source": [
    "mg, _ = tensorrt_fine_tune_transform_pass(mg, pass_args=tensorrt_quantize_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1.4 TensorRT Quantization\n",
    "\n",
    "After QAT, we are now ready to convert the model to a tensorRT engine so that it can be run with the superior inference speeds. To do so, we use the `tensorrt_engine_interface_pass` which converts the `MaseGraph`'s model from a Pytorch one to an ONNX format as an intermediate stage of the conversion.\n",
    "\n",
    "During the conversion process, the `.onnx` and `.trt` files are stored to their respective folders shown in [Section 1.3](#section-13-quantized-aware-training-qat).\n",
    "\n",
    "This interface pass returns a dictionary containing the `onnx_path` and `trt_engine_path`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "I0318 11:56:33.023713 140129150785344 quantize.py:129] Converting PyTorch model to ONNX...\n",
      "/opt/conda/envs/mase/lib/python3.11/site-packages/pytorch_quantization/tensor_quant.py:363: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if min_amax < 0:\n",
      "/opt/conda/envs/mase/lib/python3.11/site-packages/pytorch_quantization/tensor_quant.py:366: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  max_bound = torch.tensor((2.0**(num_bits - 1 + int(unsigned))) - 1.0, device=amax.device)\n",
      "/opt/conda/envs/mase/lib/python3.11/site-packages/pytorch_quantization/tensor_quant.py:376: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if min_amax <= epsilon:  # Treat amax smaller than minimum representable of fp16 0\n",
      "/opt/conda/envs/mase/lib/python3.11/site-packages/pytorch_quantization/tensor_quant.py:382: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if min_amax <= epsilon:\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /root/mase/mase_output/tensorrt/quantization/onnx/2024_03_18/version_3/model.onnx\u001b[0m\n",
      "I0318 11:56:33.215245 140129150785344 quantize.py:152] ONNX Conversion Complete. Stored ONNX model to /root/mase/mase_output/tensorrt/quantization/onnx/2024_03_18/version_3/model.onnx\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "I0318 11:56:33.217170 140129150785344 quantize.py:55] Converting PyTorch model to TensorRT...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /root/mase/mase_output/tensorrt/quantization/trt/2024_03_18/version_0/model.trt\u001b[0m\n",
      "I0318 11:57:23.073653 140129150785344 quantize.py:124] TensorRT Conversion Complete. Stored trt model to /root/mase/mase_output/tensorrt/quantization/trt/2024_03_18/version_0/model.trt\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /root/mase/mase_output/tensorrt/quantization/json/2024_03_18/version_0/model.json\u001b[0m\n",
      "I0318 11:57:23.354130 140129150785344 quantize.py:168] TensorRT Model Summary Exported to /root/mase/mase_output/tensorrt/quantization/json/2024_03_18/version_0/model.json\n"
     ]
    }
   ],
   "source": [
    "mg, meta = tensorrt_engine_interface_pass(mg, pass_args=tensorrt_quantize_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1.5 Performance Analysis\n",
    "\n",
    "To showcase the improved inference speeds and to evaluate accuracy and other performance metrics, the `tensorrt_analysis_pass` can be used.\n",
    "\n",
    "The tensorRT engine path obtained the previous interface pass is now inputted into the the analysis pass. The same pass can take a MaseGraph as an input, as well as an ONNX graph. For this comparison, we will first run the anaylsis pass on the original unquantized model and then on the INT8 quantized model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis\u001b[0m\n",
      "I0318 11:58:21.058617 140129150785344 analysis.py:214] Starting transformation analysis\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results jsc-toy:\n",
      "+------------------------------+--------------+\n",
      "|            Metric            |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.73168    |\n",
      "|      Average Precision       |   0.74472    |\n",
      "|        Average Recall        |   0.73037    |\n",
      "|       Average F1 Score       |   0.73369    |\n",
      "|         Average Loss         |   0.76315    |\n",
      "|       Average Latency        |  0.76946 ms  |\n",
      "|   Average GPU Power Usage    |   49.458 W   |\n",
      "| Inference Energy Consumption | 0.010571 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "I0318 11:58:24.825791 140129150785344 analysis.py:330] \n",
      "Results jsc-toy:\n",
      "+------------------------------+--------------+\n",
      "|            Metric            |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.73168    |\n",
      "|      Average Precision       |   0.74472    |\n",
      "|        Average Recall        |   0.73037    |\n",
      "|       Average F1 Score       |   0.73369    |\n",
      "|         Average Loss         |   0.76315    |\n",
      "|       Average Latency        |  0.76946 ms  |\n",
      "|   Average GPU Power Usage    |   49.458 W   |\n",
      "| Inference Energy Consumption | 0.010571 mWh |\n",
      "+------------------------------+--------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "TensorRT Engine Input/Output Information:\n",
      "Index | Type    | DataType | Static Shape         | Dynamic Shape        | Name\n",
      "------|---------|----------|----------------------|----------------------|-----------------------\n",
      "0     | Input   | FLOAT    | (256, 16)              | (256, 16)              | input\n",
      "1     | Output  | FLOAT    | (256, 5)               | (256, 5)               | 109\u001b[0m\n",
      "I0318 11:58:24.843441 140129150785344 analysis.py:117] \n",
      "TensorRT Engine Input/Output Information:\n",
      "Index | Type    | DataType | Static Shape         | Dynamic Shape        | Name\n",
      "------|---------|----------|----------------------|----------------------|-----------------------\n",
      "0     | Input   | FLOAT    | (256, 16)              | (256, 16)              | input\n",
      "1     | Output  | FLOAT    | (256, 5)               | (256, 5)               | 109\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis\u001b[0m\n",
      "I0318 11:58:24.845013 140129150785344 analysis.py:214] Starting transformation analysis\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results jsc-toy-quantized:\n",
      "+------------------------------+---------------+\n",
      "|            Metric            |     Value     |\n",
      "+------------------------------+---------------+\n",
      "|    Average Test Accuracy     |    0.73385    |\n",
      "|      Average Precision       |    0.74995    |\n",
      "|        Average Recall        |    0.73411    |\n",
      "|       Average F1 Score       |    0.73781    |\n",
      "|         Average Loss         |    0.75142    |\n",
      "|       Average Latency        |  0.17908 ms   |\n",
      "|   Average GPU Power Usage    |   56.674 W    |\n",
      "| Inference Energy Consumption | 0.0028192 mWh |\n",
      "+------------------------------+---------------+\u001b[0m\n",
      "I0318 11:58:29.142338 140129150785344 analysis.py:330] \n",
      "Results jsc-toy-quantized:\n",
      "+------------------------------+---------------+\n",
      "|            Metric            |     Value     |\n",
      "+------------------------------+---------------+\n",
      "|    Average Test Accuracy     |    0.73385    |\n",
      "|      Average Precision       |    0.74995    |\n",
      "|        Average Recall        |    0.73411    |\n",
      "|       Average F1 Score       |    0.73781    |\n",
      "|         Average Loss         |    0.75142    |\n",
      "|       Average Latency        |  0.17908 ms   |\n",
      "|   Average GPU Power Usage    |   56.674 W    |\n",
      "| Inference Energy Consumption | 0.0028192 mWh |\n",
      "+------------------------------+---------------+\n"
     ]
    }
   ],
   "source": [
    "_, _ = tensorrt_analysis_pass(mg_original, pass_args=tensorrt_analysis_config)\n",
    "_, _ = tensorrt_analysis_pass(meta['trt_engine_path'], pass_args=tensorrt_analysis_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, the latency has decreased around 4x with the `jsc-toy` model without compromising accuracy due to the well calibrated amax and quantization-aware fine tuning. The inference energy consumption has thus also dropped tremendously and this is an excellent demonstration for the need to quantize in industry especially for LLMs in order to reduce energy usage. \n",
    "\n",
    "## Section 2. FP16 Quantization\n",
    "\n",
    "We will now load in a new toml configuration that uses FP16 instead of INT8, whilst keeping the other settings the exact same for a fair comparison. This time however, we will use chop from the terminal which runs all the passes showcased in [Section 1](#section-1---int8-quantization).\n",
    "\n",
    "Since float quantization does not require calibration, nor is it supported by `pytorch-quantization`, the model will not undergo fake quantization, unfortunately, for the time being this means QAT is unavailable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "841.95s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "[2024-03-18 12:05:03,339] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "INFO: Seed set to 0\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0318 12:05:04.995262 140114542536512 seed.py:54] Seed set to 0\n",
      "+-------------------------+------------------------+--------------+--------------------------+--------------------------+\n",
      "| Name                    |        Default         | Config. File |     Manual Override      |        Effective         |\n",
      "+-------------------------+------------------------+--------------+--------------------------+--------------------------+\n",
      "| task                    |     \u001b[38;5;8mclassification\u001b[0m     |     cls      |                          |           cls            |\n",
      "| load_name               |          \u001b[38;5;8mNone\u001b[0m          |              | /root/mase/mase_output/j | /root/mase/mase_output/j |\n",
      "|                         |                        |              | sc-toy-cls_jsc/best.ckpt | sc-toy-cls_jsc/best.ckpt |\n",
      "| load_type               |           \u001b[38;5;8mmz\u001b[0m           |              |            pl            |            pl            |\n",
      "| batch_size              |          \u001b[38;5;8m128\u001b[0m           |     256      |                          |           256            |\n",
      "| to_debug                |         False          |              |                          |          False           |\n",
      "| log_level               |          info          |              |                          |           info           |\n",
      "| report_to               |      tensorboard       |              |                          |       tensorboard        |\n",
      "| seed                    |           0            |              |                          |            0             |\n",
      "| quant_config            |          None          |              |                          |           None           |\n",
      "| training_optimizer      |          adam          |              |                          |           adam           |\n",
      "| trainer_precision       |        16-mixed        |              |                          |         16-mixed         |\n",
      "| learning_rate           |         \u001b[38;5;8m1e-05\u001b[0m          |    0.001     |                          |          0.001           |\n",
      "| weight_decay            |           0            |              |                          |            0             |\n",
      "| max_epochs              |           \u001b[38;5;8m20\u001b[0m           |      20      |                          |            20            |\n",
      "| max_steps               |           -1           |              |                          |            -1            |\n",
      "| accumulate_grad_batches |           1            |              |                          |            1             |\n",
      "| log_every_n_steps       |           50           |              |                          |            50            |\n",
      "| num_workers             |           32           |              |                          |            32            |\n",
      "| num_devices             |           1            |              |                          |            1             |\n",
      "| num_nodes               |           1            |              |                          |            1             |\n",
      "| accelerator             |          \u001b[38;5;8mauto\u001b[0m          |     gpu      |                          |           gpu            |\n",
      "| strategy                |          auto          |              |                          |           auto           |\n",
      "| is_to_auto_requeue      |         False          |              |                          |          False           |\n",
      "| github_ci               |         False          |              |                          |          False           |\n",
      "| disable_dataset_cache   |         False          |              |                          |          False           |\n",
      "| target                  |  xcu250-figd2104-2L-e  |              |                          |   xcu250-figd2104-2L-e   |\n",
      "| num_targets             |          100           |              |                          |           100            |\n",
      "| is_pretrained           |         False          |              |                          |          False           |\n",
      "| max_token_len           |          512           |              |                          |           512            |\n",
      "| project_dir             | /root/mase/mase_output |              |                          |  /root/mase/mase_output  |\n",
      "| project                 |          None          |              |                          |           None           |\n",
      "| model                   |          \u001b[38;5;8mNone\u001b[0m          |   jsc-toy    |                          |         jsc-toy          |\n",
      "| dataset                 |          \u001b[38;5;8mNone\u001b[0m          |     jsc      |                          |           jsc            |\n",
      "| t_max                   |           20           |              |                          |            20            |\n",
      "| eta_min                 |         1e-06          |              |                          |          1e-06           |\n",
      "+-------------------------+------------------------+--------------+--------------------------+--------------------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mInitialising model 'jsc-toy'...\u001b[0m\n",
      "I0318 12:05:05.005421 140114542536512 cli.py:841] Initialising model 'jsc-toy'...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mInitialising dataset 'jsc'...\u001b[0m\n",
      "I0318 12:05:05.028687 140114542536512 cli.py:869] Initialising dataset 'jsc'...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mProject will be created at /root/mase/mase_output/jsc-toy_cls_jsc_2024-03-18\u001b[0m\n",
      "I0318 12:05:05.029203 140114542536512 cli.py:905] Project will be created at /root/mase/mase_output/jsc-toy_cls_jsc_2024-03-18\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTransforming model 'jsc-toy'...\u001b[0m\n",
      "I0318 12:05:05.062428 140114542536512 cli.py:365] Transforming model 'jsc-toy'...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from /root/mase/mase_output/jsc-toy-cls_jsc/best.ckpt\u001b[0m\n",
      "I0318 12:05:07.504563 140114542536512 checkpoint_load.py:85] Loaded pytorch lightning checkpoint from /root/mase/mase_output/jsc-toy-cls_jsc/best.ckpt\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mApplying fake quantization to PyTorch model...\u001b[0m\n",
      "I0318 12:05:09.955551 140114542536512 utils.py:167] Applying fake quantization to PyTorch model...\n",
      "\u001b[33mWARNING \u001b[0m \u001b[34mINT8 precision not found in config. Skipping fake quantization.\u001b[0m\n",
      "W0318 12:05:09.955886 140114542536512 utils.py:170] INT8 precision not found in config. Skipping fake quantization.\n",
      "\u001b[33mWARNING \u001b[0m \u001b[34mINT8 precision not found in config. Skipping calibration.\u001b[0m\n",
      "W0318 12:05:09.956021 140114542536512 calibrate.py:86] INT8 precision not found in config. Skipping calibration.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mQuantized graph histogram:\u001b[0m\n",
      "I0318 12:05:09.979143 140114542536512 summary.py:84] Quantized graph histogram:\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "| Original type   | OP           |   Total |   Changed |   Unchanged |\n",
      "|-----------------+--------------+---------+-----------+-------------|\n",
      "| BatchNorm1d     | batch_norm1d |       4 |         0 |           4 |\n",
      "| Linear          | linear       |       3 |         0 |           3 |\n",
      "| ReLU            | relu         |       4 |         0 |           4 |\n",
      "| output          | output       |       1 |         0 |           1 |\n",
      "| x               | placeholder  |       1 |         0 |           1 |\u001b[0m\n",
      "I0318 12:05:09.979753 140114542536512 summary.py:85] \n",
      "| Original type   | OP           |   Total |   Changed |   Unchanged |\n",
      "|-----------------+--------------+---------+-----------+-------------|\n",
      "| BatchNorm1d     | batch_norm1d |       4 |         0 |           4 |\n",
      "| Linear          | linear       |       3 |         0 |           3 |\n",
      "| ReLU            | relu         |       4 |         0 |           4 |\n",
      "| output          | output       |       1 |         0 |           1 |\n",
      "| x               | placeholder  |       1 |         0 |           1 |\n",
      "\u001b[33mWARNING \u001b[0m \u001b[34mINT8 precision not found in config. Skipping QAT fine tuning.\u001b[0m\n",
      "W0318 12:05:09.980552 140114542536512 fine_tune.py:57] INT8 precision not found in config. Skipping QAT fine tuning.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mQuantized graph histogram:\u001b[0m\n",
      "I0318 12:05:09.989234 140114542536512 summary.py:84] Quantized graph histogram:\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "| Original type   | OP           |   Total |   Changed |   Unchanged |\n",
      "|-----------------+--------------+---------+-----------+-------------|\n",
      "| BatchNorm1d     | batch_norm1d |       4 |         0 |           4 |\n",
      "| Linear          | linear       |       3 |         0 |           3 |\n",
      "| ReLU            | relu         |       4 |         0 |           4 |\n",
      "| output          | output       |       1 |         0 |           1 |\n",
      "| x               | placeholder  |       1 |         0 |           1 |\u001b[0m\n",
      "I0318 12:05:09.989790 140114542536512 summary.py:85] \n",
      "| Original type   | OP           |   Total |   Changed |   Unchanged |\n",
      "|-----------------+--------------+---------+-----------+-------------|\n",
      "| BatchNorm1d     | batch_norm1d |       4 |         0 |           4 |\n",
      "| Linear          | linear       |       3 |         0 |           3 |\n",
      "| ReLU            | relu         |       4 |         0 |           4 |\n",
      "| output          | output       |       1 |         0 |           1 |\n",
      "| x               | placeholder  |       1 |         0 |           1 |\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "I0318 12:05:09.991120 140114542536512 quantize.py:129] Converting PyTorch model to ONNX...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /root/mase/mase_output/tensorrt/quantization/onnx/2024_03_18/version_4/model.onnx\u001b[0m\n",
      "I0318 12:05:12.502104 140114542536512 quantize.py:152] ONNX Conversion Complete. Stored ONNX model to /root/mase/mase_output/tensorrt/quantization/onnx/2024_03_18/version_4/model.onnx\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "I0318 12:05:12.502495 140114542536512 quantize.py:55] Converting PyTorch model to TensorRT...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /root/mase/mase_output/tensorrt/quantization/trt/2024_03_18/version_1/model.trt\u001b[0m\n",
      "I0318 12:05:27.317476 140114542536512 quantize.py:124] TensorRT Conversion Complete. Stored trt model to /root/mase/mase_output/tensorrt/quantization/trt/2024_03_18/version_1/model.trt\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Model Summary Exported to /root/mase/mase_output/tensorrt/quantization/json/2024_03_18/version_1/model.json\u001b[0m\n",
      "I0318 12:05:27.532299 140114542536512 quantize.py:168] TensorRT Model Summary Exported to /root/mase/mase_output/tensorrt/quantization/json/2024_03_18/version_1/model.json\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mQuantized graph histogram:\u001b[0m\n",
      "I0318 12:05:27.554346 140114542536512 summary.py:84] Quantized graph histogram:\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "| Original type   | OP           |   Total |   Changed |   Unchanged |\n",
      "|-----------------+--------------+---------+-----------+-------------|\n",
      "| BatchNorm1d     | batch_norm1d |       4 |         0 |           4 |\n",
      "| Linear          | linear       |       3 |         0 |           3 |\n",
      "| ReLU            | relu         |       4 |         0 |           4 |\n",
      "| output          | output       |       1 |         0 |           1 |\n",
      "| x               | placeholder  |       1 |         0 |           1 |\u001b[0m\n",
      "I0318 12:05:27.554947 140114542536512 summary.py:85] \n",
      "| Original type   | OP           |   Total |   Changed |   Unchanged |\n",
      "|-----------------+--------------+---------+-----------+-------------|\n",
      "| BatchNorm1d     | batch_norm1d |       4 |         0 |           4 |\n",
      "| Linear          | linear       |       3 |         0 |           3 |\n",
      "| ReLU            | relu         |       4 |         0 |           4 |\n",
      "| output          | output       |       1 |         0 |           1 |\n",
      "| x               | placeholder  |       1 |         0 |           1 |\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "TensorRT Engine Input/Output Information:\n",
      "Index | Type    | DataType | Static Shape         | Dynamic Shape        | Name\n",
      "------|---------|----------|----------------------|----------------------|-----------------------\n",
      "0     | Input   | FLOAT    | (256, 16)              | (256, 16)              | input\n",
      "1     | Output  | FLOAT    | (256, 5)               | (256, 5)               | 37\u001b[0m\n",
      "I0318 12:05:27.901508 140114542536512 analysis.py:117] \n",
      "TensorRT Engine Input/Output Information:\n",
      "Index | Type    | DataType | Static Shape         | Dynamic Shape        | Name\n",
      "------|---------|----------|----------------------|----------------------|-----------------------\n",
      "0     | Input   | FLOAT    | (256, 16)              | (256, 16)              | input\n",
      "1     | Output  | FLOAT    | (256, 5)               | (256, 5)               | 37\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis\u001b[0m\n",
      "I0318 12:05:27.901711 140114542536512 analysis.py:214] Starting transformation analysis\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/mase/machop/ch\", line 6, in <module>\n",
      "    ChopCLI().run()\n",
      "  File \"/root/mase/machop/chop/cli.py\", line 272, in run\n",
      "    run_action_fn()\n",
      "  File \"/root/mase/machop/chop/cli.py\", line 382, in _run_transform\n",
      "    transform(**transform_params)\n",
      "  File \"/root/mase/machop/chop/actions/transform.py\", line 150, in transform\n",
      "    _, _ = PASSES[\"tensorrt_analysis\"](\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/mase/machop/chop/passes/graph/transforms/tensorrt/quantize/analysis.py\", line 35, in tensorrt_analysis_pass\n",
      "    results = analysis.evaluate()\n",
      "              ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/mase/machop/chop/passes/graph/transforms/tensorrt/quantize/analysis.py\", line 219, in evaluate\n",
      "    if self.config['task'] == 'cls':\n",
      "       ~~~~~~~~~~~^^^^^^^^\n",
      "KeyError: 'task'\n"
     ]
    }
   ],
   "source": [
    "!ch transform --config ../../../machop/configs/tensorrt/jsc_toy_FP16_quantization_by_type.toml --load {JSC_CHECKPOINT_PATH} --load-type pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, `FP16` acheives a slighty higher test accuracy and a slightly lower latency (~10%) from that of INT8 quantization as expected. Now lets try a more complicated model - `vgg7`.\n",
    "\n",
    "## Section 3. Type-wise Mixed Precision on Larger Model\n",
    "We will now quantize `vgg7` which includes both convolutional and linear layers, however for this demonstration we want to quantize all layer types except the linear layers.\n",
    "\n",
    "In this case, we set:\n",
    "\n",
    "- The `by` parameter to `type`\n",
    "- The `quantize` parameter to true for `passes.tensorrt_quantize.conv2d.config` and `precision` parameter to 'INT8'.\n",
    "- The `input` and `weight` quantize axis for the conv2d layers.\n",
    "- The default `passes.tensorrt_quantize.default.config` to false. \n",
    "\n",
    "During the TensorRT quantization, the model's conv2d layers will be converted to an INT8 fake quantized form, whilst the linear layers are kept to their default 'FP16'. Calibration of the conv2d layers will be undergone and fine tuning.  \n",
    "\n",
    "You may either download a pretrained model [here](https://imperiallondon-my.sharepoint.com/:f:/g/personal/zz7522_ic_ac_uk/Emh3VT7Q_qRFmnp8kDrcgDoBwGUuzLwwKNtX8ZAt368jJQ?e=gsKONa), otherwise train it yourself as shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ch train --config ../../../machop/configs/tensorrt/vgg7_FP16_quantization_by_type.toml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now load the checkpoint in and quantize the model and compare it to the unquantized version as we did in [Section 1.5](#section-15-performance-analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG_CHECKPOINT_PATH = \"../../../mase_output/vgg7-pre-trained/test-accu-0.9332.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-18 10:10:20,960] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "INFO: Seed set to 0\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0318 10:10:22.721194 139701006645056 seed.py:54] Seed set to 0\n",
      "+-------------------------+------------------------+--------------+--------------------------+--------------------------+\n",
      "| Name                    |        Default         | Config. File |     Manual Override      |        Effective         |\n",
      "+-------------------------+------------------------+--------------+--------------------------+--------------------------+\n",
      "| task                    |     \u001b[38;5;8mclassification\u001b[0m     |     cls      |                          |           cls            |\n",
      "| load_name               |          \u001b[38;5;8mNone\u001b[0m          |              | /root/mase/mase_output/v | /root/mase/mase_output/v |\n",
      "|                         |                        |              |  gg7-pre-trained/test-   |  gg7-pre-trained/test-   |\n",
      "|                         |                        |              |     accu-0.9332.ckpt     |     accu-0.9332.ckpt     |\n",
      "| load_type               |           \u001b[38;5;8mmz\u001b[0m           |              |            pl            |            pl            |\n",
      "| batch_size              |          \u001b[38;5;8m128\u001b[0m           |     256      |                          |           256            |\n",
      "| to_debug                |         False          |              |                          |          False           |\n",
      "| log_level               |          info          |              |                          |           info           |\n",
      "| report_to               |      tensorboard       |              |                          |       tensorboard        |\n",
      "| seed                    |           0            |              |                          |            0             |\n",
      "| quant_config            |          None          |              |                          |           None           |\n",
      "| training_optimizer      |          adam          |              |                          |           adam           |\n",
      "| trainer_precision       |        16-mixed        |              |                          |         16-mixed         |\n",
      "| learning_rate           |         \u001b[38;5;8m1e-05\u001b[0m          |    0.001     |                          |          0.001           |\n",
      "| weight_decay            |           0            |              |                          |            0             |\n",
      "| max_epochs              |           \u001b[38;5;8m20\u001b[0m           |      10      |                          |            10            |\n",
      "| max_steps               |           -1           |              |                          |            -1            |\n",
      "| accumulate_grad_batches |           1            |              |                          |            1             |\n",
      "| log_every_n_steps       |           50           |              |                          |            50            |\n",
      "| num_workers             |           32           |              |                          |            32            |\n",
      "| num_devices             |           1            |              |                          |            1             |\n",
      "| num_nodes               |           1            |              |                          |            1             |\n",
      "| accelerator             |          \u001b[38;5;8mauto\u001b[0m          |     gpu      |                          |           gpu            |\n",
      "| strategy                |          auto          |              |                          |           auto           |\n",
      "| is_to_auto_requeue      |         False          |              |                          |          False           |\n",
      "| github_ci               |         False          |              |                          |          False           |\n",
      "| disable_dataset_cache   |         False          |              |                          |          False           |\n",
      "| target                  |  xcu250-figd2104-2L-e  |              |                          |   xcu250-figd2104-2L-e   |\n",
      "| num_targets             |          100           |              |                          |           100            |\n",
      "| is_pretrained           |         False          |              |                          |          False           |\n",
      "| max_token_len           |          512           |              |                          |           512            |\n",
      "| project_dir             | /root/mase/mase_output |              |                          |  /root/mase/mase_output  |\n",
      "| project                 |          None          |              |                          |           None           |\n",
      "| model                   |          \u001b[38;5;8mNone\u001b[0m          |     vgg7     |                          |           vgg7           |\n",
      "| dataset                 |          \u001b[38;5;8mNone\u001b[0m          |   cifar10    |                          |         cifar10          |\n",
      "| t_max                   |           20           |              |                          |            20            |\n",
      "| eta_min                 |         1e-06          |              |                          |          1e-06           |\n",
      "+-------------------------+------------------------+--------------+--------------------------+--------------------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mInitialising model 'vgg7'...\u001b[0m\n",
      "I0318 10:10:22.731668 139701006645056 cli.py:841] Initialising model 'vgg7'...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mInitialising dataset 'cifar10'...\u001b[0m\n",
      "I0318 10:10:22.860316 139701006645056 cli.py:869] Initialising dataset 'cifar10'...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mProject will be created at /root/mase/mase_output/vgg7_cls_cifar10_2024-03-18\u001b[0m\n",
      "I0318 10:10:22.860811 139701006645056 cli.py:905] Project will be created at /root/mase/mase_output/vgg7_cls_cifar10_2024-03-18\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTransforming model 'vgg7'...\u001b[0m\n",
      "I0318 10:10:22.899374 139701006645056 cli.py:365] Transforming model 'vgg7'...\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from /root/mase/mase_output/vgg7-pre-trained/test-accu-0.9332.ckpt\u001b[0m\n",
      "I0318 10:10:28.596838 139701006645056 checkpoint_load.py:85] Loaded pytorch lightning checkpoint from /root/mase/mase_output/vgg7-pre-trained/test-accu-0.9332.ckpt\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mApplying fake quantization to PyTorch model...\u001b[0m\n",
      "I0318 10:10:33.645294 139701006645056 utils.py:166] Applying fake quantization to PyTorch model...\n",
      "\u001b[33mWARNING \u001b[0m \u001b[34mINT8 precision not found in config. Skipping fake quantization.\u001b[0m\n",
      "W0318 10:10:33.645636 139701006645056 utils.py:169] INT8 precision not found in config. Skipping fake quantization.\n",
      "\u001b[33mWARNING \u001b[0m \u001b[34mINT8 precision not found in config. Skipping calibration.\u001b[0m\n",
      "W0318 10:10:33.645772 139701006645056 calibrate.py:86] INT8 precision not found in config. Skipping calibration.\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/mase/machop/ch\", line 6, in <module>\n",
      "    ChopCLI().run()\n",
      "  File \"/root/mase/machop/chop/cli.py\", line 272, in run\n",
      "    run_action_fn()\n",
      "  File \"/root/mase/machop/chop/cli.py\", line 382, in _run_transform\n",
      "    transform(**transform_params)\n",
      "  File \"/root/mase/machop/chop/actions/transform.py\", line 119, in transform\n",
      "    ori_graph, graph, save_dir=pass_save_dir\n",
      "    ^^^^^^^^^\n",
      "UnboundLocalError: cannot access local variable 'ori_graph' where it is not associated with a value\n"
     ]
    }
   ],
   "source": [
    "!ch transform --config ../../../machop/configs/tensorrt/vgg7_INT8_quantization_by_type.toml --load {VGG_CHECKPOINT_PATH} --load-type pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 4. Layer-wise Mixed Precision\n",
    "\n",
    "So far we have strictly quantized either in INT8 or FP16. Now, we will show how to conduct layerwise mixed precision using the same `vgg7` model. In this case we will show how for instance, layer 0 and 1 can be set to FP16, while layer 2 and 3 can be INT8 quantized. \n",
    "\n",
    "For this, we set:\n",
    "- The `by` parameter to `name`\n",
    "- The `precision` to 'FP16' for `passes.tensorrt_quantize.feature_layers_0.config and passes.tensorrt_quantize.feature_layers_1.config`\n",
    "- The `precision` to 'INT8' for `passes.tensorrt_quantize.feature_layers_0.config and passes.tensorrt_quantize.feature_layers_1.config`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/mase/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-18 11:38:55,375] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mSet logging level to info\u001b[0m\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0318 11:38:56.826868 139779632510784 logger.py:44] Set logging level to info\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import toml\n",
    "from copy import copy, deepcopy\n",
    "\n",
    "# Figure out the correct path\n",
    "machop_path = Path(\".\").resolve().parent.parent.parent /\"machop\"\n",
    "assert machop_path.exists(), \"Failed to find machop at: {}\".format(machop_path)\n",
    "sys.path.append(str(machop_path))\n",
    "\n",
    "# Add directory to the PATH so that chop can be called\n",
    "new_path = \"../../../machop\"\n",
    "full_path = os.path.abspath(new_path)\n",
    "os.environ['PATH'] += os.pathsep + full_path\n",
    "\n",
    "from chop.tools.utils import to_numpy_if_tensor\n",
    "from chop.tools.logger import set_logging_verbosity\n",
    "from chop.tools import get_cf_args, get_dummy_input\n",
    "from chop.passes.graph.utils import deepcopy_mase_graph\n",
    "from chop.tools.get_input import InputGenerator\n",
    "from chop.tools.checkpoint_load import load_model\n",
    "from chop.ir import MaseGraph\n",
    "from chop.models import get_model_info, get_model, get_tokenizer\n",
    "from chop.dataset import MaseDataModule, get_dataset_info\n",
    "from chop.passes.graph.transforms import metadata_value_type_cast_transform_pass\n",
    "from chop.passes.graph import (\n",
    "    summarize_quantization_analysis_pass,\n",
    "    add_common_metadata_analysis_pass,\n",
    "    init_metadata_analysis_pass,\n",
    "    add_software_metadata_analysis_pass,\n",
    "    tensorrt_calibrate_transform_pass,\n",
    "    tensorrt_fake_quantize_transform_pass,\n",
    "    tensorrt_fine_tune_transform_pass,\n",
    "    tensorrt_engine_interface_pass,\n",
    "    tensorrt_analysis_pass,\n",
    "    )\n",
    "\n",
    "set_logging_verbosity(\"info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Path to your TOML file\n",
    "toml_file_path = '../../../machop/configs/tensorrt/vgg7_layerwise_mixed_precision.toml'\n",
    "\n",
    "# Reading TOML file and converting it into a Python dictionary\n",
    "with open(toml_file_path, 'r') as toml_file:\n",
    "    pass_args = toml.load(toml_file)\n",
    "\n",
    "# Extract the 'passes.tensorrt_quantize' section and its children\n",
    "tensorrt_quantize_config = pass_args.get('passes', {}).get('tensorrt_quantize', {})\n",
    "# Extract the 'passes.tensorrt_analysis' section and its children\n",
    "tensorrt_analysis_config = pass_args.get('passes', {}).get('tensorrt_analysis', {})\n",
    "\n",
    "# Load the basics in\n",
    "model_name = pass_args['model']\n",
    "dataset_name = pass_args['dataset']\n",
    "max_epochs = pass_args['max_epochs']\n",
    "batch_size = pass_args['batch_size']\n",
    "learning_rate = pass_args['learning_rate']\n",
    "accelerator = pass_args['accelerator']\n",
    "\n",
    "data_module = MaseDataModule(\n",
    "    name=dataset_name,\n",
    "    batch_size=batch_size,\n",
    "    model_name=model_name,\n",
    "    num_workers=0,\n",
    ")\n",
    "data_module.prepare_data()\n",
    "data_module.setup()\n",
    "\n",
    "# Add the data_module and other necessary information to the configs\n",
    "configs = [tensorrt_quantize_config, tensorrt_analysis_config]\n",
    "for config in configs:\n",
    "    config['task'] = pass_args['task']\n",
    "    config['batch_size'] = pass_args['batch_size']\n",
    "    config['model'] = pass_args['model']\n",
    "    config['data_module'] = data_module\n",
    "    config['accelerator'] = 'cuda' if pass_args['accelerator'] == 'gpu' else pass_args['accelerator']\n",
    "    if config['accelerator'] == 'gpu':\n",
    "        os.environ['CUDA_MODULE_LOADING'] = 'LAZY'\n",
    "\n",
    "model_info = get_model_info(model_name)\n",
    "model = get_model(\n",
    "    model_name,\n",
    "    task=\"cls\",\n",
    "    dataset_info=data_module.dataset_info,\n",
    "    pretrained=False)\n",
    "\n",
    "\n",
    "input_generator = InputGenerator(\n",
    "    data_module=data_module,\n",
    "    model_info=model_info,\n",
    "    task=\"cls\",\n",
    "    which_dataloader=\"train\",\n",
    ")\n",
    "\n",
    "# generate the mase graph and initialize node metadata\n",
    "mg = MaseGraph(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from ../../../mase_output/vgg7-pre-trained/test-accu-0.9332.ckpt\u001b[0m\n",
      "I0318 11:23:31.613022 140342552557376 checkpoint_load.py:85] Loaded pytorch lightning checkpoint from ../../../mase_output/vgg7-pre-trained/test-accu-0.9332.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Load in the trained checkpoint - change this accordingly\n",
    "VGG_CHECKPOINT_PATH = \"../../../mase_output/vgg7-pre-trained/test-accu-0.9332.ckpt\"\n",
    "\n",
    "model = load_model(load_name=VGG_CHECKPOINT_PATH, load_type=\"pl\", model=model)\n",
    "\n",
    "# Initiate metadata\n",
    "dummy_in = next(iter(input_generator))\n",
    "_ = model(**dummy_in)\n",
    "mg, _ = init_metadata_analysis_pass(mg, None)\n",
    "\n",
    "mg_original = deepcopy_mase_graph(mg)\n",
    "\n",
    "mg, _ = add_common_metadata_analysis_pass(mg, {\"dummy_in\": dummy_in})\n",
    "mg, _ = add_software_metadata_analysis_pass(mg, None)\n",
    "mg, _ = metadata_value_type_cast_transform_pass(mg, pass_args={\"fn\": to_numpy_if_tensor})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis\u001b[0m\n",
      "I0318 09:55:37.107798 140195009255232 analysis.py:214] Starting transformation analysis\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results vgg7:\n",
      "+------------------------------+-------------+\n",
      "|            Metric            |    Value    |\n",
      "+------------------------------+-------------+\n",
      "|    Average Test Accuracy     |   0.91967   |\n",
      "|      Average Precision       |   0.92315   |\n",
      "|        Average Recall        |   0.92362   |\n",
      "|       Average F1 Score       |   0.92326   |\n",
      "|         Average Loss         |   0.23674   |\n",
      "|       Average Latency        |  28.123 ms  |\n",
      "|   Average GPU Power Usage    |  100.17 W   |\n",
      "| Inference Energy Consumption | 0.78256 mWh |\n",
      "+------------------------------+-------------+\u001b[0m\n",
      "I0318 09:55:40.969246 140195009255232 analysis.py:330] \n",
      "Results vgg7:\n",
      "+------------------------------+-------------+\n",
      "|            Metric            |    Value    |\n",
      "+------------------------------+-------------+\n",
      "|    Average Test Accuracy     |   0.91967   |\n",
      "|      Average Precision       |   0.92315   |\n",
      "|        Average Recall        |   0.92362   |\n",
      "|       Average F1 Score       |   0.92326   |\n",
      "|         Average Loss         |   0.23674   |\n",
      "|       Average Latency        |  28.123 ms  |\n",
      "|   Average GPU Power Usage    |  100.17 W   |\n",
      "| Inference Energy Consumption | 0.78256 mWh |\n",
      "+------------------------------+-------------+\n"
     ]
    }
   ],
   "source": [
    "_, _ = tensorrt_analysis_pass(mg, pass_args=tensorrt_analysis_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mApplying fake quantization to PyTorch model...\u001b[0m\n",
      "I0318 11:28:17.732462 140342552557376 utils.py:199] Applying fake quantization to PyTorch model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mFake quantization applied to PyTorch model.\u001b[0m\n",
      "I0318 11:28:18.571809 140342552557376 utils.py:224] Fake quantization applied to PyTorch model.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting calibration of the model in PyTorch...\u001b[0m\n",
      "I0318 11:28:18.574708 140342552557376 calibrate.py:91] Starting calibration of the model in PyTorch...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "I0318 11:28:18.593663 140342552557376 calibrate.py:100] Disabling Quantization and Enabling Calibration\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "I0318 11:28:18.595410 140342552557376 calibrate.py:100] Disabling Quantization and Enabling Calibration\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "I0318 11:28:18.596705 140342552557376 calibrate.py:100] Disabling Quantization and Enabling Calibration\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "I0318 11:28:18.597985 140342552557376 calibrate.py:100] Disabling Quantization and Enabling Calibration\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "I0318 11:28:18.599245 140342552557376 calibrate.py:100] Disabling Quantization and Enabling Calibration\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "I0318 11:28:18.600471 140342552557376 calibrate.py:100] Disabling Quantization and Enabling Calibration\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "I0318 11:28:18.601733 140342552557376 calibrate.py:100] Disabling Quantization and Enabling Calibration\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "I0318 11:28:18.602964 140342552557376 calibrate.py:100] Disabling Quantization and Enabling Calibration\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "I0318 11:28:18.605333 140342552557376 calibrate.py:100] Disabling Quantization and Enabling Calibration\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "I0318 11:28:18.606415 140342552557376 calibrate.py:100] Disabling Quantization and Enabling Calibration\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "I0318 11:28:18.607586 140342552557376 calibrate.py:100] Disabling Quantization and Enabling Calibration\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "I0318 11:28:18.608670 140342552557376 calibrate.py:100] Disabling Quantization and Enabling Calibration\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "I0318 11:28:18.609715 140342552557376 calibrate.py:100] Disabling Quantization and Enabling Calibration\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "I0318 11:28:18.610790 140342552557376 calibrate.py:100] Disabling Quantization and Enabling Calibration\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "I0318 11:28:18.611837 140342552557376 calibrate.py:100] Disabling Quantization and Enabling Calibration\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mDisabling Quantization and Enabling Calibration\u001b[0m\n",
      "I0318 11:28:18.612829 140342552557376 calibrate.py:100] Disabling Quantization and Enabling Calibration\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "I0318 11:28:21.197682 140342552557376 calibrate.py:121] Enabling Quantization and Disabling Calibration\n",
      "W0318 11:28:21.199681 140342552557376 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "I0318 11:28:21.200521 140342552557376 calibrate.py:121] Enabling Quantization and Disabling Calibration\n",
      "W0318 11:28:21.201774 140342552557376 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "I0318 11:28:21.202453 140342552557376 calibrate.py:121] Enabling Quantization and Disabling Calibration\n",
      "W0318 11:28:21.203719 140342552557376 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "I0318 11:28:21.204330 140342552557376 calibrate.py:121] Enabling Quantization and Disabling Calibration\n",
      "W0318 11:28:21.205599 140342552557376 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "I0318 11:28:21.206325 140342552557376 calibrate.py:121] Enabling Quantization and Disabling Calibration\n",
      "W0318 11:28:21.207642 140342552557376 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "I0318 11:28:21.208199 140342552557376 calibrate.py:121] Enabling Quantization and Disabling Calibration\n",
      "W0318 11:28:21.209242 140342552557376 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "I0318 11:28:21.209810 140342552557376 calibrate.py:121] Enabling Quantization and Disabling Calibration\n",
      "W0318 11:28:21.210819 140342552557376 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "I0318 11:28:21.211365 140342552557376 calibrate.py:121] Enabling Quantization and Disabling Calibration\n",
      "W0318 11:28:21.212429 140342552557376 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "I0318 11:28:21.212999 140342552557376 calibrate.py:121] Enabling Quantization and Disabling Calibration\n",
      "W0318 11:28:21.214085 140342552557376 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "I0318 11:28:21.214655 140342552557376 calibrate.py:121] Enabling Quantization and Disabling Calibration\n",
      "W0318 11:28:21.215662 140342552557376 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "I0318 11:28:21.216244 140342552557376 calibrate.py:121] Enabling Quantization and Disabling Calibration\n",
      "W0318 11:28:21.217268 140342552557376 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "I0318 11:28:21.217990 140342552557376 calibrate.py:121] Enabling Quantization and Disabling Calibration\n",
      "W0318 11:28:21.219000 140342552557376 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "I0318 11:28:21.219562 140342552557376 calibrate.py:121] Enabling Quantization and Disabling Calibration\n",
      "W0318 11:28:21.220567 140342552557376 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "I0318 11:28:21.221132 140342552557376 calibrate.py:121] Enabling Quantization and Disabling Calibration\n",
      "W0318 11:28:21.222173 140342552557376 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "I0318 11:28:21.222737 140342552557376 calibrate.py:121] Enabling Quantization and Disabling Calibration\n",
      "W0318 11:28:21.223725 140342552557376 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEnabling Quantization and Disabling Calibration\u001b[0m\n",
      "I0318 11:28:21.224255 140342552557376 calibrate.py:121] Enabling Quantization and Disabling Calibration\n",
      "W0318 11:28:21.225344 140342552557376 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "W0318 11:28:21.243050 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0318 11:28:21.243606 140342552557376 tensor_quantizer.py:239] Call .cuda() if running on GPU after loading calibrated amax.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.3._input_quantizer       : TensorQuantizer(8bit fake per-tensor amax=3.3064 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:21.244405 140342552557376 calibrate.py:79] feature_layers.3._input_quantizer       : TensorQuantizer(8bit fake per-tensor amax=3.3064 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:21.246361 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.3._weight_quantizer      : TensorQuantizer(8bit fake per-tensor amax=0.2366 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:21.247056 140342552557376 calibrate.py:79] feature_layers.3._weight_quantizer      : TensorQuantizer(8bit fake per-tensor amax=0.2366 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:21.248930 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.7._input_quantizer       : TensorQuantizer(8bit fake per-tensor amax=1.8229 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:21.249636 140342552557376 calibrate.py:79] feature_layers.7._input_quantizer       : TensorQuantizer(8bit fake per-tensor amax=1.8229 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:21.251572 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.7._weight_quantizer      : TensorQuantizer(8bit fake per-tensor amax=0.2296 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:21.252292 140342552557376 calibrate.py:79] feature_layers.7._weight_quantizer      : TensorQuantizer(8bit fake per-tensor amax=0.2296 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:21.253920 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.10._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=1.4558 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:21.254510 140342552557376 calibrate.py:79] feature_layers.10._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=1.4558 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:21.256041 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.10._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.2080 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:21.256649 140342552557376 calibrate.py:79] feature_layers.10._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.2080 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:21.258250 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.14._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=1.9219 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:21.258848 140342552557376 calibrate.py:79] feature_layers.14._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=1.9219 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:21.260337 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.14._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.2013 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:21.260950 140342552557376 calibrate.py:79] feature_layers.14._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.2013 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:21.262467 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.17._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=1.6114 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:21.263044 140342552557376 calibrate.py:79] feature_layers.17._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=1.6114 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:21.264503 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.17._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.1879 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:21.265105 140342552557376 calibrate.py:79] feature_layers.17._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.1879 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:21.266860 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mclassifier.0._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=2.3207 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:21.267887 140342552557376 calibrate.py:79] classifier.0._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=2.3207 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:21.269870 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mclassifier.0._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.0907 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:21.270471 140342552557376 calibrate.py:79] classifier.0._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.0907 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:21.271997 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mclassifier.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=9.7149 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:21.272617 140342552557376 calibrate.py:79] classifier.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=9.7149 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:21.274109 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mclassifier.2._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.0590 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:21.274774 140342552557376 calibrate.py:79] classifier.2._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.0590 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:21.276411 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlast_layer._input_quantizer             : TensorQuantizer(8bit fake per-tensor amax=7.4151 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:21.277001 140342552557376 calibrate.py:79] last_layer._input_quantizer             : TensorQuantizer(8bit fake per-tensor amax=7.4151 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:21.278594 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlast_layer._weight_quantizer            : TensorQuantizer(8bit fake per-tensor amax=0.1019 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:21.279222 140342552557376 calibrate.py:79] last_layer._weight_quantizer            : TensorQuantizer(8bit fake per-tensor amax=0.1019 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPerforming post calibration analysis for calibrator percentile_99.0...\u001b[0m\n",
      "I0318 11:28:21.282034 140342552557376 calibrate.py:53] Performing post calibration analysis for calibrator percentile_99.0...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis\u001b[0m\n",
      "I0318 11:28:21.283648 140342552557376 analysis.py:214] Starting transformation analysis\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results vgg7:\n",
      "+------------------------------+------------+\n",
      "|            Metric            |   Value    |\n",
      "+------------------------------+------------+\n",
      "|    Average Test Accuracy     |  0.86901   |\n",
      "|      Average Precision       |  0.87585   |\n",
      "|        Average Recall        |  0.87477   |\n",
      "|       Average F1 Score       |  0.87472   |\n",
      "|         Average Loss         |   0.6701   |\n",
      "|       Average Latency        | 39.118 ms  |\n",
      "|   Average GPU Power Usage    |  96.331 W  |\n",
      "| Inference Energy Consumption | 1.0467 mWh |\n",
      "+------------------------------+------------+\u001b[0m\n",
      "I0318 11:28:25.935484 140342552557376 analysis.py:330] \n",
      "Results vgg7:\n",
      "+------------------------------+------------+\n",
      "|            Metric            |   Value    |\n",
      "+------------------------------+------------+\n",
      "|    Average Test Accuracy     |  0.86901   |\n",
      "|      Average Precision       |  0.87585   |\n",
      "|        Average Recall        |  0.87477   |\n",
      "|       Average F1 Score       |  0.87472   |\n",
      "|         Average Loss         |   0.6701   |\n",
      "|       Average Latency        | 39.118 ms  |\n",
      "|   Average GPU Power Usage    |  96.331 W  |\n",
      "| Inference Energy Consumption | 1.0467 mWh |\n",
      "+------------------------------+------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPost calibration analysis complete.\u001b[0m\n",
      "I0318 11:28:25.938501 140342552557376 calibrate.py:66] Post calibration analysis complete.\n",
      "W0318 11:28:25.940452 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.3._input_quantizer       : TensorQuantizer(8bit fake per-tensor amax=6.0252 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:25.941426 140342552557376 calibrate.py:79] feature_layers.3._input_quantizer       : TensorQuantizer(8bit fake per-tensor amax=6.0252 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:25.943193 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.3._weight_quantizer      : TensorQuantizer(8bit fake per-tensor amax=0.3704 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:25.943901 140342552557376 calibrate.py:79] feature_layers.3._weight_quantizer      : TensorQuantizer(8bit fake per-tensor amax=0.3704 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:25.945704 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.7._input_quantizer       : TensorQuantizer(8bit fake per-tensor amax=3.3006 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:25.946482 140342552557376 calibrate.py:79] feature_layers.7._input_quantizer       : TensorQuantizer(8bit fake per-tensor amax=3.3006 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:25.949194 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.7._weight_quantizer      : TensorQuantizer(8bit fake per-tensor amax=0.3621 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:25.950498 140342552557376 calibrate.py:79] feature_layers.7._weight_quantizer      : TensorQuantizer(8bit fake per-tensor amax=0.3621 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:25.952027 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.10._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=2.4138 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:25.952803 140342552557376 calibrate.py:79] feature_layers.10._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=2.4138 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:25.954279 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.10._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.2821 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:25.955048 140342552557376 calibrate.py:79] feature_layers.10._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.2821 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:25.956552 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.14._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=2.9919 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:25.957344 140342552557376 calibrate.py:79] feature_layers.14._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=2.9919 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:25.958792 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.14._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.2734 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:25.959579 140342552557376 calibrate.py:79] feature_layers.14._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.2734 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:25.961067 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.17._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=2.7116 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:25.961866 140342552557376 calibrate.py:79] feature_layers.17._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=2.7116 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:25.963307 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.17._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.2519 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:25.964072 140342552557376 calibrate.py:79] feature_layers.17._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.2519 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:25.965596 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mclassifier.0._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=4.0080 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:25.966368 140342552557376 calibrate.py:79] classifier.0._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=4.0080 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:25.967808 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mclassifier.0._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.1603 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:25.968582 140342552557376 calibrate.py:79] classifier.0._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.1603 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:25.970146 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mclassifier.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=37.9196 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:25.970953 140342552557376 calibrate.py:79] classifier.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=37.9196 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:25.972397 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mclassifier.2._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.1175 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:25.973172 140342552557376 calibrate.py:79] classifier.2._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.1175 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:25.974653 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlast_layer._input_quantizer             : TensorQuantizer(8bit fake per-tensor amax=18.9375 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:25.975427 140342552557376 calibrate.py:79] last_layer._input_quantizer             : TensorQuantizer(8bit fake per-tensor amax=18.9375 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:25.976882 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlast_layer._weight_quantizer            : TensorQuantizer(8bit fake per-tensor amax=0.1626 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:25.977659 140342552557376 calibrate.py:79] last_layer._weight_quantizer            : TensorQuantizer(8bit fake per-tensor amax=0.1626 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPerforming post calibration analysis for calibrator percentile_99.9...\u001b[0m\n",
      "I0318 11:28:25.980097 140342552557376 calibrate.py:53] Performing post calibration analysis for calibrator percentile_99.9...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis\u001b[0m\n",
      "I0318 11:28:25.981252 140342552557376 analysis.py:214] Starting transformation analysis\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results vgg7:\n",
      "+------------------------------+------------+\n",
      "|            Metric            |   Value    |\n",
      "+------------------------------+------------+\n",
      "| Average Validation Accuracy  |  0.91902   |\n",
      "|      Average Precision       |  0.92231   |\n",
      "|        Average Recall        |  0.92259   |\n",
      "|       Average F1 Score       |  0.92233   |\n",
      "|         Average Loss         |  0.23545   |\n",
      "|       Average Latency        | 38.241 ms  |\n",
      "|   Average GPU Power Usage    |  98.32 W   |\n",
      "| Inference Energy Consumption | 1.0444 mWh |\n",
      "+------------------------------+------------+\u001b[0m\n",
      "I0318 11:28:30.514988 140342552557376 analysis.py:330] \n",
      "Results vgg7:\n",
      "+------------------------------+------------+\n",
      "|            Metric            |   Value    |\n",
      "+------------------------------+------------+\n",
      "| Average Validation Accuracy  |  0.91902   |\n",
      "|      Average Precision       |  0.92231   |\n",
      "|        Average Recall        |  0.92259   |\n",
      "|       Average F1 Score       |  0.92233   |\n",
      "|         Average Loss         |  0.23545   |\n",
      "|       Average Latency        | 38.241 ms  |\n",
      "|   Average GPU Power Usage    |  98.32 W   |\n",
      "| Inference Energy Consumption | 1.0444 mWh |\n",
      "+------------------------------+------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPost calibration analysis complete.\u001b[0m\n",
      "I0318 11:28:30.517491 140342552557376 calibrate.py:66] Post calibration analysis complete.\n",
      "W0318 11:28:30.519387 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.3._input_quantizer       : TensorQuantizer(8bit fake per-tensor amax=8.8229 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:30.520300 140342552557376 calibrate.py:79] feature_layers.3._input_quantizer       : TensorQuantizer(8bit fake per-tensor amax=8.8229 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:30.521599 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.3._weight_quantizer      : TensorQuantizer(8bit fake per-tensor amax=0.4801 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:30.522299 140342552557376 calibrate.py:79] feature_layers.3._weight_quantizer      : TensorQuantizer(8bit fake per-tensor amax=0.4801 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:30.523626 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.7._input_quantizer       : TensorQuantizer(8bit fake per-tensor amax=4.6778 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:30.524185 140342552557376 calibrate.py:79] feature_layers.7._input_quantizer       : TensorQuantizer(8bit fake per-tensor amax=4.6778 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:30.525709 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.7._weight_quantizer      : TensorQuantizer(8bit fake per-tensor amax=0.5323 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:30.526466 140342552557376 calibrate.py:79] feature_layers.7._weight_quantizer      : TensorQuantizer(8bit fake per-tensor amax=0.5323 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:30.527942 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.10._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=3.4064 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:30.528787 140342552557376 calibrate.py:79] feature_layers.10._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=3.4064 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:30.530232 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.10._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.3551 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:30.530984 140342552557376 calibrate.py:79] feature_layers.10._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.3551 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:30.532467 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.14._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=4.1424 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:30.533243 140342552557376 calibrate.py:79] feature_layers.14._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=4.1424 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:30.534674 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.14._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.3452 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:30.535426 140342552557376 calibrate.py:79] feature_layers.14._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.3452 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:30.536897 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.17._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=3.9340 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:30.537687 140342552557376 calibrate.py:79] feature_layers.17._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=3.9340 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:30.539270 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.17._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.3140 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:30.539996 140342552557376 calibrate.py:79] feature_layers.17._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.3140 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:30.541348 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mclassifier.0._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=6.0178 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:30.542055 140342552557376 calibrate.py:79] classifier.0._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=6.0178 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:30.543355 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mclassifier.0._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.2223 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:30.544059 140342552557376 calibrate.py:79] classifier.0._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.2223 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:30.545431 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mclassifier.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=78.4245 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:30.545994 140342552557376 calibrate.py:79] classifier.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=78.4245 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:30.547391 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mclassifier.2._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.1688 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:30.548099 140342552557376 calibrate.py:79] classifier.2._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.1688 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:30.549457 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlast_layer._input_quantizer             : TensorQuantizer(8bit fake per-tensor amax=34.5309 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:30.550158 140342552557376 calibrate.py:79] last_layer._input_quantizer             : TensorQuantizer(8bit fake per-tensor amax=34.5309 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:30.551448 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlast_layer._weight_quantizer            : TensorQuantizer(8bit fake per-tensor amax=0.2025 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:30.552142 140342552557376 calibrate.py:79] last_layer._weight_quantizer            : TensorQuantizer(8bit fake per-tensor amax=0.2025 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPerforming post calibration analysis for calibrator percentile_99.99...\u001b[0m\n",
      "I0318 11:28:30.554086 140342552557376 calibrate.py:53] Performing post calibration analysis for calibrator percentile_99.99...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis\u001b[0m\n",
      "I0318 11:28:30.555100 140342552557376 analysis.py:214] Starting transformation analysis\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results vgg7:\n",
      "+------------------------------+------------+\n",
      "|            Metric            |   Value    |\n",
      "+------------------------------+------------+\n",
      "| Average Validation Accuracy  |   0.9199   |\n",
      "|      Average Precision       |  0.92349   |\n",
      "|        Average Recall        |  0.92397   |\n",
      "|       Average F1 Score       |   0.9236   |\n",
      "|         Average Loss         |  0.23618   |\n",
      "|       Average Latency        | 37.764 ms  |\n",
      "|   Average GPU Power Usage    |  99.221 W  |\n",
      "| Inference Energy Consumption | 1.0408 mWh |\n",
      "+------------------------------+------------+\u001b[0m\n",
      "I0318 11:28:35.070010 140342552557376 analysis.py:330] \n",
      "Results vgg7:\n",
      "+------------------------------+------------+\n",
      "|            Metric            |   Value    |\n",
      "+------------------------------+------------+\n",
      "| Average Validation Accuracy  |   0.9199   |\n",
      "|      Average Precision       |  0.92349   |\n",
      "|        Average Recall        |  0.92397   |\n",
      "|       Average F1 Score       |   0.9236   |\n",
      "|         Average Loss         |  0.23618   |\n",
      "|       Average Latency        | 37.764 ms  |\n",
      "|   Average GPU Power Usage    |  99.221 W  |\n",
      "| Inference Energy Consumption | 1.0408 mWh |\n",
      "+------------------------------+------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPost calibration analysis complete.\u001b[0m\n",
      "I0318 11:28:35.072438 140342552557376 calibrate.py:66] Post calibration analysis complete.\n",
      "W0318 11:28:36.382215 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.3._input_quantizer       : TensorQuantizer(8bit fake per-tensor amax=10.5813 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:36.383707 140342552557376 calibrate.py:79] feature_layers.3._input_quantizer       : TensorQuantizer(8bit fake per-tensor amax=10.5813 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:37.369438 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.3._weight_quantizer      : TensorQuantizer(8bit fake per-tensor amax=0.4989 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:37.370501 140342552557376 calibrate.py:79] feature_layers.3._weight_quantizer      : TensorQuantizer(8bit fake per-tensor amax=0.4989 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:38.678205 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.7._input_quantizer       : TensorQuantizer(8bit fake per-tensor amax=5.2901 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:38.679295 140342552557376 calibrate.py:79] feature_layers.7._input_quantizer       : TensorQuantizer(8bit fake per-tensor amax=5.2901 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:39.667615 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.7._weight_quantizer      : TensorQuantizer(8bit fake per-tensor amax=0.5739 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:39.668674 140342552557376 calibrate.py:79] feature_layers.7._weight_quantizer      : TensorQuantizer(8bit fake per-tensor amax=0.5739 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:40.903185 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.10._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=4.2021 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:40.904335 140342552557376 calibrate.py:79] feature_layers.10._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=4.2021 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:41.893523 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.10._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.3685 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:41.894849 140342552557376 calibrate.py:79] feature_layers.10._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.3685 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:43.172208 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.14._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=5.1101 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:43.173320 140342552557376 calibrate.py:79] feature_layers.14._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=5.1101 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:44.170346 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.14._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.3645 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:44.171500 140342552557376 calibrate.py:79] feature_layers.14._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.3645 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:45.174597 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.17._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=5.6426 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:45.175661 140342552557376 calibrate.py:79] feature_layers.17._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=5.6426 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:46.172044 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.17._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.3202 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:46.173436 140342552557376 calibrate.py:79] feature_layers.17._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.3202 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:47.473207 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mclassifier.0._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=7.3163 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:47.474412 140342552557376 calibrate.py:79] classifier.0._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=7.3163 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:48.464096 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mclassifier.0._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.2408 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:48.464964 140342552557376 calibrate.py:79] classifier.0._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.2408 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:49.517606 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mclassifier.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=152.1875 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:49.518703 140342552557376 calibrate.py:79] classifier.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=152.1875 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:50.509681 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mclassifier.2._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.1952 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:50.510785 140342552557376 calibrate.py:79] classifier.2._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.1952 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:51.535877 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlast_layer._input_quantizer             : TensorQuantizer(8bit fake per-tensor amax=64.6092 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:51.537046 140342552557376 calibrate.py:79] last_layer._input_quantizer             : TensorQuantizer(8bit fake per-tensor amax=64.6092 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:28:52.531830 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlast_layer._weight_quantizer            : TensorQuantizer(8bit fake per-tensor amax=0.1997 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:28:52.532883 140342552557376 calibrate.py:79] last_layer._weight_quantizer            : TensorQuantizer(8bit fake per-tensor amax=0.1997 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPerforming post calibration analysis for calibrator mse...\u001b[0m\n",
      "I0318 11:28:52.535768 140342552557376 calibrate.py:53] Performing post calibration analysis for calibrator mse...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis\u001b[0m\n",
      "I0318 11:28:52.537053 140342552557376 analysis.py:214] Starting transformation analysis\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results vgg7:\n",
      "+------------------------------+------------+\n",
      "|            Metric            |   Value    |\n",
      "+------------------------------+------------+\n",
      "| Average Validation Accuracy  |  0.92009   |\n",
      "|      Average Precision       |  0.92368   |\n",
      "|        Average Recall        |  0.92408   |\n",
      "|       Average F1 Score       |  0.92378   |\n",
      "|         Average Loss         |  0.23669   |\n",
      "|       Average Latency        | 38.354 ms  |\n",
      "|   Average GPU Power Usage    |  97.465 W  |\n",
      "| Inference Energy Consumption | 1.0384 mWh |\n",
      "+------------------------------+------------+\u001b[0m\n",
      "I0318 11:28:57.087177 140342552557376 analysis.py:330] \n",
      "Results vgg7:\n",
      "+------------------------------+------------+\n",
      "|            Metric            |   Value    |\n",
      "+------------------------------+------------+\n",
      "| Average Validation Accuracy  |  0.92009   |\n",
      "|      Average Precision       |  0.92368   |\n",
      "|        Average Recall        |  0.92408   |\n",
      "|       Average F1 Score       |  0.92378   |\n",
      "|         Average Loss         |  0.23669   |\n",
      "|       Average Latency        | 38.354 ms  |\n",
      "|   Average GPU Power Usage    |  97.465 W  |\n",
      "| Inference Energy Consumption | 1.0384 mWh |\n",
      "+------------------------------+------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPost calibration analysis complete.\u001b[0m\n",
      "I0318 11:28:57.089607 140342552557376 calibrate.py:66] Post calibration analysis complete.\n",
      "W0318 11:29:04.151026 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.3._input_quantizer       : TensorQuantizer(8bit fake per-tensor amax=10.7260 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:29:04.152235 140342552557376 calibrate.py:79] feature_layers.3._input_quantizer       : TensorQuantizer(8bit fake per-tensor amax=10.7260 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:29:08.801714 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.3._weight_quantizer      : TensorQuantizer(8bit fake per-tensor amax=0.5427 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:29:08.802824 140342552557376 calibrate.py:79] feature_layers.3._weight_quantizer      : TensorQuantizer(8bit fake per-tensor amax=0.5427 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:29:16.188955 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.7._input_quantizer       : TensorQuantizer(8bit fake per-tensor amax=6.2438 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:29:16.190120 140342552557376 calibrate.py:79] feature_layers.7._input_quantizer       : TensorQuantizer(8bit fake per-tensor amax=6.2438 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:29:20.749375 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.7._weight_quantizer      : TensorQuantizer(8bit fake per-tensor amax=0.6185 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:29:20.750648 140342552557376 calibrate.py:79] feature_layers.7._weight_quantizer      : TensorQuantizer(8bit fake per-tensor amax=0.6185 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:29:27.322470 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.10._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=4.9095 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:29:27.324110 140342552557376 calibrate.py:79] feature_layers.10._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=4.9095 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:29:32.054767 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.10._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.4083 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:29:32.056291 140342552557376 calibrate.py:79] feature_layers.10._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.4083 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:29:39.190995 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.14._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=6.2019 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:29:39.192506 140342552557376 calibrate.py:79] feature_layers.14._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=6.2019 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:29:43.876971 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.14._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.4537 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:29:43.878366 140342552557376 calibrate.py:79] feature_layers.14._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.4537 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:29:48.624796 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.17._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=5.5843 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:29:48.626186 140342552557376 calibrate.py:79] feature_layers.17._input_quantizer      : TensorQuantizer(8bit fake per-tensor amax=5.5843 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:29:53.411544 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mfeature_layers.17._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.3877 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:29:53.413097 140342552557376 calibrate.py:79] feature_layers.17._weight_quantizer     : TensorQuantizer(8bit fake per-tensor amax=0.3877 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:30:00.302274 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mclassifier.0._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=8.3903 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:30:00.303872 140342552557376 calibrate.py:79] classifier.0._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=8.3903 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:30:04.989341 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mclassifier.0._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.2154 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:30:04.990899 140342552557376 calibrate.py:79] classifier.0._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.2154 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:30:09.949727 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mclassifier.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=155.0471 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:30:09.951436 140342552557376 calibrate.py:79] classifier.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=155.0471 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:30:14.412336 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mclassifier.2._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.1901 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:30:14.413735 140342552557376 calibrate.py:79] classifier.2._weight_quantizer          : TensorQuantizer(8bit fake per-tensor amax=0.1901 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:30:19.174479 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlast_layer._input_quantizer             : TensorQuantizer(8bit fake per-tensor amax=62.1193 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:30:19.175708 140342552557376 calibrate.py:79] last_layer._input_quantizer             : TensorQuantizer(8bit fake per-tensor amax=62.1193 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "W0318 11:30:23.563438 140342552557376 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mlast_layer._weight_quantizer            : TensorQuantizer(8bit fake per-tensor amax=0.2112 calibrator=HistogramCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0318 11:30:23.565157 140342552557376 calibrate.py:79] last_layer._weight_quantizer            : TensorQuantizer(8bit fake per-tensor amax=0.2112 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPerforming post calibration analysis for calibrator entropy...\u001b[0m\n",
      "I0318 11:30:23.567919 140342552557376 calibrate.py:53] Performing post calibration analysis for calibrator entropy...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis\u001b[0m\n",
      "I0318 11:30:23.569261 140342552557376 analysis.py:214] Starting transformation analysis\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results vgg7:\n",
      "+------------------------------+------------+\n",
      "|            Metric            |   Value    |\n",
      "+------------------------------+------------+\n",
      "| Average Validation Accuracy  |  0.91864   |\n",
      "|      Average Precision       |   0.9224   |\n",
      "|        Average Recall        |  0.92282   |\n",
      "|       Average F1 Score       |  0.92248   |\n",
      "|         Average Loss         |  0.23694   |\n",
      "|       Average Latency        |  38.88 ms  |\n",
      "|   Average GPU Power Usage    |  98.198 W  |\n",
      "| Inference Energy Consumption | 1.0605 mWh |\n",
      "+------------------------------+------------+\u001b[0m\n",
      "I0318 11:30:28.236583 140342552557376 analysis.py:330] \n",
      "Results vgg7:\n",
      "+------------------------------+------------+\n",
      "|            Metric            |   Value    |\n",
      "+------------------------------+------------+\n",
      "| Average Validation Accuracy  |  0.91864   |\n",
      "|      Average Precision       |   0.9224   |\n",
      "|        Average Recall        |  0.92282   |\n",
      "|       Average F1 Score       |  0.92248   |\n",
      "|         Average Loss         |  0.23694   |\n",
      "|       Average Latency        |  38.88 ms  |\n",
      "|   Average GPU Power Usage    |  98.198 W  |\n",
      "| Inference Energy Consumption | 1.0605 mWh |\n",
      "+------------------------------+------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPost calibration analysis complete.\u001b[0m\n",
      "I0318 11:30:28.238457 140342552557376 calibrate.py:66] Post calibration analysis complete.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mSucceeded in calibrating the model in PyTorch!\u001b[0m\n",
      "I0318 11:30:28.239268 140342552557376 calibrate.py:159] Succeeded in calibrating the model in PyTorch!\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting Fine Tuning...\u001b[0m\n",
      "I0318 11:30:28.245524 140342552557376 fine_tune.py:62] Starting Fine Tuning...\n",
      "I0318 11:30:58.501808 140342552557376 rank_zero.py:64] GPU available: True (cuda), used: True\n",
      "I0318 11:30:58.536208 140342552557376 rank_zero.py:64] TPU available: False, using: 0 TPU cores\n",
      "I0318 11:30:58.536926 140342552557376 rank_zero.py:64] IPU available: False, using: 0 IPUs\n",
      "I0318 11:30:58.537610 140342552557376 rank_zero.py:64] HPU available: False, using: 0 HPUs\n",
      "I0318 11:30:58.554492 140342552557376 rank_zero.py:64] You are using a CUDA device ('NVIDIA GeForce RTX 3070') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0318 11:31:02.771356 140342552557376 cuda.py:61] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "I0318 11:31:02.798513 140342552557376 model_summary.py:94] \n",
      "  | Name      | Type               | Params\n",
      "-------------------------------------------------\n",
      "0 | model     | GraphModule        | 14.0 M\n",
      "1 | loss_fn   | CrossEntropyLoss   | 0     \n",
      "2 | acc_train | MulticlassAccuracy | 0     \n",
      "3 | loss_val  | MeanMetric         | 0     \n",
      "4 | loss_test | MeanMetric         | 0     \n",
      "-------------------------------------------------\n",
      "14.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "14.0 M    Total params\n",
      "56.118    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/mase/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/mase/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 196/196 [00:58<00:00,  3.37it/s, v_num=1, train_acc_step=0.875, val_acc_epoch=0.896, val_loss_epoch=0.219]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0318 11:33:01.304579 140342552557376 rank_zero.py:64] `Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 196/196 [00:58<00:00,  3.35it/s, v_num=1, train_acc_step=0.875, val_acc_epoch=0.896, val_loss_epoch=0.219]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mFine Tuning Complete\u001b[0m\n",
      "I0318 11:33:01.409875 140342552557376 fine_tune.py:121] Fine Tuning Complete\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "I0318 11:33:01.418860 140342552557376 quantize.py:129] Converting PyTorch model to ONNX...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/mase/lib/python3.11/site-packages/pytorch_quantization/tensor_quant.py:363: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if min_amax < 0:\n",
      "/opt/conda/envs/mase/lib/python3.11/site-packages/pytorch_quantization/tensor_quant.py:366: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  max_bound = torch.tensor((2.0**(num_bits - 1 + int(unsigned))) - 1.0, device=amax.device)\n",
      "/opt/conda/envs/mase/lib/python3.11/site-packages/pytorch_quantization/tensor_quant.py:376: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if min_amax <= epsilon:  # Treat amax smaller than minimum representable of fp16 0\n",
      "/opt/conda/envs/mase/lib/python3.11/site-packages/pytorch_quantization/tensor_quant.py:382: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if min_amax <= epsilon:\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /root/mase/mase_output/tensorrt/quantization/onnx/2024_03_18/version_2/model.onnx\u001b[0m\n",
      "I0318 11:33:02.396777 140342552557376 quantize.py:152] ONNX Conversion Complete. Stored ONNX model to /root/mase/mase_output/tensorrt/quantization/onnx/2024_03_18/version_2/model.onnx\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "I0318 11:33:02.399959 140342552557376 quantize.py:55] Converting PyTorch model to TensorRT...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m mg, _ \u001b[38;5;241m=\u001b[39m tensorrt_calibrate_transform_pass(mg, pass_args\u001b[38;5;241m=\u001b[39mtensorrt_quantize_config)\n\u001b[1;32m      4\u001b[0m mg, _ \u001b[38;5;241m=\u001b[39m tensorrt_fine_tune_transform_pass(mg, pass_args\u001b[38;5;241m=\u001b[39mtensorrt_quantize_config)\n\u001b[0;32m----> 5\u001b[0m mg, meta \u001b[38;5;241m=\u001b[39m \u001b[43mtensorrt_engine_interface_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpass_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensorrt_quantize_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mase/machop/chop/passes/graph/transforms/tensorrt/quantize/quantize.py:20\u001b[0m, in \u001b[0;36mtensorrt_engine_interface_pass\u001b[0;34m(graph, pass_args)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtensorrt_engine_interface_pass\u001b[39m(graph, pass_args\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     19\u001b[0m     quantizer \u001b[38;5;241m=\u001b[39m Quantizer(pass_args)\n\u001b[0;32m---> 20\u001b[0m     trt_engine_path, onnx_path \u001b[38;5;241m=\u001b[39m \u001b[43mquantizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpytorch_to_trt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# link the model with graph\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     graph\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfx\u001b[38;5;241m.\u001b[39mGraphModule(graph\u001b[38;5;241m.\u001b[39mmodel, graph\u001b[38;5;241m.\u001b[39mfx_graph)\n",
      "File \u001b[0;32m~/mase/machop/chop/passes/graph/transforms/tensorrt/quantize/quantize.py:36\u001b[0m, in \u001b[0;36mQuantizer.pytorch_to_trt\u001b[0;34m(self, graph)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Model is first converted to ONNX format and then to TensorRT\u001b[39;00m\n\u001b[1;32m     35\u001b[0m ONNX_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpytorch_to_ONNX(graph\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[0;32m---> 36\u001b[0m TRT_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mONNX_to_TRT\u001b[49m\u001b[43m(\u001b[49m\u001b[43mONNX_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexport_TRT_model_summary(TRT_path)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m TRT_path, ONNX_path\n",
      "File \u001b[0;32m~/mase/machop/chop/passes/graph/transforms/tensorrt/quantize/quantize.py:61\u001b[0m, in \u001b[0;36mQuantizer.ONNX_to_TRT\u001b[0;34m(self, ONNX_path)\u001b[0m\n\u001b[1;32m     58\u001b[0m layer_wise_mixed_precision \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m check_for_value_in_dict(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mINT8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m check_for_value_in_dict(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFP16\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     60\u001b[0m TRT_LOGGER \u001b[38;5;241m=\u001b[39m trt\u001b[38;5;241m.\u001b[39mLogger(trt\u001b[38;5;241m.\u001b[39mLogger\u001b[38;5;241m.\u001b[39mWARNING)\n\u001b[0;32m---> 61\u001b[0m builder \u001b[38;5;241m=\u001b[39m \u001b[43mtrt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBuilder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTRT_LOGGER\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m network \u001b[38;5;241m=\u001b[39m builder\u001b[38;5;241m.\u001b[39mcreate_network(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m<<\u001b[39m \u001b[38;5;28mint\u001b[39m(trt\u001b[38;5;241m.\u001b[39mNetworkDefinitionCreationFlag\u001b[38;5;241m.\u001b[39mEXPLICIT_BATCH))\n\u001b[1;32m     63\u001b[0m parser \u001b[38;5;241m=\u001b[39m trt\u001b[38;5;241m.\u001b[39mOnnxParser(network, TRT_LOGGER)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mg, _ = tensorrt_fake_quantize_transform_pass(mg, pass_args=tensorrt_quantize_config)\n",
    "# summarize_quantization_analysis_pass(mg_original, mg)\n",
    "mg, _ = tensorrt_calibrate_transform_pass(mg, pass_args=tensorrt_quantize_config)\n",
    "mg, _ = tensorrt_fine_tune_transform_pass(mg, pass_args=tensorrt_quantize_config)\n",
    "mg, meta = tensorrt_engine_interface_pass(mg, pass_args=tensorrt_quantize_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ch transform --config ../../../machop/configs/tensorrt/vgg7_INT8_quantization_by_type.toml --load {VGG_CHECKPOINT_PATH} --load-type pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5. Language Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your TOML file\n",
    "toml_file_path = '../../../machop/configs/tensorrt/opt-125M_layerwise_mixed_precision_by_name.toml'\n",
    "\n",
    "# Reading TOML file and converting it into a Python dictionary\n",
    "with open(toml_file_path, 'r') as toml_file:\n",
    "    pass_args = toml.load(toml_file)\n",
    "\n",
    "# Extract the 'passes.tensorrt_quantize' section and its children\n",
    "tensorrt_quantize_config = pass_args.get('passes', {}).get('tensorrt_quantize', {})\n",
    "# Extract the 'passes.tensorrt_analysis' section and its children\n",
    "tensorrt_analysis_config = pass_args.get('passes', {}).get('tensorrt_analysis', {})\n",
    "\n",
    "# Load the basics in\n",
    "model_name = pass_args['model']\n",
    "dataset_name = pass_args['dataset']\n",
    "max_epochs = pass_args['max_epochs']\n",
    "batch_size = pass_args['batch_size']\n",
    "learning_rate = pass_args['learning_rate']\n",
    "accelerator = pass_args['accelerator']\n",
    "\n",
    "opt_tokenizer = get_tokenizer(\"facebook/opt-125m\")\n",
    "\n",
    "data_module = MaseDataModule(\n",
    "    name=dataset_name,\n",
    "    batch_size=batch_size,\n",
    "    model_name=model_name,\n",
    "    num_workers=os.cpu_count(),\n",
    "    max_token_len=128,\n",
    "    tokenizer=opt_tokenizer,\n",
    "    load_from_cache_file=True,\n",
    ")\n",
    "data_module.prepare_data()\n",
    "data_module.setup()\n",
    "\n",
    "# Add the data_module and other necessary information to the configs\n",
    "configs = [tensorrt_quantize_config, tensorrt_analysis_config]\n",
    "for config in configs:\n",
    "    config['task'] = pass_args['task']\n",
    "    config['batch_size'] = pass_args['batch_size']\n",
    "    config['model'] = pass_args['model']\n",
    "    config['data_module'] = data_module\n",
    "    config['accelerator'] = 'cuda' if pass_args['accelerator'] == 'gpu' else pass_args['accelerator']\n",
    "    if config['accelerator'] == 'gpu':\n",
    "        os.environ['CUDA_MODULE_LOADING'] = 'LAZY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_info = get_model_info(model_name)\n",
    "model = get_model(\n",
    "    \"facebook/opt-125m:patched\",\n",
    "    task=\"lm\",\n",
    "    dataset_info=get_dataset_info(\"wikitext2\"),\n",
    "    pretrained=True,\n",
    ")\n",
    "\n",
    "# Load in the trained checkpoint - change this accordingly\n",
    "# OPT125M_CHECKPOINT_PATH = \"../../../mase_output/jsc-toy_classification_jsc_2024-03-17/software/training_ckpts/best.ckpt\"\n",
    "# model = load_model(load_name=OPT125M_CHECKPOINT_PATH, load_type=\"pl\", model=model)\n",
    "\n",
    "model_info = get_model_info(\"facebook/opt-125m:patched\")\n",
    "cf_args = get_cf_args(model_info=model_info, task=\"lm\", model=model)\n",
    "\n",
    "mg = MaseGraph(model=model, cf_args=cf_args)\n",
    "\n",
    "# dummy_in = get_dummy_input(model_info, data_module=data_module, task=\"lm\")\n",
    "# if len(mg.model.additional_inputs) > 0:\n",
    "#     dummy_in = dummy_in | mg.model.additional_inputs\n",
    "\n",
    "# Initiate metadata\n",
    "mg, _ = init_metadata_analysis_pass(mg, pass_args=None)\n",
    "\n",
    "# # Before we begin, we will copy the original MaseGraph model to use for comparison during quantization analysis\n",
    "# mg_original = deepcopy_mase_graph(mg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _, _ = tensorrt_analysis_pass(mg, pass_args=tensorrt_analysis_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "I0318 08:54:47.010779 139760749061952 quantize.py:129] Converting PyTorch model to ONNX...\n",
      "ERROR:tornado.general:SEND Error: Host unreachable\n",
      "Traceback (most recent call last):\n",
      "  File \"_pydevd_bundle/pydevd_cython.pyx\", line 577, in _pydevd_bundle.pydevd_cython.PyDBFrame._handle_exception\n",
      "  File \"_pydevd_bundle/pydevd_cython.pyx\", line 312, in _pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\n",
      "  File \"/opt/conda/envs/mase/lib/python3.11/site-packages/debugpy/_vendored/pydevd/pydevd.py\", line 2070, in do_wait_suspend\n",
      "    keep_suspended = self._do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/envs/mase/lib/python3.11/site-packages/debugpy/_vendored/pydevd/pydevd.py\", line 2106, in _do_wait_suspend\n",
      "    time.sleep(0.01)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# mg, _ = tensorrt_fake_quantize_transform_pass(mg, pass_args=tensorrt_quantize_config)\n",
    "# summarize_quantization_analysis_pass(mg_original, mg)\n",
    "\n",
    "# mg, _ = tensorrt_calibrate_transform_pass(mg, pass_args=tensorrt_quantize_config)\n",
    "\n",
    "# mg, _ = tensorrt_fine_tune_transform_pass(mg, pass_args=tensorrt_quantize_config)\n",
    "\n",
    "mg, meta = tensorrt_engine_interface_pass(mg, pass_args=tensorrt_quantize_config)\n",
    "\n",
    "_, _ = tensorrt_analysis_pass(mg_original, pass_args=tensorrt_analysis_config)\n",
    "_, _ = tensorrt_analysis_pass(meta['trt_engine_path'], pass_args=tensorrt_analysis_config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
