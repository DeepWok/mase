{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome To the ONNX Runtime Tutorial!\n",
    "\n",
    "This notebook is designed to demonstrate the features of the ONNXRT passes integrated into MASE as part of the MASERT framework.\n",
    "\n",
    "## Section 1. INT8 Quantization\n",
    "Firstly, we will show you how to do an int8 quantization of a simple model, `jsc-toy`, and compare the quantized model to the original model using the `Machop API`. The quantization process is split into the following stages, each using their own individual pass, and are explained in depth at each subsection:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/mase/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-20 11:53:05,861] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mSet logging level to info\u001b[0m\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0320 11:53:07.422378 139711941265216 logger.py:44] Set logging level to info\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import toml\n",
    "from copy import copy, deepcopy\n",
    "\n",
    "# Figure out the correct path\n",
    "machop_path = Path(\".\").resolve().parent.parent.parent /\"machop\"\n",
    "assert machop_path.exists(), \"Failed to find machop at: {}\".format(machop_path)\n",
    "sys.path.append(str(machop_path))\n",
    "\n",
    "# Add directory to the PATH so that chop can be called\n",
    "new_path = \"../../../machop\"\n",
    "full_path = os.path.abspath(new_path)\n",
    "os.environ['PATH'] += os.pathsep + full_path\n",
    "\n",
    "from chop.tools.utils import to_numpy_if_tensor\n",
    "from chop.tools.logger import set_logging_verbosity\n",
    "from chop.tools import get_cf_args, get_dummy_input\n",
    "from chop.passes.graph.utils import deepcopy_mase_graph\n",
    "from chop.tools.get_input import InputGenerator\n",
    "from chop.tools.checkpoint_load import load_model\n",
    "from chop.ir import MaseGraph\n",
    "from chop.models import get_model_info, get_model, get_tokenizer\n",
    "from chop.dataset import MaseDataModule, get_dataset_info\n",
    "from chop.passes.graph.transforms import metadata_value_type_cast_transform_pass\n",
    "from chop.passes.graph import (\n",
    "    summarize_quantization_analysis_pass,\n",
    "    add_common_metadata_analysis_pass,\n",
    "    init_metadata_analysis_pass,\n",
    "    add_software_metadata_analysis_pass,\n",
    "    onnx_runtime_transform_pass,\n",
    "    runtime_analysis_pass,\n",
    "    )\n",
    "\n",
    "set_logging_verbosity(\"info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your TOML file\n",
    "# toml_file_path = '../../../machop/configs/tensorrt/vgg7_layerwise_mixed_precision.toml'\n",
    "# toml_file_path = '../../../machop/configs/tensorrt/vgg7_typewise_mixed_precision.toml'\n",
    "toml_file_path = \"../../../machop/configs/onnx/jsc_pl2ort.toml\"\n",
    "\n",
    "# Reading TOML file and converting it into a Python dictionary\n",
    "with open(toml_file_path, 'r') as toml_file:\n",
    "    pass_args = toml.load(toml_file)\n",
    "\n",
    "# Extract the 'passes.tensorrt' section and its children\n",
    "onnx_config = pass_args.get('passes', {}).get('onnxruntime', {})\n",
    "# Extract the 'passes.runtime_analysis' section and its children\n",
    "runtime_analysis_config = pass_args.get('passes', {}).get('runtime_analysis', {})\n",
    "\n",
    "# Load the basics in\n",
    "model_name = pass_args['model']\n",
    "dataset_name = pass_args['dataset']\n",
    "max_epochs = pass_args['max_epochs']\n",
    "batch_size = pass_args['batch_size']\n",
    "learning_rate = pass_args['learning_rate']\n",
    "accelerator = pass_args['accelerator']\n",
    "\n",
    "data_module = MaseDataModule(\n",
    "    name=dataset_name,\n",
    "    batch_size=batch_size,\n",
    "    model_name=model_name,\n",
    "    num_workers=0,\n",
    ")\n",
    "data_module.prepare_data()\n",
    "data_module.setup()\n",
    "\n",
    "# Add the data_module and other necessary information to the configs\n",
    "configs = [onnx_config, runtime_analysis_config]\n",
    "for config in configs:\n",
    "    config['task'] = pass_args['task']\n",
    "    config['batch_size'] = pass_args['batch_size']\n",
    "    config['model'] = pass_args['model']\n",
    "    config['data_module'] = data_module\n",
    "    config['accelerator'] = 'cuda' if pass_args['accelerator'] == 'gpu' else pass_args['accelerator']\n",
    "    if config['accelerator'] == 'gpu':\n",
    "        os.environ['CUDA_MODULE_LOADING'] = 'LAZY'\n",
    "\n",
    "model_info = get_model_info(model_name)\n",
    "model = get_model(\n",
    "    model_name,\n",
    "    task=\"cls\",\n",
    "    dataset_info=data_module.dataset_info,\n",
    "    pretrained=False)\n",
    "\n",
    "input_generator = InputGenerator(\n",
    "    data_module=data_module,\n",
    "    model_info=model_info,\n",
    "    task=\"cls\",\n",
    "    which_dataloader=\"train\",\n",
    ")\n",
    "\n",
    "# generate the mase graph and initialize node metadata\n",
    "mg = MaseGraph(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load in the trained checkpoint - change this accordingly\n",
    "# VGG_CHECKPOINT_PATH = \"../../../mase_output/jsc-toy_classification_jsc_2024-03-17/software/training_ckpts/best.ckpt\"\n",
    "\n",
    "# model = load_model(load_name=VGG_CHECKPOINT_PATH, load_type=\"pl\", model=model)\n",
    "\n",
    "# Initiate metadata\n",
    "dummy_in = next(iter(input_generator))\n",
    "_ = model(**dummy_in)\n",
    "mg, _ = init_metadata_analysis_pass(mg, None)\n",
    "\n",
    "mg_original = deepcopy_mase_graph(mg)\n",
    "\n",
    "mg, _ = add_common_metadata_analysis_pass(mg, {\"dummy_in\": dummy_in})\n",
    "mg, _ = add_software_metadata_analysis_pass(mg, None)\n",
    "mg, _ = metadata_value_type_cast_transform_pass(mg, pass_args={\"fn\": to_numpy_if_tensor})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "I0320 11:53:11.919002 139711941265216 onnx_runtime.py:51] Converting PyTorch model to ONNX...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /root/mase/mase_output/onnx_runtime/unquantized/2024_03_20/version_13/model.onnx\u001b[0m\n",
      "I0320 11:53:12.055048 139711941265216 onnx_runtime.py:69] ONNX Conversion Complete. Stored ONNX model to /root/mase/mase_output/onnx_runtime/unquantized/2024_03_20/version_13/model.onnx\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Model Summary: \n",
      "+-------+----------------------------------+--------------------+--------------------------------------------------------------------------------------------------------------------------+-------------------------------------------+---------------------+\n",
      "| Index |               Name               |        Type        |                                                          Inputs                                                          |                  Outputs                  |      Attributes     |\n",
      "+-------+----------------------------------+--------------------+--------------------------------------------------------------------------------------------------------------------------+-------------------------------------------+---------------------+\n",
      "|   0   |            Identity_0            |      Identity      |                                                    seq_blocks.3.bias                                                     |             seq_blocks.6.bias             |                     |\n",
      "|   1   |            Identity_1            |      Identity      |                                                   seq_blocks.3.weight                                                    |            seq_blocks.6.weight            |                     |\n",
      "|   2   | /seq_blocks.0/BatchNormalization | BatchNormalization |            input, seq_blocks.0.weight, seq_blocks.0.bias, seq_blocks.0.running_mean, seq_blocks.0.running_var            | /seq_blocks.0/BatchNormalization_output_0 |  epsilon, momentum  |\n",
      "|   3   |        /seq_blocks.1/Relu        |        Relu        |                                        /seq_blocks.0/BatchNormalization_output_0                                         |        /seq_blocks.1/Relu_output_0        |                     |\n",
      "|   4   |        /seq_blocks.2/Gemm        |        Gemm        |                           /seq_blocks.1/Relu_output_0, seq_blocks.2.weight, seq_blocks.2.bias                            |        /seq_blocks.2/Gemm_output_0        | alpha, beta, transB |\n",
      "|   5   | /seq_blocks.3/BatchNormalization | BatchNormalization | /seq_blocks.2/Gemm_output_0, seq_blocks.3.weight, seq_blocks.3.bias, seq_blocks.3.running_mean, seq_blocks.3.running_var | /seq_blocks.3/BatchNormalization_output_0 |  epsilon, momentum  |\n",
      "|   6   |        /seq_blocks.4/Relu        |        Relu        |                                        /seq_blocks.3/BatchNormalization_output_0                                         |        /seq_blocks.4/Relu_output_0        |                     |\n",
      "|   7   |        /seq_blocks.5/Gemm        |        Gemm        |                           /seq_blocks.4/Relu_output_0, seq_blocks.5.weight, seq_blocks.5.bias                            |        /seq_blocks.5/Gemm_output_0        | alpha, beta, transB |\n",
      "|   8   | /seq_blocks.6/BatchNormalization | BatchNormalization | /seq_blocks.5/Gemm_output_0, seq_blocks.6.weight, seq_blocks.6.bias, seq_blocks.6.running_mean, seq_blocks.6.running_var | /seq_blocks.6/BatchNormalization_output_0 |  epsilon, momentum  |\n",
      "|   9   |        /seq_blocks.7/Relu        |        Relu        |                                        /seq_blocks.6/BatchNormalization_output_0                                         |        /seq_blocks.7/Relu_output_0        |                     |\n",
      "|   10  |        /seq_blocks.8/Gemm        |        Gemm        |                           /seq_blocks.7/Relu_output_0, seq_blocks.8.weight, seq_blocks.8.bias                            |        /seq_blocks.8/Gemm_output_0        | alpha, beta, transB |\n",
      "|   11  | /seq_blocks.9/BatchNormalization | BatchNormalization | /seq_blocks.8/Gemm_output_0, seq_blocks.9.weight, seq_blocks.9.bias, seq_blocks.9.running_mean, seq_blocks.9.running_var | /seq_blocks.9/BatchNormalization_output_0 |  epsilon, momentum  |\n",
      "|   12  |       /seq_blocks.10/Relu        |        Relu        |                                        /seq_blocks.9/BatchNormalization_output_0                                         |                     37                    |                     |\n",
      "+-------+----------------------------------+--------------------+--------------------------------------------------------------------------------------------------------------------------+-------------------------------------------+---------------------+\u001b[0m\n",
      "I0320 11:53:12.069086 139711941265216 onnx_runtime.py:91] ONNX Model Summary: \n",
      "+-------+----------------------------------+--------------------+--------------------------------------------------------------------------------------------------------------------------+-------------------------------------------+---------------------+\n",
      "| Index |               Name               |        Type        |                                                          Inputs                                                          |                  Outputs                  |      Attributes     |\n",
      "+-------+----------------------------------+--------------------+--------------------------------------------------------------------------------------------------------------------------+-------------------------------------------+---------------------+\n",
      "|   0   |            Identity_0            |      Identity      |                                                    seq_blocks.3.bias                                                     |             seq_blocks.6.bias             |                     |\n",
      "|   1   |            Identity_1            |      Identity      |                                                   seq_blocks.3.weight                                                    |            seq_blocks.6.weight            |                     |\n",
      "|   2   | /seq_blocks.0/BatchNormalization | BatchNormalization |            input, seq_blocks.0.weight, seq_blocks.0.bias, seq_blocks.0.running_mean, seq_blocks.0.running_var            | /seq_blocks.0/BatchNormalization_output_0 |  epsilon, momentum  |\n",
      "|   3   |        /seq_blocks.1/Relu        |        Relu        |                                        /seq_blocks.0/BatchNormalization_output_0                                         |        /seq_blocks.1/Relu_output_0        |                     |\n",
      "|   4   |        /seq_blocks.2/Gemm        |        Gemm        |                           /seq_blocks.1/Relu_output_0, seq_blocks.2.weight, seq_blocks.2.bias                            |        /seq_blocks.2/Gemm_output_0        | alpha, beta, transB |\n",
      "|   5   | /seq_blocks.3/BatchNormalization | BatchNormalization | /seq_blocks.2/Gemm_output_0, seq_blocks.3.weight, seq_blocks.3.bias, seq_blocks.3.running_mean, seq_blocks.3.running_var | /seq_blocks.3/BatchNormalization_output_0 |  epsilon, momentum  |\n",
      "|   6   |        /seq_blocks.4/Relu        |        Relu        |                                        /seq_blocks.3/BatchNormalization_output_0                                         |        /seq_blocks.4/Relu_output_0        |                     |\n",
      "|   7   |        /seq_blocks.5/Gemm        |        Gemm        |                           /seq_blocks.4/Relu_output_0, seq_blocks.5.weight, seq_blocks.5.bias                            |        /seq_blocks.5/Gemm_output_0        | alpha, beta, transB |\n",
      "|   8   | /seq_blocks.6/BatchNormalization | BatchNormalization | /seq_blocks.5/Gemm_output_0, seq_blocks.6.weight, seq_blocks.6.bias, seq_blocks.6.running_mean, seq_blocks.6.running_var | /seq_blocks.6/BatchNormalization_output_0 |  epsilon, momentum  |\n",
      "|   9   |        /seq_blocks.7/Relu        |        Relu        |                                        /seq_blocks.6/BatchNormalization_output_0                                         |        /seq_blocks.7/Relu_output_0        |                     |\n",
      "|   10  |        /seq_blocks.8/Gemm        |        Gemm        |                           /seq_blocks.7/Relu_output_0, seq_blocks.8.weight, seq_blocks.8.bias                            |        /seq_blocks.8/Gemm_output_0        | alpha, beta, transB |\n",
      "|   11  | /seq_blocks.9/BatchNormalization | BatchNormalization | /seq_blocks.8/Gemm_output_0, seq_blocks.9.weight, seq_blocks.9.bias, seq_blocks.9.running_mean, seq_blocks.9.running_var | /seq_blocks.9/BatchNormalization_output_0 |  epsilon, momentum  |\n",
      "|   12  |       /seq_blocks.10/Relu        |        Relu        |                                        /seq_blocks.9/BatchNormalization_output_0                                         |                     37                    |                     |\n",
      "+-------+----------------------------------+--------------------+--------------------------------------------------------------------------------------------------------------------------+-------------------------------------------+---------------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mQuantizing model using dynamic quantization...\u001b[0m\n",
      "I0320 11:53:12.072128 139711941265216 quantize.py:42] Quantizing model using dynamic quantization...\n",
      "W0320 11:53:12.089064 139711941265216 quantize.py:442] Please consider to run pre-processing before quantization. Refer to example: https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0320 11:53:38.699918 139711941265216 quantize.py:540] Please consider pre-processing before quantization. See https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mQuantization complete. Model is now dynamically quantized.\u001b[0m\n",
      "I0320 11:53:38.700979 139711941265216 quantize.py:59] Quantization complete. Model is now dynamically quantized.\n"
     ]
    }
   ],
   "source": [
    "mg, onnx_meta = onnx_runtime_transform_pass(mg, pass_args=onnx_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on jsc-toy\u001b[0m\n",
      "I0320 09:13:54.422588 139697046427456 analysis.py:233] Starting transformation analysis on jsc-toy\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results jsc-toy:\n",
      "+------------------------------+---------------+\n",
      "|            Metric            |     Value     |\n",
      "+------------------------------+---------------+\n",
      "|    Average Test Accuracy     |    0.15471    |\n",
      "|      Average Precision       |    0.14226    |\n",
      "|        Average Recall        |    0.16118    |\n",
      "|       Average F1 Score       |    0.14833    |\n",
      "|         Average Loss         |    1.8961     |\n",
      "|       Average Latency        |   1.4385 ms   |\n",
      "|   Average GPU Power Usage    |   16.857 W    |\n",
      "| Inference Energy Consumption | 0.0067358 mWh |\n",
      "+------------------------------+---------------+\u001b[0m\n",
      "I0320 09:13:55.835249 139697046427456 analysis.py:347] \n",
      "Results jsc-toy:\n",
      "+------------------------------+---------------+\n",
      "|            Metric            |     Value     |\n",
      "+------------------------------+---------------+\n",
      "|    Average Test Accuracy     |    0.15471    |\n",
      "|      Average Precision       |    0.14226    |\n",
      "|        Average Recall        |    0.16118    |\n",
      "|       Average F1 Score       |    0.14833    |\n",
      "|         Average Loss         |    1.8961     |\n",
      "|       Average Latency        |   1.4385 ms   |\n",
      "|   Average GPU Power Usage    |   16.857 W    |\n",
      "| Inference Energy Consumption | 0.0067358 mWh |\n",
      "+------------------------------+---------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /root/mase_output/tensorrt/quantization/mase_graph/2024-03-20/version_2/model.json\u001b[0m\n",
      "I0320 09:13:55.839934 139697046427456 analysis.py:84] Runtime analysis results saved to /root/mase_output/tensorrt/quantization/mase_graph/2024-03-20/version_2/model.json\n"
     ]
    }
   ],
   "source": [
    "mg, _ = runtime_analysis_pass(mg, pass_args=runtime_analysis_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on jsc-toy-onnx\u001b[0m\n",
      "I0320 09:13:56.434021 139697046427456 analysis.py:233] Starting transformation analysis on jsc-toy-onnx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results jsc-toy-onnx:\n",
      "+------------------------------+---------------+\n",
      "|            Metric            |     Value     |\n",
      "+------------------------------+---------------+\n",
      "|    Average Test Accuracy     |    0.20404    |\n",
      "|      Average Precision       |   0.042026    |\n",
      "|        Average Recall        |    0.20461    |\n",
      "|       Average F1 Score       |   0.069729    |\n",
      "|         Average Loss         |    1.6203     |\n",
      "|       Average Latency        |  0.36442 ms   |\n",
      "|   Average GPU Power Usage    |   21.985 W    |\n",
      "| Inference Energy Consumption | 0.0022255 mWh |\n",
      "+------------------------------+---------------+\u001b[0m\n",
      "I0320 09:13:57.393121 139697046427456 analysis.py:347] \n",
      "Results jsc-toy-onnx:\n",
      "+------------------------------+---------------+\n",
      "|            Metric            |     Value     |\n",
      "+------------------------------+---------------+\n",
      "|    Average Test Accuracy     |    0.20404    |\n",
      "|      Average Precision       |   0.042026    |\n",
      "|        Average Recall        |    0.20461    |\n",
      "|       Average F1 Score       |   0.069729    |\n",
      "|         Average Loss         |    1.6203     |\n",
      "|       Average Latency        |  0.36442 ms   |\n",
      "|   Average GPU Power Usage    |   21.985 W    |\n",
      "| Inference Energy Consumption | 0.0022255 mWh |\n",
      "+------------------------------+---------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /root/mase_output/tensorrt/quantization/onnx/2024-03-20/version_0/model.json\u001b[0m\n",
      "I0320 09:13:57.397167 139697046427456 analysis.py:84] Runtime analysis results saved to /root/mase_output/tensorrt/quantization/onnx/2024-03-20/version_0/model.json\n"
     ]
    }
   ],
   "source": [
    "mg, _ = runtime_analysis_pass(onnx_meta['onnx_dynamic_quantized_path'], pass_args=runtime_analysis_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on jsc-toy-onnx\u001b[0m\n",
      "I0320 11:54:09.398242 139711941265216 analysis.py:224] Starting transformation analysis on jsc-toy-onnx\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results jsc-toy-onnx:\n",
      "+------------------------------+----------------+\n",
      "|            Metric            |     Value      |\n",
      "+------------------------------+----------------+\n",
      "|    Average Test Accuracy     |    0.16166     |\n",
      "|      Average Precision       |    0.064334    |\n",
      "|        Average Recall        |    0.15987     |\n",
      "|       Average F1 Score       |    0.090376    |\n",
      "|         Average Loss         |     1.6116     |\n",
      "|       Average Latency        |   0.18648 ms   |\n",
      "|   Average GPU Power Usage    |    12.917 W    |\n",
      "| Inference Energy Consumption | 0.00066911 mWh |\n",
      "+------------------------------+----------------+\u001b[0m\n",
      "I0320 11:54:10.146393 139711941265216 analysis.py:340] \n",
      "Results jsc-toy-onnx:\n",
      "+------------------------------+----------------+\n",
      "|            Metric            |     Value      |\n",
      "+------------------------------+----------------+\n",
      "|    Average Test Accuracy     |    0.16166     |\n",
      "|      Average Precision       |    0.064334    |\n",
      "|        Average Recall        |    0.15987     |\n",
      "|       Average F1 Score       |    0.090376    |\n",
      "|         Average Loss         |     1.6116     |\n",
      "|       Average Latency        |   0.18648 ms   |\n",
      "|   Average GPU Power Usage    |    12.917 W    |\n",
      "| Inference Energy Consumption | 0.00066911 mWh |\n",
      "+------------------------------+----------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /root/mase_output/tensorrt/quantization/onnx/2024-03-20/version_1/model.json\u001b[0m\n",
      "I0320 11:54:10.149954 139711941265216 analysis.py:84] Runtime analysis results saved to /root/mase_output/tensorrt/quantization/onnx/2024-03-20/version_1/model.json\n"
     ]
    }
   ],
   "source": [
    "mg, _ = runtime_analysis_pass(onnx_meta['onnx_static_quantized_path'], pass_args=runtime_analysis_config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
