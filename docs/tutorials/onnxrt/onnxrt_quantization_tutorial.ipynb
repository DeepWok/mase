{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome To the ONNX Runtime Tutorial!\n",
    "\n",
    "This notebook is designed to demonstrate the features of the ONNXRT passes integrated into MASE as part of the MASERT framework.\n",
    "\n",
    "## Section 1. ONNX Runtime Optimizations\n",
    "Firstly, we will show you how we can utilise the ONNX RT optimizations. We expect to see a speed up without a loss in model accuracy. We will use a simple model, `jsc-toy`, and compare the optimized model to the original model using the `Machop API`.\n",
    "\n",
    "First, we load the machop requirements by running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/mase/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-23 17:56:50,031] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mSet logging level to info\u001b[0m\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0323 17:56:51.653448 140222021797696 logger.py:44] Set logging level to info\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import toml\n",
    "\n",
    "# Figure out the correct path\n",
    "machop_path = Path(\".\").resolve().parent.parent.parent /\"machop\"\n",
    "assert machop_path.exists(), \"Failed to find machop at: {}\".format(machop_path)\n",
    "sys.path.append(str(machop_path))\n",
    "\n",
    "# Add directory to the PATH so that chop can be called\n",
    "new_path = \"../../../machop\"\n",
    "full_path = os.path.abspath(new_path)\n",
    "os.environ['PATH'] += os.pathsep + full_path\n",
    "\n",
    "from chop.tools.utils import to_numpy_if_tensor\n",
    "from chop.tools.logger import set_logging_verbosity\n",
    "from chop.tools import get_cf_args, get_dummy_input\n",
    "from chop.passes.graph.utils import deepcopy_mase_graph\n",
    "from chop.tools.get_input import InputGenerator\n",
    "from chop.tools.checkpoint_load import load_model\n",
    "from chop.ir import MaseGraph\n",
    "from chop.models import get_model_info, get_model, get_tokenizer\n",
    "from chop.dataset import MaseDataModule, get_dataset_info\n",
    "from chop.passes.graph.transforms import metadata_value_type_cast_transform_pass\n",
    "from chop.passes.graph import (\n",
    "    summarize_quantization_analysis_pass,\n",
    "    add_common_metadata_analysis_pass,\n",
    "    init_metadata_analysis_pass,\n",
    "    add_software_metadata_analysis_pass,\n",
    "    onnx_runtime_transform_pass,\n",
    "    runtime_analysis_pass,\n",
    "    )\n",
    "\n",
    "set_logging_verbosity(\"info\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then load in a demonstration toml file and set the relevant pass arguments (this is all done automatically if we were to use the command line, see [Section X]())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# JSC_TOML_PATH = \"../../../machop/configs/onnx/jsc_gpu_ort.toml\"\n",
    "\n",
    "# # Reading TOML file and converting it into a Python dictionary\n",
    "# with open(JSC_TOML_PATH, 'r') as toml_file:\n",
    "#     pass_args = toml.load(toml_file)\n",
    "\n",
    "VGG_TOML_PATH = \"../../../machop/configs/onnx/vgg7_gpu_quant.toml\"\n",
    "\n",
    "with open(VGG_TOML_PATH, 'r') as toml_file:\n",
    "    pass_args = toml.load(toml_file)\n",
    "\n",
    "# Extract the 'passes.tensorrt' section and its children\n",
    "onnx_config = pass_args.get('passes', {}).get('onnxruntime', {})\n",
    "# Extract the 'passes.runtime_analysis' section and its children\n",
    "runtime_analysis_config = pass_args.get('passes', {}).get('runtime_analysis', {})\n",
    "\n",
    "# Load the basics in\n",
    "model_name = pass_args['model']\n",
    "dataset_name = pass_args['dataset']\n",
    "max_epochs = pass_args['max_epochs']\n",
    "batch_size = pass_args['batch_size']\n",
    "learning_rate = pass_args['learning_rate']\n",
    "accelerator = pass_args['accelerator']\n",
    "\n",
    "data_module = MaseDataModule(\n",
    "    name=dataset_name,\n",
    "    batch_size=batch_size,\n",
    "    model_name=model_name,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "data_module.prepare_data()\n",
    "data_module.setup()\n",
    "\n",
    "# Add the data_module and other necessary information to the configs\n",
    "configs = [onnx_config, runtime_analysis_config]\n",
    "for config in configs:\n",
    "    config['task'] = pass_args['task']\n",
    "    config['batch_size'] = pass_args['batch_size']\n",
    "    config['model'] = pass_args['model']\n",
    "    config['data_module'] = data_module\n",
    "    config['dataset'] = pass_args['dataset']\n",
    "    config['accelerator'] = 'cuda' if pass_args['accelerator'] == 'gpu' else pass_args['accelerator']\n",
    "    if config['accelerator'] == 'gpu':\n",
    "        os.environ['CUDA_MODULE_LOADING'] = 'LAZY'\n",
    "\n",
    "model_info = get_model_info(model_name)\n",
    "model = get_model(\n",
    "    model_name,\n",
    "    task=\"cls\",\n",
    "    dataset_info=data_module.dataset_info,\n",
    "    pretrained=False)\n",
    "\n",
    "input_generator = InputGenerator(\n",
    "    data_module=data_module,\n",
    "    model_info=model_info,\n",
    "    task=\"cls\",\n",
    "    which_dataloader=\"train\",\n",
    ")\n",
    "\n",
    "# generate the mase graph and initialize node metadata\n",
    "mg = MaseGraph(model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we train the `jsc-toy` model using the machop `train` action with the config from the toml file. You may want to switch to GPU for this task - it will not affect the cpu optimizations later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ch train --config {JSC_TOML_PATH} --accelerator gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we load in the checkpoint. You will have to adjust this according to where it has been stored in the mase_output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from ../../../mase_output/vgg7-pre-trained/test-accu-0.9332.ckpt\u001b[0m\n",
      "I0323 17:57:22.510873 140222021797696 checkpoint_load.py:85] Loaded pytorch lightning checkpoint from ../../../mase_output/vgg7-pre-trained/test-accu-0.9332.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Load in the trained checkpoint - change this accordingly\n",
    "# JSC_CHECKPOINT_PATH = \"../../../mase_output/jsc-toy_cls_jsc/software/training_ckpts/best.ckpt\"\n",
    "# model = load_model(load_name=JSC_CHECKPOINT_PATH, load_type=\"pl\", model=model)\n",
    "\n",
    "VGG_CHECKPOINT_PATH = \"../../../mase_output/vgg7-pre-trained/test-accu-0.9332.ckpt\"\n",
    "model = load_model(load_name=VGG_CHECKPOINT_PATH, load_type=\"pl\", model=model)\n",
    "\n",
    "# Initiate metadata\n",
    "dummy_in = next(iter(input_generator))\n",
    "_ = model(**dummy_in)\n",
    "mg, _ = init_metadata_analysis_pass(mg, None)\n",
    "\n",
    "# Copy original graph for analysis later\n",
    "mg_original = deepcopy_mase_graph(mg)\n",
    "\n",
    "mg, _ = add_common_metadata_analysis_pass(mg, {\"dummy_in\": dummy_in})\n",
    "mg, _ = add_software_metadata_analysis_pass(mg, None)\n",
    "mg, _ = metadata_value_type_cast_transform_pass(mg, pass_args={\"fn\": to_numpy_if_tensor})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then run the `onnx_runtime_transform_pass` which completes the optimizations using the dataloader and `jsc-toy` model. This returns metadata containing the paths to the models:\n",
    "\n",
    "- `onnx_path` (the optimized model)\n",
    "- `onnx_dynamic_quantized_path` (the dynamically )\n",
    "\n",
    "In this case, since we are not quantizing the model, only the `onnx_path` is available. \n",
    "\n",
    "The models are also stored in the directory:\n",
    "```\n",
    "mase_output\n",
    "└── onnxrt\n",
    "    └── model_task_dataset_date\n",
    "        ├── optimized\n",
    "        ├── pre_processed\n",
    "        ├── static_quantized\n",
    "        └── dynamic_quantized\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "I0323 17:57:30.319553 140222021797696 onnx_runtime.py:51] Converting PyTorch model to ONNX...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mProject will be created at /root/mase/mase_output/onnxrt/vgg7_cls_cifar10_2024-03-23\u001b[0m\n",
      "I0323 17:57:30.322780 140222021797696 onnx_runtime.py:53] Project will be created at /root/mase/mase_output/onnxrt/vgg7_cls_cifar10_2024-03-23\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /root/mase/mase_output/onnxrt/vgg7_cls_cifar10_2024-03-23/optimized/version_1/model.onnx\u001b[0m\n",
      "I0323 17:57:31.196530 140222021797696 onnx_runtime.py:71] ONNX Conversion Complete. Stored ONNX model to /root/mase/mase_output/onnxrt/vgg7_cls_cifar10_2024-03-23/optimized/version_1/model.onnx\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Model Summary: \n",
      "+-------+----------------------------+----------+---------------------------------------------------------------------+-------------------------------------+---------------------------------------------------+\n",
      "| Index |            Name            |   Type   |                                Inputs                               |               Outputs               |                     Attributes                    |\n",
      "+-------+----------------------------+----------+---------------------------------------------------------------------+-------------------------------------+---------------------------------------------------+\n",
      "|   0   |   /feature_layers.0/Conv   |   Conv   |                 input, onnx::Conv_78, onnx::Conv_79                 |   /feature_layers.0/Conv_output_0   |   dilations, group, kernel_shape, pads, strides   |\n",
      "|   1   |   /feature_layers.2/Relu   |   Relu   |                   /feature_layers.0/Conv_output_0                   |   /feature_layers.2/Relu_output_0   |                                                   |\n",
      "|   2   |   /feature_layers.3/Conv   |   Conv   |    /feature_layers.2/Relu_output_0, onnx::Conv_81, onnx::Conv_82    |   /feature_layers.3/Conv_output_0   |   dilations, group, kernel_shape, pads, strides   |\n",
      "|   3   |   /feature_layers.5/Relu   |   Relu   |                   /feature_layers.3/Conv_output_0                   |   /feature_layers.5/Relu_output_0   |                                                   |\n",
      "|   4   | /feature_layers.6/MaxPool  | MaxPool  |                   /feature_layers.5/Relu_output_0                   |  /feature_layers.6/MaxPool_output_0 | ceil_mode, dilations, kernel_shape, pads, strides |\n",
      "|   5   |   /feature_layers.7/Conv   |   Conv   |   /feature_layers.6/MaxPool_output_0, onnx::Conv_84, onnx::Conv_85  |   /feature_layers.7/Conv_output_0   |   dilations, group, kernel_shape, pads, strides   |\n",
      "|   6   |   /feature_layers.9/Relu   |   Relu   |                   /feature_layers.7/Conv_output_0                   |   /feature_layers.9/Relu_output_0   |                                                   |\n",
      "|   7   |  /feature_layers.10/Conv   |   Conv   |    /feature_layers.9/Relu_output_0, onnx::Conv_87, onnx::Conv_88    |   /feature_layers.10/Conv_output_0  |   dilations, group, kernel_shape, pads, strides   |\n",
      "|   8   |  /feature_layers.12/Relu   |   Relu   |                   /feature_layers.10/Conv_output_0                  |   /feature_layers.12/Relu_output_0  |                                                   |\n",
      "|   9   | /feature_layers.13/MaxPool | MaxPool  |                   /feature_layers.12/Relu_output_0                  | /feature_layers.13/MaxPool_output_0 | ceil_mode, dilations, kernel_shape, pads, strides |\n",
      "|   10  |  /feature_layers.14/Conv   |   Conv   |  /feature_layers.13/MaxPool_output_0, onnx::Conv_90, onnx::Conv_91  |   /feature_layers.14/Conv_output_0  |   dilations, group, kernel_shape, pads, strides   |\n",
      "|   11  |  /feature_layers.16/Relu   |   Relu   |                   /feature_layers.14/Conv_output_0                  |   /feature_layers.16/Relu_output_0  |                                                   |\n",
      "|   12  |  /feature_layers.17/Conv   |   Conv   |    /feature_layers.16/Relu_output_0, onnx::Conv_93, onnx::Conv_94   |   /feature_layers.17/Conv_output_0  |   dilations, group, kernel_shape, pads, strides   |\n",
      "|   13  |  /feature_layers.19/Relu   |   Relu   |                   /feature_layers.17/Conv_output_0                  |   /feature_layers.19/Relu_output_0  |                                                   |\n",
      "|   14  | /feature_layers.20/MaxPool | MaxPool  |                   /feature_layers.19/Relu_output_0                  | /feature_layers.20/MaxPool_output_0 | ceil_mode, dilations, kernel_shape, pads, strides |\n",
      "|   15  |         /Constant          | Constant |                                                                     |          /Constant_output_0         |                       value                       |\n",
      "|   16  |          /Reshape          | Reshape  |       /feature_layers.20/MaxPool_output_0, /Constant_output_0       |          /Reshape_output_0          |                                                   |\n",
      "|   17  |     /classifier.0/Gemm     |   Gemm   |      /Reshape_output_0, classifier.0.weight, classifier.0.bias      |     /classifier.0/Gemm_output_0     |                alpha, beta, transB                |\n",
      "|   18  |     /classifier.1/Relu     |   Relu   |                     /classifier.0/Gemm_output_0                     |     /classifier.1/Relu_output_0     |                                                   |\n",
      "|   19  |     /classifier.2/Gemm     |   Gemm   | /classifier.1/Relu_output_0, classifier.2.weight, classifier.2.bias |     /classifier.2/Gemm_output_0     |                alpha, beta, transB                |\n",
      "|   20  |     /classifier.3/Relu     |   Relu   |                     /classifier.2/Gemm_output_0                     |     /classifier.3/Relu_output_0     |                                                   |\n",
      "|   21  |      /last_layer/Gemm      |   Gemm   |   /classifier.3/Relu_output_0, last_layer.weight, last_layer.bias   |                  76                 |                alpha, beta, transB                |\n",
      "+-------+----------------------------+----------+---------------------------------------------------------------------+-------------------------------------+---------------------------------------------------+\u001b[0m\n",
      "I0323 17:57:31.378051 140222021797696 onnx_runtime.py:93] ONNX Model Summary: \n",
      "+-------+----------------------------+----------+---------------------------------------------------------------------+-------------------------------------+---------------------------------------------------+\n",
      "| Index |            Name            |   Type   |                                Inputs                               |               Outputs               |                     Attributes                    |\n",
      "+-------+----------------------------+----------+---------------------------------------------------------------------+-------------------------------------+---------------------------------------------------+\n",
      "|   0   |   /feature_layers.0/Conv   |   Conv   |                 input, onnx::Conv_78, onnx::Conv_79                 |   /feature_layers.0/Conv_output_0   |   dilations, group, kernel_shape, pads, strides   |\n",
      "|   1   |   /feature_layers.2/Relu   |   Relu   |                   /feature_layers.0/Conv_output_0                   |   /feature_layers.2/Relu_output_0   |                                                   |\n",
      "|   2   |   /feature_layers.3/Conv   |   Conv   |    /feature_layers.2/Relu_output_0, onnx::Conv_81, onnx::Conv_82    |   /feature_layers.3/Conv_output_0   |   dilations, group, kernel_shape, pads, strides   |\n",
      "|   3   |   /feature_layers.5/Relu   |   Relu   |                   /feature_layers.3/Conv_output_0                   |   /feature_layers.5/Relu_output_0   |                                                   |\n",
      "|   4   | /feature_layers.6/MaxPool  | MaxPool  |                   /feature_layers.5/Relu_output_0                   |  /feature_layers.6/MaxPool_output_0 | ceil_mode, dilations, kernel_shape, pads, strides |\n",
      "|   5   |   /feature_layers.7/Conv   |   Conv   |   /feature_layers.6/MaxPool_output_0, onnx::Conv_84, onnx::Conv_85  |   /feature_layers.7/Conv_output_0   |   dilations, group, kernel_shape, pads, strides   |\n",
      "|   6   |   /feature_layers.9/Relu   |   Relu   |                   /feature_layers.7/Conv_output_0                   |   /feature_layers.9/Relu_output_0   |                                                   |\n",
      "|   7   |  /feature_layers.10/Conv   |   Conv   |    /feature_layers.9/Relu_output_0, onnx::Conv_87, onnx::Conv_88    |   /feature_layers.10/Conv_output_0  |   dilations, group, kernel_shape, pads, strides   |\n",
      "|   8   |  /feature_layers.12/Relu   |   Relu   |                   /feature_layers.10/Conv_output_0                  |   /feature_layers.12/Relu_output_0  |                                                   |\n",
      "|   9   | /feature_layers.13/MaxPool | MaxPool  |                   /feature_layers.12/Relu_output_0                  | /feature_layers.13/MaxPool_output_0 | ceil_mode, dilations, kernel_shape, pads, strides |\n",
      "|   10  |  /feature_layers.14/Conv   |   Conv   |  /feature_layers.13/MaxPool_output_0, onnx::Conv_90, onnx::Conv_91  |   /feature_layers.14/Conv_output_0  |   dilations, group, kernel_shape, pads, strides   |\n",
      "|   11  |  /feature_layers.16/Relu   |   Relu   |                   /feature_layers.14/Conv_output_0                  |   /feature_layers.16/Relu_output_0  |                                                   |\n",
      "|   12  |  /feature_layers.17/Conv   |   Conv   |    /feature_layers.16/Relu_output_0, onnx::Conv_93, onnx::Conv_94   |   /feature_layers.17/Conv_output_0  |   dilations, group, kernel_shape, pads, strides   |\n",
      "|   13  |  /feature_layers.19/Relu   |   Relu   |                   /feature_layers.17/Conv_output_0                  |   /feature_layers.19/Relu_output_0  |                                                   |\n",
      "|   14  | /feature_layers.20/MaxPool | MaxPool  |                   /feature_layers.19/Relu_output_0                  | /feature_layers.20/MaxPool_output_0 | ceil_mode, dilations, kernel_shape, pads, strides |\n",
      "|   15  |         /Constant          | Constant |                                                                     |          /Constant_output_0         |                       value                       |\n",
      "|   16  |          /Reshape          | Reshape  |       /feature_layers.20/MaxPool_output_0, /Constant_output_0       |          /Reshape_output_0          |                                                   |\n",
      "|   17  |     /classifier.0/Gemm     |   Gemm   |      /Reshape_output_0, classifier.0.weight, classifier.0.bias      |     /classifier.0/Gemm_output_0     |                alpha, beta, transB                |\n",
      "|   18  |     /classifier.1/Relu     |   Relu   |                     /classifier.0/Gemm_output_0                     |     /classifier.1/Relu_output_0     |                                                   |\n",
      "|   19  |     /classifier.2/Gemm     |   Gemm   | /classifier.1/Relu_output_0, classifier.2.weight, classifier.2.bias |     /classifier.2/Gemm_output_0     |                alpha, beta, transB                |\n",
      "|   20  |     /classifier.3/Relu     |   Relu   |                     /classifier.2/Gemm_output_0                     |     /classifier.3/Relu_output_0     |                                                   |\n",
      "|   21  |      /last_layer/Gemm      |   Gemm   |   /classifier.3/Relu_output_0, last_layer.weight, last_layer.bias   |                  76                 |                alpha, beta, transB                |\n",
      "+-------+----------------------------+----------+---------------------------------------------------------------------+-------------------------------------+---------------------------------------------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mQuantizing model using static quantization with calibration...\u001b[0m\n",
      "I0323 17:57:32.364011 140222021797696 quantize.py:49] Quantizing model using static quantization with calibration...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mQuantization complete. Model is now calibrated and dynamically quantized.\u001b[0m\n",
      "I0323 17:58:52.714454 140222021797696 quantize.py:86] Quantization complete. Model is now calibrated and dynamically quantized.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mQuantizing model using dynamic quantization...\u001b[0m\n",
      "I0323 17:58:52.723992 140222021797696 quantize.py:28] Quantizing model using dynamic quantization...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mQuantization complete. Model is now dynamically quantized.\u001b[0m\n",
      "I0323 17:58:54.153032 140222021797696 quantize.py:43] Quantization complete. Model is now dynamically quantized.\n"
     ]
    }
   ],
   "source": [
    "mg, onnx_meta = onnx_runtime_transform_pass(mg, pass_args=onnx_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can view a summary of the ONNX model (which is the unmodified from the Pytorch one), however it should be optimized. Let's run an analysis path on both the original `MaseGraph` and the `.onnx` optimized model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on vgg7\u001b[0m\n",
      "I0323 17:59:20.901860 140222021797696 analysis.py:270] Starting transformation analysis on vgg7\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results vgg7:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.88664    |\n",
      "|      Average Precision       |   0.91334    |\n",
      "|        Average Recall        |   0.91351    |\n",
      "|       Average F1 Score       |   0.91325    |\n",
      "|         Average Loss         |   0.26564    |\n",
      "|       Average Latency        |   3.65 ms    |\n",
      "|   Average GPU Power Usage    |   31.981 W   |\n",
      "| Inference Energy Consumption | 0.032425 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "I0323 17:59:28.030013 140222021797696 analysis.py:393] \n",
      "Results vgg7:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.88664    |\n",
      "|      Average Precision       |   0.91334    |\n",
      "|        Average Recall        |   0.91351    |\n",
      "|       Average F1 Score       |   0.91325    |\n",
      "|         Average Loss         |   0.26564    |\n",
      "|       Average Latency        |   3.65 ms    |\n",
      "|   Average GPU Power Usage    |   31.981 W   |\n",
      "| Inference Energy Consumption | 0.032425 mWh |\n",
      "+------------------------------+--------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /root/mase_output/tensorrt/quantization/vgg7_cls_cifar10_2024-03-23/mase_graph/version_2/model.json\u001b[0m\n",
      "I0323 17:59:28.032738 140222021797696 analysis.py:84] Runtime analysis results saved to /root/mase_output/tensorrt/quantization/vgg7_cls_cifar10_2024-03-23/mase_graph/version_2/model.json\n"
     ]
    }
   ],
   "source": [
    "_, _ = runtime_analysis_pass(mg_original, pass_args=runtime_analysis_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on vgg7-onnx\u001b[0m\n",
      "I0323 17:59:35.753415 140222021797696 analysis.py:270] Starting transformation analysis on vgg7-onnx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results vgg7-onnx:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.90009    |\n",
      "|      Average Precision       |   0.92233    |\n",
      "|        Average Recall        |   0.92172    |\n",
      "|       Average F1 Score       |   0.92141    |\n",
      "|         Average Loss         |   0.24462    |\n",
      "|       Average Latency        |  2.3949 ms   |\n",
      "|   Average GPU Power Usage    |   39.176 W   |\n",
      "| Inference Energy Consumption | 0.026062 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "I0323 17:59:40.753919 140222021797696 analysis.py:393] \n",
      "Results vgg7-onnx:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.90009    |\n",
      "|      Average Precision       |   0.92233    |\n",
      "|        Average Recall        |   0.92172    |\n",
      "|       Average F1 Score       |   0.92141    |\n",
      "|         Average Loss         |   0.24462    |\n",
      "|       Average Latency        |  2.3949 ms   |\n",
      "|   Average GPU Power Usage    |   39.176 W   |\n",
      "| Inference Energy Consumption | 0.026062 mWh |\n",
      "+------------------------------+--------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /root/mase_output/tensorrt/quantization/vgg7_cls_cifar10_2024-03-23/onnx/version_2/model.json\u001b[0m\n",
      "I0323 17:59:40.756712 140222021797696 analysis.py:84] Runtime analysis results saved to /root/mase_output/tensorrt/quantization/vgg7_cls_cifar10_2024-03-23/onnx/version_2/model.json\n"
     ]
    }
   ],
   "source": [
    "_, _ = runtime_analysis_pass(onnx_meta['onnx_path'], pass_args=runtime_analysis_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0;93m2024-03-23 18:00:23.525246942 [W:onnxruntime:, transformer_memcpy.cc:74 ApplyImpl] 9 Memcpy nodes are added to the graph main_graph for CUDAExecutionProvider. It might have negative impact on performance (including unable to run CUDA graph). Set session_options.log_severity_level=1 to see the detail logs before this message.\u001b[m\n",
      "\u001b[0;93m2024-03-23 18:00:23.526694728 [W:onnxruntime:, session_state.cc:1166 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.\u001b[m\n",
      "\u001b[0;93m2024-03-23 18:00:23.526715163 [W:onnxruntime:, session_state.cc:1168 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.\u001b[m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on vgg7-onnx\u001b[0m\n",
      "I0323 18:00:23.547759 140222021797696 analysis.py:270] Starting transformation analysis on vgg7-onnx\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results vgg7-onnx:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |    0.8983    |\n",
      "|      Average Precision       |   0.92149    |\n",
      "|        Average Recall        |   0.92096    |\n",
      "|       Average F1 Score       |   0.92063    |\n",
      "|         Average Loss         |   0.24834    |\n",
      "|       Average Latency        |  3.2869 ms   |\n",
      "|   Average GPU Power Usage    |   40.221 W   |\n",
      "| Inference Energy Consumption | 0.036722 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "I0323 18:00:29.131531 140222021797696 analysis.py:393] \n",
      "Results vgg7-onnx:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |    0.8983    |\n",
      "|      Average Precision       |   0.92149    |\n",
      "|        Average Recall        |   0.92096    |\n",
      "|       Average F1 Score       |   0.92063    |\n",
      "|         Average Loss         |   0.24834    |\n",
      "|       Average Latency        |  3.2869 ms   |\n",
      "|   Average GPU Power Usage    |   40.221 W   |\n",
      "| Inference Energy Consumption | 0.036722 mWh |\n",
      "+------------------------------+--------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /root/mase_output/tensorrt/quantization/vgg7_cls_cifar10_2024-03-23/onnx/version_3/model.json\u001b[0m\n",
      "I0323 18:00:29.134114 140222021797696 analysis.py:84] Runtime analysis results saved to /root/mase_output/tensorrt/quantization/vgg7_cls_cifar10_2024-03-23/onnx/version_3/model.json\n"
     ]
    }
   ],
   "source": [
    "_, _ = runtime_analysis_pass(onnx_meta['onnx_static_quantized_path'], pass_args=runtime_analysis_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0;93m2024-03-23 18:01:34.334436249 [W:onnxruntime:, transformer_memcpy.cc:74 ApplyImpl] 26 Memcpy nodes are added to the graph main_graph for CUDAExecutionProvider. It might have negative impact on performance (including unable to run CUDA graph). Set session_options.log_severity_level=1 to see the detail logs before this message.\u001b[m\n"
     ]
    },
    {
     "ename": "NotImplemented",
     "evalue": "[ONNXRuntimeError] : 9 : NOT_IMPLEMENTED : Could not find an implementation for ConvInteger(10) node with name '/feature_layers.0/Conv_quant'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplemented\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mruntime_analysis_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[43monnx_meta\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43monnx_dynamic_quantized_path\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpass_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mruntime_analysis_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mase/machop/chop/passes/graph/analysis/runtime/analysis.py:24\u001b[0m, in \u001b[0;36mruntime_analysis_pass\u001b[0;34m(model, pass_args)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mruntime_analysis_pass\u001b[39m(model, pass_args\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 24\u001b[0m     analysis \u001b[38;5;241m=\u001b[39m \u001b[43mRuntimeAnalysis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpass_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m     results \u001b[38;5;241m=\u001b[39m analysis\u001b[38;5;241m.\u001b[39mevaluate()\n\u001b[1;32m     26\u001b[0m     analysis\u001b[38;5;241m.\u001b[39mstore(results)\n",
      "File \u001b[0;32m~/mase/machop/chop/passes/graph/analysis/runtime/analysis.py:69\u001b[0m, in \u001b[0;36mRuntimeAnalysis.__init__\u001b[0;34m(self, model, config)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensorrt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mcase\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.onnx\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# Load the exported ONNX model into an ONNXRuntime inference session\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mort\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInferenceSession\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproviders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mget_execution_provider\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-onnx\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124monnx\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/mase/lib/python3.11/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:419\u001b[0m, in \u001b[0;36mInferenceSession.__init__\u001b[0;34m(self, path_or_bytes, sess_options, providers, provider_options, **kwargs)\u001b[0m\n\u001b[1;32m    416\u001b[0m disabled_optimizers \u001b[38;5;241m=\u001b[39m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisabled_optimizers\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisabled_optimizers\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 419\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_inference_session\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproviders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprovider_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisabled_optimizers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_fallback:\n",
      "File \u001b[0;32m~/anaconda3/envs/mase/lib/python3.11/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:483\u001b[0m, in \u001b[0;36mInferenceSession._create_inference_session\u001b[0;34m(self, providers, provider_options, disabled_optimizers)\u001b[0m\n\u001b[1;32m    480\u001b[0m     disabled_optimizers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(disabled_optimizers)\n\u001b[1;32m    482\u001b[0m \u001b[38;5;66;03m# initialize the C++ InferenceSession\u001b[39;00m\n\u001b[0;32m--> 483\u001b[0m \u001b[43msess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize_session\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproviders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprovider_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisabled_optimizers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sess \u001b[38;5;241m=\u001b[39m sess\n\u001b[1;32m    486\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sess_options \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sess\u001b[38;5;241m.\u001b[39msession_options\n",
      "\u001b[0;31mNotImplemented\u001b[0m: [ONNXRuntimeError] : 9 : NOT_IMPLEMENTED : Could not find an implementation for ConvInteger(10) node with name '/feature_layers.0/Conv_quant'"
     ]
    }
   ],
   "source": [
    "_, _ = runtime_analysis_pass(onnx_meta['onnx_dynamic_quantized_path'], pass_args=runtime_analysis_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, the latency has decreased around 4x with the `jsc-toy` model without compromising accuracy due to the well calibrated amax and quantization-aware fine tuning. The inference energy consumption has thus also dropped tremendously and this is an excellent demonstration for the need to quantize in industry especially for LLMs in order to reduce energy usage. \n",
    "\n",
    "## Section 2. INT8 Quantization\n",
    "\n",
    "We may quantize either using FP16 or INT8 by setting the `precision` parameter in `passes.onnxruntime.default.config` to `'fp16'` or `'int8'` respectively. INT8 quantization will show the most notable latency improvements but will likely lower performance. \n",
    "\n",
    "There are two types of quantization for ONNXRT and can be set in `onnxruntime.default.config` under `quantization_types`. The differences are for how they calibrate i.e. set the scale and zero points which are only relevant for integer based quantization:\n",
    "- **Static Quantization**:\n",
    "    - The scale and zero point of activations are calculated in advance (offline) using a calibration data set.\n",
    "    - The activations have the same scale and zero point during each forward pass.\n",
    "- **Dynamic Quantization**:\n",
    "    - The scale and zero point of activations are calculated on-the-fly (online) and are specific for each forward pass.\n",
    "    - This approach is more accurate but introduces extra computational overhead.\n",
    "\n",
    "Both methodolgies first pre-procsses the model before quantization adding further optimizations. This intermidate model is stored to the `pre-processed` directory. \n",
    "\n",
    "For this example, we will set the `precision` to `'int8'` and the `precision_types` to `['static', 'dynamic']` to compare both quantization methods, whilst keeping the other settings the exact same for a fair comparison against the optimized model. This time however, we will use chop from the terminal which runs the same pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "JSC_TOML_PATH = \"../../../machop/configs/onnx/jsc_gpu_quant.toml\"\n",
    "# VGG_TOML_PATH = \"../../../machop/configs/onnx/vgg7_gpu_quant.toml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-23 17:30:06,279] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "INFO: Seed set to 0\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0323 17:30:08.548976 139671930701632 seed.py:54] Seed set to 0\n",
      "+-------------------------+------------------------+--------------+-----------------+------------------------+\n",
      "| Name                    |        Default         | Config. File | Manual Override |       Effective        |\n",
      "+-------------------------+------------------------+--------------+-----------------+------------------------+\n",
      "| task                    |     \u001b[38;5;8mclassification\u001b[0m     |     cls      |                 |          cls           |\n",
      "| load_name               |          None          |              |                 |          None          |\n",
      "| load_type               |           mz           |              |                 |           mz           |\n",
      "| batch_size              |          \u001b[38;5;8m128\u001b[0m           |     256      |                 |          256           |\n",
      "| to_debug                |         False          |              |                 |         False          |\n",
      "| log_level               |          info          |              |                 |          info          |\n",
      "| report_to               |      tensorboard       |              |                 |      tensorboard       |\n",
      "| seed                    |           0            |              |                 |           0            |\n",
      "| quant_config            |          None          |              |                 |          None          |\n",
      "| training_optimizer      |          adam          |              |                 |          adam          |\n",
      "| trainer_precision       |        16-mixed        |              |                 |        16-mixed        |\n",
      "| learning_rate           |         \u001b[38;5;8m1e-05\u001b[0m          |    1000.0    |                 |         1000.0         |\n",
      "| weight_decay            |           0            |              |                 |           0            |\n",
      "| max_epochs              |           \u001b[38;5;8m20\u001b[0m           |      10      |                 |           10           |\n",
      "| max_steps               |           -1           |              |                 |           -1           |\n",
      "| accumulate_grad_batches |           1            |              |                 |           1            |\n",
      "| log_every_n_steps       |           50           |              |                 |           50           |\n",
      "| num_workers             |           28           |              |                 |           28           |\n",
      "| num_devices             |           1            |              |                 |           1            |\n",
      "| num_nodes               |           1            |              |                 |           1            |\n",
      "| accelerator             |          \u001b[38;5;8mauto\u001b[0m          |     gpu      |                 |          gpu           |\n",
      "| strategy                |          auto          |              |                 |          auto          |\n",
      "| is_to_auto_requeue      |         False          |              |                 |         False          |\n",
      "| github_ci               |         False          |              |                 |         False          |\n",
      "| disable_dataset_cache   |         False          |              |                 |         False          |\n",
      "| target                  |  xcu250-figd2104-2L-e  |              |                 |  xcu250-figd2104-2L-e  |\n",
      "| num_targets             |          100           |              |                 |          100           |\n",
      "| is_pretrained           |         False          |              |                 |         False          |\n",
      "| max_token_len           |          512           |              |                 |          512           |\n",
      "| project_dir             | /root/mase/mase_output |              |                 | /root/mase/mase_output |\n",
      "| project                 |          None          |              |                 |          None          |\n",
      "| model                   |          \u001b[38;5;8mNone\u001b[0m          |   jsc-toy    |                 |        jsc-toy         |\n",
      "| dataset                 |          \u001b[38;5;8mNone\u001b[0m          |     jsc      |                 |          jsc           |\n",
      "| t_max                   |           20           |              |                 |           20           |\n",
      "| eta_min                 |         1e-06          |              |                 |         1e-06          |\n",
      "+-------------------------+------------------------+--------------+-----------------+------------------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mInitialising model 'jsc-toy'...\u001b[0m\n",
      "I0323 17:30:08.556980 139671930701632 cli.py:841] Initialising model 'jsc-toy'...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mInitialising dataset 'jsc'...\u001b[0m\n",
      "I0323 17:30:08.558956 139671930701632 cli.py:869] Initialising dataset 'jsc'...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mProject will be created at /root/mase/mase_output/jsc-toy_cls_jsc_2024-03-23\u001b[0m\n",
      "I0323 17:30:08.559209 139671930701632 cli.py:905] Project will be created at /root/mase/mase_output/jsc-toy_cls_jsc_2024-03-23\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTransforming model 'jsc-toy'...\u001b[0m\n",
      "I0323 17:30:08.594670 139671930701632 cli.py:365] Transforming model 'jsc-toy'...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "I0323 17:30:13.437961 139671930701632 onnx_runtime.py:51] Converting PyTorch model to ONNX...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mProject will be created at /root/mase/mase_output/onnxrt/jsc-toy_cls_jsc_2024-03-23\u001b[0m\n",
      "I0323 17:30:13.438657 139671930701632 onnx_runtime.py:53] Project will be created at /root/mase/mase_output/onnxrt/jsc-toy_cls_jsc_2024-03-23\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /root/mase/mase_output/onnxrt/jsc-toy_cls_jsc_2024-03-23/optimized/version_5/model.onnx\u001b[0m\n",
      "I0323 17:30:15.476591 139671930701632 onnx_runtime.py:71] ONNX Conversion Complete. Stored ONNX model to /root/mase/mase_output/onnxrt/jsc-toy_cls_jsc_2024-03-23/optimized/version_5/model.onnx\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Model Summary: \n",
      "+-------+----------------------------------+--------------------+--------------------------------------------------------------------------------------------------------------------------+-------------------------------------------+---------------------+\n",
      "| Index |               Name               |        Type        |                                                          Inputs                                                          |                  Outputs                  |      Attributes     |\n",
      "+-------+----------------------------------+--------------------+--------------------------------------------------------------------------------------------------------------------------+-------------------------------------------+---------------------+\n",
      "|   0   |            Identity_0            |      Identity      |                                                    seq_blocks.3.bias                                                     |             seq_blocks.6.bias             |                     |\n",
      "|   1   |            Identity_1            |      Identity      |                                                   seq_blocks.3.weight                                                    |            seq_blocks.6.weight            |                     |\n",
      "|   2   | /seq_blocks.0/BatchNormalization | BatchNormalization |            input, seq_blocks.0.weight, seq_blocks.0.bias, seq_blocks.0.running_mean, seq_blocks.0.running_var            | /seq_blocks.0/BatchNormalization_output_0 |  epsilon, momentum  |\n",
      "|   3   |        /seq_blocks.1/Relu        |        Relu        |                                        /seq_blocks.0/BatchNormalization_output_0                                         |        /seq_blocks.1/Relu_output_0        |                     |\n",
      "|   4   |        /seq_blocks.2/Gemm        |        Gemm        |                           /seq_blocks.1/Relu_output_0, seq_blocks.2.weight, seq_blocks.2.bias                            |        /seq_blocks.2/Gemm_output_0        | alpha, beta, transB |\n",
      "|   5   | /seq_blocks.3/BatchNormalization | BatchNormalization | /seq_blocks.2/Gemm_output_0, seq_blocks.3.weight, seq_blocks.3.bias, seq_blocks.3.running_mean, seq_blocks.3.running_var | /seq_blocks.3/BatchNormalization_output_0 |  epsilon, momentum  |\n",
      "|   6   |        /seq_blocks.4/Relu        |        Relu        |                                        /seq_blocks.3/BatchNormalization_output_0                                         |        /seq_blocks.4/Relu_output_0        |                     |\n",
      "|   7   |        /seq_blocks.5/Gemm        |        Gemm        |                           /seq_blocks.4/Relu_output_0, seq_blocks.5.weight, seq_blocks.5.bias                            |        /seq_blocks.5/Gemm_output_0        | alpha, beta, transB |\n",
      "|   8   | /seq_blocks.6/BatchNormalization | BatchNormalization | /seq_blocks.5/Gemm_output_0, seq_blocks.6.weight, seq_blocks.6.bias, seq_blocks.6.running_mean, seq_blocks.6.running_var | /seq_blocks.6/BatchNormalization_output_0 |  epsilon, momentum  |\n",
      "|   9   |        /seq_blocks.7/Relu        |        Relu        |                                        /seq_blocks.6/BatchNormalization_output_0                                         |        /seq_blocks.7/Relu_output_0        |                     |\n",
      "|   10  |        /seq_blocks.8/Gemm        |        Gemm        |                           /seq_blocks.7/Relu_output_0, seq_blocks.8.weight, seq_blocks.8.bias                            |        /seq_blocks.8/Gemm_output_0        | alpha, beta, transB |\n",
      "|   11  | /seq_blocks.9/BatchNormalization | BatchNormalization | /seq_blocks.8/Gemm_output_0, seq_blocks.9.weight, seq_blocks.9.bias, seq_blocks.9.running_mean, seq_blocks.9.running_var | /seq_blocks.9/BatchNormalization_output_0 |  epsilon, momentum  |\n",
      "|   12  |       /seq_blocks.10/Relu        |        Relu        |                                        /seq_blocks.9/BatchNormalization_output_0                                         |                     37                    |                     |\n",
      "+-------+----------------------------------+--------------------+--------------------------------------------------------------------------------------------------------------------------+-------------------------------------------+---------------------+\u001b[0m\n",
      "I0323 17:30:15.480776 139671930701632 onnx_runtime.py:93] ONNX Model Summary: \n",
      "+-------+----------------------------------+--------------------+--------------------------------------------------------------------------------------------------------------------------+-------------------------------------------+---------------------+\n",
      "| Index |               Name               |        Type        |                                                          Inputs                                                          |                  Outputs                  |      Attributes     |\n",
      "+-------+----------------------------------+--------------------+--------------------------------------------------------------------------------------------------------------------------+-------------------------------------------+---------------------+\n",
      "|   0   |            Identity_0            |      Identity      |                                                    seq_blocks.3.bias                                                     |             seq_blocks.6.bias             |                     |\n",
      "|   1   |            Identity_1            |      Identity      |                                                   seq_blocks.3.weight                                                    |            seq_blocks.6.weight            |                     |\n",
      "|   2   | /seq_blocks.0/BatchNormalization | BatchNormalization |            input, seq_blocks.0.weight, seq_blocks.0.bias, seq_blocks.0.running_mean, seq_blocks.0.running_var            | /seq_blocks.0/BatchNormalization_output_0 |  epsilon, momentum  |\n",
      "|   3   |        /seq_blocks.1/Relu        |        Relu        |                                        /seq_blocks.0/BatchNormalization_output_0                                         |        /seq_blocks.1/Relu_output_0        |                     |\n",
      "|   4   |        /seq_blocks.2/Gemm        |        Gemm        |                           /seq_blocks.1/Relu_output_0, seq_blocks.2.weight, seq_blocks.2.bias                            |        /seq_blocks.2/Gemm_output_0        | alpha, beta, transB |\n",
      "|   5   | /seq_blocks.3/BatchNormalization | BatchNormalization | /seq_blocks.2/Gemm_output_0, seq_blocks.3.weight, seq_blocks.3.bias, seq_blocks.3.running_mean, seq_blocks.3.running_var | /seq_blocks.3/BatchNormalization_output_0 |  epsilon, momentum  |\n",
      "|   6   |        /seq_blocks.4/Relu        |        Relu        |                                        /seq_blocks.3/BatchNormalization_output_0                                         |        /seq_blocks.4/Relu_output_0        |                     |\n",
      "|   7   |        /seq_blocks.5/Gemm        |        Gemm        |                           /seq_blocks.4/Relu_output_0, seq_blocks.5.weight, seq_blocks.5.bias                            |        /seq_blocks.5/Gemm_output_0        | alpha, beta, transB |\n",
      "|   8   | /seq_blocks.6/BatchNormalization | BatchNormalization | /seq_blocks.5/Gemm_output_0, seq_blocks.6.weight, seq_blocks.6.bias, seq_blocks.6.running_mean, seq_blocks.6.running_var | /seq_blocks.6/BatchNormalization_output_0 |  epsilon, momentum  |\n",
      "|   9   |        /seq_blocks.7/Relu        |        Relu        |                                        /seq_blocks.6/BatchNormalization_output_0                                         |        /seq_blocks.7/Relu_output_0        |                     |\n",
      "|   10  |        /seq_blocks.8/Gemm        |        Gemm        |                           /seq_blocks.7/Relu_output_0, seq_blocks.8.weight, seq_blocks.8.bias                            |        /seq_blocks.8/Gemm_output_0        | alpha, beta, transB |\n",
      "|   11  | /seq_blocks.9/BatchNormalization | BatchNormalization | /seq_blocks.8/Gemm_output_0, seq_blocks.9.weight, seq_blocks.9.bias, seq_blocks.9.running_mean, seq_blocks.9.running_var | /seq_blocks.9/BatchNormalization_output_0 |  epsilon, momentum  |\n",
      "|   12  |       /seq_blocks.10/Relu        |        Relu        |                                        /seq_blocks.9/BatchNormalization_output_0                                         |                     37                    |                     |\n",
      "+-------+----------------------------------+--------------------+--------------------------------------------------------------------------------------------------------------------------+-------------------------------------------+---------------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mQuantizing model using static quantization with calibration...\u001b[0m\n",
      "I0323 17:30:15.506266 139671930701632 quantize.py:49] Quantizing model using static quantization with calibration...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mQuantization complete. Model is now calibrated and dynamically quantized.\u001b[0m\n",
      "I0323 17:30:18.068330 139671930701632 quantize.py:86] Quantization complete. Model is now calibrated and dynamically quantized.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mQuantizing model using dynamic quantization...\u001b[0m\n",
      "I0323 17:30:18.090440 139671930701632 quantize.py:28] Quantizing model using dynamic quantization...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mQuantization complete. Model is now dynamically quantized.\u001b[0m\n",
      "I0323 17:30:18.096197 139671930701632 quantize.py:43] Quantization complete. Model is now dynamically quantized.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPerforming runtime analysis on original graph...\u001b[0m\n",
      "I0323 17:30:18.096409 139671930701632 transform.py:169] Performing runtime analysis on original graph...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on jsc-toy\u001b[0m\n",
      "I0323 17:30:18.096645 139671930701632 analysis.py:270] Starting transformation analysis on jsc-toy\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results jsc-toy:\n",
      "+------------------------------+---------------+\n",
      "|      Metric (Per Batch)      |     Value     |\n",
      "+------------------------------+---------------+\n",
      "|    Average Test Accuracy     |    0.2042     |\n",
      "|      Average Precision       |    0.22737    |\n",
      "|        Average Recall        |    0.2042     |\n",
      "|       Average F1 Score       |    0.20298    |\n",
      "|         Average Loss         |    1.7029     |\n",
      "|       Average Latency        |  0.78594 ms   |\n",
      "|   Average GPU Power Usage    |   22.478 W    |\n",
      "| Inference Energy Consumption | 0.0049072 mWh |\n",
      "+------------------------------+---------------+\u001b[0m\n",
      "I0323 17:30:22.659376 139671930701632 analysis.py:393] \n",
      "Results jsc-toy:\n",
      "+------------------------------+---------------+\n",
      "|      Metric (Per Batch)      |     Value     |\n",
      "+------------------------------+---------------+\n",
      "|    Average Test Accuracy     |    0.2042     |\n",
      "|      Average Precision       |    0.22737    |\n",
      "|        Average Recall        |    0.2042     |\n",
      "|       Average F1 Score       |    0.20298    |\n",
      "|         Average Loss         |    1.7029     |\n",
      "|       Average Latency        |  0.78594 ms   |\n",
      "|   Average GPU Power Usage    |   22.478 W    |\n",
      "| Inference Energy Consumption | 0.0049072 mWh |\n",
      "+------------------------------+---------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /root/mase_output/tensorrt/quantization/jsc-toy_cls_jsc_2024-03-23/mase_graph/version_0/model.json\u001b[0m\n",
      "I0323 17:30:22.660689 139671930701632 analysis.py:84] Runtime analysis results saved to /root/mase_output/tensorrt/quantization/jsc-toy_cls_jsc_2024-03-23/mase_graph/version_0/model.json\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPerforming runtime analysis on optimized quantized graph...\u001b[0m\n",
      "I0323 17:30:22.660854 139671930701632 transform.py:175] Performing runtime analysis on optimized quantized graph...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on jsc-toy-onnx\u001b[0m\n",
      "I0323 17:30:22.673654 139671930701632 analysis.py:270] Starting transformation analysis on jsc-toy-onnx\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results jsc-toy-onnx:\n",
      "+------------------------------+---------------+\n",
      "|      Metric (Per Batch)      |     Value     |\n",
      "+------------------------------+---------------+\n",
      "|    Average Test Accuracy     |      0.2      |\n",
      "|      Average Precision       |   0.040634    |\n",
      "|        Average Recall        |    0.20158    |\n",
      "|       Average F1 Score       |   0.067634    |\n",
      "|         Average Loss         |    1.5954     |\n",
      "|       Average Latency        |  0.25075 ms   |\n",
      "|   Average GPU Power Usage    |   22.529 W    |\n",
      "| Inference Energy Consumption | 0.0015692 mWh |\n",
      "+------------------------------+---------------+\u001b[0m\n",
      "I0323 17:30:27.241518 139671930701632 analysis.py:393] \n",
      "Results jsc-toy-onnx:\n",
      "+------------------------------+---------------+\n",
      "|      Metric (Per Batch)      |     Value     |\n",
      "+------------------------------+---------------+\n",
      "|    Average Test Accuracy     |      0.2      |\n",
      "|      Average Precision       |   0.040634    |\n",
      "|        Average Recall        |    0.20158    |\n",
      "|       Average F1 Score       |   0.067634    |\n",
      "|         Average Loss         |    1.5954     |\n",
      "|       Average Latency        |  0.25075 ms   |\n",
      "|   Average GPU Power Usage    |   22.529 W    |\n",
      "| Inference Energy Consumption | 0.0015692 mWh |\n",
      "+------------------------------+---------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /root/mase_output/tensorrt/quantization/jsc-toy_cls_jsc_2024-03-23/onnx/version_0/model.json\u001b[0m\n",
      "I0323 17:30:27.243621 139671930701632 analysis.py:84] Runtime analysis results saved to /root/mase_output/tensorrt/quantization/jsc-toy_cls_jsc_2024-03-23/onnx/version_0/model.json\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPerforming runtime analysis on static quantized graph...\u001b[0m\n",
      "I0323 17:30:27.246692 139671930701632 transform.py:190] Performing runtime analysis on static quantized graph...\n",
      "\u001b[0;93m2024-03-23 17:30:27.261344631 [W:onnxruntime:, transformer_memcpy.cc:74 ApplyImpl] 3 Memcpy nodes are added to the graph main_graph for CUDAExecutionProvider. It might have negative impact on performance (including unable to run CUDA graph). Set session_options.log_severity_level=1 to see the detail logs before this message.\u001b[m\n",
      "\u001b[0;93m2024-03-23 17:30:27.261755590 [W:onnxruntime:, session_state.cc:1166 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.\u001b[m\n",
      "\u001b[0;93m2024-03-23 17:30:27.261772077 [W:onnxruntime:, session_state.cc:1168 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.\u001b[m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on jsc-toy-onnx\u001b[0m\n",
      "I0323 17:30:27.266188 139671930701632 analysis.py:270] Starting transformation analysis on jsc-toy-onnx\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results jsc-toy-onnx:\n",
      "+------------------------------+---------------+\n",
      "|      Metric (Per Batch)      |     Value     |\n",
      "+------------------------------+---------------+\n",
      "|    Average Test Accuracy     |      0.2      |\n",
      "|      Average Precision       |   0.040634    |\n",
      "|        Average Recall        |    0.20158    |\n",
      "|       Average F1 Score       |   0.067634    |\n",
      "|         Average Loss         |    1.5955     |\n",
      "|       Average Latency        |  0.30824 ms   |\n",
      "|   Average GPU Power Usage    |   22.546 W    |\n",
      "| Inference Energy Consumption | 0.0019304 mWh |\n",
      "+------------------------------+---------------+\u001b[0m\n",
      "I0323 17:30:31.753788 139671930701632 analysis.py:393] \n",
      "Results jsc-toy-onnx:\n",
      "+------------------------------+---------------+\n",
      "|      Metric (Per Batch)      |     Value     |\n",
      "+------------------------------+---------------+\n",
      "|    Average Test Accuracy     |      0.2      |\n",
      "|      Average Precision       |   0.040634    |\n",
      "|        Average Recall        |    0.20158    |\n",
      "|       Average F1 Score       |   0.067634    |\n",
      "|         Average Loss         |    1.5955     |\n",
      "|       Average Latency        |  0.30824 ms   |\n",
      "|   Average GPU Power Usage    |   22.546 W    |\n",
      "| Inference Energy Consumption | 0.0019304 mWh |\n",
      "+------------------------------+---------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /root/mase_output/tensorrt/quantization/jsc-toy_cls_jsc_2024-03-23/onnx/version_1/model.json\u001b[0m\n",
      "I0323 17:30:31.754825 139671930701632 analysis.py:84] Runtime analysis results saved to /root/mase_output/tensorrt/quantization/jsc-toy_cls_jsc_2024-03-23/onnx/version_1/model.json\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPerforming runtime analysis on dynamic quantized graph...\u001b[0m\n",
      "I0323 17:30:31.757782 139671930701632 transform.py:195] Performing runtime analysis on dynamic quantized graph...\n",
      "\u001b[0;93m2024-03-23 17:30:31.826145248 [W:onnxruntime:, transformer_memcpy.cc:74 ApplyImpl] 9 Memcpy nodes are added to the graph main_graph for CUDAExecutionProvider. It might have negative impact on performance (including unable to run CUDA graph). Set session_options.log_severity_level=1 to see the detail logs before this message.\u001b[m\n",
      "\u001b[0;93m2024-03-23 17:30:31.826687284 [W:onnxruntime:, session_state.cc:1166 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.\u001b[m\n",
      "\u001b[0;93m2024-03-23 17:30:31.826704446 [W:onnxruntime:, session_state.cc:1168 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.\u001b[m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on jsc-toy-onnx\u001b[0m\n",
      "I0323 17:30:31.831305 139671930701632 analysis.py:270] Starting transformation analysis on jsc-toy-onnx\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results jsc-toy-onnx:\n",
      "+------------------------------+---------------+\n",
      "|      Metric (Per Batch)      |     Value     |\n",
      "+------------------------------+---------------+\n",
      "|    Average Test Accuracy     |      0.2      |\n",
      "|      Average Precision       |   0.040634    |\n",
      "|        Average Recall        |    0.20158    |\n",
      "|       Average F1 Score       |   0.067634    |\n",
      "|         Average Loss         |    1.5955     |\n",
      "|       Average Latency        |  0.43082 ms   |\n",
      "|   Average GPU Power Usage    |   22.683 W    |\n",
      "| Inference Energy Consumption | 0.0027145 mWh |\n",
      "+------------------------------+---------------+\u001b[0m\n",
      "I0323 17:30:36.754137 139671930701632 analysis.py:393] \n",
      "Results jsc-toy-onnx:\n",
      "+------------------------------+---------------+\n",
      "|      Metric (Per Batch)      |     Value     |\n",
      "+------------------------------+---------------+\n",
      "|    Average Test Accuracy     |      0.2      |\n",
      "|      Average Precision       |   0.040634    |\n",
      "|        Average Recall        |    0.20158    |\n",
      "|       Average F1 Score       |   0.067634    |\n",
      "|         Average Loss         |    1.5955     |\n",
      "|       Average Latency        |  0.43082 ms   |\n",
      "|   Average GPU Power Usage    |   22.683 W    |\n",
      "| Inference Energy Consumption | 0.0027145 mWh |\n",
      "+------------------------------+---------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /root/mase_output/tensorrt/quantization/jsc-toy_cls_jsc_2024-03-23/onnx/version_2/model.json\u001b[0m\n",
      "I0323 17:30:36.755477 139671930701632 analysis.py:84] Runtime analysis results saved to /root/mase_output/tensorrt/quantization/jsc-toy_cls_jsc_2024-03-23/onnx/version_2/model.json\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mSaved mase graph to /root/mase/mase_output/jsc-toy_cls_jsc_2024-03-23/software/transform/transformed_ckpt\u001b[0m\n",
      "I0323 17:30:36.867921 139671930701632 save_and_load.py:147] Saved mase graph to /root/mase/mase_output/jsc-toy_cls_jsc_2024-03-23/software/transform/transformed_ckpt\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTransformation is completed\u001b[0m\n",
      "I0323 17:30:36.868196 139671930701632 cli.py:383] Transformation is completed\n"
     ]
    }
   ],
   "source": [
    "!ch transform --config {JSC_TOML_PATH}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
