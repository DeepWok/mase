{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome To the ONNX Runtime Tutorial!\n",
    "\n",
    "This notebook is designed to demonstrate the features of the ONNXRT passes integrated into MASE as part of the MASERT framework.\n",
    "\n",
    "## Section 1. ONNX Runtime Optimizations\n",
    "Firstly, we will show you how we can utilise the ONNX RT optimizations. We expect to see a speed up without a loss in model accuracy. We will use a simple model, `jsc-toy`, and compare the optimized model to the original model using the `Machop API`.\n",
    "\n",
    "First, we load the machop requirements by running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mSet logging level to info\u001b[0m\n",
      "I0326 20:06:17.898586 140536527320896 logger.py:44] Set logging level to info\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import toml\n",
    "\n",
    "# Figure out the correct path\n",
    "machop_path = Path(\".\").resolve().parent.parent.parent /\"machop\"\n",
    "assert machop_path.exists(), \"Failed to find machop at: {}\".format(machop_path)\n",
    "sys.path.append(str(machop_path))\n",
    "\n",
    "# Add directory to the PATH so that chop can be called\n",
    "new_path = \"../../../machop\"\n",
    "full_path = os.path.abspath(new_path)\n",
    "os.environ['PATH'] += os.pathsep + full_path\n",
    "\n",
    "from chop.tools.utils import to_numpy_if_tensor\n",
    "from chop.tools.logger import set_logging_verbosity\n",
    "from chop.tools import get_cf_args, get_dummy_input\n",
    "from chop.passes.graph.utils import deepcopy_mase_graph\n",
    "from chop.tools.get_input import InputGenerator\n",
    "from chop.tools.checkpoint_load import load_model\n",
    "from chop.ir import MaseGraph\n",
    "from chop.models import get_model_info, get_model, get_tokenizer\n",
    "from chop.dataset import MaseDataModule, get_dataset_info\n",
    "from chop.passes.graph.transforms import metadata_value_type_cast_transform_pass\n",
    "from chop.passes.graph import (\n",
    "    summarize_quantization_analysis_pass,\n",
    "    add_common_metadata_analysis_pass,\n",
    "    init_metadata_analysis_pass,\n",
    "    add_software_metadata_analysis_pass,\n",
    "    onnx_runtime_transform_pass,\n",
    "    runtime_analysis_pass,\n",
    "    )\n",
    "\n",
    "set_logging_verbosity(\"info\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then load in a demonstration toml file and set the relevant pass arguments (this is all done automatically if we were to use the command line, see [Section 2](#section-2-int8-quantization))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "JSC_TOML_PATH = \"../../../machop/configs/onnx/jsc_cpu_ort.toml\"\n",
    "\n",
    "# Reading TOML file and converting it into a Python dictionary\n",
    "with open(JSC_TOML_PATH, 'r') as toml_file:\n",
    "    pass_args = toml.load(toml_file)\n",
    "\n",
    "# Extract the 'passes.tensorrt' section and its children\n",
    "onnx_config = pass_args.get('passes', {}).get('onnxruntime', {})\n",
    "# Extract the 'passes.runtime_analysis' section and its children\n",
    "runtime_analysis_config = pass_args.get('passes', {}).get('runtime_analysis', {})\n",
    "\n",
    "# Load the basics in\n",
    "model_name = pass_args['model']\n",
    "dataset_name = pass_args['dataset']\n",
    "max_epochs = pass_args['max_epochs']\n",
    "batch_size = pass_args['batch_size']\n",
    "learning_rate = pass_args['learning_rate']\n",
    "accelerator = pass_args['accelerator']\n",
    "\n",
    "data_module = MaseDataModule(\n",
    "    name=dataset_name,\n",
    "    batch_size=batch_size,\n",
    "    model_name=model_name,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "data_module.prepare_data()\n",
    "data_module.setup()\n",
    "\n",
    "# Add the data_module and other necessary information to the configs\n",
    "configs = [onnx_config, runtime_analysis_config]\n",
    "for config in configs:\n",
    "    config['task'] = pass_args['task']\n",
    "    config['batch_size'] = pass_args['batch_size']\n",
    "    config['model'] = pass_args['model']\n",
    "    config['data_module'] = data_module\n",
    "    config['dataset'] = pass_args['dataset']\n",
    "    config['accelerator'] = 'cuda' if pass_args['accelerator'] == 'gpu' else pass_args['accelerator']\n",
    "    if config['accelerator'] == 'gpu':\n",
    "        os.environ['CUDA_MODULE_LOADING'] = 'LAZY'\n",
    "\n",
    "model_info = get_model_info(model_name)\n",
    "model = get_model(\n",
    "    model_name,\n",
    "    task=\"cls\",\n",
    "    dataset_info=data_module.dataset_info,\n",
    "    pretrained=False)\n",
    "\n",
    "input_generator = InputGenerator(\n",
    "    data_module=data_module,\n",
    "    model_info=model_info,\n",
    "    task=\"cls\",\n",
    "    which_dataloader=\"train\",\n",
    ")\n",
    "\n",
    "# generate the mase graph and initialize node metadata\n",
    "mg = MaseGraph(model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we train the `jsc-toy` model using the machop `train` action with the config from the toml file. You may want to switch to GPU for this task - it will not affect the cpu optimizations later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ch train --config {JSC_TOML_PATH} --accelerator gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we load in the checkpoint. You will have to adjust this according to where it has been stored in the mase_output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from ../../../mase_output/jsc-toy_cls_jsc/software/training_ckpts/best.ckpt\u001b[0m\n",
      "I0326 16:06:02.322584 140445122471744 checkpoint_load.py:85] Loaded pytorch lightning checkpoint from ../../../mase_output/jsc-toy_cls_jsc/software/training_ckpts/best.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Load in the trained checkpoint - change this accordingly\n",
    "JSC_CHECKPOINT_PATH = \"../../../mase_output/jsc-toy_cls_jsc/software/training_ckpts/best.ckpt\"\n",
    "model = load_model(load_name=JSC_CHECKPOINT_PATH, load_type=\"pl\", model=model)\n",
    "\n",
    "# Initiate metadata\n",
    "dummy_in = next(iter(input_generator))\n",
    "_ = model(**dummy_in)\n",
    "mg, _ = init_metadata_analysis_pass(mg, None)\n",
    "\n",
    "# Copy original graph for analysis later\n",
    "mg_original = deepcopy_mase_graph(mg)\n",
    "\n",
    "mg, _ = add_common_metadata_analysis_pass(mg, {\"dummy_in\": dummy_in})\n",
    "mg, _ = add_software_metadata_analysis_pass(mg, None)\n",
    "mg, _ = metadata_value_type_cast_transform_pass(mg, pass_args={\"fn\": to_numpy_if_tensor})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then run the `onnx_runtime_transform_pass` which completes the optimizations using the dataloader and `jsc-toy` model. This returns metadata containing the paths to the models:\n",
    "\n",
    "- `onnx_path` (the optimized model)\n",
    "- `onnx_dynamic_quantized_path` (the dynamically )\n",
    "\n",
    "In this case, since we are not quantizing the model, only the `onnx_path` is available. \n",
    "\n",
    "The models are also stored in the directory:\n",
    "```\n",
    "mase_output\n",
    "└── onnxrt\n",
    "    └── model_task_dataset_date\n",
    "        ├── optimized\n",
    "        ├── pre_processed\n",
    "        ├── static_quantized\n",
    "        └── dynamic_quantized\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "I0326 16:06:15.656519 140445122471744 onnx_runtime.py:48] Converting PyTorch model to ONNX...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mProject will be created at /root/mase/mase_output/onnxrt/jsc-toy_cls_jsc_2024-03-26\u001b[0m\n",
      "I0326 16:06:15.661494 140445122471744 onnx_runtime.py:50] Project will be created at /root/mase/mase_output/onnxrt/jsc-toy_cls_jsc_2024-03-26\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /root/mase/mase_output/onnxrt/jsc-toy_cls_jsc_2024-03-26/optimized/version_0/model.onnx\u001b[0m\n",
      "I0326 16:06:15.785387 140445122471744 onnx_runtime.py:68] ONNX Conversion Complete. Stored ONNX model to /root/mase/mase_output/onnxrt/jsc-toy_cls_jsc_2024-03-26/optimized/version_0/model.onnx\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Model Summary: \n",
      "+-------+----------------------------------+--------------------+--------------------------------------------------------------------------------------------------------------------------+-------------------------------------------+---------------------+\n",
      "| Index |               Name               |        Type        |                                                          Inputs                                                          |                  Outputs                  |      Attributes     |\n",
      "+-------+----------------------------------+--------------------+--------------------------------------------------------------------------------------------------------------------------+-------------------------------------------+---------------------+\n",
      "|   0   | /seq_blocks.0/BatchNormalization | BatchNormalization |            input, seq_blocks.0.weight, seq_blocks.0.bias, seq_blocks.0.running_mean, seq_blocks.0.running_var            | /seq_blocks.0/BatchNormalization_output_0 |  epsilon, momentum  |\n",
      "|   1   |        /seq_blocks.1/Relu        |        Relu        |                                        /seq_blocks.0/BatchNormalization_output_0                                         |        /seq_blocks.1/Relu_output_0        |                     |\n",
      "|   2   |        /seq_blocks.2/Gemm        |        Gemm        |                           /seq_blocks.1/Relu_output_0, seq_blocks.2.weight, seq_blocks.2.bias                            |        /seq_blocks.2/Gemm_output_0        | alpha, beta, transB |\n",
      "|   3   | /seq_blocks.3/BatchNormalization | BatchNormalization | /seq_blocks.2/Gemm_output_0, seq_blocks.3.weight, seq_blocks.3.bias, seq_blocks.3.running_mean, seq_blocks.3.running_var | /seq_blocks.3/BatchNormalization_output_0 |  epsilon, momentum  |\n",
      "|   4   |        /seq_blocks.4/Relu        |        Relu        |                                        /seq_blocks.3/BatchNormalization_output_0                                         |        /seq_blocks.4/Relu_output_0        |                     |\n",
      "|   5   |        /seq_blocks.5/Gemm        |        Gemm        |                           /seq_blocks.4/Relu_output_0, seq_blocks.5.weight, seq_blocks.5.bias                            |        /seq_blocks.5/Gemm_output_0        | alpha, beta, transB |\n",
      "|   6   | /seq_blocks.6/BatchNormalization | BatchNormalization | /seq_blocks.5/Gemm_output_0, seq_blocks.6.weight, seq_blocks.6.bias, seq_blocks.6.running_mean, seq_blocks.6.running_var | /seq_blocks.6/BatchNormalization_output_0 |  epsilon, momentum  |\n",
      "|   7   |        /seq_blocks.7/Relu        |        Relu        |                                        /seq_blocks.6/BatchNormalization_output_0                                         |        /seq_blocks.7/Relu_output_0        |                     |\n",
      "|   8   |        /seq_blocks.8/Gemm        |        Gemm        |                           /seq_blocks.7/Relu_output_0, seq_blocks.8.weight, seq_blocks.8.bias                            |        /seq_blocks.8/Gemm_output_0        | alpha, beta, transB |\n",
      "|   9   | /seq_blocks.9/BatchNormalization | BatchNormalization | /seq_blocks.8/Gemm_output_0, seq_blocks.9.weight, seq_blocks.9.bias, seq_blocks.9.running_mean, seq_blocks.9.running_var | /seq_blocks.9/BatchNormalization_output_0 |  epsilon, momentum  |\n",
      "|   10  |       /seq_blocks.10/Relu        |        Relu        |                                        /seq_blocks.9/BatchNormalization_output_0                                         |                     37                    |                     |\n",
      "+-------+----------------------------------+--------------------+--------------------------------------------------------------------------------------------------------------------------+-------------------------------------------+---------------------+\u001b[0m\n",
      "I0326 16:06:15.792428 140445122471744 onnx_runtime.py:90] ONNX Model Summary: \n",
      "+-------+----------------------------------+--------------------+--------------------------------------------------------------------------------------------------------------------------+-------------------------------------------+---------------------+\n",
      "| Index |               Name               |        Type        |                                                          Inputs                                                          |                  Outputs                  |      Attributes     |\n",
      "+-------+----------------------------------+--------------------+--------------------------------------------------------------------------------------------------------------------------+-------------------------------------------+---------------------+\n",
      "|   0   | /seq_blocks.0/BatchNormalization | BatchNormalization |            input, seq_blocks.0.weight, seq_blocks.0.bias, seq_blocks.0.running_mean, seq_blocks.0.running_var            | /seq_blocks.0/BatchNormalization_output_0 |  epsilon, momentum  |\n",
      "|   1   |        /seq_blocks.1/Relu        |        Relu        |                                        /seq_blocks.0/BatchNormalization_output_0                                         |        /seq_blocks.1/Relu_output_0        |                     |\n",
      "|   2   |        /seq_blocks.2/Gemm        |        Gemm        |                           /seq_blocks.1/Relu_output_0, seq_blocks.2.weight, seq_blocks.2.bias                            |        /seq_blocks.2/Gemm_output_0        | alpha, beta, transB |\n",
      "|   3   | /seq_blocks.3/BatchNormalization | BatchNormalization | /seq_blocks.2/Gemm_output_0, seq_blocks.3.weight, seq_blocks.3.bias, seq_blocks.3.running_mean, seq_blocks.3.running_var | /seq_blocks.3/BatchNormalization_output_0 |  epsilon, momentum  |\n",
      "|   4   |        /seq_blocks.4/Relu        |        Relu        |                                        /seq_blocks.3/BatchNormalization_output_0                                         |        /seq_blocks.4/Relu_output_0        |                     |\n",
      "|   5   |        /seq_blocks.5/Gemm        |        Gemm        |                           /seq_blocks.4/Relu_output_0, seq_blocks.5.weight, seq_blocks.5.bias                            |        /seq_blocks.5/Gemm_output_0        | alpha, beta, transB |\n",
      "|   6   | /seq_blocks.6/BatchNormalization | BatchNormalization | /seq_blocks.5/Gemm_output_0, seq_blocks.6.weight, seq_blocks.6.bias, seq_blocks.6.running_mean, seq_blocks.6.running_var | /seq_blocks.6/BatchNormalization_output_0 |  epsilon, momentum  |\n",
      "|   7   |        /seq_blocks.7/Relu        |        Relu        |                                        /seq_blocks.6/BatchNormalization_output_0                                         |        /seq_blocks.7/Relu_output_0        |                     |\n",
      "|   8   |        /seq_blocks.8/Gemm        |        Gemm        |                           /seq_blocks.7/Relu_output_0, seq_blocks.8.weight, seq_blocks.8.bias                            |        /seq_blocks.8/Gemm_output_0        | alpha, beta, transB |\n",
      "|   9   | /seq_blocks.9/BatchNormalization | BatchNormalization | /seq_blocks.8/Gemm_output_0, seq_blocks.9.weight, seq_blocks.9.bias, seq_blocks.9.running_mean, seq_blocks.9.running_var | /seq_blocks.9/BatchNormalization_output_0 |  epsilon, momentum  |\n",
      "|   10  |       /seq_blocks.10/Relu        |        Relu        |                                        /seq_blocks.9/BatchNormalization_output_0                                         |                     37                    |                     |\n",
      "+-------+----------------------------------+--------------------+--------------------------------------------------------------------------------------------------------------------------+-------------------------------------------+---------------------+\n",
      "\u001b[33mWARNING \u001b[0m \u001b[34mQuantization is not set in default config. Skipping quantization.\u001b[0m\n",
      "W0326 16:06:15.794154 140445122471744 onnx_runtime.py:97] Quantization is not set in default config. Skipping quantization.\n"
     ]
    }
   ],
   "source": [
    "mg, onnx_meta = onnx_runtime_transform_pass(mg, pass_args=onnx_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can view a summary of the ONNX model (which is the unmodified from the Pytorch one), however it should be optimized. Let's run an analysis path on both the original `MaseGraph` and the `.onnx` optimized model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on jsc-toy\u001b[0m\n",
      "I0326 16:06:44.630763 140445122471744 analysis.py:270] Starting transformation analysis on jsc-toy\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results jsc-toy:\n",
      "+------------------------------+---------------+\n",
      "|      Metric (Per Batch)      |     Value     |\n",
      "+------------------------------+---------------+\n",
      "|    Average Test Accuracy     |    0.73159    |\n",
      "|      Average Precision       |    0.74429    |\n",
      "|        Average Recall        |    0.73023    |\n",
      "|       Average F1 Score       |    0.73347    |\n",
      "|         Average Loss         |    0.76373    |\n",
      "|       Average Latency        |  0.75542 ms   |\n",
      "|   Average GPU Power Usage    |   19.851 W    |\n",
      "| Inference Energy Consumption | 0.0041654 mWh |\n",
      "+------------------------------+---------------+\u001b[0m\n",
      "I0326 16:06:47.443415 140445122471744 analysis.py:393] \n",
      "Results jsc-toy:\n",
      "+------------------------------+---------------+\n",
      "|      Metric (Per Batch)      |     Value     |\n",
      "+------------------------------+---------------+\n",
      "|    Average Test Accuracy     |    0.73159    |\n",
      "|      Average Precision       |    0.74429    |\n",
      "|        Average Recall        |    0.73023    |\n",
      "|       Average F1 Score       |    0.73347    |\n",
      "|         Average Loss         |    0.76373    |\n",
      "|       Average Latency        |  0.75542 ms   |\n",
      "|   Average GPU Power Usage    |   19.851 W    |\n",
      "| Inference Energy Consumption | 0.0041654 mWh |\n",
      "+------------------------------+---------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /root/mase_output/tensorrt/quantization/jsc-toy_cls_jsc_2024-03-26/mase_graph/version_0/model.json\u001b[0m\n",
      "I0326 16:06:47.446247 140445122471744 analysis.py:84] Runtime analysis results saved to /root/mase_output/tensorrt/quantization/jsc-toy_cls_jsc_2024-03-26/mase_graph/version_0/model.json\n"
     ]
    }
   ],
   "source": [
    "_, _ = runtime_analysis_pass(mg_original, pass_args=runtime_analysis_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on jsc-toy-onnx\u001b[0m\n",
      "I0326 16:06:55.764947 140445122471744 analysis.py:270] Starting transformation analysis on jsc-toy-onnx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results jsc-toy-onnx:\n",
      "+------------------------------+---------------+\n",
      "|      Metric (Per Batch)      |     Value     |\n",
      "+------------------------------+---------------+\n",
      "|    Average Test Accuracy     |    0.73509    |\n",
      "|      Average Precision       |    0.74981    |\n",
      "|        Average Recall        |    0.73531    |\n",
      "|       Average F1 Score       |    0.73865    |\n",
      "|         Average Loss         |    0.74883    |\n",
      "|       Average Latency        |   0.215 ms    |\n",
      "|   Average GPU Power Usage    |   21.748 W    |\n",
      "| Inference Energy Consumption | 0.0012989 mWh |\n",
      "+------------------------------+---------------+\u001b[0m\n",
      "I0326 16:06:58.668864 140445122471744 analysis.py:393] \n",
      "Results jsc-toy-onnx:\n",
      "+------------------------------+---------------+\n",
      "|      Metric (Per Batch)      |     Value     |\n",
      "+------------------------------+---------------+\n",
      "|    Average Test Accuracy     |    0.73509    |\n",
      "|      Average Precision       |    0.74981    |\n",
      "|        Average Recall        |    0.73531    |\n",
      "|       Average F1 Score       |    0.73865    |\n",
      "|         Average Loss         |    0.74883    |\n",
      "|       Average Latency        |   0.215 ms    |\n",
      "|   Average GPU Power Usage    |   21.748 W    |\n",
      "| Inference Energy Consumption | 0.0012989 mWh |\n",
      "+------------------------------+---------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /root/mase_output/tensorrt/quantization/jsc-toy_cls_jsc_2024-03-26/onnx/version_0/model.json\u001b[0m\n",
      "I0326 16:06:58.671292 140445122471744 analysis.py:84] Runtime analysis results saved to /root/mase_output/tensorrt/quantization/jsc-toy_cls_jsc_2024-03-26/onnx/version_0/model.json\n"
     ]
    }
   ],
   "source": [
    "_, _ = runtime_analysis_pass(onnx_meta['onnx_path'], pass_args=runtime_analysis_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, the latency of the cpu inference is around 3.5x less with the `jsc-toy` model without compromising accuracy simply by using the optimizations of ONNXRT. \n",
    "\n",
    "Lets now run the same optimzations, this time using a GPU and a larger model - the `vgg7`.  We will also utilse the chop action from the terminal which runs the same `onnx_runtime_transform_pass` pass.\n",
    "\n",
    "First lets train the `vgg7` model using the machop `train` action with the config from the new toml file and then load the trained checkpoint it into the `transform` pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-26 16:55:18,821] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "INFO: Seed set to 0\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0326 16:55:21.074783 140315112290112 seed.py:54] Seed set to 0\n",
      "+-------------------------+------------------------+--------------+--------------------------+--------------------------+\n",
      "| Name                    |        Default         | Config. File |     Manual Override      |        Effective         |\n",
      "+-------------------------+------------------------+--------------+--------------------------+--------------------------+\n",
      "| task                    |     \u001b[38;5;8mclassification\u001b[0m     |     cls      |                          |           cls            |\n",
      "| load_name               |          \u001b[38;5;8mNone\u001b[0m          |              | /root/mase/mase_output/v | /root/mase/mase_output/v |\n",
      "|                         |                        |              |  gg7-pre-trained/test-   |  gg7-pre-trained/test-   |\n",
      "|                         |                        |              |     accu-0.9332.ckpt     |     accu-0.9332.ckpt     |\n",
      "| load_type               |           \u001b[38;5;8mmz\u001b[0m           |              |            pl            |            pl            |\n",
      "| batch_size              |          \u001b[38;5;8m128\u001b[0m           |      16      |                          |            16            |\n",
      "| to_debug                |         False          |              |                          |          False           |\n",
      "| log_level               |          info          |              |                          |           info           |\n",
      "| report_to               |      tensorboard       |              |                          |       tensorboard        |\n",
      "| seed                    |           0            |              |                          |            0             |\n",
      "| quant_config            |          None          |              |                          |           None           |\n",
      "| training_optimizer      |          adam          |              |                          |           adam           |\n",
      "| trainer_precision       |        16-mixed        |              |                          |         16-mixed         |\n",
      "| learning_rate           |         \u001b[38;5;8m1e-05\u001b[0m          |    0.001     |                          |          0.001           |\n",
      "| weight_decay            |           0            |              |                          |            0             |\n",
      "| max_epochs              |           \u001b[38;5;8m20\u001b[0m           |      10      |                          |            10            |\n",
      "| max_steps               |           -1           |              |                          |            -1            |\n",
      "| accumulate_grad_batches |           1            |              |                          |            1             |\n",
      "| log_every_n_steps       |           50           |              |                          |            50            |\n",
      "| num_workers             |           28           |              |                          |            28            |\n",
      "| num_devices             |           1            |              |                          |            1             |\n",
      "| num_nodes               |           1            |              |                          |            1             |\n",
      "| accelerator             |          \u001b[38;5;8mauto\u001b[0m          |     gpu      |                          |           gpu            |\n",
      "| strategy                |          auto          |              |                          |           auto           |\n",
      "| is_to_auto_requeue      |         False          |              |                          |          False           |\n",
      "| github_ci               |         False          |              |                          |          False           |\n",
      "| disable_dataset_cache   |         False          |              |                          |          False           |\n",
      "| target                  |  xcu250-figd2104-2L-e  |              |                          |   xcu250-figd2104-2L-e   |\n",
      "| num_targets             |          100           |              |                          |           100            |\n",
      "| is_pretrained           |         False          |              |                          |          False           |\n",
      "| max_token_len           |          512           |              |                          |           512            |\n",
      "| project_dir             | /root/mase/mase_output |              |                          |  /root/mase/mase_output  |\n",
      "| project                 |          None          |              |                          |           None           |\n",
      "| model                   |          \u001b[38;5;8mNone\u001b[0m          |     vgg7     |                          |           vgg7           |\n",
      "| dataset                 |          \u001b[38;5;8mNone\u001b[0m          |   cifar10    |                          |         cifar10          |\n",
      "| t_max                   |           20           |              |                          |            20            |\n",
      "| eta_min                 |         1e-06          |              |                          |          1e-06           |\n",
      "+-------------------------+------------------------+--------------+--------------------------+--------------------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mInitialising model 'vgg7'...\u001b[0m\n",
      "I0326 16:55:21.083962 140315112290112 cli.py:841] Initialising model 'vgg7'...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mInitialising dataset 'cifar10'...\u001b[0m\n",
      "I0326 16:55:21.191835 140315112290112 cli.py:869] Initialising dataset 'cifar10'...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mProject will be created at /root/mase/mase_output/vgg7_cls_cifar10_2024-03-26\u001b[0m\n",
      "I0326 16:55:21.192201 140315112290112 cli.py:905] Project will be created at /root/mase/mase_output/vgg7_cls_cifar10_2024-03-26\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTransforming model 'vgg7'...\u001b[0m\n",
      "I0326 16:55:21.311757 140315112290112 cli.py:365] Transforming model 'vgg7'...\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from /root/mase/mase_output/vgg7-pre-trained/test-accu-0.9332.ckpt\u001b[0m\n",
      "I0326 16:55:27.028542 140315112290112 checkpoint_load.py:85] Loaded pytorch lightning checkpoint from /root/mase/mase_output/vgg7-pre-trained/test-accu-0.9332.ckpt\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "I0326 16:55:34.497331 140315112290112 onnx_runtime.py:48] Converting PyTorch model to ONNX...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mProject will be created at /root/mase/mase_output/onnxrt/vgg7_cls_cifar10_2024-03-26\u001b[0m\n",
      "I0326 16:55:34.498144 140315112290112 onnx_runtime.py:50] Project will be created at /root/mase/mase_output/onnxrt/vgg7_cls_cifar10_2024-03-26\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /root/mase/mase_output/onnxrt/vgg7_cls_cifar10_2024-03-26/optimized/version_1/model.onnx\u001b[0m\n",
      "I0326 16:55:39.358922 140315112290112 onnx_runtime.py:68] ONNX Conversion Complete. Stored ONNX model to /root/mase/mase_output/onnxrt/vgg7_cls_cifar10_2024-03-26/optimized/version_1/model.onnx\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Model Summary: \n",
      "+-------+----------------------------+----------+---------------------------------------------------------------------+-------------------------------------+---------------------------------------------------+\n",
      "| Index |            Name            |   Type   |                                Inputs                               |               Outputs               |                     Attributes                    |\n",
      "+-------+----------------------------+----------+---------------------------------------------------------------------+-------------------------------------+---------------------------------------------------+\n",
      "|   0   |   /feature_layers.0/Conv   |   Conv   |                 input, onnx::Conv_78, onnx::Conv_79                 |   /feature_layers.0/Conv_output_0   |   dilations, group, kernel_shape, pads, strides   |\n",
      "|   1   |   /feature_layers.2/Relu   |   Relu   |                   /feature_layers.0/Conv_output_0                   |   /feature_layers.2/Relu_output_0   |                                                   |\n",
      "|   2   |   /feature_layers.3/Conv   |   Conv   |    /feature_layers.2/Relu_output_0, onnx::Conv_81, onnx::Conv_82    |   /feature_layers.3/Conv_output_0   |   dilations, group, kernel_shape, pads, strides   |\n",
      "|   3   |   /feature_layers.5/Relu   |   Relu   |                   /feature_layers.3/Conv_output_0                   |   /feature_layers.5/Relu_output_0   |                                                   |\n",
      "|   4   | /feature_layers.6/MaxPool  | MaxPool  |                   /feature_layers.5/Relu_output_0                   |  /feature_layers.6/MaxPool_output_0 | ceil_mode, dilations, kernel_shape, pads, strides |\n",
      "|   5   |   /feature_layers.7/Conv   |   Conv   |   /feature_layers.6/MaxPool_output_0, onnx::Conv_84, onnx::Conv_85  |   /feature_layers.7/Conv_output_0   |   dilations, group, kernel_shape, pads, strides   |\n",
      "|   6   |   /feature_layers.9/Relu   |   Relu   |                   /feature_layers.7/Conv_output_0                   |   /feature_layers.9/Relu_output_0   |                                                   |\n",
      "|   7   |  /feature_layers.10/Conv   |   Conv   |    /feature_layers.9/Relu_output_0, onnx::Conv_87, onnx::Conv_88    |   /feature_layers.10/Conv_output_0  |   dilations, group, kernel_shape, pads, strides   |\n",
      "|   8   |  /feature_layers.12/Relu   |   Relu   |                   /feature_layers.10/Conv_output_0                  |   /feature_layers.12/Relu_output_0  |                                                   |\n",
      "|   9   | /feature_layers.13/MaxPool | MaxPool  |                   /feature_layers.12/Relu_output_0                  | /feature_layers.13/MaxPool_output_0 | ceil_mode, dilations, kernel_shape, pads, strides |\n",
      "|   10  |  /feature_layers.14/Conv   |   Conv   |  /feature_layers.13/MaxPool_output_0, onnx::Conv_90, onnx::Conv_91  |   /feature_layers.14/Conv_output_0  |   dilations, group, kernel_shape, pads, strides   |\n",
      "|   11  |  /feature_layers.16/Relu   |   Relu   |                   /feature_layers.14/Conv_output_0                  |   /feature_layers.16/Relu_output_0  |                                                   |\n",
      "|   12  |  /feature_layers.17/Conv   |   Conv   |    /feature_layers.16/Relu_output_0, onnx::Conv_93, onnx::Conv_94   |   /feature_layers.17/Conv_output_0  |   dilations, group, kernel_shape, pads, strides   |\n",
      "|   13  |  /feature_layers.19/Relu   |   Relu   |                   /feature_layers.17/Conv_output_0                  |   /feature_layers.19/Relu_output_0  |                                                   |\n",
      "|   14  | /feature_layers.20/MaxPool | MaxPool  |                   /feature_layers.19/Relu_output_0                  | /feature_layers.20/MaxPool_output_0 | ceil_mode, dilations, kernel_shape, pads, strides |\n",
      "|   15  |         /Constant          | Constant |                                                                     |          /Constant_output_0         |                       value                       |\n",
      "|   16  |          /Reshape          | Reshape  |       /feature_layers.20/MaxPool_output_0, /Constant_output_0       |          /Reshape_output_0          |                                                   |\n",
      "|   17  |     /classifier.0/Gemm     |   Gemm   |      /Reshape_output_0, classifier.0.weight, classifier.0.bias      |     /classifier.0/Gemm_output_0     |                alpha, beta, transB                |\n",
      "|   18  |     /classifier.1/Relu     |   Relu   |                     /classifier.0/Gemm_output_0                     |     /classifier.1/Relu_output_0     |                                                   |\n",
      "|   19  |     /classifier.2/Gemm     |   Gemm   | /classifier.1/Relu_output_0, classifier.2.weight, classifier.2.bias |     /classifier.2/Gemm_output_0     |                alpha, beta, transB                |\n",
      "|   20  |     /classifier.3/Relu     |   Relu   |                     /classifier.2/Gemm_output_0                     |     /classifier.3/Relu_output_0     |                                                   |\n",
      "|   21  |      /last_layer/Gemm      |   Gemm   |   /classifier.3/Relu_output_0, last_layer.weight, last_layer.bias   |                  76                 |                alpha, beta, transB                |\n",
      "+-------+----------------------------+----------+---------------------------------------------------------------------+-------------------------------------+---------------------------------------------------+\u001b[0m\n",
      "I0326 16:55:39.478744 140315112290112 onnx_runtime.py:90] ONNX Model Summary: \n",
      "+-------+----------------------------+----------+---------------------------------------------------------------------+-------------------------------------+---------------------------------------------------+\n",
      "| Index |            Name            |   Type   |                                Inputs                               |               Outputs               |                     Attributes                    |\n",
      "+-------+----------------------------+----------+---------------------------------------------------------------------+-------------------------------------+---------------------------------------------------+\n",
      "|   0   |   /feature_layers.0/Conv   |   Conv   |                 input, onnx::Conv_78, onnx::Conv_79                 |   /feature_layers.0/Conv_output_0   |   dilations, group, kernel_shape, pads, strides   |\n",
      "|   1   |   /feature_layers.2/Relu   |   Relu   |                   /feature_layers.0/Conv_output_0                   |   /feature_layers.2/Relu_output_0   |                                                   |\n",
      "|   2   |   /feature_layers.3/Conv   |   Conv   |    /feature_layers.2/Relu_output_0, onnx::Conv_81, onnx::Conv_82    |   /feature_layers.3/Conv_output_0   |   dilations, group, kernel_shape, pads, strides   |\n",
      "|   3   |   /feature_layers.5/Relu   |   Relu   |                   /feature_layers.3/Conv_output_0                   |   /feature_layers.5/Relu_output_0   |                                                   |\n",
      "|   4   | /feature_layers.6/MaxPool  | MaxPool  |                   /feature_layers.5/Relu_output_0                   |  /feature_layers.6/MaxPool_output_0 | ceil_mode, dilations, kernel_shape, pads, strides |\n",
      "|   5   |   /feature_layers.7/Conv   |   Conv   |   /feature_layers.6/MaxPool_output_0, onnx::Conv_84, onnx::Conv_85  |   /feature_layers.7/Conv_output_0   |   dilations, group, kernel_shape, pads, strides   |\n",
      "|   6   |   /feature_layers.9/Relu   |   Relu   |                   /feature_layers.7/Conv_output_0                   |   /feature_layers.9/Relu_output_0   |                                                   |\n",
      "|   7   |  /feature_layers.10/Conv   |   Conv   |    /feature_layers.9/Relu_output_0, onnx::Conv_87, onnx::Conv_88    |   /feature_layers.10/Conv_output_0  |   dilations, group, kernel_shape, pads, strides   |\n",
      "|   8   |  /feature_layers.12/Relu   |   Relu   |                   /feature_layers.10/Conv_output_0                  |   /feature_layers.12/Relu_output_0  |                                                   |\n",
      "|   9   | /feature_layers.13/MaxPool | MaxPool  |                   /feature_layers.12/Relu_output_0                  | /feature_layers.13/MaxPool_output_0 | ceil_mode, dilations, kernel_shape, pads, strides |\n",
      "|   10  |  /feature_layers.14/Conv   |   Conv   |  /feature_layers.13/MaxPool_output_0, onnx::Conv_90, onnx::Conv_91  |   /feature_layers.14/Conv_output_0  |   dilations, group, kernel_shape, pads, strides   |\n",
      "|   11  |  /feature_layers.16/Relu   |   Relu   |                   /feature_layers.14/Conv_output_0                  |   /feature_layers.16/Relu_output_0  |                                                   |\n",
      "|   12  |  /feature_layers.17/Conv   |   Conv   |    /feature_layers.16/Relu_output_0, onnx::Conv_93, onnx::Conv_94   |   /feature_layers.17/Conv_output_0  |   dilations, group, kernel_shape, pads, strides   |\n",
      "|   13  |  /feature_layers.19/Relu   |   Relu   |                   /feature_layers.17/Conv_output_0                  |   /feature_layers.19/Relu_output_0  |                                                   |\n",
      "|   14  | /feature_layers.20/MaxPool | MaxPool  |                   /feature_layers.19/Relu_output_0                  | /feature_layers.20/MaxPool_output_0 | ceil_mode, dilations, kernel_shape, pads, strides |\n",
      "|   15  |         /Constant          | Constant |                                                                     |          /Constant_output_0         |                       value                       |\n",
      "|   16  |          /Reshape          | Reshape  |       /feature_layers.20/MaxPool_output_0, /Constant_output_0       |          /Reshape_output_0          |                                                   |\n",
      "|   17  |     /classifier.0/Gemm     |   Gemm   |      /Reshape_output_0, classifier.0.weight, classifier.0.bias      |     /classifier.0/Gemm_output_0     |                alpha, beta, transB                |\n",
      "|   18  |     /classifier.1/Relu     |   Relu   |                     /classifier.0/Gemm_output_0                     |     /classifier.1/Relu_output_0     |                                                   |\n",
      "|   19  |     /classifier.2/Gemm     |   Gemm   | /classifier.1/Relu_output_0, classifier.2.weight, classifier.2.bias |     /classifier.2/Gemm_output_0     |                alpha, beta, transB                |\n",
      "|   20  |     /classifier.3/Relu     |   Relu   |                     /classifier.2/Gemm_output_0                     |     /classifier.3/Relu_output_0     |                                                   |\n",
      "|   21  |      /last_layer/Gemm      |   Gemm   |   /classifier.3/Relu_output_0, last_layer.weight, last_layer.bias   |                  76                 |                alpha, beta, transB                |\n",
      "+-------+----------------------------+----------+---------------------------------------------------------------------+-------------------------------------+---------------------------------------------------+\n",
      "\u001b[33mWARNING \u001b[0m \u001b[34mQuantization is not set in default config. Skipping quantization.\u001b[0m\n",
      "W0326 16:55:39.479027 140315112290112 onnx_runtime.py:97] Quantization is not set in default config. Skipping quantization.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPerforming runtime analysis on original graph...\u001b[0m\n",
      "I0326 16:55:39.483327 140315112290112 transform.py:169] Performing runtime analysis on original graph...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on vgg7\u001b[0m\n",
      "I0326 16:55:39.483551 140315112290112 analysis.py:270] Starting transformation analysis on vgg7\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results vgg7:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.89024    |\n",
      "|      Average Precision       |   0.92059    |\n",
      "|        Average Recall        |   0.92039    |\n",
      "|       Average F1 Score       |    0.9203    |\n",
      "|         Average Loss         |   0.22849    |\n",
      "|       Average Latency        |  3.1543 ms   |\n",
      "|   Average GPU Power Usage    |   28.688 W   |\n",
      "| Inference Energy Consumption | 0.025137 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "I0326 16:55:44.860560 140315112290112 analysis.py:393] \n",
      "Results vgg7:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.89024    |\n",
      "|      Average Precision       |   0.92059    |\n",
      "|        Average Recall        |   0.92039    |\n",
      "|       Average F1 Score       |    0.9203    |\n",
      "|         Average Loss         |   0.22849    |\n",
      "|       Average Latency        |  3.1543 ms   |\n",
      "|   Average GPU Power Usage    |   28.688 W   |\n",
      "| Inference Energy Consumption | 0.025137 mWh |\n",
      "+------------------------------+--------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /root/mase_output/tensorrt/quantization/vgg7_cls_cifar10_2024-03-26/mase_graph/version_1/model.json\u001b[0m\n",
      "I0326 16:55:44.861986 140315112290112 analysis.py:84] Runtime analysis results saved to /root/mase_output/tensorrt/quantization/vgg7_cls_cifar10_2024-03-26/mase_graph/version_1/model.json\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPerforming runtime analysis on optimized quantized graph...\u001b[0m\n",
      "I0326 16:55:44.862186 140315112290112 transform.py:175] Performing runtime analysis on optimized quantized graph...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on vgg7-onnx\u001b[0m\n",
      "I0326 16:55:45.180822 140315112290112 analysis.py:270] Starting transformation analysis on vgg7-onnx\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results vgg7-onnx:\n",
      "+------------------------------+------------+\n",
      "|      Metric (Per Batch)      |   Value    |\n",
      "+------------------------------+------------+\n",
      "|    Average Test Accuracy     |  0.88533   |\n",
      "|      Average Precision       |  0.91987   |\n",
      "|        Average Recall        |  0.91579   |\n",
      "|       Average F1 Score       |  0.91576   |\n",
      "|         Average Loss         |  0.24644   |\n",
      "|       Average Latency        | 2.1102 ms  |\n",
      "|   Average GPU Power Usage    |  33.778 W  |\n",
      "| Inference Energy Consumption | 0.0198 mWh |\n",
      "+------------------------------+------------+\u001b[0m\n",
      "I0326 16:55:50.564863 140315112290112 analysis.py:393] \n",
      "Results vgg7-onnx:\n",
      "+------------------------------+------------+\n",
      "|      Metric (Per Batch)      |   Value    |\n",
      "+------------------------------+------------+\n",
      "|    Average Test Accuracy     |  0.88533   |\n",
      "|      Average Precision       |  0.91987   |\n",
      "|        Average Recall        |  0.91579   |\n",
      "|       Average F1 Score       |  0.91576   |\n",
      "|         Average Loss         |  0.24644   |\n",
      "|       Average Latency        | 2.1102 ms  |\n",
      "|   Average GPU Power Usage    |  33.778 W  |\n",
      "| Inference Energy Consumption | 0.0198 mWh |\n",
      "+------------------------------+------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /root/mase_output/tensorrt/quantization/vgg7_cls_cifar10_2024-03-26/onnx/version_1/model.json\u001b[0m\n",
      "I0326 16:55:50.566696 140315112290112 analysis.py:84] Runtime analysis results saved to /root/mase_output/tensorrt/quantization/vgg7_cls_cifar10_2024-03-26/onnx/version_1/model.json\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mSaved mase graph to /root/mase/mase_output/vgg7_cls_cifar10_2024-03-26/software/transform/transformed_ckpt\u001b[0m\n",
      "I0326 16:57:14.725967 140315112290112 save_and_load.py:147] Saved mase graph to /root/mase/mase_output/vgg7_cls_cifar10_2024-03-26/software/transform/transformed_ckpt\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTransformation is completed\u001b[0m\n",
      "I0326 16:57:14.726318 140315112290112 cli.py:383] Transformation is completed\n"
     ]
    }
   ],
   "source": [
    "VGG_TOML_PATH = \"../../../machop/configs/onnx/vgg7_gpu_ort.toml\"\n",
    "\n",
    "# !ch train --config {VGG_TOML_PATH}\n",
    "\n",
    "# Load in the checkpoint from the previous train - modify accordingly\n",
    "VGG_CHECKPOINT_PATH = \"../../../mase_output/vgg7-pre-trained/test-accu-0.9332.ckpt\"\n",
    "\n",
    "!ch transform --config {VGG_TOML_PATH} --load {VGG_CHECKPOINT_PATH} --load-type pl "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, the latency of the gpu inference is 30% less with the `vgg7` model without compromising accuracy simply by using the optimizations of ONNXRT. \n",
    "\n",
    "We will now look at quantization to further speed up the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2. Quantization\n",
    "\n",
    "We may quantize either using FP16 or INT8 by setting the `precision` parameter in `passes.onnxruntime.default.config` to `'fp16'` or `'int8'` respectively. INT8 quantization will show the most notable latency improvements but will likely lower performance. \n",
    "\n",
    "There are three types of quantization for ONNXRT and can be set in `onnxruntime.default.config` under `quantization_types`. The differences of the first two are for how they calibrate i.e. set the scale and zero points which are only relevant for integer based quantization:\n",
    "- **Static Quantization**:\n",
    "    - The scale and zero point of activations are calculated in advance (offline) using a calibration data set.\n",
    "    - The activations have the same scale and zero point during each forward pass.\n",
    "    - The `num_calibration_batches` parameter must also be set to ensure calibration is tested on a subset of the training dataset. A larger subset will be beneficial for calibrating the amaxes and may improve accuracy, however it will result in a longer calibration time.\n",
    "- **Dynamic Quantization**:\n",
    "    - The scale and zero point of activations are calculated on-the-fly (online) and are specific for each forward pass.\n",
    "    - This approach is more accurate but introduces extra computational overhead\n",
    "\n",
    "The `onnx_runtime_transform_pass` pass also supports mixed precision. This is an automatic only procedure, where ONNXRT finds a minimal set of ops to skip while retaining a certain level of accuracy, converting most of the ops to float16 but leaving some in float32. \n",
    "- **Auto Mixed Precision Quantization**:\n",
    "    - Automatically adjusts between FP16 and FP32 precisions to retain certain level of accuracy\n",
    "    - The `precision` parameter does not need to be set in the config since the whole process is automatic.\n",
    "    - There are three other optional parameters that control the mixed precision selection:\n",
    "        - `rtol` (relative tolerance): Defines the acceptable relative difference between the original and converted model's outputs to ensure minimal impact on accuracy.\n",
    "        - `atol` (absolute tolerance): Specifies the acceptable absolute difference between the original and converted model's outputs, assessing numerical integrity in    absolute terms.\n",
    "        - `keep_io_types`: Controls whether the original input and output data types are preserved during the model conversion process.\n",
    "\n",
    "    - Unfortunately, this process is currently only supported on GPU.\n",
    "    - This approach is most beneficial when INT8 or FP16 exclusive quantizations (static or dynamic) are giving poor results.\n",
    "\n",
    "All three methodolgies first pre-procsses the model before quantization adding further optimizations. This intermidate model is stored to the `pre-processed` directory. \n",
    "\n",
    "For this example, we will set the `precision` to `'uint8'` (since `ConvInteger` node is not currently supported for `'int8'` on ONNXRT GPU execution provider). \n",
    "\n",
    "We will also set the `precision_types` to `['static', 'dynamic', 'auto']` to compare all three quantization methods, whilst keeping the other settings the exact same for a fair comparison against the optimized `vgg7` model used in the previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-26 21:24:50,742] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "INFO: Seed set to 0\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0326 21:24:52.903464 140189651072832 seed.py:54] Seed set to 0\n",
      "+-------------------------+------------------------+--------------+--------------------------+--------------------------+\n",
      "| Name                    |        Default         | Config. File |     Manual Override      |        Effective         |\n",
      "+-------------------------+------------------------+--------------+--------------------------+--------------------------+\n",
      "| task                    |     \u001b[38;5;8mclassification\u001b[0m     |     cls      |                          |           cls            |\n",
      "| load_name               |          \u001b[38;5;8mNone\u001b[0m          |              | /root/mase/mase_output/v | /root/mase/mase_output/v |\n",
      "|                         |                        |              |  gg7-pre-trained/test-   |  gg7-pre-trained/test-   |\n",
      "|                         |                        |              |     accu-0.9332.ckpt     |     accu-0.9332.ckpt     |\n",
      "| load_type               |           \u001b[38;5;8mmz\u001b[0m           |              |            pl            |            pl            |\n",
      "| batch_size              |          \u001b[38;5;8m128\u001b[0m           |      16      |                          |            16            |\n",
      "| to_debug                |         False          |              |                          |          False           |\n",
      "| log_level               |          info          |              |                          |           info           |\n",
      "| report_to               |      tensorboard       |              |                          |       tensorboard        |\n",
      "| seed                    |           0            |              |                          |            0             |\n",
      "| quant_config            |          None          |              |                          |           None           |\n",
      "| training_optimizer      |          adam          |              |                          |           adam           |\n",
      "| trainer_precision       |        16-mixed        |              |                          |         16-mixed         |\n",
      "| learning_rate           |         \u001b[38;5;8m1e-05\u001b[0m          |    0.001     |                          |          0.001           |\n",
      "| weight_decay            |           0            |              |                          |            0             |\n",
      "| max_epochs              |           \u001b[38;5;8m20\u001b[0m           |      10      |                          |            10            |\n",
      "| max_steps               |           -1           |              |                          |            -1            |\n",
      "| accumulate_grad_batches |           1            |              |                          |            1             |\n",
      "| log_every_n_steps       |           50           |              |                          |            50            |\n",
      "| num_workers             |           28           |              |                          |            28            |\n",
      "| num_devices             |           1            |              |                          |            1             |\n",
      "| num_nodes               |           1            |              |                          |            1             |\n",
      "| accelerator             |          \u001b[38;5;8mauto\u001b[0m          |     gpu      |                          |           gpu            |\n",
      "| strategy                |          auto          |              |                          |           auto           |\n",
      "| is_to_auto_requeue      |         False          |              |                          |          False           |\n",
      "| github_ci               |         False          |              |                          |          False           |\n",
      "| disable_dataset_cache   |         False          |              |                          |          False           |\n",
      "| target                  |  xcu250-figd2104-2L-e  |              |                          |   xcu250-figd2104-2L-e   |\n",
      "| num_targets             |          100           |              |                          |           100            |\n",
      "| is_pretrained           |         False          |              |                          |          False           |\n",
      "| max_token_len           |          512           |              |                          |           512            |\n",
      "| project_dir             | /root/mase/mase_output |              |                          |  /root/mase/mase_output  |\n",
      "| project                 |          None          |              |                          |           None           |\n",
      "| model                   |          \u001b[38;5;8mNone\u001b[0m          |     vgg7     |                          |           vgg7           |\n",
      "| dataset                 |          \u001b[38;5;8mNone\u001b[0m          |   cifar10    |                          |         cifar10          |\n",
      "| t_max                   |           20           |              |                          |            20            |\n",
      "| eta_min                 |         1e-06          |              |                          |          1e-06           |\n",
      "+-------------------------+------------------------+--------------+--------------------------+--------------------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mInitialising model 'vgg7'...\u001b[0m\n",
      "I0326 21:24:52.912628 140189651072832 cli.py:841] Initialising model 'vgg7'...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mInitialising dataset 'cifar10'...\u001b[0m\n",
      "I0326 21:24:53.016817 140189651072832 cli.py:869] Initialising dataset 'cifar10'...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mProject will be created at /root/mase/mase_output/vgg7_cls_cifar10_2024-03-26\u001b[0m\n",
      "I0326 21:24:53.017221 140189651072832 cli.py:905] Project will be created at /root/mase/mase_output/vgg7_cls_cifar10_2024-03-26\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTransforming model 'vgg7'...\u001b[0m\n",
      "I0326 21:24:53.141939 140189651072832 cli.py:365] Transforming model 'vgg7'...\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from /root/mase/mase_output/vgg7-pre-trained/test-accu-0.9332.ckpt\u001b[0m\n",
      "I0326 21:24:58.877447 140189651072832 checkpoint_load.py:85] Loaded pytorch lightning checkpoint from /root/mase/mase_output/vgg7-pre-trained/test-accu-0.9332.ckpt\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "I0326 21:25:05.028244 140189651072832 onnx_runtime.py:48] Converting PyTorch model to ONNX...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mProject will be created at /root/mase/mase_output/onnxrt/vgg7_cls_cifar10_2024-03-26\u001b[0m\n",
      "I0326 21:25:05.028982 140189651072832 onnx_runtime.py:50] Project will be created at /root/mase/mase_output/onnxrt/vgg7_cls_cifar10_2024-03-26\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /root/mase/mase_output/onnxrt/vgg7_cls_cifar10_2024-03-26/optimized/version_22/model.onnx\u001b[0m\n",
      "I0326 21:25:09.587803 140189651072832 onnx_runtime.py:68] ONNX Conversion Complete. Stored ONNX model to /root/mase/mase_output/onnxrt/vgg7_cls_cifar10_2024-03-26/optimized/version_22/model.onnx\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Model Summary: \n",
      "+-------+----------------------------+----------+---------------------------------------------------------------------+-------------------------------------+---------------------------------------------------+\n",
      "| Index |            Name            |   Type   |                                Inputs                               |               Outputs               |                     Attributes                    |\n",
      "+-------+----------------------------+----------+---------------------------------------------------------------------+-------------------------------------+---------------------------------------------------+\n",
      "|   0   |   /feature_layers.0/Conv   |   Conv   |                 input, onnx::Conv_78, onnx::Conv_79                 |   /feature_layers.0/Conv_output_0   |   dilations, group, kernel_shape, pads, strides   |\n",
      "|   1   |   /feature_layers.2/Relu   |   Relu   |                   /feature_layers.0/Conv_output_0                   |   /feature_layers.2/Relu_output_0   |                                                   |\n",
      "|   2   |   /feature_layers.3/Conv   |   Conv   |    /feature_layers.2/Relu_output_0, onnx::Conv_81, onnx::Conv_82    |   /feature_layers.3/Conv_output_0   |   dilations, group, kernel_shape, pads, strides   |\n",
      "|   3   |   /feature_layers.5/Relu   |   Relu   |                   /feature_layers.3/Conv_output_0                   |   /feature_layers.5/Relu_output_0   |                                                   |\n",
      "|   4   | /feature_layers.6/MaxPool  | MaxPool  |                   /feature_layers.5/Relu_output_0                   |  /feature_layers.6/MaxPool_output_0 | ceil_mode, dilations, kernel_shape, pads, strides |\n",
      "|   5   |   /feature_layers.7/Conv   |   Conv   |   /feature_layers.6/MaxPool_output_0, onnx::Conv_84, onnx::Conv_85  |   /feature_layers.7/Conv_output_0   |   dilations, group, kernel_shape, pads, strides   |\n",
      "|   6   |   /feature_layers.9/Relu   |   Relu   |                   /feature_layers.7/Conv_output_0                   |   /feature_layers.9/Relu_output_0   |                                                   |\n",
      "|   7   |  /feature_layers.10/Conv   |   Conv   |    /feature_layers.9/Relu_output_0, onnx::Conv_87, onnx::Conv_88    |   /feature_layers.10/Conv_output_0  |   dilations, group, kernel_shape, pads, strides   |\n",
      "|   8   |  /feature_layers.12/Relu   |   Relu   |                   /feature_layers.10/Conv_output_0                  |   /feature_layers.12/Relu_output_0  |                                                   |\n",
      "|   9   | /feature_layers.13/MaxPool | MaxPool  |                   /feature_layers.12/Relu_output_0                  | /feature_layers.13/MaxPool_output_0 | ceil_mode, dilations, kernel_shape, pads, strides |\n",
      "|   10  |  /feature_layers.14/Conv   |   Conv   |  /feature_layers.13/MaxPool_output_0, onnx::Conv_90, onnx::Conv_91  |   /feature_layers.14/Conv_output_0  |   dilations, group, kernel_shape, pads, strides   |\n",
      "|   11  |  /feature_layers.16/Relu   |   Relu   |                   /feature_layers.14/Conv_output_0                  |   /feature_layers.16/Relu_output_0  |                                                   |\n",
      "|   12  |  /feature_layers.17/Conv   |   Conv   |    /feature_layers.16/Relu_output_0, onnx::Conv_93, onnx::Conv_94   |   /feature_layers.17/Conv_output_0  |   dilations, group, kernel_shape, pads, strides   |\n",
      "|   13  |  /feature_layers.19/Relu   |   Relu   |                   /feature_layers.17/Conv_output_0                  |   /feature_layers.19/Relu_output_0  |                                                   |\n",
      "|   14  | /feature_layers.20/MaxPool | MaxPool  |                   /feature_layers.19/Relu_output_0                  | /feature_layers.20/MaxPool_output_0 | ceil_mode, dilations, kernel_shape, pads, strides |\n",
      "|   15  |         /Constant          | Constant |                                                                     |          /Constant_output_0         |                       value                       |\n",
      "|   16  |          /Reshape          | Reshape  |       /feature_layers.20/MaxPool_output_0, /Constant_output_0       |          /Reshape_output_0          |                                                   |\n",
      "|   17  |     /classifier.0/Gemm     |   Gemm   |      /Reshape_output_0, classifier.0.weight, classifier.0.bias      |     /classifier.0/Gemm_output_0     |                alpha, beta, transB                |\n",
      "|   18  |     /classifier.1/Relu     |   Relu   |                     /classifier.0/Gemm_output_0                     |     /classifier.1/Relu_output_0     |                                                   |\n",
      "|   19  |     /classifier.2/Gemm     |   Gemm   | /classifier.1/Relu_output_0, classifier.2.weight, classifier.2.bias |     /classifier.2/Gemm_output_0     |                alpha, beta, transB                |\n",
      "|   20  |     /classifier.3/Relu     |   Relu   |                     /classifier.2/Gemm_output_0                     |     /classifier.3/Relu_output_0     |                                                   |\n",
      "|   21  |      /last_layer/Gemm      |   Gemm   |   /classifier.3/Relu_output_0, last_layer.weight, last_layer.bias   |                  76                 |                alpha, beta, transB                |\n",
      "+-------+----------------------------+----------+---------------------------------------------------------------------+-------------------------------------+---------------------------------------------------+\u001b[0m\n",
      "I0326 21:25:09.702524 140189651072832 onnx_runtime.py:90] ONNX Model Summary: \n",
      "+-------+----------------------------+----------+---------------------------------------------------------------------+-------------------------------------+---------------------------------------------------+\n",
      "| Index |            Name            |   Type   |                                Inputs                               |               Outputs               |                     Attributes                    |\n",
      "+-------+----------------------------+----------+---------------------------------------------------------------------+-------------------------------------+---------------------------------------------------+\n",
      "|   0   |   /feature_layers.0/Conv   |   Conv   |                 input, onnx::Conv_78, onnx::Conv_79                 |   /feature_layers.0/Conv_output_0   |   dilations, group, kernel_shape, pads, strides   |\n",
      "|   1   |   /feature_layers.2/Relu   |   Relu   |                   /feature_layers.0/Conv_output_0                   |   /feature_layers.2/Relu_output_0   |                                                   |\n",
      "|   2   |   /feature_layers.3/Conv   |   Conv   |    /feature_layers.2/Relu_output_0, onnx::Conv_81, onnx::Conv_82    |   /feature_layers.3/Conv_output_0   |   dilations, group, kernel_shape, pads, strides   |\n",
      "|   3   |   /feature_layers.5/Relu   |   Relu   |                   /feature_layers.3/Conv_output_0                   |   /feature_layers.5/Relu_output_0   |                                                   |\n",
      "|   4   | /feature_layers.6/MaxPool  | MaxPool  |                   /feature_layers.5/Relu_output_0                   |  /feature_layers.6/MaxPool_output_0 | ceil_mode, dilations, kernel_shape, pads, strides |\n",
      "|   5   |   /feature_layers.7/Conv   |   Conv   |   /feature_layers.6/MaxPool_output_0, onnx::Conv_84, onnx::Conv_85  |   /feature_layers.7/Conv_output_0   |   dilations, group, kernel_shape, pads, strides   |\n",
      "|   6   |   /feature_layers.9/Relu   |   Relu   |                   /feature_layers.7/Conv_output_0                   |   /feature_layers.9/Relu_output_0   |                                                   |\n",
      "|   7   |  /feature_layers.10/Conv   |   Conv   |    /feature_layers.9/Relu_output_0, onnx::Conv_87, onnx::Conv_88    |   /feature_layers.10/Conv_output_0  |   dilations, group, kernel_shape, pads, strides   |\n",
      "|   8   |  /feature_layers.12/Relu   |   Relu   |                   /feature_layers.10/Conv_output_0                  |   /feature_layers.12/Relu_output_0  |                                                   |\n",
      "|   9   | /feature_layers.13/MaxPool | MaxPool  |                   /feature_layers.12/Relu_output_0                  | /feature_layers.13/MaxPool_output_0 | ceil_mode, dilations, kernel_shape, pads, strides |\n",
      "|   10  |  /feature_layers.14/Conv   |   Conv   |  /feature_layers.13/MaxPool_output_0, onnx::Conv_90, onnx::Conv_91  |   /feature_layers.14/Conv_output_0  |   dilations, group, kernel_shape, pads, strides   |\n",
      "|   11  |  /feature_layers.16/Relu   |   Relu   |                   /feature_layers.14/Conv_output_0                  |   /feature_layers.16/Relu_output_0  |                                                   |\n",
      "|   12  |  /feature_layers.17/Conv   |   Conv   |    /feature_layers.16/Relu_output_0, onnx::Conv_93, onnx::Conv_94   |   /feature_layers.17/Conv_output_0  |   dilations, group, kernel_shape, pads, strides   |\n",
      "|   13  |  /feature_layers.19/Relu   |   Relu   |                   /feature_layers.17/Conv_output_0                  |   /feature_layers.19/Relu_output_0  |                                                   |\n",
      "|   14  | /feature_layers.20/MaxPool | MaxPool  |                   /feature_layers.19/Relu_output_0                  | /feature_layers.20/MaxPool_output_0 | ceil_mode, dilations, kernel_shape, pads, strides |\n",
      "|   15  |         /Constant          | Constant |                                                                     |          /Constant_output_0         |                       value                       |\n",
      "|   16  |          /Reshape          | Reshape  |       /feature_layers.20/MaxPool_output_0, /Constant_output_0       |          /Reshape_output_0          |                                                   |\n",
      "|   17  |     /classifier.0/Gemm     |   Gemm   |      /Reshape_output_0, classifier.0.weight, classifier.0.bias      |     /classifier.0/Gemm_output_0     |                alpha, beta, transB                |\n",
      "|   18  |     /classifier.1/Relu     |   Relu   |                     /classifier.0/Gemm_output_0                     |     /classifier.1/Relu_output_0     |                                                   |\n",
      "|   19  |     /classifier.2/Gemm     |   Gemm   | /classifier.1/Relu_output_0, classifier.2.weight, classifier.2.bias |     /classifier.2/Gemm_output_0     |                alpha, beta, transB                |\n",
      "|   20  |     /classifier.3/Relu     |   Relu   |                     /classifier.2/Gemm_output_0                     |     /classifier.3/Relu_output_0     |                                                   |\n",
      "|   21  |      /last_layer/Gemm      |   Gemm   |   /classifier.3/Relu_output_0, last_layer.weight, last_layer.bias   |                  76                 |                alpha, beta, transB                |\n",
      "+-------+----------------------------+----------+---------------------------------------------------------------------+-------------------------------------+---------------------------------------------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mQuantizing model using static quantization with calibration...\u001b[0m\n",
      "I0326 21:25:10.386137 140189651072832 quantize.py:52] Quantizing model using static quantization with calibration...\n",
      "/root/anaconda3/envs/mase/lib/python3.11/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:69: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
      "  warnings.warn(\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mQuantization complete. Model is now calibrated and statically quantized.\u001b[0m\n",
      "I0326 21:26:25.402518 140189651072832 quantize.py:90] Quantization complete. Model is now calibrated and statically quantized.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mQuantizing model using dynamic quantization...\u001b[0m\n",
      "I0326 21:26:25.411698 140189651072832 quantize.py:31] Quantizing model using dynamic quantization...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mQuantization complete. Model is now dynamically quantized.\u001b[0m\n",
      "I0326 21:26:25.962112 140189651072832 quantize.py:46] Quantization complete. Model is now dynamically quantized.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mQuantizing model using automatic mixed precision quantization...\u001b[0m\n",
      "I0326 21:26:25.962691 140189651072832 quantize.py:96] Quantizing model using automatic mixed precision quantization...\n",
      "Adding missing dtypes for 0 outputs\n",
      "/root/anaconda3/envs/mase/lib/python3.11/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:69: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
      "  warnings.warn(\n",
      "['/feature_layers.0/Conv', '/feature_layers.2/Relu', '/feature_layers.3/Conv', '/feature_layers.5/Relu', '/feature_layers.6/MaxPool', '/feature_layers.7/Conv', '/feature_layers.9/Relu', '/feature_layers.10/Conv', '/feature_layers.12/Relu', '/feature_layers.13/MaxPool', '/feature_layers.14/Conv', '/feature_layers.16/Relu', '/feature_layers.17/Conv', '/feature_layers.19/Relu', '/feature_layers.20/MaxPool', '/Reshape', '/classifier.0/Gemm', '/classifier.1/Relu', '/classifier.2/Gemm', '/classifier.3/Relu', '/last_layer/Gemm']\n",
      "True\n",
      "Sanity checks passed. Starting autoconvert.\n",
      "Running attempt 1 excluding conversion of 0 nodes\n",
      "[]\n",
      "True\n",
      "Attempt succeeded.\n",
      "[*21*]\n",
      "Done: []\n",
      "[]\n",
      "Final model validated successfully.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mQuantization complete. Model is now quantized using automatic mixed precision.\u001b[0m\n",
      "I0326 21:26:35.657346 140189651072832 quantize.py:118] Quantization complete. Model is now quantized using automatic mixed precision.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPerforming runtime analysis on original graph...\u001b[0m\n",
      "I0326 21:26:35.679898 140189651072832 transform.py:170] Performing runtime analysis on original graph...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on vgg7\u001b[0m\n",
      "I0326 21:26:35.680151 140189651072832 analysis.py:270] Starting transformation analysis on vgg7\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results vgg7:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.89024    |\n",
      "|      Average Precision       |   0.92059    |\n",
      "|        Average Recall        |   0.92039    |\n",
      "|       Average F1 Score       |    0.9203    |\n",
      "|         Average Loss         |   0.22849    |\n",
      "|       Average Latency        |  3.1209 ms   |\n",
      "|   Average GPU Power Usage    |   22.218 W   |\n",
      "| Inference Energy Consumption | 0.019261 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "I0326 21:26:40.657045 140189651072832 analysis.py:398] \n",
      "Results vgg7:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.89024    |\n",
      "|      Average Precision       |   0.92059    |\n",
      "|        Average Recall        |   0.92039    |\n",
      "|       Average F1 Score       |    0.9203    |\n",
      "|         Average Loss         |   0.22849    |\n",
      "|       Average Latency        |  3.1209 ms   |\n",
      "|   Average GPU Power Usage    |   22.218 W   |\n",
      "| Inference Energy Consumption | 0.019261 mWh |\n",
      "+------------------------------+--------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /root/mase_output/tensorrt/quantization/vgg7_cls_cifar10_2024-03-26/mase_graph/version_9/model.json\u001b[0m\n",
      "I0326 21:26:40.659531 140189651072832 analysis.py:84] Runtime analysis results saved to /root/mase_output/tensorrt/quantization/vgg7_cls_cifar10_2024-03-26/mase_graph/version_9/model.json\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPerforming runtime analysis on optimized quantized graph...\u001b[0m\n",
      "I0326 21:26:40.659884 140189651072832 transform.py:176] Performing runtime analysis on optimized quantized graph...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on vgg7-onnx\u001b[0m\n",
      "I0326 21:26:40.825015 140189651072832 analysis.py:270] Starting transformation analysis on vgg7-onnx\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results vgg7-onnx:\n",
      "+------------------------------+-----------+\n",
      "|      Metric (Per Batch)      |   Value   |\n",
      "+------------------------------+-----------+\n",
      "|    Average Test Accuracy     |  0.88533  |\n",
      "|      Average Precision       |  0.91987  |\n",
      "|        Average Recall        |  0.91579  |\n",
      "|       Average F1 Score       |  0.91576  |\n",
      "|         Average Loss         |  0.24646  |\n",
      "|       Average Latency        | 171.71 ms |\n",
      "|   Average GPU Power Usage    | 21.554 W  |\n",
      "| Inference Energy Consumption | 1.028 mWh |\n",
      "+------------------------------+-----------+\u001b[0m\n",
      "I0326 21:27:03.831091 140189651072832 analysis.py:398] \n",
      "Results vgg7-onnx:\n",
      "+------------------------------+-----------+\n",
      "|      Metric (Per Batch)      |   Value   |\n",
      "+------------------------------+-----------+\n",
      "|    Average Test Accuracy     |  0.88533  |\n",
      "|      Average Precision       |  0.91987  |\n",
      "|        Average Recall        |  0.91579  |\n",
      "|       Average F1 Score       |  0.91576  |\n",
      "|         Average Loss         |  0.24646  |\n",
      "|       Average Latency        | 171.71 ms |\n",
      "|   Average GPU Power Usage    | 21.554 W  |\n",
      "| Inference Energy Consumption | 1.028 mWh |\n",
      "+------------------------------+-----------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /root/mase_output/tensorrt/quantization/vgg7_cls_cifar10_2024-03-26/onnx/version_13/model.json\u001b[0m\n",
      "I0326 21:27:03.832996 140189651072832 analysis.py:84] Runtime analysis results saved to /root/mase_output/tensorrt/quantization/vgg7_cls_cifar10_2024-03-26/onnx/version_13/model.json\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPerforming runtime analysis on static quantized graph...\u001b[0m\n",
      "I0326 21:27:03.834278 140189651072832 transform.py:191] Performing runtime analysis on static quantized graph...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on vgg7-onnx\u001b[0m\n",
      "I0326 21:27:03.898595 140189651072832 analysis.py:270] Starting transformation analysis on vgg7-onnx\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results vgg7-onnx:\n",
      "+------------------------------+-------------+\n",
      "|      Metric (Per Batch)      |    Value    |\n",
      "+------------------------------+-------------+\n",
      "|    Average Test Accuracy     |   0.88589   |\n",
      "|      Average Precision       |   0.9191    |\n",
      "|        Average Recall        |   0.91513   |\n",
      "|       Average F1 Score       |   0.91498   |\n",
      "|         Average Loss         |   0.25254   |\n",
      "|       Average Latency        |  159.93 ms  |\n",
      "|   Average GPU Power Usage    |  21.732 W   |\n",
      "| Inference Energy Consumption | 0.96546 mWh |\n",
      "+------------------------------+-------------+\u001b[0m\n",
      "I0326 21:27:27.070293 140189651072832 analysis.py:398] \n",
      "Results vgg7-onnx:\n",
      "+------------------------------+-------------+\n",
      "|      Metric (Per Batch)      |    Value    |\n",
      "+------------------------------+-------------+\n",
      "|    Average Test Accuracy     |   0.88589   |\n",
      "|      Average Precision       |   0.9191    |\n",
      "|        Average Recall        |   0.91513   |\n",
      "|       Average F1 Score       |   0.91498   |\n",
      "|         Average Loss         |   0.25254   |\n",
      "|       Average Latency        |  159.93 ms  |\n",
      "|   Average GPU Power Usage    |  21.732 W   |\n",
      "| Inference Energy Consumption | 0.96546 mWh |\n",
      "+------------------------------+-------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /root/mase_output/tensorrt/quantization/vgg7_cls_cifar10_2024-03-26/onnx/version_14/model.json\u001b[0m\n",
      "I0326 21:27:27.072537 140189651072832 analysis.py:84] Runtime analysis results saved to /root/mase_output/tensorrt/quantization/vgg7_cls_cifar10_2024-03-26/onnx/version_14/model.json\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPerforming runtime analysis on dynamic quantized graph...\u001b[0m\n",
      "I0326 21:27:27.075068 140189651072832 transform.py:196] Performing runtime analysis on dynamic quantized graph...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on vgg7-onnx\u001b[0m\n",
      "I0326 21:27:27.148433 140189651072832 analysis.py:270] Starting transformation analysis on vgg7-onnx\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results vgg7-onnx:\n",
      "+------------------------------+------------+\n",
      "|      Metric (Per Batch)      |   Value    |\n",
      "+------------------------------+------------+\n",
      "|    Average Test Accuracy     |  0.88349   |\n",
      "|      Average Precision       |   0.918    |\n",
      "|        Average Recall        |  0.91382   |\n",
      "|       Average F1 Score       |  0.91367   |\n",
      "|         Average Loss         |  0.25111   |\n",
      "|       Average Latency        | 372.93 ms  |\n",
      "|   Average GPU Power Usage    |  21.939 W  |\n",
      "| Inference Energy Consumption | 2.2727 mWh |\n",
      "+------------------------------+------------+\u001b[0m\n",
      "I0326 21:28:11.467866 140189651072832 analysis.py:398] \n",
      "Results vgg7-onnx:\n",
      "+------------------------------+------------+\n",
      "|      Metric (Per Batch)      |   Value    |\n",
      "+------------------------------+------------+\n",
      "|    Average Test Accuracy     |  0.88349   |\n",
      "|      Average Precision       |   0.918    |\n",
      "|        Average Recall        |  0.91382   |\n",
      "|       Average F1 Score       |  0.91367   |\n",
      "|         Average Loss         |  0.25111   |\n",
      "|       Average Latency        | 372.93 ms  |\n",
      "|   Average GPU Power Usage    |  21.939 W  |\n",
      "| Inference Energy Consumption | 2.2727 mWh |\n",
      "+------------------------------+------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /root/mase_output/tensorrt/quantization/vgg7_cls_cifar10_2024-03-26/onnx/version_15/model.json\u001b[0m\n",
      "I0326 21:28:11.470496 140189651072832 analysis.py:84] Runtime analysis results saved to /root/mase_output/tensorrt/quantization/vgg7_cls_cifar10_2024-03-26/onnx/version_15/model.json\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPerforming runtime analysis on auto mixed precision quantized graph...\u001b[0m\n",
      "I0326 21:28:11.473682 140189651072832 transform.py:201] Performing runtime analysis on auto mixed precision quantized graph...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on vgg7-onnx\u001b[0m\n",
      "I0326 21:28:11.542679 140189651072832 analysis.py:270] Starting transformation analysis on vgg7-onnx\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results vgg7-onnx:\n",
      "+------------------------------+------------+\n",
      "|      Metric (Per Batch)      |   Value    |\n",
      "+------------------------------+------------+\n",
      "|    Average Test Accuracy     |  0.88533   |\n",
      "|      Average Precision       |  0.91987   |\n",
      "|        Average Recall        |  0.91579   |\n",
      "|       Average F1 Score       |  0.91576   |\n",
      "|         Average Loss         |  0.24648   |\n",
      "|       Average Latency        | 338.65 ms  |\n",
      "|   Average GPU Power Usage    |  22.158 W  |\n",
      "| Inference Energy Consumption | 2.0844 mWh |\n",
      "+------------------------------+------------+\u001b[0m\n",
      "I0326 21:28:52.965342 140189651072832 analysis.py:398] \n",
      "Results vgg7-onnx:\n",
      "+------------------------------+------------+\n",
      "|      Metric (Per Batch)      |   Value    |\n",
      "+------------------------------+------------+\n",
      "|    Average Test Accuracy     |  0.88533   |\n",
      "|      Average Precision       |  0.91987   |\n",
      "|        Average Recall        |  0.91579   |\n",
      "|       Average F1 Score       |  0.91576   |\n",
      "|         Average Loss         |  0.24648   |\n",
      "|       Average Latency        | 338.65 ms  |\n",
      "|   Average GPU Power Usage    |  22.158 W  |\n",
      "| Inference Energy Consumption | 2.0844 mWh |\n",
      "+------------------------------+------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /root/mase_output/tensorrt/quantization/vgg7_cls_cifar10_2024-03-26/onnx/version_16/model.json\u001b[0m\n",
      "I0326 21:28:52.967841 140189651072832 analysis.py:84] Runtime analysis results saved to /root/mase_output/tensorrt/quantization/vgg7_cls_cifar10_2024-03-26/onnx/version_16/model.json\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mSaved mase graph to /root/mase/mase_output/vgg7_cls_cifar10_2024-03-26/software/transform/transformed_ckpt\u001b[0m\n",
      "I0326 21:30:17.158000 140189651072832 save_and_load.py:147] Saved mase graph to /root/mase/mase_output/vgg7_cls_cifar10_2024-03-26/software/transform/transformed_ckpt\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTransformation is completed\u001b[0m\n",
      "I0326 21:30:17.158302 140189651072832 cli.py:383] Transformation is completed\n"
     ]
    }
   ],
   "source": [
    "VGG_TOML_PATH = \"../../../machop/configs/onnx/vgg7_gpu_quant.toml\"\n",
    "VGG_CHECKPOINT_PATH = \"../../../mase_output/vgg7-pre-trained/test-accu-0.9332.ckpt\"\n",
    "\n",
    "!ch transform --config {VGG_TOML_PATH} --load {VGG_CHECKPOINT_PATH} --load-type pl \n",
    "\n",
    "# JSC_TOML_PATH = \"../../../machop/configs/onnx/jsc_gpu_quant.toml\"\n",
    "# JSC_CHECKPOINT_PATH = \"../../../mase_output/jsc-toy_cls_jsc/software/training_ckpts/best.ckpt\"\n",
    "# !ch transform --config {JSC_TOML_PATH} --load {JSC_CHECKPOINT_PATH} --load-type pl"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
