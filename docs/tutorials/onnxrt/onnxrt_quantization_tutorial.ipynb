{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome To the ONNX Runtime Tutorial!\n",
    "\n",
    "This notebook is designed to demonstrate the features of the ONNXRT passes integrated into MASE as part of the MASERT framework.\n",
    "\n",
    "## Section 1. ONNX Runtime Optimizations\n",
    "Firstly, we will show you how we can utilise the ONNX RT optimizations. We expect to see a speed up without a loss in model accuracy. We will use a simple model, `jsc-toy`, and compare the optimized model to the original model using the `Machop API`.\n",
    "\n",
    "First, we load the machop requirements by running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/mase/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-23 16:45:14,890] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mSet logging level to info\u001b[0m\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0323 16:45:16.544360 140355237783360 logger.py:44] Set logging level to info\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import toml\n",
    "\n",
    "# Figure out the correct path\n",
    "machop_path = Path(\".\").resolve().parent.parent.parent /\"machop\"\n",
    "assert machop_path.exists(), \"Failed to find machop at: {}\".format(machop_path)\n",
    "sys.path.append(str(machop_path))\n",
    "\n",
    "# Add directory to the PATH so that chop can be called\n",
    "new_path = \"../../../machop\"\n",
    "full_path = os.path.abspath(new_path)\n",
    "os.environ['PATH'] += os.pathsep + full_path\n",
    "\n",
    "from chop.tools.utils import to_numpy_if_tensor\n",
    "from chop.tools.logger import set_logging_verbosity\n",
    "from chop.tools import get_cf_args, get_dummy_input\n",
    "from chop.passes.graph.utils import deepcopy_mase_graph\n",
    "from chop.tools.get_input import InputGenerator\n",
    "from chop.tools.checkpoint_load import load_model\n",
    "from chop.ir import MaseGraph\n",
    "from chop.models import get_model_info, get_model, get_tokenizer\n",
    "from chop.dataset import MaseDataModule, get_dataset_info\n",
    "from chop.passes.graph.transforms import metadata_value_type_cast_transform_pass\n",
    "from chop.passes.graph import (\n",
    "    summarize_quantization_analysis_pass,\n",
    "    add_common_metadata_analysis_pass,\n",
    "    init_metadata_analysis_pass,\n",
    "    add_software_metadata_analysis_pass,\n",
    "    onnx_runtime_transform_pass,\n",
    "    runtime_analysis_pass,\n",
    "    )\n",
    "\n",
    "set_logging_verbosity(\"info\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then load in a demonstration toml file and set the relevant pass arguments (this is all done automatically if we were to use the command line, see [Section X]())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# JSC_TOML_PATH = \"../../../machop/configs/onnx/jsc_gpu_ort.toml\"\n",
    "\n",
    "# Reading TOML file and converting it into a Python dictionary\n",
    "# with open(JSC_TOML_PATH, 'r') as toml_file:\n",
    "#     pass_args = toml.load(toml_file)\n",
    "\n",
    "VGG_TOML_PATH = \"../../../machop/configs/onnx/vgg7_gpu_ort.toml\"\n",
    "with open(VGG_TOML_PATH, 'r') as toml_file:\n",
    "    pass_args = toml.load(toml_file)\n",
    "\n",
    "# Extract the 'passes.tensorrt' section and its children\n",
    "onnx_config = pass_args.get('passes', {}).get('onnxruntime', {})\n",
    "# Extract the 'passes.runtime_analysis' section and its children\n",
    "runtime_analysis_config = pass_args.get('passes', {}).get('runtime_analysis', {})\n",
    "\n",
    "# Load the basics in\n",
    "model_name = pass_args['model']\n",
    "dataset_name = pass_args['dataset']\n",
    "max_epochs = pass_args['max_epochs']\n",
    "batch_size = pass_args['batch_size']\n",
    "learning_rate = pass_args['learning_rate']\n",
    "accelerator = pass_args['accelerator']\n",
    "\n",
    "data_module = MaseDataModule(\n",
    "    name=dataset_name,\n",
    "    batch_size=batch_size,\n",
    "    model_name=model_name,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "data_module.prepare_data()\n",
    "data_module.setup()\n",
    "\n",
    "# Add the data_module and other necessary information to the configs\n",
    "configs = [onnx_config, runtime_analysis_config]\n",
    "for config in configs:\n",
    "    config['task'] = pass_args['task']\n",
    "    config['batch_size'] = pass_args['batch_size']\n",
    "    config['model'] = pass_args['model']\n",
    "    config['data_module'] = data_module\n",
    "    config['dataset'] = pass_args['dataset']\n",
    "    config['accelerator'] = 'cuda' if pass_args['accelerator'] == 'gpu' else pass_args['accelerator']\n",
    "    if config['accelerator'] == 'gpu':\n",
    "        os.environ['CUDA_MODULE_LOADING'] = 'LAZY'\n",
    "\n",
    "model_info = get_model_info(model_name)\n",
    "model = get_model(\n",
    "    model_name,\n",
    "    task=\"cls\",\n",
    "    dataset_info=data_module.dataset_info,\n",
    "    pretrained=False)\n",
    "\n",
    "input_generator = InputGenerator(\n",
    "    data_module=data_module,\n",
    "    model_info=model_info,\n",
    "    task=\"cls\",\n",
    "    which_dataloader=\"train\",\n",
    ")\n",
    "\n",
    "# generate the mase graph and initialize node metadata\n",
    "mg = MaseGraph(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.utils.data.dataloader.DataLoader"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data_module.train_dataloader())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we train the `jsc-toy` model using the machop `train` action with the config from the toml file. You may want to switch to GPU for this task - it will not affect the cpu optimizations later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ch train --config {JSC_TOML_PATH} --accelerator gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we load in the checkpoint. You will have to adjust this according to where it has been stored in the mase_output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from ../../../mase_output/vgg7-pre-trained/test-accu-0.9332.ckpt\u001b[0m\n",
      "I0322 18:17:19.236122 139736793290560 checkpoint_load.py:85] Loaded pytorch lightning checkpoint from ../../../mase_output/vgg7-pre-trained/test-accu-0.9332.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Load in the trained checkpoint - change this accordingly\n",
    "# JSC_CHECKPOINT_PATH = \"../../../mase_output/jsc-toy_cls_jsc/software/training_ckpts/best.ckpt\"\n",
    "# model = load_model(load_name=JSC_CHECKPOINT_PATH, load_type=\"pl\", model=model)\n",
    "\n",
    "VGG_CHECKPOINT_PATH = \"../../../mase_output/vgg7-pre-trained/test-accu-0.9332.ckpt\"\n",
    "model = load_model(load_name=VGG_CHECKPOINT_PATH, load_type=\"pl\", model=model)\n",
    "\n",
    "# Initiate metadata\n",
    "dummy_in = next(iter(input_generator))\n",
    "_ = model(**dummy_in)\n",
    "mg, _ = init_metadata_analysis_pass(mg, None)\n",
    "\n",
    "# Copy original graph for analysis later\n",
    "mg_original = deepcopy_mase_graph(mg)\n",
    "\n",
    "mg, _ = add_common_metadata_analysis_pass(mg, {\"dummy_in\": dummy_in})\n",
    "mg, _ = add_software_metadata_analysis_pass(mg, None)\n",
    "mg, _ = metadata_value_type_cast_transform_pass(mg, pass_args={\"fn\": to_numpy_if_tensor})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then run the `onnx_runtime_transform_pass` which completes the optimizations using the dataloader and `jsc-toy` model. This returns metadata containing the paths to the models:\n",
    "\n",
    "- `onnx_path` (the optimized model)\n",
    "- `onnx_dynamic_quantized_path` (the dynamically )\n",
    "\n",
    "In this case, since we are not quantizing the model, only the `onnx_path` is available. \n",
    "\n",
    "The models are also stored in the directory:\n",
    "```\n",
    "mase_output\n",
    "└── onnxrt\n",
    "    └── model_task_dataset_date\n",
    "        ├── optimized\n",
    "        ├── pre_processed\n",
    "        ├── static_quantized\n",
    "        └── dynamic_quantized\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "I0322 18:17:23.816130 139736793290560 onnx_runtime.py:48] Converting PyTorch model to ONNX...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mProject will be created at /root/mase/mase_output/onnxrt/vgg7_cls_cifar10_2024-03-22\u001b[0m\n",
      "I0322 18:17:23.825595 139736793290560 onnx_runtime.py:50] Project will be created at /root/mase/mase_output/onnxrt/vgg7_cls_cifar10_2024-03-22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /root/mase/mase_output/onnxrt/vgg7_cls_cifar10_2024-03-22/optimized/version_4/model.onnx\u001b[0m\n",
      "I0322 18:17:25.000550 139736793290560 onnx_runtime.py:68] ONNX Conversion Complete. Stored ONNX model to /root/mase/mase_output/onnxrt/vgg7_cls_cifar10_2024-03-22/optimized/version_4/model.onnx\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Model Summary: \n",
      "+-------+----------------------------+----------+---------------------------------------------------------------------+-------------------------------------+---------------------------------------------------+\n",
      "| Index |            Name            |   Type   |                                Inputs                               |               Outputs               |                     Attributes                    |\n",
      "+-------+----------------------------+----------+---------------------------------------------------------------------+-------------------------------------+---------------------------------------------------+\n",
      "|   0   |   /feature_layers.0/Conv   |   Conv   |                 input, onnx::Conv_78, onnx::Conv_79                 |   /feature_layers.0/Conv_output_0   |   dilations, group, kernel_shape, pads, strides   |\n",
      "|   1   |   /feature_layers.2/Relu   |   Relu   |                   /feature_layers.0/Conv_output_0                   |   /feature_layers.2/Relu_output_0   |                                                   |\n",
      "|   2   |   /feature_layers.3/Conv   |   Conv   |    /feature_layers.2/Relu_output_0, onnx::Conv_81, onnx::Conv_82    |   /feature_layers.3/Conv_output_0   |   dilations, group, kernel_shape, pads, strides   |\n",
      "|   3   |   /feature_layers.5/Relu   |   Relu   |                   /feature_layers.3/Conv_output_0                   |   /feature_layers.5/Relu_output_0   |                                                   |\n",
      "|   4   | /feature_layers.6/MaxPool  | MaxPool  |                   /feature_layers.5/Relu_output_0                   |  /feature_layers.6/MaxPool_output_0 | ceil_mode, dilations, kernel_shape, pads, strides |\n",
      "|   5   |   /feature_layers.7/Conv   |   Conv   |   /feature_layers.6/MaxPool_output_0, onnx::Conv_84, onnx::Conv_85  |   /feature_layers.7/Conv_output_0   |   dilations, group, kernel_shape, pads, strides   |\n",
      "|   6   |   /feature_layers.9/Relu   |   Relu   |                   /feature_layers.7/Conv_output_0                   |   /feature_layers.9/Relu_output_0   |                                                   |\n",
      "|   7   |  /feature_layers.10/Conv   |   Conv   |    /feature_layers.9/Relu_output_0, onnx::Conv_87, onnx::Conv_88    |   /feature_layers.10/Conv_output_0  |   dilations, group, kernel_shape, pads, strides   |\n",
      "|   8   |  /feature_layers.12/Relu   |   Relu   |                   /feature_layers.10/Conv_output_0                  |   /feature_layers.12/Relu_output_0  |                                                   |\n",
      "|   9   | /feature_layers.13/MaxPool | MaxPool  |                   /feature_layers.12/Relu_output_0                  | /feature_layers.13/MaxPool_output_0 | ceil_mode, dilations, kernel_shape, pads, strides |\n",
      "|   10  |  /feature_layers.14/Conv   |   Conv   |  /feature_layers.13/MaxPool_output_0, onnx::Conv_90, onnx::Conv_91  |   /feature_layers.14/Conv_output_0  |   dilations, group, kernel_shape, pads, strides   |\n",
      "|   11  |  /feature_layers.16/Relu   |   Relu   |                   /feature_layers.14/Conv_output_0                  |   /feature_layers.16/Relu_output_0  |                                                   |\n",
      "|   12  |  /feature_layers.17/Conv   |   Conv   |    /feature_layers.16/Relu_output_0, onnx::Conv_93, onnx::Conv_94   |   /feature_layers.17/Conv_output_0  |   dilations, group, kernel_shape, pads, strides   |\n",
      "|   13  |  /feature_layers.19/Relu   |   Relu   |                   /feature_layers.17/Conv_output_0                  |   /feature_layers.19/Relu_output_0  |                                                   |\n",
      "|   14  | /feature_layers.20/MaxPool | MaxPool  |                   /feature_layers.19/Relu_output_0                  | /feature_layers.20/MaxPool_output_0 | ceil_mode, dilations, kernel_shape, pads, strides |\n",
      "|   15  |         /Constant          | Constant |                                                                     |          /Constant_output_0         |                       value                       |\n",
      "|   16  |          /Reshape          | Reshape  |       /feature_layers.20/MaxPool_output_0, /Constant_output_0       |          /Reshape_output_0          |                                                   |\n",
      "|   17  |     /classifier.0/Gemm     |   Gemm   |      /Reshape_output_0, classifier.0.weight, classifier.0.bias      |     /classifier.0/Gemm_output_0     |                alpha, beta, transB                |\n",
      "|   18  |     /classifier.1/Relu     |   Relu   |                     /classifier.0/Gemm_output_0                     |     /classifier.1/Relu_output_0     |                                                   |\n",
      "|   19  |     /classifier.2/Gemm     |   Gemm   | /classifier.1/Relu_output_0, classifier.2.weight, classifier.2.bias |     /classifier.2/Gemm_output_0     |                alpha, beta, transB                |\n",
      "|   20  |     /classifier.3/Relu     |   Relu   |                     /classifier.2/Gemm_output_0                     |     /classifier.3/Relu_output_0     |                                                   |\n",
      "|   21  |      /last_layer/Gemm      |   Gemm   |   /classifier.3/Relu_output_0, last_layer.weight, last_layer.bias   |                  76                 |                alpha, beta, transB                |\n",
      "+-------+----------------------------+----------+---------------------------------------------------------------------+-------------------------------------+---------------------------------------------------+\u001b[0m\n",
      "I0322 18:17:25.196635 139736793290560 onnx_runtime.py:90] ONNX Model Summary: \n",
      "+-------+----------------------------+----------+---------------------------------------------------------------------+-------------------------------------+---------------------------------------------------+\n",
      "| Index |            Name            |   Type   |                                Inputs                               |               Outputs               |                     Attributes                    |\n",
      "+-------+----------------------------+----------+---------------------------------------------------------------------+-------------------------------------+---------------------------------------------------+\n",
      "|   0   |   /feature_layers.0/Conv   |   Conv   |                 input, onnx::Conv_78, onnx::Conv_79                 |   /feature_layers.0/Conv_output_0   |   dilations, group, kernel_shape, pads, strides   |\n",
      "|   1   |   /feature_layers.2/Relu   |   Relu   |                   /feature_layers.0/Conv_output_0                   |   /feature_layers.2/Relu_output_0   |                                                   |\n",
      "|   2   |   /feature_layers.3/Conv   |   Conv   |    /feature_layers.2/Relu_output_0, onnx::Conv_81, onnx::Conv_82    |   /feature_layers.3/Conv_output_0   |   dilations, group, kernel_shape, pads, strides   |\n",
      "|   3   |   /feature_layers.5/Relu   |   Relu   |                   /feature_layers.3/Conv_output_0                   |   /feature_layers.5/Relu_output_0   |                                                   |\n",
      "|   4   | /feature_layers.6/MaxPool  | MaxPool  |                   /feature_layers.5/Relu_output_0                   |  /feature_layers.6/MaxPool_output_0 | ceil_mode, dilations, kernel_shape, pads, strides |\n",
      "|   5   |   /feature_layers.7/Conv   |   Conv   |   /feature_layers.6/MaxPool_output_0, onnx::Conv_84, onnx::Conv_85  |   /feature_layers.7/Conv_output_0   |   dilations, group, kernel_shape, pads, strides   |\n",
      "|   6   |   /feature_layers.9/Relu   |   Relu   |                   /feature_layers.7/Conv_output_0                   |   /feature_layers.9/Relu_output_0   |                                                   |\n",
      "|   7   |  /feature_layers.10/Conv   |   Conv   |    /feature_layers.9/Relu_output_0, onnx::Conv_87, onnx::Conv_88    |   /feature_layers.10/Conv_output_0  |   dilations, group, kernel_shape, pads, strides   |\n",
      "|   8   |  /feature_layers.12/Relu   |   Relu   |                   /feature_layers.10/Conv_output_0                  |   /feature_layers.12/Relu_output_0  |                                                   |\n",
      "|   9   | /feature_layers.13/MaxPool | MaxPool  |                   /feature_layers.12/Relu_output_0                  | /feature_layers.13/MaxPool_output_0 | ceil_mode, dilations, kernel_shape, pads, strides |\n",
      "|   10  |  /feature_layers.14/Conv   |   Conv   |  /feature_layers.13/MaxPool_output_0, onnx::Conv_90, onnx::Conv_91  |   /feature_layers.14/Conv_output_0  |   dilations, group, kernel_shape, pads, strides   |\n",
      "|   11  |  /feature_layers.16/Relu   |   Relu   |                   /feature_layers.14/Conv_output_0                  |   /feature_layers.16/Relu_output_0  |                                                   |\n",
      "|   12  |  /feature_layers.17/Conv   |   Conv   |    /feature_layers.16/Relu_output_0, onnx::Conv_93, onnx::Conv_94   |   /feature_layers.17/Conv_output_0  |   dilations, group, kernel_shape, pads, strides   |\n",
      "|   13  |  /feature_layers.19/Relu   |   Relu   |                   /feature_layers.17/Conv_output_0                  |   /feature_layers.19/Relu_output_0  |                                                   |\n",
      "|   14  | /feature_layers.20/MaxPool | MaxPool  |                   /feature_layers.19/Relu_output_0                  | /feature_layers.20/MaxPool_output_0 | ceil_mode, dilations, kernel_shape, pads, strides |\n",
      "|   15  |         /Constant          | Constant |                                                                     |          /Constant_output_0         |                       value                       |\n",
      "|   16  |          /Reshape          | Reshape  |       /feature_layers.20/MaxPool_output_0, /Constant_output_0       |          /Reshape_output_0          |                                                   |\n",
      "|   17  |     /classifier.0/Gemm     |   Gemm   |      /Reshape_output_0, classifier.0.weight, classifier.0.bias      |     /classifier.0/Gemm_output_0     |                alpha, beta, transB                |\n",
      "|   18  |     /classifier.1/Relu     |   Relu   |                     /classifier.0/Gemm_output_0                     |     /classifier.1/Relu_output_0     |                                                   |\n",
      "|   19  |     /classifier.2/Gemm     |   Gemm   | /classifier.1/Relu_output_0, classifier.2.weight, classifier.2.bias |     /classifier.2/Gemm_output_0     |                alpha, beta, transB                |\n",
      "|   20  |     /classifier.3/Relu     |   Relu   |                     /classifier.2/Gemm_output_0                     |     /classifier.3/Relu_output_0     |                                                   |\n",
      "|   21  |      /last_layer/Gemm      |   Gemm   |   /classifier.3/Relu_output_0, last_layer.weight, last_layer.bias   |                  76                 |                alpha, beta, transB                |\n",
      "+-------+----------------------------+----------+---------------------------------------------------------------------+-------------------------------------+---------------------------------------------------+\n",
      "\u001b[33mWARNING \u001b[0m \u001b[34mQuantization is not set in default config. Skipping quantization.\u001b[0m\n",
      "W0322 18:17:35.960459 139736793290560 onnx_runtime.py:97] Quantization is not set in default config. Skipping quantization.\n"
     ]
    }
   ],
   "source": [
    "mg, onnx_meta = onnx_runtime_transform_pass(mg, pass_args=onnx_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can view a summary of the ONNX model (which is the unmodified from the Pytorch one), however it should be optimized. Let's run an analysis path on both the original `MaseGraph` and the `.onnx` optimized model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on vgg7\u001b[0m\n",
      "I0322 18:17:59.828980 139736793290560 analysis.py:270] Starting transformation analysis on vgg7\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results vgg7:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.89024    |\n",
      "|      Average Precision       |   0.92059    |\n",
      "|        Average Recall        |   0.92039    |\n",
      "|       Average F1 Score       |    0.9203    |\n",
      "|         Average Loss         |   0.22849    |\n",
      "|       Average Latency        |  3.4081 ms   |\n",
      "|   Average GPU Power Usage    |   27.112 W   |\n",
      "| Inference Energy Consumption | 0.025667 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "I0322 18:18:01.599439 139736793290560 analysis.py:393] \n",
      "Results vgg7:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.89024    |\n",
      "|      Average Precision       |   0.92059    |\n",
      "|        Average Recall        |   0.92039    |\n",
      "|       Average F1 Score       |    0.9203    |\n",
      "|         Average Loss         |   0.22849    |\n",
      "|       Average Latency        |  3.4081 ms   |\n",
      "|   Average GPU Power Usage    |   27.112 W   |\n",
      "| Inference Energy Consumption | 0.025667 mWh |\n",
      "+------------------------------+--------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /root/mase_output/tensorrt/quantization/vgg7_cls_cifar10_2024-03-22/mase_graph/version_2/model.json\u001b[0m\n",
      "I0322 18:18:01.602724 139736793290560 analysis.py:84] Runtime analysis results saved to /root/mase_output/tensorrt/quantization/vgg7_cls_cifar10_2024-03-22/mase_graph/version_2/model.json\n"
     ]
    }
   ],
   "source": [
    "mg, _ = runtime_analysis_pass(mg, pass_args=runtime_analysis_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting transformation analysis on vgg7-onnx\u001b[0m\n",
      "I0322 18:17:53.968372 139736793290560 analysis.py:270] Starting transformation analysis on vgg7-onnx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Results vgg7-onnx:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.90831    |\n",
      "|      Average Precision       |   0.93161    |\n",
      "|        Average Recall        |   0.92961    |\n",
      "|       Average F1 Score       |   0.92954    |\n",
      "|         Average Loss         |    0.2251    |\n",
      "|       Average Latency        |  2.1648 ms   |\n",
      "|   Average GPU Power Usage    |   37.101 W   |\n",
      "| Inference Energy Consumption | 0.022311 mWh |\n",
      "+------------------------------+--------------+\u001b[0m\n",
      "I0322 18:17:55.379748 139736793290560 analysis.py:393] \n",
      "Results vgg7-onnx:\n",
      "+------------------------------+--------------+\n",
      "|      Metric (Per Batch)      |    Value     |\n",
      "+------------------------------+--------------+\n",
      "|    Average Test Accuracy     |   0.90831    |\n",
      "|      Average Precision       |   0.93161    |\n",
      "|        Average Recall        |   0.92961    |\n",
      "|       Average F1 Score       |   0.92954    |\n",
      "|         Average Loss         |    0.2251    |\n",
      "|       Average Latency        |  2.1648 ms   |\n",
      "|   Average GPU Power Usage    |   37.101 W   |\n",
      "| Inference Energy Consumption | 0.022311 mWh |\n",
      "+------------------------------+--------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mRuntime analysis results saved to /root/mase_output/tensorrt/quantization/vgg7_cls_cifar10_2024-03-22/onnx/version_6/model.json\u001b[0m\n",
      "I0322 18:17:55.383457 139736793290560 analysis.py:84] Runtime analysis results saved to /root/mase_output/tensorrt/quantization/vgg7_cls_cifar10_2024-03-22/onnx/version_6/model.json\n"
     ]
    }
   ],
   "source": [
    "_, _ = runtime_analysis_pass(onnx_meta['onnx_path'], pass_args=runtime_analysis_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, the latency has decreased around 4x with the `jsc-toy` model without compromising accuracy due to the well calibrated amax and quantization-aware fine tuning. The inference energy consumption has thus also dropped tremendously and this is an excellent demonstration for the need to quantize in industry especially for LLMs in order to reduce energy usage. \n",
    "\n",
    "## Section 2. INT8 Quantization\n",
    "\n",
    "We may quantize either using FP16 or INT8 by setting the `precision` parameter in `passes.onnxruntime.default.config` to `'fp16'` or `'int8'` respectively. INT8 quantization will show the most notable latency improvements but will likely lower performance. \n",
    "\n",
    "There are two types of quantization for ONNXRT and can be set in `onnxruntime.default.config` under `quantization_types`. The differences are for how they calibrate i.e. set the scale and zero points which are only relevant for integer based quantization:\n",
    "- **Static Quantization**:\n",
    "    - The scale and zero point of activations are calculated in advance (offline) using a calibration data set.\n",
    "    - The activations have the same scale and zero point during each forward pass.\n",
    "- **Dynamic Quantization**:\n",
    "    - The scale and zero point of activations are calculated on-the-fly (online) and are specific for each forward pass.\n",
    "    - This approach is more accurate but introduces extra computational overhead.\n",
    "\n",
    "Both methodolgies first pre-procsses the model before quantization adding further optimizations. This intermidate model is stored to the `pre-processed` directory. \n",
    "\n",
    "For this example, we will set the `precision` to `'int8'` and the `precision_types` to `['static', 'dynamic']` to compare both quantization methods, whilst keeping the other settings the exact same for a fair comparison against the optimized model. This time however, we will use chop from the terminal which runs the same pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSC_TOML_PATH = \"../../../machop/configs/onnx/jsc_gpu_quant.toml\"\n",
    "VGG_TOML_PATH = \"../../../machop/configs/onnx/vgg7_gpu_quant.toml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.97s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "[2024-03-22 18:18:49,576] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "INFO: Seed set to 0\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0322 18:18:51.892687 139886932555584 seed.py:54] Seed set to 0\n",
      "+-------------------------+------------------------+--------------+-----------------+------------------------+\n",
      "| Name                    |        Default         | Config. File | Manual Override |       Effective        |\n",
      "+-------------------------+------------------------+--------------+-----------------+------------------------+\n",
      "| task                    |     \u001b[38;5;8mclassification\u001b[0m     |     cls      |                 |          cls           |\n",
      "| load_name               |          None          |              |                 |          None          |\n",
      "| load_type               |           mz           |              |                 |           mz           |\n",
      "| batch_size              |          \u001b[38;5;8m128\u001b[0m           |      16      |                 |           16           |\n",
      "| to_debug                |         False          |              |                 |         False          |\n",
      "| log_level               |          info          |              |                 |          info          |\n",
      "| report_to               |      tensorboard       |              |                 |      tensorboard       |\n",
      "| seed                    |           0            |              |                 |           0            |\n",
      "| quant_config            |          None          |              |                 |          None          |\n",
      "| training_optimizer      |          adam          |              |                 |          adam          |\n",
      "| trainer_precision       |        16-mixed        |              |                 |        16-mixed        |\n",
      "| learning_rate           |         \u001b[38;5;8m1e-05\u001b[0m          |    0.001     |                 |         0.001          |\n",
      "| weight_decay            |           0            |              |                 |           0            |\n",
      "| max_epochs              |           \u001b[38;5;8m20\u001b[0m           |      10      |                 |           10           |\n",
      "| max_steps               |           -1           |              |                 |           -1           |\n",
      "| accumulate_grad_batches |           1            |              |                 |           1            |\n",
      "| log_every_n_steps       |           50           |              |                 |           50           |\n",
      "| num_workers             |           28           |              |                 |           28           |\n",
      "| num_devices             |           1            |              |                 |           1            |\n",
      "| num_nodes               |           1            |              |                 |           1            |\n",
      "| accelerator             |          \u001b[38;5;8mauto\u001b[0m          |     gpu      |                 |          gpu           |\n",
      "| strategy                |          auto          |              |                 |          auto          |\n",
      "| is_to_auto_requeue      |         False          |              |                 |         False          |\n",
      "| github_ci               |         False          |              |                 |         False          |\n",
      "| disable_dataset_cache   |         False          |              |                 |         False          |\n",
      "| target                  |  xcu250-figd2104-2L-e  |              |                 |  xcu250-figd2104-2L-e  |\n",
      "| num_targets             |          100           |              |                 |          100           |\n",
      "| is_pretrained           |         False          |              |                 |         False          |\n",
      "| max_token_len           |          512           |              |                 |          512           |\n",
      "| project_dir             | /root/mase/mase_output |              |                 | /root/mase/mase_output |\n",
      "| project                 |          None          |              |                 |          None          |\n",
      "| model                   |          \u001b[38;5;8mNone\u001b[0m          |     vgg7     |                 |          vgg7          |\n",
      "| dataset                 |          \u001b[38;5;8mNone\u001b[0m          |   cifar10    |                 |        cifar10         |\n",
      "| t_max                   |           20           |              |                 |           20           |\n",
      "| eta_min                 |         1e-06          |              |                 |         1e-06          |\n",
      "+-------------------------+------------------------+--------------+-----------------+------------------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mInitialising model 'vgg7'...\u001b[0m\n",
      "I0322 18:18:51.902141 139886932555584 cli.py:841] Initialising model 'vgg7'...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mInitialising dataset 'cifar10'...\u001b[0m\n",
      "I0322 18:18:52.011340 139886932555584 cli.py:869] Initialising dataset 'cifar10'...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mProject will be created at /root/mase/mase_output/vgg7_cls_cifar10_2024-03-22\u001b[0m\n",
      "I0322 18:18:52.011706 139886932555584 cli.py:905] Project will be created at /root/mase/mase_output/vgg7_cls_cifar10_2024-03-22\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTransforming model 'vgg7'...\u001b[0m\n",
      "I0322 18:18:52.068424 139886932555584 cli.py:365] Transforming model 'vgg7'...\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "I0322 18:19:17.386682 139886932555584 onnx_runtime.py:48] Converting PyTorch model to ONNX...\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mProject will be created at /root/mase/mase_output/onnxrt/vgg7_cls_cifar10_2024-03-22\u001b[0m\n",
      "I0322 18:19:17.387409 139886932555584 onnx_runtime.py:50] Project will be created at /root/mase/mase_output/onnxrt/vgg7_cls_cifar10_2024-03-22\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /root/mase/mase_output/onnxrt/vgg7_cls_cifar10_2024-03-22/optimized/version_5/model.onnx\u001b[0m\n",
      "I0322 18:19:26.364434 139886932555584 onnx_runtime.py:68] ONNX Conversion Complete. Stored ONNX model to /root/mase/mase_output/onnxrt/vgg7_cls_cifar10_2024-03-22/optimized/version_5/model.onnx\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Model Summary: \n",
      "+-------+----------------------------+----------+---------------------------------------------------------------------+-------------------------------------+---------------------------------------------------+\n",
      "| Index |            Name            |   Type   |                                Inputs                               |               Outputs               |                     Attributes                    |\n",
      "+-------+----------------------------+----------+---------------------------------------------------------------------+-------------------------------------+---------------------------------------------------+\n",
      "|   0   |   /feature_layers.0/Conv   |   Conv   |                 input, onnx::Conv_78, onnx::Conv_79                 |   /feature_layers.0/Conv_output_0   |   dilations, group, kernel_shape, pads, strides   |\n",
      "|   1   |   /feature_layers.2/Relu   |   Relu   |                   /feature_layers.0/Conv_output_0                   |   /feature_layers.2/Relu_output_0   |                                                   |\n",
      "|   2   |   /feature_layers.3/Conv   |   Conv   |    /feature_layers.2/Relu_output_0, onnx::Conv_81, onnx::Conv_82    |   /feature_layers.3/Conv_output_0   |   dilations, group, kernel_shape, pads, strides   |\n",
      "|   3   |   /feature_layers.5/Relu   |   Relu   |                   /feature_layers.3/Conv_output_0                   |   /feature_layers.5/Relu_output_0   |                                                   |\n",
      "|   4   | /feature_layers.6/MaxPool  | MaxPool  |                   /feature_layers.5/Relu_output_0                   |  /feature_layers.6/MaxPool_output_0 | ceil_mode, dilations, kernel_shape, pads, strides |\n",
      "|   5   |   /feature_layers.7/Conv   |   Conv   |   /feature_layers.6/MaxPool_output_0, onnx::Conv_84, onnx::Conv_85  |   /feature_layers.7/Conv_output_0   |   dilations, group, kernel_shape, pads, strides   |\n",
      "|   6   |   /feature_layers.9/Relu   |   Relu   |                   /feature_layers.7/Conv_output_0                   |   /feature_layers.9/Relu_output_0   |                                                   |\n",
      "|   7   |  /feature_layers.10/Conv   |   Conv   |    /feature_layers.9/Relu_output_0, onnx::Conv_87, onnx::Conv_88    |   /feature_layers.10/Conv_output_0  |   dilations, group, kernel_shape, pads, strides   |\n",
      "|   8   |  /feature_layers.12/Relu   |   Relu   |                   /feature_layers.10/Conv_output_0                  |   /feature_layers.12/Relu_output_0  |                                                   |\n",
      "|   9   | /feature_layers.13/MaxPool | MaxPool  |                   /feature_layers.12/Relu_output_0                  | /feature_layers.13/MaxPool_output_0 | ceil_mode, dilations, kernel_shape, pads, strides |\n",
      "|   10  |  /feature_layers.14/Conv   |   Conv   |  /feature_layers.13/MaxPool_output_0, onnx::Conv_90, onnx::Conv_91  |   /feature_layers.14/Conv_output_0  |   dilations, group, kernel_shape, pads, strides   |\n",
      "|   11  |  /feature_layers.16/Relu   |   Relu   |                   /feature_layers.14/Conv_output_0                  |   /feature_layers.16/Relu_output_0  |                                                   |\n",
      "|   12  |  /feature_layers.17/Conv   |   Conv   |    /feature_layers.16/Relu_output_0, onnx::Conv_93, onnx::Conv_94   |   /feature_layers.17/Conv_output_0  |   dilations, group, kernel_shape, pads, strides   |\n",
      "|   13  |  /feature_layers.19/Relu   |   Relu   |                   /feature_layers.17/Conv_output_0                  |   /feature_layers.19/Relu_output_0  |                                                   |\n",
      "|   14  | /feature_layers.20/MaxPool | MaxPool  |                   /feature_layers.19/Relu_output_0                  | /feature_layers.20/MaxPool_output_0 | ceil_mode, dilations, kernel_shape, pads, strides |\n",
      "|   15  |         /Constant          | Constant |                                                                     |          /Constant_output_0         |                       value                       |\n",
      "|   16  |          /Reshape          | Reshape  |       /feature_layers.20/MaxPool_output_0, /Constant_output_0       |          /Reshape_output_0          |                                                   |\n",
      "|   17  |     /classifier.0/Gemm     |   Gemm   |      /Reshape_output_0, classifier.0.weight, classifier.0.bias      |     /classifier.0/Gemm_output_0     |                alpha, beta, transB                |\n",
      "|   18  |     /classifier.1/Relu     |   Relu   |                     /classifier.0/Gemm_output_0                     |     /classifier.1/Relu_output_0     |                                                   |\n",
      "|   19  |     /classifier.2/Gemm     |   Gemm   | /classifier.1/Relu_output_0, classifier.2.weight, classifier.2.bias |     /classifier.2/Gemm_output_0     |                alpha, beta, transB                |\n",
      "|   20  |     /classifier.3/Relu     |   Relu   |                     /classifier.2/Gemm_output_0                     |     /classifier.3/Relu_output_0     |                                                   |\n",
      "|   21  |      /last_layer/Gemm      |   Gemm   |   /classifier.3/Relu_output_0, last_layer.weight, last_layer.bias   |                  76                 |                alpha, beta, transB                |\n",
      "+-------+----------------------------+----------+---------------------------------------------------------------------+-------------------------------------+---------------------------------------------------+\u001b[0m\n",
      "I0322 18:19:26.556474 139886932555584 onnx_runtime.py:90] ONNX Model Summary: \n",
      "+-------+----------------------------+----------+---------------------------------------------------------------------+-------------------------------------+---------------------------------------------------+\n",
      "| Index |            Name            |   Type   |                                Inputs                               |               Outputs               |                     Attributes                    |\n",
      "+-------+----------------------------+----------+---------------------------------------------------------------------+-------------------------------------+---------------------------------------------------+\n",
      "|   0   |   /feature_layers.0/Conv   |   Conv   |                 input, onnx::Conv_78, onnx::Conv_79                 |   /feature_layers.0/Conv_output_0   |   dilations, group, kernel_shape, pads, strides   |\n",
      "|   1   |   /feature_layers.2/Relu   |   Relu   |                   /feature_layers.0/Conv_output_0                   |   /feature_layers.2/Relu_output_0   |                                                   |\n",
      "|   2   |   /feature_layers.3/Conv   |   Conv   |    /feature_layers.2/Relu_output_0, onnx::Conv_81, onnx::Conv_82    |   /feature_layers.3/Conv_output_0   |   dilations, group, kernel_shape, pads, strides   |\n",
      "|   3   |   /feature_layers.5/Relu   |   Relu   |                   /feature_layers.3/Conv_output_0                   |   /feature_layers.5/Relu_output_0   |                                                   |\n",
      "|   4   | /feature_layers.6/MaxPool  | MaxPool  |                   /feature_layers.5/Relu_output_0                   |  /feature_layers.6/MaxPool_output_0 | ceil_mode, dilations, kernel_shape, pads, strides |\n",
      "|   5   |   /feature_layers.7/Conv   |   Conv   |   /feature_layers.6/MaxPool_output_0, onnx::Conv_84, onnx::Conv_85  |   /feature_layers.7/Conv_output_0   |   dilations, group, kernel_shape, pads, strides   |\n",
      "|   6   |   /feature_layers.9/Relu   |   Relu   |                   /feature_layers.7/Conv_output_0                   |   /feature_layers.9/Relu_output_0   |                                                   |\n",
      "|   7   |  /feature_layers.10/Conv   |   Conv   |    /feature_layers.9/Relu_output_0, onnx::Conv_87, onnx::Conv_88    |   /feature_layers.10/Conv_output_0  |   dilations, group, kernel_shape, pads, strides   |\n",
      "|   8   |  /feature_layers.12/Relu   |   Relu   |                   /feature_layers.10/Conv_output_0                  |   /feature_layers.12/Relu_output_0  |                                                   |\n",
      "|   9   | /feature_layers.13/MaxPool | MaxPool  |                   /feature_layers.12/Relu_output_0                  | /feature_layers.13/MaxPool_output_0 | ceil_mode, dilations, kernel_shape, pads, strides |\n",
      "|   10  |  /feature_layers.14/Conv   |   Conv   |  /feature_layers.13/MaxPool_output_0, onnx::Conv_90, onnx::Conv_91  |   /feature_layers.14/Conv_output_0  |   dilations, group, kernel_shape, pads, strides   |\n",
      "|   11  |  /feature_layers.16/Relu   |   Relu   |                   /feature_layers.14/Conv_output_0                  |   /feature_layers.16/Relu_output_0  |                                                   |\n",
      "|   12  |  /feature_layers.17/Conv   |   Conv   |    /feature_layers.16/Relu_output_0, onnx::Conv_93, onnx::Conv_94   |   /feature_layers.17/Conv_output_0  |   dilations, group, kernel_shape, pads, strides   |\n",
      "|   13  |  /feature_layers.19/Relu   |   Relu   |                   /feature_layers.17/Conv_output_0                  |   /feature_layers.19/Relu_output_0  |                                                   |\n",
      "|   14  | /feature_layers.20/MaxPool | MaxPool  |                   /feature_layers.19/Relu_output_0                  | /feature_layers.20/MaxPool_output_0 | ceil_mode, dilations, kernel_shape, pads, strides |\n",
      "|   15  |         /Constant          | Constant |                                                                     |          /Constant_output_0         |                       value                       |\n",
      "|   16  |          /Reshape          | Reshape  |       /feature_layers.20/MaxPool_output_0, /Constant_output_0       |          /Reshape_output_0          |                                                   |\n",
      "|   17  |     /classifier.0/Gemm     |   Gemm   |      /Reshape_output_0, classifier.0.weight, classifier.0.bias      |     /classifier.0/Gemm_output_0     |                alpha, beta, transB                |\n",
      "|   18  |     /classifier.1/Relu     |   Relu   |                     /classifier.0/Gemm_output_0                     |     /classifier.1/Relu_output_0     |                                                   |\n",
      "|   19  |     /classifier.2/Gemm     |   Gemm   | /classifier.1/Relu_output_0, classifier.2.weight, classifier.2.bias |     /classifier.2/Gemm_output_0     |                alpha, beta, transB                |\n",
      "|   20  |     /classifier.3/Relu     |   Relu   |                     /classifier.2/Gemm_output_0                     |     /classifier.3/Relu_output_0     |                                                   |\n",
      "|   21  |      /last_layer/Gemm      |   Gemm   |   /classifier.3/Relu_output_0, last_layer.weight, last_layer.bias   |                  76                 |                alpha, beta, transB                |\n",
      "+-------+----------------------------+----------+---------------------------------------------------------------------+-------------------------------------+---------------------------------------------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mQuantizing model using static quantization with calibration...\u001b[0m\n",
      "I0322 18:19:27.600748 139886932555584 quantize.py:48] Quantizing model using static quantization with calibration...\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/mase/machop/ch\", line 6, in <module>\n",
      "    ChopCLI().run()\n",
      "  File \"/root/mase/machop/chop/cli.py\", line 272, in run\n",
      "    run_action_fn()\n",
      "  File \"/root/mase/machop/chop/cli.py\", line 382, in _run_transform\n",
      "    transform(**transform_params)\n",
      "  File \"/root/mase/machop/chop/actions/transform.py\", line 153, in transform\n",
      "    graph, runtime_meta = PASSES[\"onnxruntime\"](graph, pass_args=pass_config)\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/mase/machop/chop/passes/graph/transforms/onnxrt/onnx_runtime.py\", line 18, in onnx_runtime_transform_pass\n",
      "    quant_meta = onnx_runtime_session.quantize(onnx_model_path)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/mase/machop/chop/passes/graph/transforms/onnxrt/onnx_runtime.py\", line 117, in quantize\n",
      "    quantizer.quantize_static(prep_path, quantized_path)\n",
      "  File \"/root/mase/machop/chop/passes/graph/transforms/onnxrt/quantize.py\", line 73, in quantize_static\n",
      "    quantized_model = quantize_static(\n",
      "                      ^^^^^^^^^^^^^^^^\n",
      "  File \"/root/anaconda3/envs/mase/lib/python3.11/site-packages/onnxruntime/quantization/quantize.py\", line 496, in quantize_static\n",
      "    calibrator.collect_data(calibration_data_reader)\n",
      "  File \"/root/anaconda3/envs/mase/lib/python3.11/site-packages/onnxruntime/quantization/calibrate.py\", line 366, in collect_data\n",
      "    self.intermediate_outputs.append(self.infer_session.run(None, inputs))\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/anaconda3/envs/mase/lib/python3.11/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py\", line 220, in run\n",
      "    return self._sess.run(output_names, input_feed, run_options)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!ch transform --config {VGG_TOML_PATH}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
