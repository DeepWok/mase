{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rds/general/user/jj21/home/miniforge3/envs/adls-project/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from difflogic import LogicLayer, GroupSum\n",
    "import torch\n",
    "from chop import MaseGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import sys\n",
    "\n",
    "# \"Add dot (pydot) to path if needed:\"\n",
    "\n",
    "# new_path = os.path.expanduser(\"~/miniforge3/envs/adls-project/bin/\")\n",
    "# if new_path not in sys.path:\n",
    "#     sys.path.append(new_path)\n",
    "\n",
    "# # Add to environment PATH as well\n",
    "# os.environ[\"PATH\"] = new_path + os.pathsep + os.environ[\"PATH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    LogicLayer(400, 8_000),\n",
    "    LogicLayer(8_000, 8_000),\n",
    "    LogicLayer(8_000, 8_000),\n",
    "    LogicLayer(8_000, 8_000),\n",
    "    LogicLayer(8_000, 8_000),\n",
    "    LogicLayer(8_000, 8_000),\n",
    "    GroupSum(k=10, tau=20)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSTOM_OPS = {\n",
    "    \"modules\": {\n",
    "        LogicLayer: {\n",
    "            \"args\": {\"input\":\"data_in\"},\n",
    "        },\n",
    "        GroupSum: {\n",
    "            \"args\": {\"input\":\"data_in\"},\n",
    "        },\n",
    "    },\n",
    "    \"functions\": {},\n",
    "}\n",
    "\n",
    "mg = MaseGraph(model, custom_ops=CUSTOM_OPS)\n",
    "\n",
    "# mg.draw(\"DLG.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, loader, mode):\n",
    "    orig_mode = model.training\n",
    "    with torch.no_grad():\n",
    "        model.train(mode=mode)\n",
    "        res = np.mean(\n",
    "            [\n",
    "                (model(x.to('cpu').round()).argmax(-1) == y.to('cpu')).to(torch.float32).mean().item()\n",
    "                for x, y in loader\n",
    "            ]\n",
    "        )\n",
    "        model.train(mode=orig_mode)\n",
    "    return res.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['7.k', '7.tau'], unexpected_keys=[])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mnist_dataset\n",
    "import numpy as np\n",
    "\n",
    "train_set = mnist_dataset.MNIST('./data-mnist', train=True, download=True, remove_border=True)\n",
    "test_set = mnist_dataset.MNIST('./data-mnist', train=False, remove_border=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=100, shuffle=True, pin_memory=True, drop_last=True, num_workers=4)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=100, shuffle=False, pin_memory=True, drop_last=True)\n",
    "\n",
    "state_dict = torch.load(\"best_model_full.pth\", map_location=torch.device('cpu'))  # Load the dictionary\n",
    "mg.model.load_state_dict(state_dict, strict=False)  # Apply the weights\n",
    "\n",
    "# mg.model.eval()\n",
    "\n",
    "# print(\"Accuracy: \", eval(mg.model, test_loader, mode=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import types\n",
    "\n",
    "def test_pass(\n",
    "    graph,\n",
    "    pass_args={\"model\":\"None\", \"state_dict\":{}},\n",
    "):\n",
    "#     model = pass_args[\"model\"]\n",
    "#     given_params = model.state_dict()\n",
    "#     if (pass_args[\"state_dict\"]):\n",
    "#         given_params = pass_args[\"state_dict\"]\n",
    "    \n",
    "    \n",
    "    # Step 1: Copy input placeholder nodes\n",
    "    for node in graph.nodes:\n",
    "        print(node.op)\n",
    "        print(node.meta[\"mase\"].parameters)\n",
    "        print()\n",
    "#         if \"LogicLayer\" in node.op:  # Detect input nodes\n",
    "            \n",
    "    \n",
    "\n",
    "    return mg, None\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "#     nodes = set({})\n",
    "#     for node in mg.fx_graph.nodes:\n",
    "#         if (node.op == \"call_module\"):\n",
    "#             pass\n",
    "#         elif (node.op == \"call_method\" and long not in node.target ):\n",
    "#             if len(node.args) > 1:\n",
    "#                 raise \"What?\"\n",
    "#             node.replace_all_uses_with(node.args[0])\n",
    "#         elif (isinstance(node.target, types.BuiltinFunctionType):\n",
    "#              node.replace_all_uses_with(node.args[0]) \n",
    "            \n",
    "            \n",
    "#     return graph, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "placeholder\n",
      "{'common': {'mase_type': 'placeholder', 'mase_op': 'placeholder', 'args': {}, 'results': OrderedDict([('data_out_0', {'type': 'float', 'precision': [32], 'shape': [1, 1, 20, 20], 'torch_dtype': torch.float32, 'value': tensor([[[[0.0000, 0.0000, 0.3294, 0.7255, 0.6235, 0.5922, 0.2353, 0.1412,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.8706, 0.9961, 0.9961, 0.9961, 0.9961, 0.9451,\n",
      "           0.7765, 0.7765, 0.7765, 0.7765, 0.7765, 0.7765, 0.7765, 0.7765,\n",
      "           0.6667, 0.2039, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.2627, 0.4471, 0.2824, 0.4471, 0.6392, 0.8902,\n",
      "           0.9961, 0.8824, 0.9961, 0.9961, 0.9961, 0.9804, 0.8980, 0.9961,\n",
      "           0.9961, 0.5490, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0667,\n",
      "           0.2588, 0.0549, 0.2627, 0.2627, 0.2627, 0.2314, 0.0824, 0.9255,\n",
      "           0.9961, 0.4157, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3255, 0.9922,\n",
      "           0.8196, 0.0706, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0863, 0.9137, 1.0000,\n",
      "           0.3255, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5059, 0.9961, 0.9333,\n",
      "           0.1725, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000, 0.2314, 0.9765, 0.9961, 0.2431,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000, 0.5216, 0.9961, 0.7333, 0.0196,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0353, 0.8039, 0.9725, 0.2275, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.4941, 0.9961, 0.7137, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.2941, 0.9843, 0.9412, 0.2235, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0745, 0.8667, 0.9961, 0.6510, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0118, 0.7961, 0.9961, 0.8588, 0.1373, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.1490, 0.9961, 0.9961, 0.3020, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1216,\n",
      "           0.8784, 0.9961, 0.4510, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5216,\n",
      "           0.9961, 0.9961, 0.2039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2392, 0.9490,\n",
      "           0.9961, 0.9961, 0.2039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4745, 0.9961,\n",
      "           0.9961, 0.8588, 0.1569, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4745, 0.9961,\n",
      "           0.8118, 0.0706, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000]]]])})])}, 'software': {}, 'hardware': {'is_implicit': True}}\n",
      "\n",
      "call_module\n",
      "{'common': {'mase_type': 'module_related_func', 'mase_op': 'flatten', 'args': OrderedDict([('data_in_0', {'shape': [1, 1, 20, 20], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32], 'value': tensor([[[[0.0000, 0.0000, 0.3294, 0.7255, 0.6235, 0.5922, 0.2353, 0.1412,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.8706, 0.9961, 0.9961, 0.9961, 0.9961, 0.9451,\n",
      "           0.7765, 0.7765, 0.7765, 0.7765, 0.7765, 0.7765, 0.7765, 0.7765,\n",
      "           0.6667, 0.2039, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.2627, 0.4471, 0.2824, 0.4471, 0.6392, 0.8902,\n",
      "           0.9961, 0.8824, 0.9961, 0.9961, 0.9961, 0.9804, 0.8980, 0.9961,\n",
      "           0.9961, 0.5490, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0667,\n",
      "           0.2588, 0.0549, 0.2627, 0.2627, 0.2627, 0.2314, 0.0824, 0.9255,\n",
      "           0.9961, 0.4157, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3255, 0.9922,\n",
      "           0.8196, 0.0706, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0863, 0.9137, 1.0000,\n",
      "           0.3255, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5059, 0.9961, 0.9333,\n",
      "           0.1725, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000, 0.2314, 0.9765, 0.9961, 0.2431,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000, 0.5216, 0.9961, 0.7333, 0.0196,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0353, 0.8039, 0.9725, 0.2275, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.4941, 0.9961, 0.7137, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.2941, 0.9843, 0.9412, 0.2235, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0745, 0.8667, 0.9961, 0.6510, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0118, 0.7961, 0.9961, 0.8588, 0.1373, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.1490, 0.9961, 0.9961, 0.3020, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1216,\n",
      "           0.8784, 0.9961, 0.4510, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5216,\n",
      "           0.9961, 0.9961, 0.2039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2392, 0.9490,\n",
      "           0.9961, 0.9961, 0.2039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4745, 0.9961,\n",
      "           0.9961, 0.8588, 0.1569, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4745, 0.9961,\n",
      "           0.8118, 0.0706, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000]]]])})]), 'results': OrderedDict([('data_out_0', {'type': 'float', 'precision': [32], 'shape': [1, 400], 'torch_dtype': torch.float32, 'value': tensor([[0.0000, 0.0000, 0.3294, 0.7255, 0.6235, 0.5922, 0.2353, 0.1412, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.8706, 0.9961, 0.9961, 0.9961, 0.9961,\n",
      "         0.9451, 0.7765, 0.7765, 0.7765, 0.7765, 0.7765, 0.7765, 0.7765, 0.7765,\n",
      "         0.6667, 0.2039, 0.0000, 0.0000, 0.0000, 0.0000, 0.2627, 0.4471, 0.2824,\n",
      "         0.4471, 0.6392, 0.8902, 0.9961, 0.8824, 0.9961, 0.9961, 0.9961, 0.9804,\n",
      "         0.8980, 0.9961, 0.9961, 0.5490, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0667, 0.2588, 0.0549, 0.2627, 0.2627,\n",
      "         0.2627, 0.2314, 0.0824, 0.9255, 0.9961, 0.4157, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.3255, 0.9922, 0.8196, 0.0706, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0863, 0.9137, 1.0000, 0.3255,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5059, 0.9961,\n",
      "         0.9333, 0.1725, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2314,\n",
      "         0.9765, 0.9961, 0.2431, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.5216, 0.9961, 0.7333, 0.0196, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0353, 0.8039, 0.9725, 0.2275, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.4941, 0.9961, 0.7137, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2941, 0.9843, 0.9412, 0.2235,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0745, 0.8667, 0.9961,\n",
      "         0.6510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.7961,\n",
      "         0.9961, 0.8588, 0.1373, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.1490, 0.9961, 0.9961, 0.3020, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.1216, 0.8784, 0.9961, 0.4510, 0.0039, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.5216, 0.9961, 0.9961, 0.2039, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.2392, 0.9490, 0.9961, 0.9961, 0.2039,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4745, 0.9961, 0.9961,\n",
      "         0.8588, 0.1569, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4745,\n",
      "         0.9961, 0.8118, 0.0706, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000]])})])}, 'software': {}, 'hardware': {}}\n",
      "\n",
      "call_module\n",
      "{'common': {'mase_type': 'module_related_func', 'mase_op': 'user_defined_module', 'args': OrderedDict([('data_in_0', {'shape': [1, 400], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32], 'value': tensor([[0.0000, 0.0000, 0.3294, 0.7255, 0.6235, 0.5922, 0.2353, 0.1412, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.8706, 0.9961, 0.9961, 0.9961, 0.9961,\n",
      "         0.9451, 0.7765, 0.7765, 0.7765, 0.7765, 0.7765, 0.7765, 0.7765, 0.7765,\n",
      "         0.6667, 0.2039, 0.0000, 0.0000, 0.0000, 0.0000, 0.2627, 0.4471, 0.2824,\n",
      "         0.4471, 0.6392, 0.8902, 0.9961, 0.8824, 0.9961, 0.9961, 0.9961, 0.9804,\n",
      "         0.8980, 0.9961, 0.9961, 0.5490, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0667, 0.2588, 0.0549, 0.2627, 0.2627,\n",
      "         0.2627, 0.2314, 0.0824, 0.9255, 0.9961, 0.4157, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.3255, 0.9922, 0.8196, 0.0706, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0863, 0.9137, 1.0000, 0.3255,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5059, 0.9961,\n",
      "         0.9333, 0.1725, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2314,\n",
      "         0.9765, 0.9961, 0.2431, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.5216, 0.9961, 0.7333, 0.0196, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0353, 0.8039, 0.9725, 0.2275, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.4941, 0.9961, 0.7137, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2941, 0.9843, 0.9412, 0.2235,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0745, 0.8667, 0.9961,\n",
      "         0.6510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.7961,\n",
      "         0.9961, 0.8588, 0.1373, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.1490, 0.9961, 0.9961, 0.3020, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.1216, 0.8784, 0.9961, 0.4510, 0.0039, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.5216, 0.9961, 0.9961, 0.2039, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.2392, 0.9490, 0.9961, 0.9961, 0.2039,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4745, 0.9961, 0.9961,\n",
      "         0.8588, 0.1569, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4745,\n",
      "         0.9961, 0.8118, 0.0706, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000]])}), ('weights', {'type': 'float', 'precision': [32], 'shape': [8000, 16], 'from': None, 'value': Parameter containing:\n",
      "tensor([[-3.1171, -3.0228, -3.3257,  ..., -2.4036, -0.3832, -0.4898],\n",
      "        [-5.3392, -5.0056, -5.7966,  ..., -4.3592, -5.0173, -5.3013],\n",
      "        [-2.9236, -3.1242, -2.6519,  ..., -3.2646, -3.3187, -3.3288],\n",
      "        ...,\n",
      "        [-1.2249, 13.0285, -4.0221,  ..., -5.0735, -6.0271, -5.8215],\n",
      "        [-2.3252, -3.2661, -2.0738,  ..., -4.0397, -3.9529, -4.0368],\n",
      "        [-6.3166, -6.1052, -6.0224,  ..., -2.2150, -1.7534, 12.1391]],\n",
      "       requires_grad=True)}), ('indices', {'type': 'float', 'precision': [32], 'shape': [2, 8000], 'from': None, 'value': Parameter containing:\n",
      "tensor([[  8, 145,  76,  ..., 269, 376,  54],\n",
      "        [ 19, 153,  91,  ..., 272, 380,  57]])})]), 'results': OrderedDict([('data_out_0', {'type': 'float', 'precision': [32], 'shape': [1, 8000], 'torch_dtype': torch.float32, 'value': tensor([[1.0000e+00, 2.3530e-02, 1.0000e+00,  ..., 1.0927e-01, 4.1917e-08,\n",
      "         1.0000e+00]], grad_fn=<AddBackward0>)})])}, 'software': {}, 'hardware': {}}\n",
      "\n",
      "call_module\n",
      "{'common': {'mase_type': 'module_related_func', 'mase_op': 'user_defined_module', 'args': OrderedDict([('data_in_0', {'shape': [1, 8000], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32], 'value': tensor([[1.0000e+00, 2.3530e-02, 1.0000e+00,  ..., 1.0927e-01, 4.1917e-08,\n",
      "         1.0000e+00]], grad_fn=<AddBackward0>)}), ('weights', {'type': 'float', 'precision': [32], 'shape': [8000, 16], 'from': None, 'value': Parameter containing:\n",
      "tensor([[-3.3484, -4.3727, -3.8919,  ..., -3.4519, -3.4863, -4.0421],\n",
      "        [-8.1917, -7.9658, -3.8873,  ..., -8.1941, -5.2084, -4.7791],\n",
      "        [-5.4132, -6.2218, -0.0611,  ..., -6.0543, -2.0085, -5.1801],\n",
      "        ...,\n",
      "        [-7.6447, -4.5792, -7.5331,  ..., -3.7903, -7.5524, 11.4992],\n",
      "        [-3.2287, -3.4121, -2.6508,  ..., -5.2601, -4.1558, -3.4727],\n",
      "        [-3.7646, -4.8178, -2.7618,  ..., -4.7910, -2.0389,  4.1543]],\n",
      "       requires_grad=True)}), ('indices', {'type': 'float', 'precision': [32], 'shape': [2, 8000], 'from': None, 'value': Parameter containing:\n",
      "tensor([[7771, 4567, 6876,  ..., 6307, 4788, 5905],\n",
      "        [7772, 4568, 6877,  ..., 6308, 4789, 5906]])})]), 'results': OrderedDict([('data_out_0', {'type': 'float', 'precision': [32], 'shape': [1, 8000], 'torch_dtype': torch.float32, 'value': tensor([[2.4781e-07, 1.0000e+00, 2.3762e-07,  ..., 1.0000e+00, 3.9217e-03,\n",
      "         1.0000e+00]], grad_fn=<AddBackward0>)})])}, 'software': {}, 'hardware': {}}\n",
      "\n",
      "call_module\n",
      "{'common': {'mase_type': 'module_related_func', 'mase_op': 'user_defined_module', 'args': OrderedDict([('data_in_0', {'shape': [1, 8000], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32], 'value': tensor([[2.4781e-07, 1.0000e+00, 2.3762e-07,  ..., 1.0000e+00, 3.9217e-03,\n",
      "         1.0000e+00]], grad_fn=<AddBackward0>)}), ('weights', {'type': 'float', 'precision': [32], 'shape': [8000, 16], 'from': None, 'value': Parameter containing:\n",
      "tensor([[-2.9559, -5.8648,  4.9133,  ..., -5.2748,  3.5174, -5.4928],\n",
      "        [-3.5859, -2.8534, -3.8926,  ..., -3.8399, -4.0838, -1.5359],\n",
      "        [-2.8281, -4.6490, -4.7606,  ..., -4.0424, -3.7008, -4.5671],\n",
      "        ...,\n",
      "        [-0.3976,  0.9536, -1.0441,  ..., -0.5227, -1.5538,  5.8615],\n",
      "        [-5.9300, 12.6791, -6.7476,  ..., -3.0091, -6.9662, -5.1900],\n",
      "        [-2.7642, -1.2418, -1.8168,  ...,  0.2783,  0.7660,  5.8177]],\n",
      "       requires_grad=True)}), ('indices', {'type': 'float', 'precision': [32], 'shape': [2, 8000], 'from': None, 'value': Parameter containing:\n",
      "tensor([[6798, 1705, 5099,  ...,  595, 7900, 6221],\n",
      "        [6799, 1706, 5100,  ...,  596, 7901, 6222]])})]), 'results': OrderedDict([('data_out_0', {'type': 'float', 'precision': [32], 'shape': [1, 8000], 'torch_dtype': torch.float32, 'value': tensor([[1.6086e-07, 1.0000e+00, 1.0000e+00,  ..., 9.9247e-01, 2.4874e-07,\n",
      "         9.9381e-01]], grad_fn=<AddBackward0>)})])}, 'software': {}, 'hardware': {}}\n",
      "\n",
      "call_module\n",
      "{'common': {'mase_type': 'module_related_func', 'mase_op': 'user_defined_module', 'args': OrderedDict([('data_in_0', {'shape': [1, 8000], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32], 'value': tensor([[1.6086e-07, 1.0000e+00, 1.0000e+00,  ..., 9.9247e-01, 2.4874e-07,\n",
      "         9.9381e-01]], grad_fn=<AddBackward0>)}), ('weights', {'type': 'float', 'precision': [32], 'shape': [8000, 16], 'from': None, 'value': Parameter containing:\n",
      "tensor([[-4.2207, -4.8978, -3.5935,  ..., -3.7076, -2.0687,  5.0622],\n",
      "        [-4.5036, -5.5177, -5.6961,  ..., -2.7672, -1.6542, -2.8073],\n",
      "        [-5.0884, -5.9399, 12.0650,  ..., -5.9322, -4.4320, -5.3952],\n",
      "        ...,\n",
      "        [-3.7124, -4.1993, -6.0419,  ..., -1.9481, -3.8145, -4.7949],\n",
      "        [-1.0743, 14.4899, -2.7117,  ..., -4.2354, -4.6452, -4.2918],\n",
      "        [-3.7054, -3.0638, -3.1783,  ..., -3.2507, -2.6559, -2.4995]],\n",
      "       requires_grad=True)}), ('indices', {'type': 'float', 'precision': [32], 'shape': [2, 8000], 'from': None, 'value': Parameter containing:\n",
      "tensor([[6021, 6132, 6080,  ..., 7862, 7768, 1510],\n",
      "        [6022, 6133, 6081,  ..., 7863, 7769, 1511]])})]), 'results': OrderedDict([('data_out_0', {'type': 'float', 'precision': [32], 'shape': [1, 8000], 'torch_dtype': torch.float32, 'value': tensor([[8.2823e-01, 3.8517e-07, 4.4610e-02,  ..., 1.9423e-07, 1.2123e-02,\n",
      "         1.0000e+00]], grad_fn=<AddBackward0>)})])}, 'software': {}, 'hardware': {}}\n",
      "\n",
      "call_module\n",
      "{'common': {'mase_type': 'module_related_func', 'mase_op': 'user_defined_module', 'args': OrderedDict([('data_in_0', {'shape': [1, 8000], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32], 'value': tensor([[8.2823e-01, 3.8517e-07, 4.4610e-02,  ..., 1.9423e-07, 1.2123e-02,\n",
      "         1.0000e+00]], grad_fn=<AddBackward0>)}), ('weights', {'type': 'float', 'precision': [32], 'shape': [8000, 16], 'from': None, 'value': Parameter containing:\n",
      "tensor([[-4.6793, -4.8016, -4.5116,  ..., -3.1392, 13.1280, -2.9549],\n",
      "        [-3.2912, -3.2494, -3.7484,  ..., -1.9863, -2.1471, -2.6962],\n",
      "        [-4.9414, -5.5866, -6.6235,  ..., -0.5015, -5.5865, -5.1621],\n",
      "        ...,\n",
      "        [-3.0373,  7.4275, -5.6730,  ...,  5.3574, -4.3527, -4.7096],\n",
      "        [-3.5802, -3.0010, -3.3361,  ..., -4.8798, -5.5294, -4.9313],\n",
      "        [-1.7191, -5.6455, -2.9785,  ..., -4.1012, -1.1445, -4.8380]],\n",
      "       requires_grad=True)}), ('indices', {'type': 'float', 'precision': [32], 'shape': [2, 8000], 'from': None, 'value': Parameter containing:\n",
      "tensor([[5269, 4675, 1933,  ..., 1589, 3609, 1801],\n",
      "        [5270, 4676, 1934,  ..., 1590, 3610, 1802]])})]), 'results': OrderedDict([('data_out_0', {'type': 'float', 'precision': [32], 'shape': [1, 8000], 'torch_dtype': torch.float32, 'value': tensor([[9.1474e-01, 2.3438e-01, 5.0548e-07,  ..., 9.9720e-01, 1.7968e-06,\n",
      "         2.7561e-07]], grad_fn=<AddBackward0>)})])}, 'software': {}, 'hardware': {}}\n",
      "\n",
      "call_module\n",
      "{'common': {'mase_type': 'module_related_func', 'mase_op': 'user_defined_module', 'args': OrderedDict([('data_in_0', {'shape': [1, 8000], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32], 'value': tensor([[9.1474e-01, 2.3438e-01, 5.0548e-07,  ..., 9.9720e-01, 1.7968e-06,\n",
      "         2.7561e-07]], grad_fn=<AddBackward0>)}), ('weights', {'type': 'float', 'precision': [32], 'shape': [8000, 16], 'from': None, 'value': Parameter containing:\n",
      "tensor([[-2.6517, -0.9771, -3.4216,  ..., 14.3585, -3.4072, -2.6257],\n",
      "        [-4.5017, -5.5763, -5.6709,  ..., -2.6726, -4.4260, -5.0620],\n",
      "        [-2.1000, -3.4716, -1.2227,  ..., -3.1664, -2.4870, -2.1072],\n",
      "        ...,\n",
      "        [-3.1227, -4.2357, -2.4135,  ..., -4.7770, -1.6430, -3.6907],\n",
      "        [-6.2442, -6.0625, -6.7701,  ...,  0.4717, -6.0448, -5.5861],\n",
      "        [-4.5820, -4.5861, -4.1926,  ..., -5.6028, -5.1093, -4.7523]],\n",
      "       requires_grad=True)}), ('indices', {'type': 'float', 'precision': [32], 'shape': [2, 8000], 'from': None, 'value': Parameter containing:\n",
      "tensor([[3970, 3119, 6604,  ..., 1388, 7729, 3811],\n",
      "        [3971, 3120, 6605,  ..., 1389, 7730, 3812]])})]), 'results': OrderedDict([('data_out_0', {'type': 'float', 'precision': [32], 'shape': [1, 8000], 'torch_dtype': torch.float32, 'value': tensor([[7.8085e-01, 1.7678e-04, 1.0000e+00,  ..., 5.3135e-01, 1.8911e-03,\n",
      "         2.5397e-03]], grad_fn=<AddBackward0>)})])}, 'software': {}, 'hardware': {}}\n",
      "\n",
      "call_module\n",
      "{'common': {'mase_type': 'module_related_func', 'mase_op': 'user_defined_module', 'args': OrderedDict([('data_in_0', {'shape': [1, 8000], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32], 'value': tensor([[7.8085e-01, 1.7678e-04, 1.0000e+00,  ..., 5.3135e-01, 1.8911e-03,\n",
      "         2.5397e-03]], grad_fn=<AddBackward0>)}), ('k', {'type': 'float', 'precision': [32], 'shape': [1], 'from': None, 'value': Parameter containing:\n",
      "tensor(10)}), ('tau', {'type': 'float', 'precision': [32], 'shape': [1], 'from': None, 'value': Parameter containing:\n",
      "tensor(20)})]), 'results': OrderedDict([('data_out_0', {'type': 'float', 'precision': [32], 'shape': [1, 10], 'torch_dtype': torch.float32, 'value': tensor([[17.6272, 18.1400, 20.4036, 20.2401, 16.6199, 17.1533, 14.5829, 25.3482,\n",
      "         18.3927, 17.6782]], grad_fn=<DivBackward0>)})])}, 'software': {}, 'hardware': {}}\n",
      "\n",
      "output\n",
      "{'common': {'mase_type': 'output', 'mase_op': 'output', 'args': {}, 'results': OrderedDict([('data_out_0', {'type': 'float', 'precision': [32], 'shape': [1, 10], 'torch_dtype': torch.float32, 'value': tensor([[17.6272, 18.1400, 20.4036, 20.2401, 16.6199, 17.1533, 14.5829, 25.3482,\n",
      "         18.3927, 17.6782]], grad_fn=<DivBackward0>)})])}, 'software': {}, 'hardware': {'is_implicit': True}}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<chop.ir.graph.mase_graph.MaseGraph at 0x149a5192d8d0>, None)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import chop.passes as passes\n",
    "\n",
    "dummy_in_loader = torch.utils.data.DataLoader(test_set, batch_size=1, shuffle=False, pin_memory=True, drop_last=True)\n",
    "image, label = next(iter(dummy_in_loader))\n",
    "# image = image.cpu().squeeze(0) \n",
    "\n",
    "mg_test, _ = passes.init_metadata_analysis_pass(mg)\n",
    "mg_test, _ = passes.add_common_metadata_analysis_pass(\n",
    "    mg_test,\n",
    "    pass_args={\n",
    "        \"dummy_in\": {\"input_1\": image}, #input name Hardcoded here, change\n",
    "#         \"add_value\": False,\n",
    "    },\n",
    ")\n",
    "\n",
    "# There is error below, need to fix\n",
    "# mg_test, _ = passes.add_hardware_metadata_analysis_pass(mg_test)\n",
    "\n",
    "\n",
    "mg_test.draw(\"DLG_test.svg\")\n",
    "\n",
    "\n",
    "# below pass just prints out the metadata for us to debug\n",
    "test_pass(mg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adls-project",
   "language": "python",
   "name": "adls-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
