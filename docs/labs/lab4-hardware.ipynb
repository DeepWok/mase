{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />\n",
    "<div align=\"center\">\n",
    "  <a href=\"https://deepwok.github.io/\">\n",
    "    <img src=\"../imgs/deepwok.png\" alt=\"Logo\" width=\"160\" height=\"160\">\n",
    "  </a>\n",
    "\n",
    "  <h1 align=\"center\">Lab 4 for Advanced Deep Learning Systems (ADLS) - Hardware Stream</h1>\n",
    "\n",
    "  <p align=\"center\">\n",
    "    ELEC70109/EE9-AML3-10/EE9-AO25\n",
    "    <br />\n",
    "\t\tWritten by\n",
    "    <a href=\"https://aaron-zhao123.github.io/\">Aaron Zhao, Pedro Gimenes </a>\n",
    "  </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General introduction\n",
    "\n",
    "In this lab, you will learn how to emit SystemVerilog code for a neural network that's been transformed and optimized by MASE. Then, you'll design some hardware for a new Pytorch layer, and simulate the hardware using your new module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Hardware Emit pass\n",
    "\n",
    "The `emit_verilog` transform pass generates a top-level RTL file and testbench file according to the `MaseGraph`, which includes a hardware implementation of each layer in the network. This top-level file instantiates modules from the `components` library in MASE and/or modules generated using [HLS](https://en.wikipedia.org/wiki/High-level_synthesis), when internal components are not available. The hardware can then be simulated using [Verilator](https://www.veripool.org/verilator/), or deployed on an FPGA.\n",
    "\n",
    "First, add Machop to your system PATH (if you haven't already done so) and import the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pg519/anaconda3/envs/mase/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mSet logging level to debug\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/bin /Users/pg519/mase-tools-cli/machop /Users/pg519/anaconda3/envs/mase/bin /Users/pg519/anaconda3/condabin /opt/homebrew/bin /usr/local/bin /System/Cryptexes/App/usr/bin /usr/bin /bin /usr/sbin /sbin /var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/local/bin /var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/bin /var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/appleinternal/bin /opt/X11/bin /Library/TeX/texbin\n",
      "Usage:\n",
      "        verilator --help\n",
      "        verilator --version\n",
      "        verilator --binary -j 0 [options] [source_files.v]... [opt_c_files.cpp/c/cc/a/o/so]\n",
      "        verilator --cc [options] [source_files.v]... [opt_c_files.cpp/c/cc/a/o/so]\n",
      "        verilator --sc [options] [source_files.v]... [opt_c_files.cpp/c/cc/a/o/so]\n",
      "        verilator --lint-only -Wall [source_files.v]...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "from chop.ir.graph.mase_graph import MaseGraph\n",
    "\n",
    "from chop.passes.graph.analysis import (\n",
    "    init_metadata_analysis_pass,\n",
    "    add_common_metadata_analysis_pass,\n",
    "    add_hardware_metadata_analysis_pass,\n",
    "    report_node_type_analysis_pass,\n",
    ")\n",
    "\n",
    "from chop.passes.graph.transforms import (\n",
    "    emit_verilog_top_transform_pass,\n",
    "    emit_internal_rtl_transform_pass,\n",
    "    emit_bram_transform_pass,\n",
    "    emit_cocotb_transform_pass,\n",
    "    quantize_transform_pass,\n",
    ")\n",
    "\n",
    "from chop.tools.logger import set_logging_verbosity\n",
    "\n",
    "set_logging_verbosity(\"debug\")\n",
    "\n",
    "import toml\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# TO DO: remove\n",
    "import os\n",
    "os.environ[\"PATH\"] = \"/opt/homebrew/bin:\" + os.environ[\"PATH\"]\n",
    "!echo $PATH\n",
    "!verilator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, define the neural network. We're using a model which can be used to perform digit classification on the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Toy FC model for digit recognition on MNIST\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(4, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, start_dim=1, end_dim=-1)\n",
    "        x = torch.nn.functional.relu(self.fc1(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll generate a MaseGraph and add metadata. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pg519/anaconda3/envs/mase/lib/python3.10/site-packages/torch/overrides.py:110: UserWarning: 'has_cuda' is deprecated, please use 'torch.backends.cuda.is_built()'\n",
      "  torch.has_cuda,\n",
      "/Users/pg519/anaconda3/envs/mase/lib/python3.10/site-packages/torch/overrides.py:111: UserWarning: 'has_cudnn' is deprecated, please use 'torch.backends.cudnn.is_available()'\n",
      "  torch.has_cudnn,\n",
      "/Users/pg519/anaconda3/envs/mase/lib/python3.10/site-packages/torch/overrides.py:117: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  torch.has_mps,\n",
      "/Users/pg519/anaconda3/envs/mase/lib/python3.10/site-packages/torch/overrides.py:118: UserWarning: 'has_mkldnn' is deprecated, please use 'torch.backends.mkldnn.is_available()'\n",
      "  torch.has_mkldnn,\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[34mgraph():\n",
      "    %x : [num_users=1] = placeholder[target=x]\n",
      "    %flatten : [num_users=1] = call_function[target=torch.flatten](args = (%x,), kwargs = {start_dim: 1, end_dim: -1})\n",
      "    %fc1 : [num_users=1] = call_module[target=fc1](args = (%flatten,), kwargs = {})\n",
      "    %relu : [num_users=1] = call_function[target=torch.nn.functional.relu](args = (%fc1,), kwargs = {inplace: False})\n",
      "    return relu\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node name: fc1, arg: data_in_0, arg_info: {'shape': [1, 4], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]}\n",
      "node name: fc1, arg: weight, arg_info: {'type': 'float', 'precision': [32], 'shape': [10, 4], 'from': None}\n",
      "node name: fc1, arg: bias, arg_info: {'type': 'float', 'precision': [32], 'shape': [10], 'from': None}\n",
      "node name: relu, arg: data_in_0, arg_info: {'shape': [1, 10], 'torch_dtype': torch.float32, 'type': 'float', 'precision': [32]}\n"
     ]
    }
   ],
   "source": [
    "mlp = MLP()\n",
    "mg = MaseGraph(model=mlp)\n",
    "\n",
    "# Provide a dummy input for the graph so it can use for tracing\n",
    "batch_size = 1\n",
    "x = torch.randn((batch_size, 2, 2))\n",
    "dummy_in = {\"x\": x}\n",
    "\n",
    "mg, _ = init_metadata_analysis_pass(mg, None)\n",
    "mg, _ = add_common_metadata_analysis_pass(\n",
    "    mg, {\"dummy_in\": dummy_in, \"add_value\": False}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running `emit_verilog`, we'll quantize the model to fixed precision. Refer back to [lab 2](https://github.com/DeepWok/mase/blob/main/docs/labs/lab2.md) if you've forgotten how this works. Check that the data type for each node is correct after quantization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mInspecting graph [add_common_node_type_analysis_pass]\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Node name    Fx Node op     Mase type            Mase op      Value type\n",
      "-----------  -------------  -------------------  -----------  ------------\n",
      "x            placeholder    placeholder          placeholder  NA\n",
      "flatten      call_function  implicit_func        flatten      float\n",
      "fc1          call_module    module_related_func  linear       fixed\n",
      "relu         call_function  module_related_func  relu         fixed\n",
      "output       output         output               output       NA\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "config_file = os.path.join(\n",
    "    os.path.abspath(\"\"),\n",
    "    \"..\",\n",
    "    \"..\",\n",
    "    \"machop\",\n",
    "    \"configs\",\n",
    "    \"tests\",\n",
    "    \"quantize\",\n",
    "    \"fixed.toml\",\n",
    ")\n",
    "with open(config_file, \"r\") as f:\n",
    "    quan_args = toml.load(f)[\"passes\"][\"quantize\"]\n",
    "mg, _ = quantize_transform_pass(mg, quan_args)\n",
    "\n",
    "_ = report_node_type_analysis_pass(mg)\n",
    "\n",
    "# Update the metadata\n",
    "for node in mg.fx_graph.nodes:\n",
    "    for arg, arg_info in node.meta[\"mase\"].parameters[\"common\"][\"args\"].items():\n",
    "        if isinstance(arg_info, dict):\n",
    "            arg_info[\"type\"] = \"fixed\"\n",
    "            arg_info[\"precision\"] = [8, 3]\n",
    "    for result, result_info in (\n",
    "        node.meta[\"mase\"].parameters[\"common\"][\"results\"].items()\n",
    "    ):\n",
    "        if isinstance(result_info, dict):\n",
    "            result_info[\"type\"] = \"fixed\"\n",
    "            result_info[\"precision\"] = [8, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, it's important to run the `add_hardware_metadata` analysis pass. This adds all the required metadata which is later used by the `emit_verilog` pass, including:\n",
    "\n",
    "1. The node's toolchain, which defines whether we use internal Verilog modules from the `components` library or the HLS flow.\n",
    "2. The Verilog parameters associated with each node.\n",
    "\n",
    "> **_TASK:_** Read [this page](https://jianyicheng.github.io/mase-tools/modules/analysis/add_metadata.html#add-hardware-metadata-analysis-pass) for more information on the hardware metadata pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg, _ = add_hardware_metadata_analysis_pass(mg, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, run the emit verilog pass to generate the SystemVerilog files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mEmitting Verilog...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mEmitting internal components...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "mg, _ = emit_verilog_top_transform_pass(mg)\n",
    "mg, _ = emit_internal_rtl_transform_pass(mg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generated files should now be found under `top/hardware`. \n",
    "\n",
    "> **_TASK:_** Read through `top/hardware/rtl/top.sv` and make sure you understand how our MLP model maps to this hardware design. \n",
    "\n",
    "You will notice the following instantiated modules:\n",
    "\n",
    "* `fixed_linear`: this is found under `components/linear/fixed_linear.sv` and implements each Linear layer in the model.\n",
    "* `fc<layer number>_weight/bias_source`: these are [BRAM](https://nandland.com/lesson-15-what-is-a-block-ram-bram/) memories which drive the weights and biases into the linear layers for computation.\n",
    "* `fixed_relu`: found under `components/activations/fixed_relu.sv`, implements the ReLU activation.\n",
    "\n",
    "As of now, we can't yet run a simulation on the model, as we haven't yet generated the memory components. To do this, run the `emit_bram` transform pass as follows, which will generate the memory initialization files and SystemVerilog modules to drive weights and biases into the linear layers. Finally, the `emit_verilog_tb` transform pass will generate the testbench files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mEmitting BRAM...\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[34mEmitting DAT file for node: fc1, parameter: weight\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[34mROM module weight successfully written into top/hardware/rtl/fc1_weight_source.sv\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[34mInit data weight successfully written into top/hardware/rtl/fc1_weight_rom.dat\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[34mEmitting DAT file for node: fc1, parameter: bias\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[34mROM module bias successfully written into top/hardware/rtl/fc1_bias_source.sv\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[34mInit data bias successfully written into top/hardware/rtl/fc1_bias_rom.dat\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "mg, _ = emit_bram_transform_pass(mg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mEmitting test bench...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project_dir top\n"
     ]
    }
   ],
   "source": [
    "mg, _ = emit_cocotb_transform_pass(mg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Running command /Users/pg519/mase-tools-emit-verilog-test/docs/labs/sim_build/top in directory /Users/pg519/mase-tools-emit-verilog-test/docs/labs/sim_build\n",
      "     -.--ns INFO     gpi                                ..mbed/gpi_embed.cpp:78   in set_program_name_in_venv        Did not detect Python virtual environment. Using system-wide Python interpreter\n",
      "     -.--ns INFO     gpi                                ../gpi/GpiCommon.cpp:101  in gpi_print_registered_impl       VPI registered\n",
      "     0.00ns INFO     cocotb                             Running on Verilator version 5.018 2023-10-30\n",
      "     0.00ns INFO     cocotb                             Running tests with cocotb v1.8.0 from /Users/pg519/anaconda3/envs/mase/lib/python3.10/site-packages/cocotb\n",
      "     0.00ns INFO     cocotb                             Seeding Python random module with 1705938214\n",
      "     0.00ns INFO     cocotb.regression                  Found test top_tb.test\n",
      "     0.00ns INFO     cocotb.regression                  running test (1/1)\n",
      "Running test for top\n",
      "%Warning: top/hardware/rtl/fc1_weight_rom.dat:0: $readmem file not found\n",
      "%Warning: top/hardware/rtl/fc1_bias_rom.dat:0: $readmem file not found\n",
      "    40.00ns INFO     cocotb.regression                  test failed\n",
      "                                                        Traceback (most recent call last):\n",
      "                                                          File \"/Users/pg519/mase-tools-emit-verilog-test/docs/labs/top_tb.py\", line 53, in test\n",
      "                                                            tb.output_monitor.ready.value = 1\n",
      "                                                        AttributeError: 'ModelTB' object has no attribute 'output_monitor'\n",
      "    40.00ns INFO     cocotb.regression                  **************************************************************************************\n",
      "                                                        ** TEST                          STATUS  SIM TIME (ns)  REAL TIME (s)  RATIO (ns/s) **\n",
      "                                                        **************************************************************************************\n",
      "                                                        ** top_tb.test                    FAIL          40.00           0.00      37567.48  **\n",
      "                                                        **************************************************************************************\n",
      "                                                        ** TESTS=1 PASS=0 FAIL=1 SKIP=0                 40.00           7.18          5.57  **\n",
      "                                                        **************************************************************************************\n",
      "                                                        \n",
      "- :0: Verilog $finish\n",
      "INFO: Results file: /Users/pg519/mase-tools-emit-verilog-test/docs/labs/sim_build/results.xml\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'is_file'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 47\u001b[0m\n\u001b[1;32m     43\u001b[0m     num_tests, fail \u001b[38;5;241m=\u001b[39m get_results(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuild/results.xml\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m num_tests, fail\n\u001b[0;32m---> 47\u001b[0m \u001b[43mrun_tb_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmg\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[17], line 43\u001b[0m, in \u001b[0;36mrun_tb_action\u001b[0;34m(mg)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# runner.build(\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#     verilog_sources=sources,\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#     includes=[\"top/hardware/rtl\", \"top/hardware/test\"],\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m#     parameters=[],  # use default parameters,\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[1;32m     42\u001b[0m runner\u001b[38;5;241m.\u001b[39mtest(hdl_toplevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop\u001b[39m\u001b[38;5;124m\"\u001b[39m, test_module\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_tb\u001b[39m\u001b[38;5;124m\"\u001b[39m, hdl_toplevel_lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mverilog\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 43\u001b[0m num_tests, fail \u001b[38;5;241m=\u001b[39m \u001b[43mget_results\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbuild/results.xml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m num_tests, fail\n",
      "File \u001b[0;32m~/anaconda3/envs/mase/lib/python3.10/site-packages/cocotb/runner.py:379\u001b[0m, in \u001b[0;36mget_results\u001b[0;34m(results_xml_file)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return number of tests and fails in *results_xml_file*.\u001b[39;00m\n\u001b[1;32m    369\u001b[0m \n\u001b[1;32m    370\u001b[0m \u001b[38;5;124;03mReturns:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;124;03m    SystemExit: *results_xml_file* is non-existent.\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    377\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# Hide the traceback when using PyTest.\u001b[39;00m\n\u001b[0;32m--> 379\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mresults_xml_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_file\u001b[49m():\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mSystemExit\u001b[39;00m(\n\u001b[1;32m    381\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mERROR: Simulation terminated abnormally. Results file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults_xml_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    382\u001b[0m     )\n\u001b[1;32m    384\u001b[0m num_tests \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'is_file'"
     ]
    }
   ],
   "source": [
    "from chop.actions import simulate\n",
    "\n",
    "simulate(skip_build=False, skip_test=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **_TASK:_** Launch a simulation as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !chmod +x top/hardware/sim/build.sh\n",
    "# !top/hardware/sim/build.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extension Task\n",
    "\n",
    "Pytorch has a number of layers which are available to users to define neural network models. At the moment, `emit_verilog` supports generating Verilog for models including Linear layers and the ReLU activation.\n",
    "\n",
    "> **_EXTENSION TASK:_** choose another layer type from the [Pytorch list](https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity) and write a SystemVerilog file to implement that layer in hardware. Then, change the generated `top.sv` file to inject that layer within the design. For example, you may replace the ReLU activations with [Leaky ReLU](https://pytorch.org/docs/stable/generated/torch.nn.RReLU.html#torch.nn.RReLU). Re-build the simulation and observe the effect on latency and accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
