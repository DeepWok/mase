{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 5: Searching for Optimal Transformer Architectures for Sequence Classification (NAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRIALS = 10\n",
    "TRIAL_CONCURRENCY = 3\n",
    "EPOCHS_PER_TRIAL = 5\n",
    "NUM_LATENCY_EVALUATION_ITERATIONS = 10\n",
    "\n",
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer_checkpoint = \"bert-base-uncased\"\n",
    "dataset_name = \"imdb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.bert.configuration_bert import BertConfig\n",
    "from chop.actions.search.search_space import NasBertSpace\n",
    "\n",
    "cf = BertConfig.from_pretrained(checkpoint)\n",
    "cf._attn_implementation = \"eager\"\n",
    "\n",
    "# Full model parameters\n",
    "cf.num_hidden_layers = 3\n",
    "cf.space_hidden_size = [128, 256, 512, 768, 1024]\n",
    "\n",
    "# Per layer\n",
    "cf.space_self_attention_implementation = [\"attention\", \"linear\", \"feedthrough\"]\n",
    "cf.space_self_attention_layer_norm = [\"layer_norm\", \"identity\"]\n",
    "cf.space_output_layer_norm = [\"layer_norm\", \"identity\"]\n",
    "cf.space_intermediate_size = [192, 384, 768, 1536, 3072]\n",
    "cf.space_num_attention_heads = [2, 4, 8, 16]\n",
    "\n",
    "space = NasBertSpace(cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nni\n",
    "from chop.tools import get_tokenized_dataset, get_trainer\n",
    "\n",
    "dataset, tokenizer = get_tokenized_dataset(\n",
    "    dataset=dataset_name,\n",
    "    checkpoint=tokenizer_checkpoint,\n",
    "    return_tokenizer=True,\n",
    ")\n",
    "\n",
    "\n",
    "def fit(model):\n",
    "    trainer = get_trainer(\n",
    "        model=model,\n",
    "        checkpoint=checkpoint,\n",
    "        tokenized_dataset=dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        evaluate_metric=\"accuracy\",\n",
    "    )\n",
    "\n",
    "    # Train the model for 1 epoch\n",
    "    trainer.train()\n",
    "\n",
    "    # Evaluate accuracy\n",
    "    eval_results = trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nni.nas.evaluator import FunctionalEvaluator\n",
    "\n",
    "evaluator = FunctionalEvaluator(fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nni.nas.strategy as strategy\n",
    "\n",
    "strat = strategy.TPE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nni.nas.experiment import NasExperimentConfig\n",
    "\n",
    "experiment_config = NasExperimentConfig.default(space, evaluator, strat)\n",
    "experiment_config.max_trial_number = NUM_TRIALS  # spawn 3 trials at most\n",
    "experiment_config.trial_concurrency = TRIAL_CONCURRENCY  # will run 1 trial concurrently\n",
    "experiment_config.trial_gpu_number = 1  # use 1 GPU for each trial\n",
    "experiment_config.training_service.use_active_gpu = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "\n",
    "\n",
    "def find_free_port():\n",
    "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
    "        s.bind((\"\", 0))\n",
    "        return s.getsockname()[1]\n",
    "\n",
    "\n",
    "free_port = find_free_port()\n",
    "\n",
    "print(free_port)\n",
    "\n",
    "from nni.nas.experiment import NasExperiment\n",
    "\n",
    "experiment = NasExperiment(space, evaluator, strat, config=experiment_config)\n",
    "experiment.start(port=free_port)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
