{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 5: Neural Architecture Search (NAS) with Mase and Optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we'll see how Mase can be integrated with Optuna, the popular hyperparameter optimization framework, to search for a Bert model optimized for sequence classification on the IMDb dataset. We'll take the Optuna-generated model and import it into Mase, then run the CompressionPipeline to prepare the model for edge deployment by quantizing and pruning its weights.\n",
    "\n",
    "As we'll see, running Architecture Search with Mase/Optuna involves the following steps.\n",
    "\n",
    "1. **Define the search space**: this is a dictionary containing the range of values for each parameter at each layer in the model.\n",
    "\n",
    "2. **Write the model constructor**: this is a function which uses Optuna utilities to sample a model from the search space, and constructs the model using transformers from_config class method.\n",
    "\n",
    "3. **Write the objective function**: this function calls on the model constructor defined in Step 2 and defines the training/evaluation setup for each search iteration.\n",
    "\n",
    "4. **Go!** Choose an Optuna sampler, create a study and launch the search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"prajjwal1/bert-tiny\"\n",
    "tokenizer_checkpoint = \"bert-base-uncased\"\n",
    "dataset_name = \"imdb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, fetch the dataset using the `get_tokenized_dataset` utility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/blou/Documents/IC/mase/mase_latest/.venv/lib/python3.11/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "/Users/blou/Documents/IC/mase/mase_latest/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTokenizing dataset imdb with AutoTokenizer for bert-base-uncased.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from chop.tools import get_tokenized_dataset\n",
    "\n",
    "dataset, tokenizer = get_tokenized_dataset(\n",
    "    dataset=dataset_name,\n",
    "    checkpoint=tokenizer_checkpoint,\n",
    "    return_tokenizer=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Defining the Search Space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by defining a search space, i.e. enumerating the possible combinations of hyperparameters that Optuna can choose during search. We'll explore the following range of values for the model's hidden size, intermediate size, number of layers and number of heads, inspired by the [NAS-BERT paper](https://arxiv.org/abs/2105.14444)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from chop.nn.modules import Identity\n",
    "\n",
    "search_space = {\n",
    "    \"num_layers\": [2, 4, 8],\n",
    "    \"num_heads\": [2, 4, 8, 16],\n",
    "    \"hidden_size\": [128, 192, 256, 384, 512],\n",
    "    \"intermediate_size\": [512, 768, 1024, 1536, 2048],\n",
    "    \"linear_layer_choices\": [\n",
    "        nn.Linear,\n",
    "        Identity,\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Writing a Model Constructor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the following function, which will get called in each iteration of the search process. The function is passed the `trial` argument, which is an Optuna object that comes with many functionalities - see the [Trial documentation](https://optuna.readthedocs.io/en/stable/reference/trial.html) for more details. Here, we use the `trial.suggest_int` and `trial.suggest_categorical` functions to trigger the chosen sampler to choose parameter choices and layer types. The suggested integer is the index into the search space for each parameter, which we defined in the previous cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig, AutoModelForSequenceClassification\n",
    "from chop.tools.utils import deepsetattr\n",
    "\n",
    "\n",
    "def construct_model(trial):\n",
    "    config = AutoConfig.from_pretrained(checkpoint)\n",
    "\n",
    "    # Update the paramaters in the config\n",
    "    for param in [\n",
    "        \"num_layers\",\n",
    "        \"num_heads\",\n",
    "        \"hidden_size\",\n",
    "        \"intermediate_size\",\n",
    "    ]:\n",
    "        chosen_idx = trial.suggest_int(param, 0, len(search_space[param]) - 1)\n",
    "        setattr(config, param, search_space[param][chosen_idx])\n",
    "\n",
    "    trial_model = AutoModelForSequenceClassification.from_config(config)\n",
    "\n",
    "    for name, layer in trial_model.named_modules():\n",
    "        if isinstance(layer, nn.Linear) and layer.in_features == layer.out_features:\n",
    "            new_layer_cls = trial.suggest_categorical(\n",
    "                f\"{name}_type\",\n",
    "                search_space[\"linear_layer_choices\"],\n",
    "            )\n",
    "\n",
    "            if new_layer_cls == nn.Linear:\n",
    "                continue\n",
    "            elif new_layer_cls == Identity:\n",
    "                new_layer = Identity()\n",
    "                deepsetattr(trial_model, name, new_layer)\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown layer type: {new_layer_cls}\")\n",
    "\n",
    "    return trial_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Defining the Objective Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define the objective function for the search, which gets called on each trial. In each trial, we create a new model instace with chosen hyperparameters according to the defined sampler. We then use the `get_trainer` utility in Mase to run a training loop on the IMDb dataset for a number of epochs. Finally, we use `evaluate` to report back the classification accuracy on the test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chop.tools import get_trainer\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    # Define the model\n",
    "    model = construct_model(trial)\n",
    "\n",
    "    trainer = get_trainer(\n",
    "        model=model,\n",
    "        tokenized_dataset=dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        evaluate_metric=\"accuracy\",\n",
    "        num_train_epochs=1,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    eval_results = trainer.evaluate()\n",
    "\n",
    "    # Set the model as an attribute so we can fetch it later\n",
    "    trial.set_user_attr(\"model\", model)\n",
    "\n",
    "    return eval_results[\"eval_accuracy\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Launching the Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optuna provides a number of samplers, for example:\n",
    "\n",
    "* **GridSampler**: iterates through every possible combination of hyperparameters in the search space\n",
    "* **RandomSampler**: chooses a random combination of hyperparameters in each iteration\n",
    "* **TPESampler**: uses Tree-structured Parzen Estimator algorithm to choose hyperparameter values.\n",
    "\n",
    "You can define the chosen sampler by simply importing from `optuna.samplers` as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.samplers import GridSampler, RandomSampler, TPESampler\n",
    "\n",
    "sampler = RandomSampler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all the pieces in place, we can launch the search as follows. The number of trials is set to 1 so you can go get a coffee for 10 minutes, then proceed with the tutorial. However, this will essentially be a random model - for better results, set this to 100 and leave it running overnight!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-14 20:36:39,894] A new study created in memory with name: bert-tiny-nas-study\n",
      "/Users/blou/Documents/IC/mase/mase_latest/.venv/lib/python3.11/site-packages/optuna/distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.nn.modules.linear.Linear'> which is of type type.\n",
      "  warnings.warn(message)\n",
      "/Users/blou/Documents/IC/mase/mase_latest/.venv/lib/python3.11/site-packages/optuna/distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'chop.nn.modules.identity.Identity'> which is of type type.\n",
      "  warnings.warn(message)\n",
      "/Users/blou/Documents/IC/mase/mase_latest/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1437' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1437/3125 01:21 < 01:35, 17.60 it/s, Epoch 0.46/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.692300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.626900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=\"bert-tiny-nas-study\",\n",
    "    sampler=sampler,\n",
    ")\n",
    "\n",
    "study.optimize(\n",
    "    objective,\n",
    "    n_trials=1,\n",
    "    timeout=60 * 60 * 24,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch the model associated with the best trial as follows, and export to be used in future tutorials. In Tutorial 6, we'll see how to run mixed-precision quantization search on top of the model we've just found through NAS to further find the optimal quantization mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import dill\n",
    "\n",
    "model = study.best_trial.user_attrs[\"model\"].cpu()\n",
    "\n",
    "with open(f\"{Path.home()}/tutorial_5_best_model.pkl\", \"wb\") as f:\n",
    "    dill.dump(model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying the Optimized Model with CompressionPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can run the CompressionPipeline in Mase to run uniform quantization and pruning over the searched model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`past_key_values` were not specified as input names, but model.config.use_cache = True. Setting model.config.use_cache = False.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mGetting dummy input for prajjwal1/bert-tiny.\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: classifier\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "tensor([[[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]])\n",
      "tensor([[[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]])\n",
      "tensor([[[-0.1047,  1.3223, -0.1421,  ..., -0.8481, -1.3715,  1.5195],\n",
      "         [-1.8460, -1.2518,  2.7948,  ..., -0.9918, -1.1175,  0.8962],\n",
      "         [-0.5514, -0.5617, -0.1957,  ..., -0.7488, -0.6441,  0.3547],\n",
      "         ...,\n",
      "         [-0.3019, -0.1135, -1.1225,  ..., -1.3748, -1.2532,  0.4485],\n",
      "         [-0.8324, -0.0672,  0.3035,  ..., -1.2021, -0.0862, -0.8044],\n",
      "         [-1.1560, -0.7695, -1.2500,  ...,  0.5969, -1.1206,  0.1342]],\n",
      "\n",
      "        [[-0.1047,  1.3223, -0.1421,  ..., -0.8481, -1.3715,  1.5195],\n",
      "         [-1.2697, -0.4725,  0.3597,  ..., -0.2590, -0.8371, -0.1100],\n",
      "         [-0.5502, -0.5456, -0.3298,  ...,  0.2326, -0.5255,  1.1707],\n",
      "         ...,\n",
      "         [ 0.6201, -0.2652, -0.0465,  ..., -1.1537, -1.2983,  0.9455],\n",
      "         [-0.0506,  0.4288, -0.0028,  ..., -0.8162, -1.0160,  0.8248],\n",
      "         [-1.1560, -0.7695, -1.2500,  ...,  0.5969, -1.1206,  0.1342]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[-0.1047,  1.3223, -0.1421,  ..., -0.8481, -1.3715,  1.5195],\n",
      "         [-1.8460, -1.2518,  2.7948,  ..., -0.9918, -1.1175,  0.8962],\n",
      "         [-0.5514, -0.5617, -0.1957,  ..., -0.7488, -0.6441,  0.3547],\n",
      "         ...,\n",
      "         [-0.3019, -0.1135, -1.1225,  ..., -1.3748, -1.2532,  0.4485],\n",
      "         [-0.8324, -0.0672,  0.3035,  ..., -1.2021, -0.0862, -0.8044],\n",
      "         [-1.1560, -0.7695, -1.2500,  ...,  0.5969, -1.1206,  0.1342]],\n",
      "\n",
      "        [[-0.1047,  1.3223, -0.1421,  ..., -0.8481, -1.3715,  1.5195],\n",
      "         [-1.2697, -0.4725,  0.3597,  ..., -0.2590, -0.8371, -0.1100],\n",
      "         [-0.5502, -0.5456, -0.3298,  ...,  0.2326, -0.5255,  1.1707],\n",
      "         ...,\n",
      "         [ 0.6201, -0.2652, -0.0465,  ..., -1.1537, -1.2983,  0.9455],\n",
      "         [-0.0506,  0.4288, -0.0028,  ..., -0.8162, -1.0160,  0.8248],\n",
      "         [-1.1560, -0.7695, -1.2500,  ...,  0.5969, -1.1206,  0.1342]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[-0.1047,  1.3223, -0.1421,  ..., -0.8481, -1.3715,  1.5195],\n",
      "         [-1.8460, -1.2518,  2.7948,  ..., -0.9918, -1.1175,  0.8962],\n",
      "         [-0.5514, -0.5617, -0.1957,  ..., -0.7488, -0.6441,  0.3547],\n",
      "         ...,\n",
      "         [-0.3019, -0.1135, -1.1225,  ..., -1.3748, -1.2532,  0.4485],\n",
      "         [-0.8324, -0.0672,  0.3035,  ..., -1.2021, -0.0862, -0.8044],\n",
      "         [-1.1560, -0.7695, -1.2500,  ...,  0.5969, -1.1206,  0.1342]],\n",
      "\n",
      "        [[-0.1047,  1.3223, -0.1421,  ..., -0.8481, -1.3715,  1.5195],\n",
      "         [-1.2697, -0.4725,  0.3597,  ..., -0.2590, -0.8371, -0.1100],\n",
      "         [-0.5502, -0.5456, -0.3298,  ...,  0.2326, -0.5255,  1.1707],\n",
      "         ...,\n",
      "         [ 0.6201, -0.2652, -0.0465,  ..., -1.1537, -1.2983,  0.9455],\n",
      "         [-0.0506,  0.4288, -0.0028,  ..., -0.8162, -1.0160,  0.8248],\n",
      "         [-1.1560, -0.7695, -1.2500,  ...,  0.5969, -1.1206,  0.1342]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[[-1.0468e-01,  1.3223e+00, -1.4215e-01,  ..., -2.0458e+00,\n",
      "           -1.7233e+00,  1.0805e+00],\n",
      "          [ 1.2603e-03, -2.4217e-01,  2.4355e-01,  ..., -8.4806e-01,\n",
      "           -1.3715e+00,  1.5195e+00]],\n",
      "\n",
      "         [[-1.8460e+00, -1.2518e+00,  2.7948e+00,  ...,  8.6407e-01,\n",
      "            1.3529e+00,  1.5147e+00],\n",
      "          [ 1.6118e+00,  1.1047e+00, -5.8495e-01,  ..., -9.9177e-01,\n",
      "           -1.1175e+00,  8.9615e-01]],\n",
      "\n",
      "         [[-5.5136e-01, -5.6170e-01, -1.9575e-01,  ..., -4.8577e-02,\n",
      "            2.4005e-01,  2.1872e+00],\n",
      "          [ 3.5447e-01,  3.9465e-01, -2.7852e-01,  ..., -7.4879e-01,\n",
      "           -6.4408e-01,  3.5473e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.0188e-01, -1.1352e-01, -1.1225e+00,  ...,  1.4473e+00,\n",
      "           -6.1682e-01, -7.0202e-01],\n",
      "          [ 1.0752e+00,  1.8312e+00, -3.5410e-01,  ..., -1.3748e+00,\n",
      "           -1.2532e+00,  4.4848e-01]],\n",
      "\n",
      "         [[-8.3244e-01, -6.7204e-02,  3.0349e-01,  ..., -2.4524e+00,\n",
      "           -3.0069e-01, -5.0440e-01],\n",
      "          [ 1.7671e+00,  2.2104e+00,  6.8434e-01,  ..., -1.2021e+00,\n",
      "           -8.6223e-02, -8.0438e-01]],\n",
      "\n",
      "         [[-1.1560e+00, -7.6946e-01, -1.2500e+00,  ...,  4.6560e-01,\n",
      "           -1.3067e+00,  1.6072e+00],\n",
      "          [-2.3245e-01,  1.2482e+00, -3.3021e-02,  ...,  5.9690e-01,\n",
      "           -1.1206e+00,  1.3422e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.0468e-01,  1.3223e+00, -1.4215e-01,  ..., -2.0458e+00,\n",
      "           -1.7233e+00,  1.0805e+00],\n",
      "          [ 1.2603e-03, -2.4217e-01,  2.4355e-01,  ..., -8.4806e-01,\n",
      "           -1.3715e+00,  1.5195e+00]],\n",
      "\n",
      "         [[-1.2697e+00, -4.7248e-01,  3.5969e-01,  ...,  1.5393e+00,\n",
      "            6.6499e-01,  7.0377e-01],\n",
      "          [ 1.4096e+00,  1.2677e+00, -6.9316e-01,  ..., -2.5904e-01,\n",
      "           -8.3707e-01, -1.1005e-01]],\n",
      "\n",
      "         [[-5.5018e-01, -5.4565e-01, -3.2984e-01,  ...,  5.1383e-01,\n",
      "            4.1990e-01,  2.4540e+00],\n",
      "          [ 8.3671e-01, -5.6217e-02, -1.2216e-01,  ...,  2.3258e-01,\n",
      "           -5.2547e-01,  1.1707e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 6.2010e-01, -2.6519e-01, -4.6499e-02,  ...,  1.0819e+00,\n",
      "           -5.9445e-01,  6.1165e-01],\n",
      "          [ 1.5281e+00,  2.1760e+00,  5.8212e-01,  ..., -1.1537e+00,\n",
      "           -1.2983e+00,  9.4551e-01]],\n",
      "\n",
      "         [[-5.0614e-02,  4.2879e-01, -2.8418e-03,  ..., -1.4462e+00,\n",
      "           -1.3134e+00,  1.9031e+00],\n",
      "          [ 1.2877e-01,  1.7261e+00, -2.3857e-01,  ..., -8.1624e-01,\n",
      "           -1.0160e+00,  8.2476e-01]],\n",
      "\n",
      "         [[-1.1560e+00, -7.6946e-01, -1.2500e+00,  ...,  4.6560e-01,\n",
      "           -1.3067e+00,  1.6072e+00],\n",
      "          [-2.3245e-01,  1.2482e+00, -3.3021e-02,  ...,  5.9690e-01,\n",
      "           -1.1206e+00,  1.3422e-01]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.2400,  0.2807, -0.1482,  ..., -0.2063, -0.5802, -0.1272],\n",
      "         [ 0.5994,  0.5068,  0.2236,  ...,  0.0774, -0.0954, -0.0264],\n",
      "         [ 0.0407,  0.3706,  0.1125,  ..., -0.1214,  0.0085,  0.1595],\n",
      "         ...,\n",
      "         [ 0.2978,  0.1901, -0.2167,  ...,  0.0471,  0.0055, -0.6473],\n",
      "         [ 0.2817,  0.0800, -0.4007,  ...,  0.1809, -0.4544, -0.1866],\n",
      "         [ 0.9335, -0.0439,  0.0315,  ...,  0.1442, -0.1273, -0.3609]],\n",
      "\n",
      "        [[ 0.2400,  0.2807, -0.1482,  ..., -0.2063, -0.5802, -0.1272],\n",
      "         [ 0.4932,  0.3801,  0.3467,  ...,  0.0304, -0.0331, -0.1451],\n",
      "         [ 0.2279,  0.3811,  0.2679,  ..., -0.0333,  0.0153, -0.1030],\n",
      "         ...,\n",
      "         [ 0.1616,  0.1043, -0.0599,  ..., -0.2253, -0.2168,  0.0155],\n",
      "         [ 0.4747,  0.5641, -0.1041,  ...,  0.3298, -0.1642, -0.0857],\n",
      "         [ 0.9335, -0.0439,  0.0315,  ...,  0.1442, -0.1273, -0.3609]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.2400,  0.2807, -0.1482,  ..., -0.2063, -0.5802, -0.1272],\n",
      "         [ 0.5994,  0.5068,  0.2236,  ...,  0.0774, -0.0954, -0.0264],\n",
      "         [ 0.0407,  0.3706,  0.1125,  ..., -0.1214,  0.0085,  0.1595],\n",
      "         ...,\n",
      "         [ 0.2978,  0.1901, -0.2167,  ...,  0.0471,  0.0055, -0.6473],\n",
      "         [ 0.2817,  0.0800, -0.4007,  ...,  0.1809, -0.4544, -0.1866],\n",
      "         [ 0.9335, -0.0439,  0.0315,  ...,  0.1442, -0.1273, -0.3609]],\n",
      "\n",
      "        [[ 0.2400,  0.2807, -0.1482,  ..., -0.2063, -0.5802, -0.1272],\n",
      "         [ 0.4932,  0.3801,  0.3467,  ...,  0.0304, -0.0331, -0.1451],\n",
      "         [ 0.2279,  0.3811,  0.2679,  ..., -0.0333,  0.0153, -0.1030],\n",
      "         ...,\n",
      "         [ 0.1616,  0.1043, -0.0599,  ..., -0.2253, -0.2168,  0.0155],\n",
      "         [ 0.4747,  0.5641, -0.1041,  ...,  0.3298, -0.1642, -0.0857],\n",
      "         [ 0.9335, -0.0439,  0.0315,  ...,  0.1442, -0.1273, -0.3609]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 0.2400,  0.2807, -0.1482,  ...,  0.0995, -0.1882,  0.1622],\n",
      "          [ 0.1804, -0.5601,  0.2461,  ..., -0.2063, -0.5802, -0.1272]],\n",
      "\n",
      "         [[ 0.5994,  0.5068,  0.2236,  ..., -0.2396, -0.3466,  0.2126],\n",
      "          [ 0.6145,  0.2360, -0.2444,  ...,  0.0774, -0.0954, -0.0264]],\n",
      "\n",
      "         [[ 0.0407,  0.3706,  0.1125,  ...,  0.2512,  0.0279,  0.0623],\n",
      "          [ 0.4136,  0.6155,  0.0297,  ..., -0.1214,  0.0085,  0.1595]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2978,  0.1901, -0.2167,  ...,  0.4336,  0.2078,  0.0132],\n",
      "          [-0.4431, -0.0607,  0.0323,  ...,  0.0471,  0.0055, -0.6473]],\n",
      "\n",
      "         [[ 0.2817,  0.0800, -0.4007,  ..., -0.3872, -0.6190, -0.0099],\n",
      "          [-0.1208,  0.0781, -0.1865,  ...,  0.1809, -0.4544, -0.1866]],\n",
      "\n",
      "         [[ 0.9335, -0.0439,  0.0315,  ...,  0.6398, -0.0917,  0.5966],\n",
      "          [ 0.4990,  0.2392, -0.2187,  ...,  0.1442, -0.1273, -0.3609]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2400,  0.2807, -0.1482,  ...,  0.0995, -0.1882,  0.1622],\n",
      "          [ 0.1804, -0.5601,  0.2461,  ..., -0.2063, -0.5802, -0.1272]],\n",
      "\n",
      "         [[ 0.4932,  0.3801,  0.3467,  ..., -0.0047,  0.4223, -0.1382],\n",
      "          [ 0.5744,  0.3343, -0.5252,  ...,  0.0304, -0.0331, -0.1451]],\n",
      "\n",
      "         [[ 0.2279,  0.3811,  0.2679,  ...,  0.0869,  0.2785, -0.2858],\n",
      "          [ 0.2176,  0.4717, -0.1754,  ..., -0.0333,  0.0153, -0.1030]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1616,  0.1043, -0.0599,  ...,  0.1121, -0.0031,  0.1187],\n",
      "          [ 0.0215, -0.1108,  0.1039,  ..., -0.2253, -0.2168,  0.0155]],\n",
      "\n",
      "         [[ 0.4747,  0.5641, -0.1041,  ..., -0.3098, -0.8536,  0.5917],\n",
      "          [ 0.2339,  0.4336, -0.1437,  ...,  0.3298, -0.1642, -0.0857]],\n",
      "\n",
      "         [[ 0.9335, -0.0439,  0.0315,  ...,  0.6398, -0.0917,  0.5966],\n",
      "          [ 0.4990,  0.2392, -0.2187,  ...,  0.1442, -0.1273, -0.3609]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.3620,  0.0174,  0.4509,  ...,  0.5513,  0.0745, -0.0507],\n",
      "         [-0.3125,  0.0130,  0.3191,  ...,  0.1729,  0.6436, -0.5165],\n",
      "         [-0.1430,  0.4305,  0.4011,  ...,  0.1952, -0.0643, -0.6652],\n",
      "         ...,\n",
      "         [-0.2226, -0.2436,  0.3244,  ...,  0.3115,  0.1413, -0.6999],\n",
      "         [ 0.0537,  0.8220,  0.2929,  ...,  0.6679, -0.1703, -0.4100],\n",
      "         [-0.3460,  0.3537,  0.3993,  ...,  0.0776,  0.3318, -0.3728]],\n",
      "\n",
      "        [[-0.3620,  0.0174,  0.4509,  ...,  0.5513,  0.0745, -0.0507],\n",
      "         [-0.1725, -0.1924,  0.1291,  ...,  0.0301,  0.9911, -0.0033],\n",
      "         [ 0.0145,  0.7159,  0.0085,  ...,  0.2444, -0.0248, -0.9175],\n",
      "         ...,\n",
      "         [-0.2041,  0.0359,  0.6691,  ...,  0.2467,  0.5455, -0.3234],\n",
      "         [-0.0536,  0.0995,  0.4805,  ..., -0.1861,  0.3876, -0.3316],\n",
      "         [-0.3460,  0.3537,  0.3993,  ...,  0.0776,  0.3318, -0.3728]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.3620,  0.0174,  0.4509,  ...,  0.5513,  0.0745, -0.0507],\n",
      "         [-0.3125,  0.0130,  0.3191,  ...,  0.1729,  0.6436, -0.5165],\n",
      "         [-0.1430,  0.4305,  0.4011,  ...,  0.1952, -0.0643, -0.6652],\n",
      "         ...,\n",
      "         [-0.2226, -0.2436,  0.3244,  ...,  0.3115,  0.1413, -0.6999],\n",
      "         [ 0.0537,  0.8220,  0.2929,  ...,  0.6679, -0.1703, -0.4100],\n",
      "         [-0.3460,  0.3537,  0.3993,  ...,  0.0776,  0.3318, -0.3728]],\n",
      "\n",
      "        [[-0.3620,  0.0174,  0.4509,  ...,  0.5513,  0.0745, -0.0507],\n",
      "         [-0.1725, -0.1924,  0.1291,  ...,  0.0301,  0.9911, -0.0033],\n",
      "         [ 0.0145,  0.7159,  0.0085,  ...,  0.2444, -0.0248, -0.9175],\n",
      "         ...,\n",
      "         [-0.2041,  0.0359,  0.6691,  ...,  0.2467,  0.5455, -0.3234],\n",
      "         [-0.0536,  0.0995,  0.4805,  ..., -0.1861,  0.3876, -0.3316],\n",
      "         [-0.3460,  0.3537,  0.3993,  ...,  0.0776,  0.3318, -0.3728]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.3620,  0.0174,  0.4509,  ...,  0.2571,  0.4517, -0.1016],\n",
      "          [-0.6730,  0.1684,  0.0527,  ...,  0.5513,  0.0745, -0.0507]],\n",
      "\n",
      "         [[-0.3125,  0.0130,  0.3191,  ...,  0.2798, -0.0307,  0.2403],\n",
      "          [-0.1667, -0.1612, -0.0985,  ...,  0.1729,  0.6436, -0.5165]],\n",
      "\n",
      "         [[-0.1430,  0.4305,  0.4011,  ..., -0.1482,  0.4179, -0.0817],\n",
      "          [-0.4401, -0.2738,  0.2072,  ...,  0.1952, -0.0643, -0.6652]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2226, -0.2436,  0.3244,  ...,  0.3171,  0.2928, -0.2436],\n",
      "          [-0.4129,  0.4084, -0.0706,  ...,  0.3115,  0.1413, -0.6999]],\n",
      "\n",
      "         [[ 0.0537,  0.8220,  0.2929,  ...,  0.5456, -0.0038, -0.5213],\n",
      "          [-0.8628,  0.2513, -0.2563,  ...,  0.6679, -0.1703, -0.4100]],\n",
      "\n",
      "         [[-0.3460,  0.3537,  0.3993,  ...,  0.2532,  0.1418,  0.2920],\n",
      "          [-0.2223,  0.0658,  0.2581,  ...,  0.0776,  0.3318, -0.3728]]],\n",
      "\n",
      "\n",
      "        [[[-0.3620,  0.0174,  0.4509,  ...,  0.2571,  0.4517, -0.1016],\n",
      "          [-0.6730,  0.1684,  0.0527,  ...,  0.5513,  0.0745, -0.0507]],\n",
      "\n",
      "         [[-0.1725, -0.1924,  0.1291,  ..., -0.0201,  0.0116,  0.2303],\n",
      "          [ 0.1809,  0.0729,  0.0518,  ...,  0.0301,  0.9911, -0.0033]],\n",
      "\n",
      "         [[ 0.0145,  0.7159,  0.0085,  ..., -0.0013,  0.2614,  0.1142],\n",
      "          [ 0.1034, -0.4193, -0.0189,  ...,  0.2444, -0.0248, -0.9175]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2041,  0.0359,  0.6691,  ...,  0.3131,  0.0938, -0.2260],\n",
      "          [ 0.0074,  0.4648,  0.0659,  ...,  0.2467,  0.5455, -0.3234]],\n",
      "\n",
      "         [[-0.0536,  0.0995,  0.4805,  ...,  0.1470, -0.1917,  0.1250],\n",
      "          [-0.2704,  0.6089,  0.1308,  ..., -0.1861,  0.3876, -0.3316]],\n",
      "\n",
      "         [[-0.3460,  0.3537,  0.3993,  ...,  0.2532,  0.1418,  0.2920],\n",
      "          [-0.2223,  0.0658,  0.2581,  ...,  0.0776,  0.3318, -0.3728]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.1744,  0.2608,  0.2700,  ...,  0.1726,  0.0325, -0.0674],\n",
      "          [-0.1813,  0.1760,  0.2852,  ...,  0.1781,  0.0307, -0.0617],\n",
      "          [-0.1917,  0.1772,  0.2796,  ...,  0.1420,  0.0513, -0.0419],\n",
      "          ...,\n",
      "          [-0.1733,  0.2433,  0.2610,  ...,  0.1326,  0.0714, -0.0707],\n",
      "          [-0.1859,  0.1998,  0.2769,  ...,  0.1580,  0.0541, -0.0558],\n",
      "          [-0.1701,  0.1905,  0.2496,  ...,  0.1554,  0.0086, -0.0585]],\n",
      "\n",
      "         [[-0.3520,  0.2177,  0.1426,  ...,  0.3459,  0.2155, -0.3302],\n",
      "          [-0.3401,  0.2128,  0.1277,  ...,  0.2870,  0.2046, -0.3225],\n",
      "          [-0.3568,  0.1781,  0.1036,  ...,  0.2825,  0.1463, -0.3459],\n",
      "          ...,\n",
      "          [-0.2368,  0.2408,  0.2289,  ...,  0.2484,  0.3049, -0.3443],\n",
      "          [-0.3013,  0.1502,  0.1328,  ...,  0.2222,  0.1837, -0.3602],\n",
      "          [-0.3542,  0.1707,  0.1138,  ...,  0.3033,  0.1789, -0.3607]]],\n",
      "\n",
      "\n",
      "        [[[-0.1614,  0.1318,  0.2176,  ...,  0.0985, -0.1257,  0.0264],\n",
      "          [-0.1885,  0.0956,  0.2077,  ...,  0.0818, -0.0936,  0.0462],\n",
      "          [-0.1548,  0.1326,  0.2436,  ...,  0.0845, -0.0458,  0.0378],\n",
      "          ...,\n",
      "          [-0.1726,  0.1353,  0.2404,  ...,  0.0964, -0.0502,  0.0350],\n",
      "          [-0.1629,  0.1386,  0.2580,  ...,  0.0894, -0.0383,  0.0414],\n",
      "          [-0.1516,  0.1303,  0.2356,  ...,  0.0896, -0.0671,  0.0196]],\n",
      "\n",
      "         [[-0.3742,  0.3512,  0.2018,  ...,  0.0715,  0.2566, -0.3573],\n",
      "          [-0.2893,  0.3013,  0.1676,  ...,  0.0452,  0.2733, -0.3574],\n",
      "          [-0.3114,  0.3070,  0.1916,  ...,  0.0851,  0.2510, -0.3575],\n",
      "          ...,\n",
      "          [-0.3513,  0.3080,  0.1664,  ...,  0.0837,  0.2390, -0.3620],\n",
      "          [-0.2950,  0.2658,  0.1411,  ...,  0.0410,  0.2609, -0.4076],\n",
      "          [-0.3119,  0.3141,  0.1963,  ...,  0.0735,  0.2646, -0.3616]]]],\n",
      "       grad_fn=<ScaledDotProductFlashAttentionForCpuBackward0>)\n",
      "tensor([[[[-0.1744,  0.2608,  0.2700,  ...,  0.1726,  0.0325, -0.0674],\n",
      "          [-0.3520,  0.2177,  0.1426,  ...,  0.3459,  0.2155, -0.3302]],\n",
      "\n",
      "         [[-0.1813,  0.1760,  0.2852,  ...,  0.1781,  0.0307, -0.0617],\n",
      "          [-0.3401,  0.2128,  0.1277,  ...,  0.2870,  0.2046, -0.3225]],\n",
      "\n",
      "         [[-0.1917,  0.1772,  0.2796,  ...,  0.1420,  0.0513, -0.0419],\n",
      "          [-0.3568,  0.1781,  0.1036,  ...,  0.2825,  0.1463, -0.3459]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1733,  0.2433,  0.2610,  ...,  0.1326,  0.0714, -0.0707],\n",
      "          [-0.2368,  0.2408,  0.2289,  ...,  0.2484,  0.3049, -0.3443]],\n",
      "\n",
      "         [[-0.1859,  0.1998,  0.2769,  ...,  0.1580,  0.0541, -0.0558],\n",
      "          [-0.3013,  0.1502,  0.1328,  ...,  0.2222,  0.1837, -0.3602]],\n",
      "\n",
      "         [[-0.1701,  0.1905,  0.2496,  ...,  0.1554,  0.0086, -0.0585],\n",
      "          [-0.3542,  0.1707,  0.1138,  ...,  0.3033,  0.1789, -0.3607]]],\n",
      "\n",
      "\n",
      "        [[[-0.1614,  0.1318,  0.2176,  ...,  0.0985, -0.1257,  0.0264],\n",
      "          [-0.3742,  0.3512,  0.2018,  ...,  0.0715,  0.2566, -0.3573]],\n",
      "\n",
      "         [[-0.1885,  0.0956,  0.2077,  ...,  0.0818, -0.0936,  0.0462],\n",
      "          [-0.2893,  0.3013,  0.1676,  ...,  0.0452,  0.2733, -0.3574]],\n",
      "\n",
      "         [[-0.1548,  0.1326,  0.2436,  ...,  0.0845, -0.0458,  0.0378],\n",
      "          [-0.3114,  0.3070,  0.1916,  ...,  0.0851,  0.2510, -0.3575]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1726,  0.1353,  0.2404,  ...,  0.0964, -0.0502,  0.0350],\n",
      "          [-0.3513,  0.3080,  0.1664,  ...,  0.0837,  0.2390, -0.3620]],\n",
      "\n",
      "         [[-0.1629,  0.1386,  0.2580,  ...,  0.0894, -0.0383,  0.0414],\n",
      "          [-0.2950,  0.2658,  0.1411,  ...,  0.0410,  0.2609, -0.4076]],\n",
      "\n",
      "         [[-0.1516,  0.1303,  0.2356,  ...,  0.0896, -0.0671,  0.0196],\n",
      "          [-0.3119,  0.3141,  0.1963,  ...,  0.0735,  0.2646, -0.3616]]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[-0.0934,  2.0332, -0.1456,  ..., -0.2968, -1.0888,  0.6544],\n",
      "         [-1.6912, -0.6490,  2.5140,  ..., -0.5960, -0.8931,  0.3390],\n",
      "         [-0.5026,  0.1720, -0.3096,  ..., -0.3178, -0.5070, -0.2773],\n",
      "         ...,\n",
      "         [-0.3847,  0.3885, -1.1088,  ..., -1.0294, -1.0575, -0.1340],\n",
      "         [-0.7411,  0.4572,  0.0899,  ..., -0.6837,  0.1917, -1.3137],\n",
      "         [-1.0697, -0.2419, -1.5552,  ...,  1.0254, -0.7589, -0.3945]],\n",
      "\n",
      "        [[-0.0299,  1.8475,  0.0237,  ..., -0.6554, -1.2204,  1.0883],\n",
      "         [-1.1010, -0.1439,  0.3693,  ..., -0.1685, -0.6013, -0.4625],\n",
      "         [-0.4194, -0.1136, -0.2232,  ...,  0.4004, -0.3424,  0.8373],\n",
      "         ...,\n",
      "         [ 0.6173,  0.2068, -0.0215,  ..., -0.9265, -1.2449,  0.4683],\n",
      "         [-0.0265,  0.9270, -0.0244,  ..., -0.8481, -0.7838,  0.4323],\n",
      "         [-1.0667, -0.6006, -1.4625,  ...,  0.8110, -0.8339, -0.1642]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[-0.0392, -1.3377, -1.1899,  ..., -0.4416, -1.0974,  2.0234],\n",
      "         [ 0.0793,  0.2134, -0.0751,  ..., -0.3175, -0.1763,  0.4343],\n",
      "         [-0.3958, -0.3624,  0.2789,  ...,  0.4122, -0.5707,  0.4900],\n",
      "         ...,\n",
      "         [ 0.1492, -0.3764, -0.8214,  ..., -0.0765, -0.6718,  0.9958],\n",
      "         [-0.2504, -0.1480,  0.2082,  ..., -0.0155, -0.5644,  0.4797],\n",
      "         [-0.1661, -0.5282, -0.4796,  ..., -0.3172, -0.0038,  0.1482]],\n",
      "\n",
      "        [[ 0.0053, -1.4123, -1.2130,  ..., -0.7099, -1.0644,  2.1082],\n",
      "         [-0.2847, -0.2444,  0.1264,  ..., -0.0555, -0.3616,  0.3199],\n",
      "         [-0.4391, -0.3420, -0.0654,  ...,  0.3407, -0.2829, -0.0711],\n",
      "         ...,\n",
      "         [-0.0519, -0.5686, -0.8583,  ..., -0.0645, -1.0651,  0.8369],\n",
      "         [ 0.3472, -0.3175, -0.0981,  ...,  0.1712, -0.5977,  0.5655],\n",
      "         [-0.1459, -0.4900, -0.4224,  ..., -0.5122,  0.1288,  0.0342]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.0392, -1.3377, -1.1899,  ..., -0.4416, -1.0974,  2.0234],\n",
      "         [ 0.0793,  0.2134, -0.0751,  ..., -0.3175, -0.1763,  0.4343],\n",
      "         [-0.3958, -0.3624,  0.2789,  ...,  0.4122, -0.5707,  0.4900],\n",
      "         ...,\n",
      "         [ 0.1492, -0.3764, -0.8214,  ..., -0.0765, -0.6718,  0.9958],\n",
      "         [-0.2504, -0.1480,  0.2082,  ..., -0.0155, -0.5644,  0.4797],\n",
      "         [-0.1661, -0.5282, -0.4796,  ..., -0.3172, -0.0038,  0.1482]],\n",
      "\n",
      "        [[ 0.0053, -1.4123, -1.2130,  ..., -0.7099, -1.0644,  2.1082],\n",
      "         [-0.2847, -0.2444,  0.1264,  ..., -0.0555, -0.3616,  0.3199],\n",
      "         [-0.4391, -0.3420, -0.0654,  ...,  0.3407, -0.2829, -0.0711],\n",
      "         ...,\n",
      "         [-0.0519, -0.5686, -0.8583,  ..., -0.0645, -1.0651,  0.8369],\n",
      "         [ 0.3472, -0.3175, -0.0981,  ...,  0.1712, -0.5977,  0.5655],\n",
      "         [-0.1459, -0.4900, -0.4224,  ..., -0.5122,  0.1288,  0.0342]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-3.9175e-02, -1.3377e+00, -1.1899e+00,  ...,  6.0307e-01,\n",
      "            1.5773e-01,  6.9247e-01],\n",
      "          [-6.9409e-01, -1.4739e+00, -8.0511e-01,  ..., -4.4161e-01,\n",
      "           -1.0974e+00,  2.0234e+00]],\n",
      "\n",
      "         [[ 7.9304e-02,  2.1343e-01, -7.5104e-02,  ..., -1.1494e-01,\n",
      "           -2.7819e-01, -2.9809e-01],\n",
      "          [ 7.5944e-02, -1.2772e+00, -4.6569e-01,  ..., -3.1753e-01,\n",
      "           -1.7626e-01,  4.3428e-01]],\n",
      "\n",
      "         [[-3.9581e-01, -3.6239e-01,  2.7894e-01,  ...,  3.1732e-01,\n",
      "           -2.2272e-01, -2.7534e-01],\n",
      "          [ 3.5909e-01, -1.1923e+00, -2.8921e-01,  ...,  4.1223e-01,\n",
      "           -5.7074e-01,  4.8998e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4923e-01, -3.7639e-01, -8.2139e-01,  ...,  1.9474e-01,\n",
      "            9.5631e-02,  2.2920e-01],\n",
      "          [-4.2215e-02,  4.9404e-03, -6.4376e-02,  ..., -7.6455e-02,\n",
      "           -6.7178e-01,  9.9577e-01]],\n",
      "\n",
      "         [[-2.5043e-01, -1.4797e-01,  2.0820e-01,  ...,  2.4147e-01,\n",
      "           -2.9537e-01,  4.6391e-01],\n",
      "          [-1.2650e-01, -4.0433e-01, -1.9000e-01,  ..., -1.5475e-02,\n",
      "           -5.6439e-01,  4.7975e-01]],\n",
      "\n",
      "         [[-1.6606e-01, -5.2824e-01, -4.7961e-01,  ..., -5.9237e-03,\n",
      "           -6.2241e-02,  3.8024e-01],\n",
      "          [-1.3684e-01, -4.6169e-01, -3.2507e-01,  ..., -3.1723e-01,\n",
      "           -3.8048e-03,  1.4820e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.2518e-03, -1.4123e+00, -1.2130e+00,  ...,  6.2068e-01,\n",
      "            5.8573e-02,  8.1183e-01],\n",
      "          [-8.3445e-01, -1.4746e+00, -9.0539e-01,  ..., -7.0991e-01,\n",
      "           -1.0644e+00,  2.1082e+00]],\n",
      "\n",
      "         [[-2.8474e-01, -2.4439e-01,  1.2642e-01,  ...,  7.4358e-02,\n",
      "           -3.2808e-01,  4.7585e-01],\n",
      "          [-1.8853e-01, -7.5592e-01, -8.8335e-02,  ..., -5.5456e-02,\n",
      "           -3.6162e-01,  3.1991e-01]],\n",
      "\n",
      "         [[-4.3909e-01, -3.4197e-01, -6.5447e-02,  ...,  4.4293e-02,\n",
      "           -3.5747e-01, -5.6776e-01],\n",
      "          [ 5.9735e-02, -9.8460e-01, -5.6971e-02,  ...,  3.4074e-01,\n",
      "           -2.8287e-01, -7.1118e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.1854e-02, -5.6855e-01, -8.5830e-01,  ...,  4.4261e-01,\n",
      "            1.3920e-01,  3.0294e-01],\n",
      "          [ 2.8049e-01, -4.6930e-01,  1.5803e-03,  ..., -6.4505e-02,\n",
      "           -1.0651e+00,  8.3690e-01]],\n",
      "\n",
      "         [[ 3.4719e-01, -3.1748e-01, -9.8119e-02,  ...,  2.7447e-01,\n",
      "           -1.1711e-01, -5.7904e-02],\n",
      "          [-3.2448e-01, -4.1552e-01, -6.1695e-01,  ...,  1.7121e-01,\n",
      "           -5.9771e-01,  5.6548e-01]],\n",
      "\n",
      "         [[-1.4590e-01, -4.8999e-01, -4.2244e-01,  ..., -3.8637e-02,\n",
      "           -1.6051e-01,  4.3262e-01],\n",
      "          [-1.8297e-01, -3.3582e-01, -3.4492e-01,  ..., -5.1221e-01,\n",
      "            1.2881e-01,  3.4154e-02]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.0934,  2.0332, -0.1456,  ..., -0.2968, -1.0888,  0.6544],\n",
      "         [-1.6912, -0.6490,  2.5140,  ..., -0.5960, -0.8931,  0.3390],\n",
      "         [-0.5026,  0.1720, -0.3096,  ..., -0.3178, -0.5070, -0.2773],\n",
      "         ...,\n",
      "         [-0.3847,  0.3885, -1.1088,  ..., -1.0294, -1.0575, -0.1340],\n",
      "         [-0.7411,  0.4572,  0.0899,  ..., -0.6837,  0.1917, -1.3137],\n",
      "         [-1.0697, -0.2419, -1.5552,  ...,  1.0254, -0.7589, -0.3945]],\n",
      "\n",
      "        [[-0.0299,  1.8475,  0.0237,  ..., -0.6554, -1.2204,  1.0883],\n",
      "         [-1.1010, -0.1439,  0.3693,  ..., -0.1685, -0.6013, -0.4625],\n",
      "         [-0.4194, -0.1136, -0.2232,  ...,  0.4004, -0.3424,  0.8373],\n",
      "         ...,\n",
      "         [ 0.6173,  0.2068, -0.0215,  ..., -0.9265, -1.2449,  0.4683],\n",
      "         [-0.0265,  0.9270, -0.0244,  ..., -0.8481, -0.7838,  0.4323],\n",
      "         [-1.0667, -0.6006, -1.4625,  ...,  0.8110, -0.8339, -0.1642]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[-0.0934,  2.0332, -0.1456,  ..., -0.2968, -1.0888,  0.6544],\n",
      "         [-1.6912, -0.6490,  2.5140,  ..., -0.5960, -0.8931,  0.3390],\n",
      "         [-0.5026,  0.1720, -0.3096,  ..., -0.3178, -0.5070, -0.2773],\n",
      "         ...,\n",
      "         [-0.3847,  0.3885, -1.1088,  ..., -1.0294, -1.0575, -0.1340],\n",
      "         [-0.7411,  0.4572,  0.0899,  ..., -0.6837,  0.1917, -1.3137],\n",
      "         [-1.0697, -0.2419, -1.5552,  ...,  1.0254, -0.7589, -0.3945]],\n",
      "\n",
      "        [[-0.0299,  1.8475,  0.0237,  ..., -0.6554, -1.2204,  1.0883],\n",
      "         [-1.1010, -0.1439,  0.3693,  ..., -0.1685, -0.6013, -0.4625],\n",
      "         [-0.4194, -0.1136, -0.2232,  ...,  0.4004, -0.3424,  0.8373],\n",
      "         ...,\n",
      "         [ 0.6173,  0.2068, -0.0215,  ..., -0.9265, -1.2449,  0.4683],\n",
      "         [-0.0265,  0.9270, -0.0244,  ..., -0.8481, -0.7838,  0.4323],\n",
      "         [-1.0667, -0.6006, -1.4625,  ...,  0.8110, -0.8339, -0.1642]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[[-9.3361e-02,  2.0332e+00, -1.4560e-01,  ..., -2.0825e+00,\n",
      "           -1.5265e+00,  1.1321e+00],\n",
      "          [ 2.3688e-01,  5.6414e-03,  1.0788e-01,  ..., -2.9682e-01,\n",
      "           -1.0888e+00,  6.5436e-01]],\n",
      "\n",
      "         [[-1.6912e+00, -6.4900e-01,  2.5140e+00,  ...,  6.8155e-01,\n",
      "            1.2807e+00,  1.5582e+00],\n",
      "          [ 1.7631e+00,  1.1158e+00, -7.4020e-01,  ..., -5.9601e-01,\n",
      "           -8.9309e-01,  3.3901e-01]],\n",
      "\n",
      "         [[-5.0257e-01,  1.7196e-01, -3.0957e-01,  ..., -2.2658e-01,\n",
      "            2.4656e-01,  2.1538e+00],\n",
      "          [ 5.6787e-01,  4.8531e-01, -2.9802e-01,  ..., -3.1778e-01,\n",
      "           -5.0703e-01, -2.7730e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.8466e-01,  3.8851e-01, -1.1088e+00,  ...,  1.2704e+00,\n",
      "           -5.3738e-01, -6.7386e-01],\n",
      "          [ 1.1754e+00,  1.7274e+00, -2.2448e-01,  ..., -1.0294e+00,\n",
      "           -1.0575e+00, -1.3396e-01]],\n",
      "\n",
      "         [[-7.4115e-01,  4.5721e-01,  8.9860e-02,  ..., -2.2212e+00,\n",
      "           -1.3030e-01, -3.4497e-01],\n",
      "          [ 1.7816e+00,  2.2688e+00,  6.7461e-01,  ..., -6.8367e-01,\n",
      "            1.9170e-01, -1.3137e+00]],\n",
      "\n",
      "         [[-1.0697e+00, -2.4186e-01, -1.5552e+00,  ...,  1.9098e-01,\n",
      "           -1.0814e+00,  1.6743e+00],\n",
      "          [ 1.2888e-01,  1.3650e+00,  3.3364e-02,  ...,  1.0254e+00,\n",
      "           -7.5886e-01, -3.9448e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.9916e-02,  1.8475e+00,  2.3702e-02,  ..., -2.2940e+00,\n",
      "           -1.4580e+00,  1.0242e+00],\n",
      "          [-7.8245e-02, -2.5571e-01,  3.1152e-01,  ..., -6.5537e-01,\n",
      "           -1.2204e+00,  1.0883e+00]],\n",
      "\n",
      "         [[-1.1010e+00, -1.4390e-01,  3.6929e-01,  ...,  1.4334e+00,\n",
      "            8.2404e-01,  5.0525e-01],\n",
      "          [ 1.2979e+00,  1.1906e+00, -6.3676e-01,  ..., -1.6853e-01,\n",
      "           -6.0131e-01, -4.6252e-01]],\n",
      "\n",
      "         [[-4.1937e-01, -1.1358e-01, -2.2324e-01,  ...,  5.1668e-01,\n",
      "            6.6087e-01,  2.3672e+00],\n",
      "          [ 8.3081e-01, -1.5870e-01,  7.7971e-02,  ...,  4.0038e-01,\n",
      "           -3.4244e-01,  8.3734e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 6.1730e-01,  2.0678e-01, -2.1459e-02,  ...,  1.0124e+00,\n",
      "           -4.7197e-01,  5.4467e-01],\n",
      "          [ 1.5250e+00,  2.1089e+00,  6.5549e-01,  ..., -9.2654e-01,\n",
      "           -1.2449e+00,  4.6830e-01]],\n",
      "\n",
      "         [[-2.6462e-02,  9.2700e-01, -2.4450e-02,  ..., -1.5897e+00,\n",
      "           -1.1794e+00,  1.7291e+00],\n",
      "          [-1.6345e-03,  1.7937e+00, -1.2117e-01,  ..., -8.4809e-01,\n",
      "           -7.8383e-01,  4.3232e-01]],\n",
      "\n",
      "         [[-1.0667e+00, -6.0059e-01, -1.4625e+00,  ...,  2.0081e-01,\n",
      "           -9.8957e-01,  1.6034e+00],\n",
      "          [-1.7161e-01,  1.2232e+00,  1.7132e-01,  ...,  8.1101e-01,\n",
      "           -8.3385e-01, -1.6419e-01]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 4.4355e-01,  7.1792e-01, -7.2880e-01,  ..., -8.3814e-01,\n",
      "          -7.5446e-01, -5.7052e-02],\n",
      "         [ 3.0657e-02,  7.1024e-01, -1.3839e-01,  ..., -3.0497e-01,\n",
      "          -2.4095e-01,  4.5741e-02],\n",
      "         [ 4.2271e-01,  7.6027e-01, -5.8394e-01,  ..., -3.9715e-01,\n",
      "          -4.4715e-01,  4.9537e-01],\n",
      "         ...,\n",
      "         [ 5.2337e-01,  8.2100e-01, -2.0884e-01,  ..., -3.8401e-01,\n",
      "          -2.7804e-01, -1.5184e-01],\n",
      "         [ 7.4228e-01,  1.2226e+00, -8.6380e-01,  ..., -4.2881e-01,\n",
      "          -1.3647e+00, -1.4663e-02],\n",
      "         [ 5.3763e-01,  8.3449e-01, -5.5771e-01,  ..., -2.8336e-01,\n",
      "          -3.1615e-01, -2.5867e-02]],\n",
      "\n",
      "        [[ 3.4572e-01,  5.0873e-01, -4.7186e-01,  ..., -5.4773e-01,\n",
      "          -3.6835e-01,  7.1668e-02],\n",
      "         [-2.4209e-01,  1.2537e-04,  3.1904e-01,  ...,  1.0063e-01,\n",
      "           3.8889e-01, -3.1264e-01],\n",
      "         [ 7.2406e-01,  8.2900e-01, -8.7566e-01,  ..., -1.2466e-01,\n",
      "          -6.3511e-01,  5.1846e-02],\n",
      "         ...,\n",
      "         [ 3.2954e-01,  3.0214e-01, -4.0906e-01,  ..., -3.3111e-01,\n",
      "          -3.9332e-01, -2.3760e-01],\n",
      "         [ 2.3598e-01,  4.2430e-01, -3.6517e-01,  ...,  3.0654e-01,\n",
      "          -8.7757e-02, -2.2706e-01],\n",
      "         [ 4.3313e-01,  6.3367e-01, -3.1338e-01,  ...,  2.9210e-02,\n",
      "           7.0016e-02,  8.8155e-02]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 4.4355e-01,  7.1792e-01, -7.2880e-01,  ..., -8.3814e-01,\n",
      "          -7.5446e-01, -5.7052e-02],\n",
      "         [ 3.0657e-02,  7.1024e-01, -1.3839e-01,  ..., -3.0497e-01,\n",
      "          -2.4095e-01,  4.5741e-02],\n",
      "         [ 4.2271e-01,  7.6027e-01, -5.8394e-01,  ..., -3.9715e-01,\n",
      "          -4.4715e-01,  4.9537e-01],\n",
      "         ...,\n",
      "         [ 5.2337e-01,  8.2100e-01, -2.0884e-01,  ..., -3.8401e-01,\n",
      "          -2.7804e-01, -1.5184e-01],\n",
      "         [ 7.4228e-01,  1.2226e+00, -8.6380e-01,  ..., -4.2881e-01,\n",
      "          -1.3647e+00, -1.4663e-02],\n",
      "         [ 5.3763e-01,  8.3449e-01, -5.5771e-01,  ..., -2.8336e-01,\n",
      "          -3.1615e-01, -2.5867e-02]],\n",
      "\n",
      "        [[ 3.4572e-01,  5.0873e-01, -4.7186e-01,  ..., -5.4773e-01,\n",
      "          -3.6835e-01,  7.1668e-02],\n",
      "         [-2.4209e-01,  1.2537e-04,  3.1904e-01,  ...,  1.0063e-01,\n",
      "           3.8889e-01, -3.1264e-01],\n",
      "         [ 7.2406e-01,  8.2900e-01, -8.7566e-01,  ..., -1.2466e-01,\n",
      "          -6.3511e-01,  5.1846e-02],\n",
      "         ...,\n",
      "         [ 3.2954e-01,  3.0214e-01, -4.0906e-01,  ..., -3.3111e-01,\n",
      "          -3.9332e-01, -2.3760e-01],\n",
      "         [ 2.3598e-01,  4.2430e-01, -3.6517e-01,  ...,  3.0654e-01,\n",
      "          -8.7757e-02, -2.2706e-01],\n",
      "         [ 4.3313e-01,  6.3367e-01, -3.1338e-01,  ...,  2.9210e-02,\n",
      "           7.0016e-02,  8.8155e-02]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 4.4355e-01,  7.1792e-01, -7.2880e-01,  ...,  1.4135e-03,\n",
      "            7.8423e-01,  1.4428e-01],\n",
      "          [ 1.9228e-01,  3.9854e-01,  2.1003e-01,  ..., -8.3814e-01,\n",
      "           -7.5446e-01, -5.7052e-02]],\n",
      "\n",
      "         [[ 3.0657e-02,  7.1024e-01, -1.3839e-01,  ..., -2.5893e-01,\n",
      "            4.0535e-01,  1.8682e-01],\n",
      "          [ 7.5684e-02,  6.1610e-01,  4.8019e-01,  ..., -3.0497e-01,\n",
      "           -2.4095e-01,  4.5741e-02]],\n",
      "\n",
      "         [[ 4.2271e-01,  7.6027e-01, -5.8394e-01,  ..., -3.3719e-01,\n",
      "            8.7137e-01,  3.1542e-01],\n",
      "          [ 9.9659e-02,  7.7828e-01,  4.4612e-01,  ..., -3.9715e-01,\n",
      "           -4.4715e-01,  4.9537e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.2337e-01,  8.2100e-01, -2.0884e-01,  ..., -3.4866e-02,\n",
      "            1.0169e+00,  3.8644e-01],\n",
      "          [ 1.1278e-01,  3.0878e-01, -2.4986e-01,  ..., -3.8401e-01,\n",
      "           -2.7804e-01, -1.5184e-01]],\n",
      "\n",
      "         [[ 7.4228e-01,  1.2226e+00, -8.6380e-01,  ..., -1.4628e-01,\n",
      "            9.1940e-01,  3.3094e-01],\n",
      "          [-5.5140e-01,  2.7810e-01,  5.9264e-01,  ..., -4.2881e-01,\n",
      "           -1.3647e+00, -1.4663e-02]],\n",
      "\n",
      "         [[ 5.3763e-01,  8.3449e-01, -5.5771e-01,  ..., -4.9062e-02,\n",
      "            1.0713e+00,  6.4996e-02],\n",
      "          [-3.9627e-01,  1.4574e+00,  4.9026e-01,  ..., -2.8336e-01,\n",
      "           -3.1615e-01, -2.5867e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.4572e-01,  5.0873e-01, -4.7186e-01,  ...,  1.1194e-01,\n",
      "            5.5471e-01,  6.9117e-02],\n",
      "          [ 2.3896e-01,  5.5411e-02, -2.7306e-02,  ..., -5.4773e-01,\n",
      "           -3.6835e-01,  7.1668e-02]],\n",
      "\n",
      "         [[-2.4209e-01,  1.2537e-04,  3.1904e-01,  ..., -3.6389e-01,\n",
      "            4.1736e-01,  3.4846e-01],\n",
      "          [-9.5397e-02,  2.0933e-01, -3.3550e-01,  ...,  1.0063e-01,\n",
      "            3.8889e-01, -3.1264e-01]],\n",
      "\n",
      "         [[ 7.2406e-01,  8.2900e-01, -8.7566e-01,  ..., -4.8245e-01,\n",
      "            6.0309e-01,  1.8992e-01],\n",
      "          [ 4.3694e-01,  6.3974e-01,  3.7302e-01,  ..., -1.2466e-01,\n",
      "           -6.3511e-01,  5.1846e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.2954e-01,  3.0214e-01, -4.0906e-01,  ..., -3.7241e-01,\n",
      "            6.0378e-01,  6.1423e-01],\n",
      "          [ 6.2484e-01,  1.4489e-01, -9.5367e-03,  ..., -3.3111e-01,\n",
      "           -3.9332e-01, -2.3760e-01]],\n",
      "\n",
      "         [[ 2.3598e-01,  4.2430e-01, -3.6517e-01,  ..., -1.3439e-02,\n",
      "            4.8288e-01, -5.0094e-02],\n",
      "          [-7.4058e-02, -2.7855e-01,  1.3584e-01,  ...,  3.0654e-01,\n",
      "           -8.7757e-02, -2.2706e-01]],\n",
      "\n",
      "         [[ 4.3313e-01,  6.3367e-01, -3.1338e-01,  ...,  4.4278e-02,\n",
      "            8.5435e-01, -1.4246e-02],\n",
      "          [-4.0333e-01,  1.2150e+00,  2.9579e-01,  ...,  2.9210e-02,\n",
      "            7.0016e-02,  8.8155e-02]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 0.3793,  0.8298, -0.5747,  ..., -0.1339,  0.5337,  0.2755],\n",
      "          [ 0.3754,  0.7752, -0.4849,  ..., -0.1408,  0.6118,  0.2163],\n",
      "          [ 0.3851,  0.7599, -0.4933,  ..., -0.1173,  0.6310,  0.2434],\n",
      "          ...,\n",
      "          [ 0.3768,  0.7733, -0.5126,  ..., -0.1319,  0.6050,  0.2449],\n",
      "          [ 0.3797,  0.7863, -0.5022,  ..., -0.1293,  0.6260,  0.2308],\n",
      "          [ 0.3943,  0.7910, -0.5530,  ..., -0.0801,  0.6058,  0.2901]],\n",
      "\n",
      "         [[-0.0888,  0.3710,  0.3383,  ..., -0.3250, -0.3507, -0.0581],\n",
      "          [-0.1184,  0.4622,  0.3363,  ..., -0.3626, -0.4056, -0.0487],\n",
      "          [-0.1114,  0.5123,  0.3266,  ..., -0.4357, -0.4772, -0.0377],\n",
      "          ...,\n",
      "          [-0.1149,  0.4653,  0.3336,  ..., -0.4008, -0.4480, -0.0516],\n",
      "          [-0.1352,  0.5121,  0.3543,  ..., -0.4387, -0.5289, -0.0277],\n",
      "          [-0.1428,  0.4877,  0.3399,  ..., -0.3729, -0.4555, -0.0351]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1105, -0.2825, -0.2685,  ...,  0.2444, -0.2408,  0.1918],\n",
      "          [ 0.2106,  0.2818, -0.3479,  ..., -0.1213,  0.4139,  0.0944],\n",
      "          [ 0.1809,  0.1128, -0.2895,  ...,  0.0116,  0.1885,  0.1387],\n",
      "          ...,\n",
      "          [ 0.1649, -0.0127, -0.3097,  ...,  0.0655,  0.0653,  0.1528],\n",
      "          [ 0.1666,  0.1595, -0.2459,  ..., -0.0318,  0.2738,  0.1112],\n",
      "          [ 0.1735,  0.0816, -0.3097,  ...,  0.0345,  0.1560,  0.1473]],\n",
      "\n",
      "         [[ 0.1865,  0.0951,  0.1060,  ..., -0.0033, -0.0448, -0.0297],\n",
      "          [ 0.0756,  0.1334,  0.0554,  ..., -0.0069,  0.0107, -0.0606],\n",
      "          [ 0.1061,  0.1751,  0.0793,  ..., -0.0220, -0.0917, -0.0717],\n",
      "          ...,\n",
      "          [ 0.1466,  0.1757,  0.1240,  ..., -0.0979, -0.1114, -0.0362],\n",
      "          [ 0.0877,  0.1527,  0.0874,  ..., -0.0260, -0.0377, -0.0587],\n",
      "          [ 0.0726,  0.1079,  0.0518,  ...,  0.0504,  0.0145, -0.0667]]]],\n",
      "       grad_fn=<ScaledDotProductFlashAttentionForCpuBackward0>)\n",
      "tensor([[[[ 0.3793,  0.8298, -0.5747,  ..., -0.1339,  0.5337,  0.2755],\n",
      "          [-0.0888,  0.3710,  0.3383,  ..., -0.3250, -0.3507, -0.0581]],\n",
      "\n",
      "         [[ 0.3754,  0.7752, -0.4849,  ..., -0.1408,  0.6118,  0.2163],\n",
      "          [-0.1184,  0.4622,  0.3363,  ..., -0.3626, -0.4056, -0.0487]],\n",
      "\n",
      "         [[ 0.3851,  0.7599, -0.4933,  ..., -0.1173,  0.6310,  0.2434],\n",
      "          [-0.1114,  0.5123,  0.3266,  ..., -0.4357, -0.4772, -0.0377]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3768,  0.7733, -0.5126,  ..., -0.1319,  0.6050,  0.2449],\n",
      "          [-0.1149,  0.4653,  0.3336,  ..., -0.4008, -0.4480, -0.0516]],\n",
      "\n",
      "         [[ 0.3797,  0.7863, -0.5022,  ..., -0.1293,  0.6260,  0.2308],\n",
      "          [-0.1352,  0.5121,  0.3543,  ..., -0.4387, -0.5289, -0.0277]],\n",
      "\n",
      "         [[ 0.3943,  0.7910, -0.5530,  ..., -0.0801,  0.6058,  0.2901],\n",
      "          [-0.1428,  0.4877,  0.3399,  ..., -0.3729, -0.4555, -0.0351]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1105, -0.2825, -0.2685,  ...,  0.2444, -0.2408,  0.1918],\n",
      "          [ 0.1865,  0.0951,  0.1060,  ..., -0.0033, -0.0448, -0.0297]],\n",
      "\n",
      "         [[ 0.2106,  0.2818, -0.3479,  ..., -0.1213,  0.4139,  0.0944],\n",
      "          [ 0.0756,  0.1334,  0.0554,  ..., -0.0069,  0.0107, -0.0606]],\n",
      "\n",
      "         [[ 0.1809,  0.1128, -0.2895,  ...,  0.0116,  0.1885,  0.1387],\n",
      "          [ 0.1061,  0.1751,  0.0793,  ..., -0.0220, -0.0917, -0.0717]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1649, -0.0127, -0.3097,  ...,  0.0655,  0.0653,  0.1528],\n",
      "          [ 0.1466,  0.1757,  0.1240,  ..., -0.0979, -0.1114, -0.0362]],\n",
      "\n",
      "         [[ 0.1666,  0.1595, -0.2459,  ..., -0.0318,  0.2738,  0.1112],\n",
      "          [ 0.0877,  0.1527,  0.0874,  ..., -0.0260, -0.0377, -0.0587]],\n",
      "\n",
      "         [[ 0.1735,  0.0816, -0.3097,  ...,  0.0345,  0.1560,  0.1473],\n",
      "          [ 0.0726,  0.1079,  0.0518,  ...,  0.0504,  0.0145, -0.0667]]]],\n",
      "       grad_fn=<TransposeBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from chop.pipelines import CompressionPipeline\n",
    "from chop import MaseGraph\n",
    "\n",
    "mg = MaseGraph(model)\n",
    "pipe = CompressionPipeline()\n",
    "\n",
    "quantization_config = {\n",
    "    \"by\": \"type\",\n",
    "    \"default\": {\n",
    "        \"config\": {\n",
    "            \"name\": None,\n",
    "        }\n",
    "    },\n",
    "    \"linear\": {\n",
    "        \"config\": {\n",
    "            \"name\": \"integer\",\n",
    "            # data\n",
    "            \"data_in_width\": 8,\n",
    "            \"data_in_frac_width\": 4,\n",
    "            # weight\n",
    "            \"weight_width\": 8,\n",
    "            \"weight_frac_width\": 4,\n",
    "            # bias\n",
    "            \"bias_width\": 8,\n",
    "            \"bias_frac_width\": 4,\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "pruning_config = {\n",
    "    \"weight\": {\n",
    "        \"sparsity\": 0.5,\n",
    "        \"method\": \"l1-norm\",\n",
    "        \"scope\": \"local\",\n",
    "    },\n",
    "    \"activation\": {\n",
    "        \"sparsity\": 0.5,\n",
    "        \"method\": \"l1-norm\",\n",
    "        \"scope\": \"local\",\n",
    "    },\n",
    "}\n",
    "\n",
    "mg, _ = pipe(\n",
    "    mg,\n",
    "    pass_args={\n",
    "        \"quantize_transform_pass\": quantization_config,\n",
    "        \"prune_transform_pass\": pruning_config,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, export the MaseGraph for the compressed checkpoint to be used in future tutorials for hardware generation and distributed deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mExporting MaseGraph to /Users/blou/tutorial_5_nas_compressed.pt, /Users/blou/tutorial_5_nas_compressed.mz\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mExporting GraphModule to /Users/blou/tutorial_5_nas_compressed.pt\u001b[0m\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Serialization of parametrized modules is only supported through state_dict(). See:\nhttps://pytorch.org/tutorials/beginner/saving_loading_models.html#saving-loading-a-general-checkpoint-for-inference-and-or-resuming-training",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mPath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhome\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/tutorial_5_nas_compressed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/IC/mase/mase_latest/src/chop/ir/graph/mase_graph.py:459\u001b[39m, in \u001b[36mMaseGraph.export\u001b[39m\u001b[34m(self, fname)\u001b[39m\n\u001b[32m    457\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExporting GraphModule to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.pt\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    458\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.pt\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m--> \u001b[39m\u001b[32m459\u001b[39m     \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    461\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExporting MaseMetadata to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.mz\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    463\u001b[39m combined_meta = {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/IC/mase/mase_latest/.venv/lib/python3.11/site-packages/torch/serialization.py:944\u001b[39m, in \u001b[36msave\u001b[39m\u001b[34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[39m\n\u001b[32m    942\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[32m    943\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[32m--> \u001b[39m\u001b[32m944\u001b[39m         \u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m            \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m            \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_disable_byteorder_record\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    951\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    952\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/IC/mase/mase_latest/.venv/lib/python3.11/site-packages/torch/serialization.py:1190\u001b[39m, in \u001b[36m_save\u001b[39m\u001b[34m(obj, zip_file, pickle_module, pickle_protocol, _disable_byteorder_record)\u001b[39m\n\u001b[32m   1187\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m persistent_id(obj)\n\u001b[32m   1189\u001b[39m pickler = PyTorchPickler(data_buf, protocol=pickle_protocol)\n\u001b[32m-> \u001b[39m\u001b[32m1190\u001b[39m \u001b[43mpickler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1191\u001b[39m data_value = data_buf.getvalue()\n\u001b[32m   1192\u001b[39m zip_file.write_record(\u001b[33m\"\u001b[39m\u001b[33mdata.pkl\u001b[39m\u001b[33m\"\u001b[39m, data_value, \u001b[38;5;28mlen\u001b[39m(data_value))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/IC/mase/mase_latest/.venv/lib/python3.11/site-packages/torch/nn/utils/parametrize.py:340\u001b[39m, in \u001b[36m_inject_new_class.<locals>.getstate\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    339\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgetstate\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m340\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    341\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mSerialization of parametrized modules is only \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    342\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33msupported through state_dict(). See:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    343\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mhttps://pytorch.org/tutorials/beginner/saving_loading_models.html\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    344\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m#saving-loading-a-general-checkpoint-for-inference-and-or-resuming-training\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    345\u001b[39m     )\n",
      "\u001b[31mRuntimeError\u001b[39m: Serialization of parametrized modules is only supported through state_dict(). See:\nhttps://pytorch.org/tutorials/beginner/saving_loading_models.html#saving-loading-a-general-checkpoint-for-inference-and-or-resuming-training"
     ]
    }
   ],
   "source": [
    "mg.export(f\"{Path.home()}/tutorial_5_nas_compressed\", save_format=\"state_dict\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
