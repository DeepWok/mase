{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 5: Neural Architecture Search (NAS) with Mase and Optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we'll see how Mase can be integrated with Optuna, the popular hyperparameter optimization framework, to search for a Bert model optimized for sequence classification on the IMDb dataset. We'll take the Optuna-generated model and import it into Mase, then run the CompressionPipeline to prepare the model for edge deployment by quantizing and pruning its weights.\n",
    "\n",
    "As we'll see, running Architecture Search with Mase/Optuna involves the following steps.\n",
    "\n",
    "1. **Define the search space**: this is a dictionary containing the range of values for each parameter at each layer in the model.\n",
    "\n",
    "2. **Write the model constructor**: this is a function which uses Optuna utilities to sample a model from the search space, and constructs the model using transformers from_config class method.\n",
    "\n",
    "3. **Write the objective function**: this function calls on the model constructor defined in Step 2 and defines the training/evaluation setup for each search iteration.\n",
    "\n",
    "4. **Go!** Choose an Optuna sampler, create a study and launch the search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"prajjwal1/bert-tiny\"\n",
    "tokenizer_checkpoint = \"bert-base-uncased\"\n",
    "dataset_name = \"imdb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, fetch the dataset using the `get_tokenized_dataset` utility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/khl22/.conda/envs/plena2/lib/python3.11/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTokenizing dataset imdb with AutoTokenizer for bert-base-uncased.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "867f5a0f7e844d539890bdc6f3d81dbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from chop.tools import get_tokenized_dataset\n",
    "\n",
    "dataset, tokenizer = get_tokenized_dataset(\n",
    "    dataset=dataset_name,\n",
    "    checkpoint=tokenizer_checkpoint,\n",
    "    return_tokenizer=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Defining the Search Space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by defining a search space, i.e. enumerating the possible combinations of hyperparameters that Optuna can choose during search. We'll explore the following range of values for the model's hidden size, intermediate size, number of layers and number of heads, inspired by the [NAS-BERT paper](https://arxiv.org/abs/2105.14444)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from chop.nn.modules import Identity\n",
    "\n",
    "search_space = {\n",
    "    \"num_layers\": [2, 4, 8],\n",
    "    \"num_heads\": [2, 4, 8, 16],\n",
    "    \"hidden_size\": [128, 192, 256, 384, 512],\n",
    "    \"intermediate_size\": [512, 768, 1024, 1536, 2048],\n",
    "    \"linear_layer_choices\": [\n",
    "        nn.Linear,\n",
    "        Identity,\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Writing a Model Constructor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the following function, which will get called in each iteration of the search process. The function is passed the `trial` argument, which is an Optuna object that comes with many functionalities - see the [Trial documentation](https://optuna.readthedocs.io/en/stable/reference/trial.html) for more details. Here, we use the `trial.suggest_int` and `trial.suggest_categorical` functions to trigger the chosen sampler to choose parameter choices and layer types. The suggested integer is the index into the search space for each parameter, which we defined in the previous cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig, AutoModelForSequenceClassification\n",
    "from chop.tools.utils import deepsetattr\n",
    "\n",
    "\n",
    "def construct_model(trial):\n",
    "    config = AutoConfig.from_pretrained(checkpoint)\n",
    "\n",
    "    # Update the paramaters in the config\n",
    "    for param in [\n",
    "        \"num_layers\",\n",
    "        \"num_heads\",\n",
    "        \"hidden_size\",\n",
    "        \"intermediate_size\",\n",
    "    ]:\n",
    "        chosen_idx = trial.suggest_int(param, 0, len(search_space[param]) - 1)\n",
    "        setattr(config, param, search_space[param][chosen_idx])\n",
    "\n",
    "    trial_model = AutoModelForSequenceClassification.from_config(config)\n",
    "\n",
    "    for name, layer in trial_model.named_modules():\n",
    "        if isinstance(layer, nn.Linear) and layer.in_features == layer.out_features:\n",
    "            new_layer_cls = trial.suggest_categorical(\n",
    "                f\"{name}_type\",\n",
    "                search_space[\"linear_layer_choices\"],\n",
    "            )\n",
    "\n",
    "            if new_layer_cls == nn.Linear:\n",
    "                continue\n",
    "            elif new_layer_cls == Identity:\n",
    "                new_layer = Identity()\n",
    "                deepsetattr(trial_model, name, new_layer)\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown layer type: {new_layer_cls}\")\n",
    "\n",
    "    return trial_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Defining the Objective Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define the objective function for the search, which gets called on each trial. In each trial, we create a new model instace with chosen hyperparameters according to the defined sampler. We then use the `get_trainer` utility in Mase to run a training loop on the IMDb dataset for a number of epochs. Finally, we use `evaluate` to report back the classification accuracy on the test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chop.tools import get_trainer\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    # Define the model\n",
    "    model = construct_model(trial)\n",
    "\n",
    "    trainer = get_trainer(\n",
    "        model=model,\n",
    "        tokenized_dataset=dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        evaluate_metric=\"accuracy\",\n",
    "        num_train_epochs=1,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    eval_results = trainer.evaluate()\n",
    "\n",
    "    # Set the model as an attribute so we can fetch it later\n",
    "    trial.set_user_attr(\"model\", model)\n",
    "\n",
    "    return eval_results[\"eval_accuracy\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Launching the Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optuna provides a number of samplers, for example:\n",
    "\n",
    "* **GridSampler**: iterates through every possible combination of hyperparameters in the search space\n",
    "* **RandomSampler**: chooses a random combination of hyperparameters in each iteration\n",
    "* **TPESampler**: uses Tree-structured Parzen Estimator algorithm to choose hyperparameter values.\n",
    "\n",
    "You can define the chosen sampler by simply importing from `optuna.samplers` as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.samplers import GridSampler, RandomSampler, TPESampler\n",
    "\n",
    "sampler = RandomSampler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all the pieces in place, we can launch the search as follows. The number of trials is set to 1 so you can go get a coffee for 10 minutes, then proceed with the tutorial. However, this will essentially be a random model - for better results, set this to 100 and leave it running overnight!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-04 16:58:07,340]\u001b[0m A new study created in memory with name: bert-tiny-nas-study\u001b[0m\n",
      "/home/khl22/.conda/envs/plena2/lib/python3.11/site-packages/optuna/distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.nn.modules.linear.Linear'> which is of type type.\n",
      "  optuna_warn(message)\n",
      "/home/khl22/.conda/envs/plena2/lib/python3.11/site-packages/optuna/distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'chop.nn.modules.identity.Identity'> which is of type type.\n",
      "  optuna_warn(message)\n",
      "/home/khl22/mase/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/home/khl22/.conda/envs/plena2/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='782' max='782' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [782/782 00:48, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.662200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/khl22/.conda/envs/plena2/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/khl22/.conda/envs/plena2/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='782' max='782' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [782/782 00:28]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-04 16:59:28,788]\u001b[0m Trial 0 finished with value: 0.78576 and parameters: {'num_layers': 0, 'num_heads': 0, 'hidden_size': 1, 'intermediate_size': 1, 'bert.encoder.layer.0.attention.self.query_type': <class 'chop.nn.modules.identity.Identity'>, 'bert.encoder.layer.0.attention.self.key_type': <class 'torch.nn.modules.linear.Linear'>, 'bert.encoder.layer.0.attention.self.value_type': <class 'chop.nn.modules.identity.Identity'>, 'bert.encoder.layer.0.attention.output.dense_type': <class 'chop.nn.modules.identity.Identity'>, 'bert.encoder.layer.1.attention.self.query_type': <class 'chop.nn.modules.identity.Identity'>, 'bert.encoder.layer.1.attention.self.key_type': <class 'torch.nn.modules.linear.Linear'>, 'bert.encoder.layer.1.attention.self.value_type': <class 'chop.nn.modules.identity.Identity'>, 'bert.encoder.layer.1.attention.output.dense_type': <class 'torch.nn.modules.linear.Linear'>, 'bert.pooler.dense_type': <class 'torch.nn.modules.linear.Linear'>}. Best is trial 0 with value: 0.78576.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=\"bert-tiny-nas-study\",\n",
    "    sampler=sampler,\n",
    ")\n",
    "\n",
    "study.optimize(\n",
    "    objective,\n",
    "    n_trials=1,\n",
    "    timeout=60 * 60 * 24,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch the model associated with the best trial as follows, and export to be used in future tutorials. In Tutorial 6, we'll see how to run mixed-precision quantization search on top of the model we've just found through NAS to further find the optimal quantization mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import dill\n",
    "\n",
    "model = study.best_trial.user_attrs[\"model\"].cpu()\n",
    "\n",
    "with open(f\"{Path.home()}/tutorial_5_best_model.pkl\", \"wb\") as f:\n",
    "    dill.dump(model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying the Optimized Model with CompressionPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can run the CompressionPipeline in Mase to run uniform quantization and pruning over the searched model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`past_key_values` were not specified as input names, but model.config.use_cache = True. Setting model.config.use_cache = False.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mGetting dummy input for prajjwal1/bert-tiny.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "tensor([[[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]])\n",
      "tensor([[[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]])\n",
      "tensor([[[-0.9614,  0.9065, -2.1133,  ...,  0.4108, -0.4437, -1.0690],\n",
      "         [ 0.2316,  1.7936,  1.0969,  ..., -0.5716,  0.5182, -0.1723],\n",
      "         [-2.5953,  2.1830,  0.9955,  ...,  0.1053,  0.8419,  0.9343],\n",
      "         ...,\n",
      "         [-0.9778,  0.2540,  0.5568,  ..., -0.3245,  1.1848, -0.2623],\n",
      "         [-0.0895, -0.5491, -0.8821,  ..., -1.3083, -0.7514,  0.7641],\n",
      "         [-1.3717,  2.6120, -0.6775,  ...,  0.3914, -0.1107,  1.4273]],\n",
      "\n",
      "        [[-0.9614,  0.9065, -2.1133,  ...,  0.4108, -0.4437, -1.0690],\n",
      "         [-0.4193,  1.6432,  0.4935,  ..., -0.3798,  0.2598,  0.3709],\n",
      "         [-0.3144,  3.0526,  0.5915,  ..., -0.8491,  1.2451,  0.6056],\n",
      "         ...,\n",
      "         [-0.7583,  0.7947,  0.9841,  ..., -0.2108,  1.0049,  0.8015],\n",
      "         [-0.0342, -0.7005, -0.5831,  ...,  0.7469, -0.6022,  0.6736],\n",
      "         [-1.3717,  2.6120, -0.6775,  ...,  0.3914, -0.1107,  1.4273]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[-0.9614,  0.9065, -2.1133,  ...,  0.4108, -0.4437, -1.0690],\n",
      "         [ 0.2316,  1.7936,  1.0969,  ..., -0.5716,  0.5182, -0.1723],\n",
      "         [-2.5953,  2.1830,  0.9955,  ...,  0.1053,  0.8419,  0.9343],\n",
      "         ...,\n",
      "         [-0.9778,  0.2540,  0.5568,  ..., -0.3245,  1.1848, -0.2623],\n",
      "         [-0.0895, -0.5491, -0.8821,  ..., -1.3083, -0.7514,  0.7641],\n",
      "         [-1.3717,  2.6120, -0.6775,  ...,  0.3914, -0.1107,  1.4273]],\n",
      "\n",
      "        [[-0.9614,  0.9065, -2.1133,  ...,  0.4108, -0.4437, -1.0690],\n",
      "         [-0.4193,  1.6432,  0.4935,  ..., -0.3798,  0.2598,  0.3709],\n",
      "         [-0.3144,  3.0526,  0.5915,  ..., -0.8491,  1.2451,  0.6056],\n",
      "         ...,\n",
      "         [-0.7583,  0.7947,  0.9841,  ..., -0.2108,  1.0049,  0.8015],\n",
      "         [-0.0342, -0.7005, -0.5831,  ...,  0.7469, -0.6022,  0.6736],\n",
      "         [-1.3717,  2.6120, -0.6775,  ...,  0.3914, -0.1107,  1.4273]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[-0.9614,  0.9065, -2.1133,  ...,  0.4108, -0.4437, -1.0690],\n",
      "         [ 0.2316,  1.7936,  1.0969,  ..., -0.5716,  0.5182, -0.1723],\n",
      "         [-2.5953,  2.1830,  0.9955,  ...,  0.1053,  0.8419,  0.9343],\n",
      "         ...,\n",
      "         [-0.9778,  0.2540,  0.5568,  ..., -0.3245,  1.1848, -0.2623],\n",
      "         [-0.0895, -0.5491, -0.8821,  ..., -1.3083, -0.7514,  0.7641],\n",
      "         [-1.3717,  2.6120, -0.6775,  ...,  0.3914, -0.1107,  1.4273]],\n",
      "\n",
      "        [[-0.9614,  0.9065, -2.1133,  ...,  0.4108, -0.4437, -1.0690],\n",
      "         [-0.4193,  1.6432,  0.4935,  ..., -0.3798,  0.2598,  0.3709],\n",
      "         [-0.3144,  3.0526,  0.5915,  ..., -0.8491,  1.2451,  0.6056],\n",
      "         ...,\n",
      "         [-0.7583,  0.7947,  0.9841,  ..., -0.2108,  1.0049,  0.8015],\n",
      "         [-0.0342, -0.7005, -0.5831,  ...,  0.7469, -0.6022,  0.6736],\n",
      "         [-1.3717,  2.6120, -0.6775,  ...,  0.3914, -0.1107,  1.4273]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[[-9.6141e-01,  9.0650e-01, -2.1133e+00,  ...,  3.4846e-01,\n",
      "            4.5512e-01,  1.1785e+00],\n",
      "          [ 1.2385e+00, -2.9610e-01,  5.1357e-01,  ...,  4.1080e-01,\n",
      "           -4.4368e-01, -1.0690e+00]],\n",
      "\n",
      "         [[ 2.3159e-01,  1.7936e+00,  1.0969e+00,  ...,  8.8265e-01,\n",
      "            8.7235e-01, -1.3688e+00],\n",
      "          [-9.9900e-01, -1.4565e+00,  1.5560e-01,  ..., -5.7158e-01,\n",
      "            5.1819e-01, -1.7235e-01]],\n",
      "\n",
      "         [[-2.5953e+00,  2.1830e+00,  9.9551e-01,  ..., -2.7514e-01,\n",
      "            1.0752e+00, -1.1726e+00],\n",
      "          [-9.9209e-01, -2.1971e+00,  1.1248e-01,  ...,  1.0527e-01,\n",
      "            8.4194e-01,  9.3434e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-9.7775e-01,  2.5401e-01,  5.5681e-01,  ...,  1.7099e-01,\n",
      "           -1.4426e-01,  6.9221e-01],\n",
      "          [-1.1375e+00, -5.3112e-01,  1.7181e+00,  ..., -3.2450e-01,\n",
      "            1.1848e+00, -2.6227e-01]],\n",
      "\n",
      "         [[-8.9545e-02, -5.4913e-01, -8.8207e-01,  ...,  1.5555e+00,\n",
      "           -3.1656e-01,  1.6649e-03],\n",
      "          [-4.8724e-01, -2.4276e+00, -1.0829e+00,  ..., -1.3083e+00,\n",
      "           -7.5140e-01,  7.6414e-01]],\n",
      "\n",
      "         [[-1.3717e+00,  2.6120e+00, -6.7752e-01,  ...,  9.7145e-01,\n",
      "           -2.7151e-01, -1.0116e+00],\n",
      "          [-3.2272e-01, -8.8203e-01, -3.2627e-01,  ...,  3.9144e-01,\n",
      "           -1.1070e-01,  1.4273e+00]]],\n",
      "\n",
      "\n",
      "        [[[-9.6141e-01,  9.0650e-01, -2.1133e+00,  ...,  3.4846e-01,\n",
      "            4.5512e-01,  1.1785e+00],\n",
      "          [ 1.2385e+00, -2.9610e-01,  5.1357e-01,  ...,  4.1080e-01,\n",
      "           -4.4368e-01, -1.0690e+00]],\n",
      "\n",
      "         [[-4.1929e-01,  1.6432e+00,  4.9353e-01,  ...,  1.7351e+00,\n",
      "           -2.6610e-01, -8.0458e-01],\n",
      "          [ 3.3257e-01, -6.0301e-01,  1.2278e+00,  ..., -3.7976e-01,\n",
      "            2.5980e-01,  3.7093e-01]],\n",
      "\n",
      "         [[-3.1444e-01,  3.0526e+00,  5.9149e-01,  ..., -3.4764e-01,\n",
      "            3.5452e-01, -1.0849e+00],\n",
      "          [-4.4242e-01, -2.0312e+00,  5.1944e-01,  ..., -8.4905e-01,\n",
      "            1.2451e+00,  6.0558e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-7.5828e-01,  7.9468e-01,  9.8408e-01,  ...,  1.3665e+00,\n",
      "           -1.2318e-01, -1.1455e-01],\n",
      "          [-8.6318e-01,  1.7687e-01,  1.3921e+00,  ..., -2.1075e-01,\n",
      "            1.0049e+00,  8.0151e-01]],\n",
      "\n",
      "         [[-3.4241e-02, -7.0046e-01, -5.8312e-01,  ...,  1.3007e+00,\n",
      "           -1.5528e+00, -1.0137e+00],\n",
      "          [ 1.1684e+00, -1.1061e+00,  3.1527e-01,  ...,  7.4691e-01,\n",
      "           -6.0222e-01,  6.7360e-01]],\n",
      "\n",
      "         [[-1.3717e+00,  2.6120e+00, -6.7752e-01,  ...,  9.7145e-01,\n",
      "           -2.7151e-01, -1.0116e+00],\n",
      "          [-3.2272e-01, -8.8203e-01, -3.2627e-01,  ...,  3.9144e-01,\n",
      "           -1.1070e-01,  1.4273e+00]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.2084, -0.0236,  0.0203,  ..., -0.0364,  0.1571,  0.4616],\n",
      "         [ 0.0043,  0.0592,  0.2718,  ..., -0.0219,  0.0606,  0.6102],\n",
      "         [ 0.3343, -0.1374,  0.5536,  ..., -0.6565, -0.0833,  0.2345],\n",
      "         ...,\n",
      "         [ 0.1128,  0.1978,  0.0938,  ..., -0.3919,  0.4842,  0.5949],\n",
      "         [ 0.3197, -0.2720,  0.2620,  ..., -0.1370, -0.1113,  0.0690],\n",
      "         [ 0.5495, -0.0433,  0.4839,  ..., -0.0158, -0.0596,  0.4314]],\n",
      "\n",
      "        [[ 0.2084, -0.0236,  0.0203,  ..., -0.0364,  0.1571,  0.4616],\n",
      "         [ 0.3556, -0.1376,  0.3866,  ...,  0.1229, -0.0372,  0.7291],\n",
      "         [ 0.1476,  0.1280,  0.2218,  ..., -0.5995,  0.3090,  0.5142],\n",
      "         ...,\n",
      "         [ 0.0532, -0.1842, -0.3509,  ..., -0.3551,  0.1056,  0.6131],\n",
      "         [ 0.1855,  0.1764,  0.4590,  ...,  0.1086, -0.2763,  0.1239],\n",
      "         [ 0.5495, -0.0433,  0.4839,  ..., -0.0158, -0.0596,  0.4314]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 0.2084, -0.0236,  0.0203,  ..., -0.0364,  0.1571,  0.4616],\n",
      "         [ 0.0043,  0.0592,  0.2718,  ..., -0.0219,  0.0606,  0.6102],\n",
      "         [ 0.3343, -0.1374,  0.5536,  ..., -0.6565, -0.0833,  0.2345],\n",
      "         ...,\n",
      "         [ 0.1128,  0.1978,  0.0938,  ..., -0.3919,  0.4842,  0.5949],\n",
      "         [ 0.3197, -0.2720,  0.2620,  ..., -0.1370, -0.1113,  0.0690],\n",
      "         [ 0.5495, -0.0433,  0.4839,  ..., -0.0158, -0.0596,  0.4314]],\n",
      "\n",
      "        [[ 0.2084, -0.0236,  0.0203,  ..., -0.0364,  0.1571,  0.4616],\n",
      "         [ 0.3556, -0.1376,  0.3866,  ...,  0.1229, -0.0372,  0.7291],\n",
      "         [ 0.1476,  0.1280,  0.2218,  ..., -0.5995,  0.3090,  0.5142],\n",
      "         ...,\n",
      "         [ 0.0532, -0.1842, -0.3509,  ..., -0.3551,  0.1056,  0.6131],\n",
      "         [ 0.1855,  0.1764,  0.4590,  ...,  0.1086, -0.2763,  0.1239],\n",
      "         [ 0.5495, -0.0433,  0.4839,  ..., -0.0158, -0.0596,  0.4314]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 0.2084, -0.0236,  0.0203,  ..., -0.2165, -0.0230, -0.3033],\n",
      "          [ 0.1233,  0.2994, -0.0495,  ..., -0.0364,  0.1571,  0.4616]],\n",
      "\n",
      "         [[ 0.0043,  0.0592,  0.2718,  ..., -0.2406, -0.1932,  0.2767],\n",
      "          [ 0.0227, -0.1844, -0.5714,  ..., -0.0219,  0.0606,  0.6102]],\n",
      "\n",
      "         [[ 0.3343, -0.1374,  0.5536,  ..., -0.4353,  0.0155, -0.0321],\n",
      "          [ 0.0790,  0.1373, -0.1074,  ..., -0.6565, -0.0833,  0.2345]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1128,  0.1978,  0.0938,  ..., -0.5636, -0.0904,  0.3834],\n",
      "          [ 0.3159,  0.2518, -0.2774,  ..., -0.3919,  0.4842,  0.5949]],\n",
      "\n",
      "         [[ 0.3197, -0.2720,  0.2620,  ..., -0.0053,  0.2310,  0.1607],\n",
      "          [ 0.3027,  0.1087,  0.2401,  ..., -0.1370, -0.1113,  0.0690]],\n",
      "\n",
      "         [[ 0.5495, -0.0433,  0.4839,  ..., -0.1883, -0.7805,  0.1714],\n",
      "          [ 0.0572,  0.2899, -0.0793,  ..., -0.0158, -0.0596,  0.4314]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2084, -0.0236,  0.0203,  ..., -0.2165, -0.0230, -0.3033],\n",
      "          [ 0.1233,  0.2994, -0.0495,  ..., -0.0364,  0.1571,  0.4616]],\n",
      "\n",
      "         [[ 0.3556, -0.1376,  0.3866,  ..., -0.2816,  0.0178,  0.3872],\n",
      "          [ 0.1752, -0.0703, -0.3482,  ...,  0.1229, -0.0372,  0.7291]],\n",
      "\n",
      "         [[ 0.1476,  0.1280,  0.2218,  ..., -0.2224, -0.1455, -0.0688],\n",
      "          [-0.2356,  0.0366, -0.2102,  ..., -0.5995,  0.3090,  0.5142]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0532, -0.1842, -0.3509,  ..., -0.4285, -0.0328, -0.1490],\n",
      "          [ 0.2490,  0.1097, -0.4213,  ..., -0.3551,  0.1056,  0.6131]],\n",
      "\n",
      "         [[ 0.1855,  0.1764,  0.4590,  ..., -0.4803, -0.1619,  0.4353],\n",
      "          [ 0.4386, -0.0961,  0.3877,  ...,  0.1086, -0.2763,  0.1239]],\n",
      "\n",
      "         [[ 0.5495, -0.0433,  0.4839,  ..., -0.1883, -0.7805,  0.1714],\n",
      "          [ 0.0572,  0.2899, -0.0793,  ..., -0.0158, -0.0596,  0.4314]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.9614,  0.9065, -2.1133,  ...,  0.4108, -0.4437, -1.0690],\n",
      "         [ 0.2316,  1.7936,  1.0969,  ..., -0.5716,  0.5182, -0.1723],\n",
      "         [-2.5953,  2.1830,  0.9955,  ...,  0.1053,  0.8419,  0.9343],\n",
      "         ...,\n",
      "         [-0.9778,  0.2540,  0.5568,  ..., -0.3245,  1.1848, -0.2623],\n",
      "         [-0.0895, -0.5491, -0.8821,  ..., -1.3083, -0.7514,  0.7641],\n",
      "         [-1.3717,  2.6120, -0.6775,  ...,  0.3914, -0.1107,  1.4273]],\n",
      "\n",
      "        [[-0.9614,  0.9065, -2.1133,  ...,  0.4108, -0.4437, -1.0690],\n",
      "         [-0.4193,  1.6432,  0.4935,  ..., -0.3798,  0.2598,  0.3709],\n",
      "         [-0.3144,  3.0526,  0.5915,  ..., -0.8491,  1.2451,  0.6056],\n",
      "         ...,\n",
      "         [-0.7583,  0.7947,  0.9841,  ..., -0.2108,  1.0049,  0.8015],\n",
      "         [-0.0342, -0.7005, -0.5831,  ...,  0.7469, -0.6022,  0.6736],\n",
      "         [-1.3717,  2.6120, -0.6775,  ...,  0.3914, -0.1107,  1.4273]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[-0.9614,  0.9065, -2.1133,  ...,  0.4108, -0.4437, -1.0690],\n",
      "         [ 0.2316,  1.7936,  1.0969,  ..., -0.5716,  0.5182, -0.1723],\n",
      "         [-2.5953,  2.1830,  0.9955,  ...,  0.1053,  0.8419,  0.9343],\n",
      "         ...,\n",
      "         [-0.9778,  0.2540,  0.5568,  ..., -0.3245,  1.1848, -0.2623],\n",
      "         [-0.0895, -0.5491, -0.8821,  ..., -1.3083, -0.7514,  0.7641],\n",
      "         [-1.3717,  2.6120, -0.6775,  ...,  0.3914, -0.1107,  1.4273]],\n",
      "\n",
      "        [[-0.9614,  0.9065, -2.1133,  ...,  0.4108, -0.4437, -1.0690],\n",
      "         [-0.4193,  1.6432,  0.4935,  ..., -0.3798,  0.2598,  0.3709],\n",
      "         [-0.3144,  3.0526,  0.5915,  ..., -0.8491,  1.2451,  0.6056],\n",
      "         ...,\n",
      "         [-0.7583,  0.7947,  0.9841,  ..., -0.2108,  1.0049,  0.8015],\n",
      "         [-0.0342, -0.7005, -0.5831,  ...,  0.7469, -0.6022,  0.6736],\n",
      "         [-1.3717,  2.6120, -0.6775,  ...,  0.3914, -0.1107,  1.4273]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[[-9.6141e-01,  9.0650e-01, -2.1133e+00,  ...,  3.4846e-01,\n",
      "            4.5512e-01,  1.1785e+00],\n",
      "          [ 1.2385e+00, -2.9610e-01,  5.1357e-01,  ...,  4.1080e-01,\n",
      "           -4.4368e-01, -1.0690e+00]],\n",
      "\n",
      "         [[ 2.3159e-01,  1.7936e+00,  1.0969e+00,  ...,  8.8265e-01,\n",
      "            8.7235e-01, -1.3688e+00],\n",
      "          [-9.9900e-01, -1.4565e+00,  1.5560e-01,  ..., -5.7158e-01,\n",
      "            5.1819e-01, -1.7235e-01]],\n",
      "\n",
      "         [[-2.5953e+00,  2.1830e+00,  9.9551e-01,  ..., -2.7514e-01,\n",
      "            1.0752e+00, -1.1726e+00],\n",
      "          [-9.9209e-01, -2.1971e+00,  1.1248e-01,  ...,  1.0527e-01,\n",
      "            8.4194e-01,  9.3434e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-9.7775e-01,  2.5401e-01,  5.5681e-01,  ...,  1.7099e-01,\n",
      "           -1.4426e-01,  6.9221e-01],\n",
      "          [-1.1375e+00, -5.3112e-01,  1.7181e+00,  ..., -3.2450e-01,\n",
      "            1.1848e+00, -2.6227e-01]],\n",
      "\n",
      "         [[-8.9545e-02, -5.4913e-01, -8.8207e-01,  ...,  1.5555e+00,\n",
      "           -3.1656e-01,  1.6649e-03],\n",
      "          [-4.8724e-01, -2.4276e+00, -1.0829e+00,  ..., -1.3083e+00,\n",
      "           -7.5140e-01,  7.6414e-01]],\n",
      "\n",
      "         [[-1.3717e+00,  2.6120e+00, -6.7752e-01,  ...,  9.7145e-01,\n",
      "           -2.7151e-01, -1.0116e+00],\n",
      "          [-3.2272e-01, -8.8203e-01, -3.2627e-01,  ...,  3.9144e-01,\n",
      "           -1.1070e-01,  1.4273e+00]]],\n",
      "\n",
      "\n",
      "        [[[-9.6141e-01,  9.0650e-01, -2.1133e+00,  ...,  3.4846e-01,\n",
      "            4.5512e-01,  1.1785e+00],\n",
      "          [ 1.2385e+00, -2.9610e-01,  5.1357e-01,  ...,  4.1080e-01,\n",
      "           -4.4368e-01, -1.0690e+00]],\n",
      "\n",
      "         [[-4.1929e-01,  1.6432e+00,  4.9353e-01,  ...,  1.7351e+00,\n",
      "           -2.6610e-01, -8.0458e-01],\n",
      "          [ 3.3257e-01, -6.0301e-01,  1.2278e+00,  ..., -3.7976e-01,\n",
      "            2.5980e-01,  3.7093e-01]],\n",
      "\n",
      "         [[-3.1444e-01,  3.0526e+00,  5.9149e-01,  ..., -3.4764e-01,\n",
      "            3.5452e-01, -1.0849e+00],\n",
      "          [-4.4242e-01, -2.0312e+00,  5.1944e-01,  ..., -8.4905e-01,\n",
      "            1.2451e+00,  6.0558e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-7.5828e-01,  7.9468e-01,  9.8408e-01,  ...,  1.3665e+00,\n",
      "           -1.2318e-01, -1.1455e-01],\n",
      "          [-8.6318e-01,  1.7687e-01,  1.3921e+00,  ..., -2.1075e-01,\n",
      "            1.0049e+00,  8.0151e-01]],\n",
      "\n",
      "         [[-3.4241e-02, -7.0046e-01, -5.8312e-01,  ...,  1.3007e+00,\n",
      "           -1.5528e+00, -1.0137e+00],\n",
      "          [ 1.1684e+00, -1.1061e+00,  3.1527e-01,  ...,  7.4691e-01,\n",
      "           -6.0222e-01,  6.7360e-01]],\n",
      "\n",
      "         [[-1.3717e+00,  2.6120e+00, -6.7752e-01,  ...,  9.7145e-01,\n",
      "           -2.7151e-01, -1.0116e+00],\n",
      "          [-3.2272e-01, -8.8203e-01, -3.2627e-01,  ...,  3.9144e-01,\n",
      "           -1.1070e-01,  1.4273e+00]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-6.6579e-01,  6.4557e-01, -1.2792e-01,  ...,  9.3953e-01,\n",
      "           -8.1618e-02, -1.7144e-02],\n",
      "          [-8.8320e-01,  9.9039e-01,  2.2099e-02,  ...,  7.9228e-01,\n",
      "           -3.3737e-02, -1.6574e-01],\n",
      "          [-7.9185e-01,  1.0858e+00,  1.7239e-01,  ...,  8.2114e-01,\n",
      "           -1.7668e-03, -9.2969e-02],\n",
      "          ...,\n",
      "          [-6.8716e-01,  8.8315e-01, -3.9746e-02,  ...,  8.7954e-01,\n",
      "           -3.7598e-02, -2.3205e-02],\n",
      "          [-8.7724e-01,  9.3878e-01, -5.1265e-03,  ...,  7.7515e-01,\n",
      "           -3.3254e-02, -9.4621e-02],\n",
      "          [-9.0475e-01,  1.0966e+00, -1.6707e-03,  ...,  7.9319e-01,\n",
      "           -2.6434e-02, -2.3043e-01]],\n",
      "\n",
      "         [[-2.6058e-01, -1.5898e+00, -8.3961e-02,  ..., -3.4076e-01,\n",
      "            1.9789e-01,  5.5795e-01],\n",
      "          [-2.0995e-01, -1.4808e+00,  5.8085e-02,  ..., -2.0243e-01,\n",
      "            3.3521e-01,  5.2734e-01],\n",
      "          [-2.2058e-01, -1.3562e+00,  1.5823e-01,  ..., -2.4818e-01,\n",
      "            3.4140e-01,  3.5579e-01],\n",
      "          ...,\n",
      "          [-2.4689e-01, -1.4286e+00, -4.6750e-02,  ..., -2.8260e-01,\n",
      "            2.4200e-01,  5.0197e-01],\n",
      "          [-3.1367e-01, -1.3701e+00,  3.1404e-04,  ..., -2.7861e-01,\n",
      "            3.3010e-01,  4.3762e-01],\n",
      "          [-1.7606e-01, -1.3592e+00,  7.7075e-03,  ..., -1.9392e-01,\n",
      "            2.7481e-01,  4.0211e-01]]],\n",
      "\n",
      "\n",
      "        [[[-5.8339e-01,  3.8702e-01, -4.0224e-01,  ...,  7.3043e-01,\n",
      "           -3.4552e-01, -3.5297e-01],\n",
      "          [-6.0845e-01,  6.9125e-01, -4.9332e-01,  ...,  6.9351e-01,\n",
      "           -1.6033e-01, -2.6245e-01],\n",
      "          [-5.4896e-01,  7.4830e-01, -3.4699e-01,  ...,  8.1864e-01,\n",
      "           -2.4148e-01, -3.1103e-01],\n",
      "          ...,\n",
      "          [-4.6552e-01,  7.6942e-01, -2.8468e-01,  ...,  8.0250e-01,\n",
      "           -2.7656e-01, -2.9515e-01],\n",
      "          [-6.5847e-01,  8.7263e-01, -3.4111e-01,  ...,  6.5625e-01,\n",
      "           -2.1551e-01, -2.2339e-01],\n",
      "          [-6.4305e-01,  9.3765e-01, -3.7135e-01,  ...,  6.7908e-01,\n",
      "           -1.9513e-01, -3.4877e-01]],\n",
      "\n",
      "         [[ 1.0672e-01, -8.5056e-01,  8.9629e-02,  ...,  3.5273e-01,\n",
      "            5.3112e-01,  4.4658e-01],\n",
      "          [ 9.1800e-02, -1.0065e+00,  2.6340e-01,  ...,  1.2189e-01,\n",
      "            4.0580e-01,  3.9846e-01],\n",
      "          [-1.2821e-01, -9.8436e-01,  2.8586e-01,  ...,  7.2176e-02,\n",
      "            5.2822e-01,  4.7419e-01],\n",
      "          ...,\n",
      "          [-1.1756e-02, -1.0981e+00,  2.4971e-01,  ...,  5.2065e-02,\n",
      "            4.5852e-01,  4.4733e-01],\n",
      "          [-6.4263e-03, -8.5171e-01,  2.6549e-01,  ...,  1.3514e-01,\n",
      "            5.1609e-01,  4.6551e-01],\n",
      "          [ 1.2081e-01, -9.7949e-01,  2.6853e-01,  ...,  1.4350e-01,\n",
      "            3.8882e-01,  3.7690e-01]]]],\n",
      "       grad_fn=<ScaledDotProductFlashAttentionForCpuBackward0>)\n",
      "tensor([[[[-6.6579e-01,  6.4557e-01, -1.2792e-01,  ...,  9.3953e-01,\n",
      "           -8.1618e-02, -1.7144e-02],\n",
      "          [-2.6058e-01, -1.5898e+00, -8.3961e-02,  ..., -3.4076e-01,\n",
      "            1.9789e-01,  5.5795e-01]],\n",
      "\n",
      "         [[-8.8320e-01,  9.9039e-01,  2.2099e-02,  ...,  7.9228e-01,\n",
      "           -3.3737e-02, -1.6574e-01],\n",
      "          [-2.0995e-01, -1.4808e+00,  5.8085e-02,  ..., -2.0243e-01,\n",
      "            3.3521e-01,  5.2734e-01]],\n",
      "\n",
      "         [[-7.9185e-01,  1.0858e+00,  1.7239e-01,  ...,  8.2114e-01,\n",
      "           -1.7668e-03, -9.2969e-02],\n",
      "          [-2.2058e-01, -1.3562e+00,  1.5823e-01,  ..., -2.4818e-01,\n",
      "            3.4140e-01,  3.5579e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.8716e-01,  8.8315e-01, -3.9746e-02,  ...,  8.7954e-01,\n",
      "           -3.7598e-02, -2.3205e-02],\n",
      "          [-2.4689e-01, -1.4286e+00, -4.6750e-02,  ..., -2.8260e-01,\n",
      "            2.4200e-01,  5.0197e-01]],\n",
      "\n",
      "         [[-8.7724e-01,  9.3878e-01, -5.1265e-03,  ...,  7.7515e-01,\n",
      "           -3.3254e-02, -9.4621e-02],\n",
      "          [-3.1367e-01, -1.3701e+00,  3.1404e-04,  ..., -2.7861e-01,\n",
      "            3.3010e-01,  4.3762e-01]],\n",
      "\n",
      "         [[-9.0475e-01,  1.0966e+00, -1.6707e-03,  ...,  7.9319e-01,\n",
      "           -2.6434e-02, -2.3043e-01],\n",
      "          [-1.7606e-01, -1.3592e+00,  7.7075e-03,  ..., -1.9392e-01,\n",
      "            2.7481e-01,  4.0211e-01]]],\n",
      "\n",
      "\n",
      "        [[[-5.8339e-01,  3.8702e-01, -4.0224e-01,  ...,  7.3043e-01,\n",
      "           -3.4552e-01, -3.5297e-01],\n",
      "          [ 1.0672e-01, -8.5056e-01,  8.9629e-02,  ...,  3.5273e-01,\n",
      "            5.3112e-01,  4.4658e-01]],\n",
      "\n",
      "         [[-6.0845e-01,  6.9125e-01, -4.9332e-01,  ...,  6.9351e-01,\n",
      "           -1.6033e-01, -2.6245e-01],\n",
      "          [ 9.1800e-02, -1.0065e+00,  2.6340e-01,  ...,  1.2189e-01,\n",
      "            4.0580e-01,  3.9846e-01]],\n",
      "\n",
      "         [[-5.4896e-01,  7.4830e-01, -3.4699e-01,  ...,  8.1864e-01,\n",
      "           -2.4148e-01, -3.1103e-01],\n",
      "          [-1.2821e-01, -9.8436e-01,  2.8586e-01,  ...,  7.2176e-02,\n",
      "            5.2822e-01,  4.7419e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.6552e-01,  7.6942e-01, -2.8468e-01,  ...,  8.0250e-01,\n",
      "           -2.7656e-01, -2.9515e-01],\n",
      "          [-1.1756e-02, -1.0981e+00,  2.4971e-01,  ...,  5.2065e-02,\n",
      "            4.5852e-01,  4.4733e-01]],\n",
      "\n",
      "         [[-6.5847e-01,  8.7263e-01, -3.4111e-01,  ...,  6.5625e-01,\n",
      "           -2.1551e-01, -2.2339e-01],\n",
      "          [-6.4263e-03, -8.5171e-01,  2.6549e-01,  ...,  1.3514e-01,\n",
      "            5.1609e-01,  4.6551e-01]],\n",
      "\n",
      "         [[-6.4305e-01,  9.3765e-01, -3.7135e-01,  ...,  6.7908e-01,\n",
      "           -1.9513e-01, -3.4877e-01],\n",
      "          [ 1.2081e-01, -9.7949e-01,  2.6853e-01,  ...,  1.4350e-01,\n",
      "            3.8882e-01,  3.7690e-01]]]], grad_fn=<TransposeBackward0>)\n",
      "tensor([[[-1.0878,  1.2102, -1.3789,  ..., -0.0495,  0.1593, -0.1572],\n",
      "         [-0.2102,  2.0157,  1.3490,  ..., -0.7951,  0.8925,  0.4499],\n",
      "         [-2.1776,  2.3204,  1.2400,  ..., -0.3121,  1.1311,  1.0622],\n",
      "         ...,\n",
      "         [-0.9691,  0.8463,  0.7775,  ..., -0.6537,  1.3339,  0.3835],\n",
      "         [-0.5320,  0.4215, -0.0111,  ..., -1.4066, -0.0681,  1.1627],\n",
      "         [-1.4144,  2.6508, -0.0996,  ..., -0.1121,  0.2904,  1.4066]],\n",
      "\n",
      "        [[-1.0315,  0.8745, -1.7816,  ...,  0.6388,  0.3328, -0.3122],\n",
      "         [-0.5492,  1.5015,  0.1782,  ..., -0.1891,  0.6282,  0.6068],\n",
      "         [-0.5476,  2.7782,  0.5743,  ..., -0.7655,  1.5492,  0.9248],\n",
      "         ...,\n",
      "         [-0.7172,  1.1259,  0.8947,  ..., -0.3233,  1.2481,  1.1302],\n",
      "         [-0.3435, -0.0249, -0.4336,  ...,  0.6013,  0.1531,  0.9444],\n",
      "         [-1.3065,  2.5513, -0.4970,  ...,  0.2181,  0.3281,  1.4046]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[-1.0878,  1.2102, -1.3789,  ..., -0.0495,  0.1593, -0.1572],\n",
      "         [-0.2102,  2.0157,  1.3490,  ..., -0.7951,  0.8925,  0.4499],\n",
      "         [-2.1776,  2.3204,  1.2400,  ..., -0.3121,  1.1311,  1.0622],\n",
      "         ...,\n",
      "         [-0.9691,  0.8463,  0.7775,  ..., -0.6537,  1.3339,  0.3835],\n",
      "         [-0.5320,  0.4215, -0.0111,  ..., -1.4066, -0.0681,  1.1627],\n",
      "         [-1.4144,  2.6508, -0.0996,  ..., -0.1121,  0.2904,  1.4066]],\n",
      "\n",
      "        [[-1.0315,  0.8745, -1.7816,  ...,  0.6388,  0.3328, -0.3122],\n",
      "         [-0.5492,  1.5015,  0.1782,  ..., -0.1891,  0.6282,  0.6068],\n",
      "         [-0.5476,  2.7782,  0.5743,  ..., -0.7655,  1.5492,  0.9248],\n",
      "         ...,\n",
      "         [-0.7172,  1.1259,  0.8947,  ..., -0.3233,  1.2481,  1.1302],\n",
      "         [-0.3435, -0.0249, -0.4336,  ...,  0.6013,  0.1531,  0.9444],\n",
      "         [-1.3065,  2.5513, -0.4970,  ...,  0.2181,  0.3281,  1.4046]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[-1.0878,  1.2102, -1.3789,  ..., -0.0495,  0.1593, -0.1572],\n",
      "         [-0.2102,  2.0157,  1.3490,  ..., -0.7951,  0.8925,  0.4499],\n",
      "         [-2.1776,  2.3204,  1.2400,  ..., -0.3121,  1.1311,  1.0622],\n",
      "         ...,\n",
      "         [-0.9691,  0.8463,  0.7775,  ..., -0.6537,  1.3339,  0.3835],\n",
      "         [-0.5320,  0.4215, -0.0111,  ..., -1.4066, -0.0681,  1.1627],\n",
      "         [-1.4144,  2.6508, -0.0996,  ..., -0.1121,  0.2904,  1.4066]],\n",
      "\n",
      "        [[-1.0315,  0.8745, -1.7816,  ...,  0.6388,  0.3328, -0.3122],\n",
      "         [-0.5492,  1.5015,  0.1782,  ..., -0.1891,  0.6282,  0.6068],\n",
      "         [-0.5476,  2.7782,  0.5743,  ..., -0.7655,  1.5492,  0.9248],\n",
      "         ...,\n",
      "         [-0.7172,  1.1259,  0.8947,  ..., -0.3233,  1.2481,  1.1302],\n",
      "         [-0.3435, -0.0249, -0.4336,  ...,  0.6013,  0.1531,  0.9444],\n",
      "         [-1.3065,  2.5513, -0.4970,  ...,  0.2181,  0.3281,  1.4046]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[[-1.0878,  1.2102, -1.3789,  ...,  1.1455,  0.1895,  1.0707],\n",
      "          [ 0.8665, -1.5603,  0.1354,  ..., -0.0495,  0.1593, -0.1572]],\n",
      "\n",
      "         [[-0.2102,  2.0157,  1.3490,  ...,  1.2642,  0.3863, -0.9916],\n",
      "          [-0.7890, -2.1095,  0.0661,  ..., -0.7951,  0.8925,  0.4499]],\n",
      "\n",
      "         [[-2.1776,  2.3204,  1.2400,  ...,  0.4794,  0.6675, -0.8232],\n",
      "          [-0.7908, -2.5155,  0.2508,  ..., -0.3121,  1.1311,  1.0622]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.9691,  0.8463,  0.7775,  ...,  0.9193, -0.1725,  0.6369],\n",
      "          [-0.9901, -1.4500,  1.2258,  ..., -0.6537,  1.3339,  0.3835]],\n",
      "\n",
      "         [[-0.5320,  0.4215, -0.0111,  ...,  1.7587, -0.3542,  0.0384],\n",
      "          [-0.6126, -2.7001, -0.8135,  ..., -1.4066, -0.0681,  1.1627]],\n",
      "\n",
      "         [[-1.4144,  2.6508, -0.0996,  ...,  1.2805, -0.2722, -0.7515],\n",
      "          [-0.1753, -1.5480, -0.3376,  ..., -0.1121,  0.2904,  1.4066]]],\n",
      "\n",
      "\n",
      "        [[[-1.0315,  0.8745, -1.7816,  ...,  0.9127,  0.0420,  0.8318],\n",
      "          [ 1.2669, -0.9200,  0.1918,  ...,  0.6388,  0.3328, -0.3122]],\n",
      "\n",
      "         [[-0.5492,  1.5015,  0.1782,  ...,  1.8722, -0.4044, -0.7830],\n",
      "          [ 0.5474, -1.0941,  0.9973,  ..., -0.1891,  0.6282,  0.6068]],\n",
      "\n",
      "         [[-0.5476,  2.7782,  0.5743,  ...,  0.4251, -0.0042, -0.8595],\n",
      "          [-0.3177, -2.2132,  0.5119,  ..., -0.7655,  1.5492,  0.9248]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.7172,  1.1259,  0.8947,  ...,  1.7707, -0.3925, -0.2114],\n",
      "          [-0.5463, -0.6512,  1.0917,  ..., -0.3233,  1.2481,  1.1302]],\n",
      "\n",
      "         [[-0.3435, -0.0249, -0.4336,  ...,  1.4356, -1.3802, -0.7963],\n",
      "          [ 1.0188, -1.4260,  0.3093,  ...,  0.6013,  0.1531,  0.9444]],\n",
      "\n",
      "         [[-1.3065,  2.5513, -0.4970,  ...,  1.2095, -0.3593, -0.8650],\n",
      "          [ 0.0808, -1.2824, -0.2125,  ...,  0.2181,  0.3281,  1.4046]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.0636,  0.1248,  0.1897,  ..., -0.4406, -0.7755, -0.1032],\n",
      "         [ 0.1629, -0.5194,  0.4349,  ..., -1.2121, -0.3927,  0.5481],\n",
      "         [ 0.1550, -0.2967,  0.6748,  ..., -1.1692, -0.3082,  0.2283],\n",
      "         ...,\n",
      "         [ 0.1092, -0.4554,  0.3753,  ..., -0.8062,  0.2608, -0.0807],\n",
      "         [-0.0019,  0.0395,  0.2863,  ..., -1.3334, -0.2363,  0.2517],\n",
      "         [-0.0911, -0.1917,  0.3195,  ..., -0.9195, -0.3417,  0.2924]],\n",
      "\n",
      "        [[-0.3748,  0.1789,  0.0654,  ...,  0.0452, -0.7953, -0.2162],\n",
      "         [ 0.0348, -0.3295,  0.0222,  ..., -0.0913, -0.4374,  0.5010],\n",
      "         [-0.0238, -0.0159,  0.4145,  ..., -0.7409, -0.5174,  0.1650],\n",
      "         ...,\n",
      "         [-0.4040, -0.6301,  0.4023,  ..., -0.4905,  0.1822,  0.1634],\n",
      "         [-0.7049,  0.0283,  0.2161,  ..., -0.2947, -0.4770, -0.1933],\n",
      "         [-0.3157, -0.1442,  0.2461,  ..., -0.6054, -0.4040,  0.2384]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.0636,  0.1248,  0.1897,  ..., -0.4406, -0.7755, -0.1032],\n",
      "         [ 0.1629, -0.5194,  0.4349,  ..., -1.2121, -0.3927,  0.5481],\n",
      "         [ 0.1550, -0.2967,  0.6748,  ..., -1.1692, -0.3082,  0.2283],\n",
      "         ...,\n",
      "         [ 0.1092, -0.4554,  0.3753,  ..., -0.8062,  0.2608, -0.0807],\n",
      "         [-0.0019,  0.0395,  0.2863,  ..., -1.3334, -0.2363,  0.2517],\n",
      "         [-0.0911, -0.1917,  0.3195,  ..., -0.9195, -0.3417,  0.2924]],\n",
      "\n",
      "        [[-0.3748,  0.1789,  0.0654,  ...,  0.0452, -0.7953, -0.2162],\n",
      "         [ 0.0348, -0.3295,  0.0222,  ..., -0.0913, -0.4374,  0.5010],\n",
      "         [-0.0238, -0.0159,  0.4145,  ..., -0.7409, -0.5174,  0.1650],\n",
      "         ...,\n",
      "         [-0.4040, -0.6301,  0.4023,  ..., -0.4905,  0.1822,  0.1634],\n",
      "         [-0.7049,  0.0283,  0.2161,  ..., -0.2947, -0.4770, -0.1933],\n",
      "         [-0.3157, -0.1442,  0.2461,  ..., -0.6054, -0.4040,  0.2384]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.0636,  0.1248,  0.1897,  ..., -0.4936, -0.1714,  0.2535],\n",
      "          [-0.2796,  0.0785, -0.2679,  ..., -0.4406, -0.7755, -0.1032]],\n",
      "\n",
      "         [[ 0.1629, -0.5194,  0.4349,  ..., -0.2124, -0.3088, -0.2224],\n",
      "          [-0.3270,  0.3583, -0.2431,  ..., -1.2121, -0.3927,  0.5481]],\n",
      "\n",
      "         [[ 0.1550, -0.2967,  0.6748,  ..., -0.2913,  0.1013, -0.1054],\n",
      "          [-0.4486,  0.2001, -0.4338,  ..., -1.1692, -0.3082,  0.2283]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1092, -0.4554,  0.3753,  ..., -0.2676, -0.3390, -0.4092],\n",
      "          [-0.6562,  0.4910, -0.3821,  ..., -0.8062,  0.2608, -0.0807]],\n",
      "\n",
      "         [[-0.0019,  0.0395,  0.2863,  ..., -0.3061, -0.0142, -0.4929],\n",
      "          [-0.2892,  0.4441, -0.4846,  ..., -1.3334, -0.2363,  0.2517]],\n",
      "\n",
      "         [[-0.0911, -0.1917,  0.3195,  ..., -0.3873,  0.1008, -0.1819],\n",
      "          [-0.1361,  0.3124, -0.4871,  ..., -0.9195, -0.3417,  0.2924]]],\n",
      "\n",
      "\n",
      "        [[[-0.3748,  0.1789,  0.0654,  ..., -0.5024, -0.0289,  0.5036],\n",
      "          [-0.1743, -0.0026, -0.2650,  ...,  0.0452, -0.7953, -0.2162]],\n",
      "\n",
      "         [[ 0.0348, -0.3295,  0.0222,  ..., -0.1406, -0.0664,  0.2800],\n",
      "          [-0.1725,  0.2022, -0.4547,  ..., -0.0913, -0.4374,  0.5010]],\n",
      "\n",
      "         [[-0.0238, -0.0159,  0.4145,  ..., -0.1764, -0.0414, -0.0166],\n",
      "          [-0.2366,  0.1505, -0.4370,  ..., -0.7409, -0.5174,  0.1650]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.4040, -0.6301,  0.4023,  ..., -0.1975,  0.3124, -0.0875],\n",
      "          [-0.7129,  0.3788, -0.6636,  ..., -0.4905,  0.1822,  0.1634]],\n",
      "\n",
      "         [[-0.7049,  0.0283,  0.2161,  ..., -0.2775,  0.2323, -0.0241],\n",
      "          [-0.2328,  0.4978, -0.3987,  ..., -0.2947, -0.4770, -0.1933]],\n",
      "\n",
      "         [[-0.3157, -0.1442,  0.2461,  ..., -0.3899,  0.2217, -0.0472],\n",
      "          [-0.0570,  0.2603, -0.4933,  ..., -0.6054, -0.4040,  0.2384]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-1.0878,  1.2102, -1.3789,  ..., -0.0495,  0.1593, -0.1572],\n",
      "         [-0.2102,  2.0157,  1.3490,  ..., -0.7951,  0.8925,  0.4499],\n",
      "         [-2.1776,  2.3204,  1.2400,  ..., -0.3121,  1.1311,  1.0622],\n",
      "         ...,\n",
      "         [-0.9691,  0.8463,  0.7775,  ..., -0.6537,  1.3339,  0.3835],\n",
      "         [-0.5320,  0.4215, -0.0111,  ..., -1.4066, -0.0681,  1.1627],\n",
      "         [-1.4144,  2.6508, -0.0996,  ..., -0.1121,  0.2904,  1.4066]],\n",
      "\n",
      "        [[-1.0315,  0.8745, -1.7816,  ...,  0.6388,  0.3328, -0.3122],\n",
      "         [-0.5492,  1.5015,  0.1782,  ..., -0.1891,  0.6282,  0.6068],\n",
      "         [-0.5476,  2.7782,  0.5743,  ..., -0.7655,  1.5492,  0.9248],\n",
      "         ...,\n",
      "         [-0.7172,  1.1259,  0.8947,  ..., -0.3233,  1.2481,  1.1302],\n",
      "         [-0.3435, -0.0249, -0.4336,  ...,  0.6013,  0.1531,  0.9444],\n",
      "         [-1.3065,  2.5513, -0.4970,  ...,  0.2181,  0.3281,  1.4046]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[-1.0878,  1.2102, -1.3789,  ..., -0.0495,  0.1593, -0.1572],\n",
      "         [-0.2102,  2.0157,  1.3490,  ..., -0.7951,  0.8925,  0.4499],\n",
      "         [-2.1776,  2.3204,  1.2400,  ..., -0.3121,  1.1311,  1.0622],\n",
      "         ...,\n",
      "         [-0.9691,  0.8463,  0.7775,  ..., -0.6537,  1.3339,  0.3835],\n",
      "         [-0.5320,  0.4215, -0.0111,  ..., -1.4066, -0.0681,  1.1627],\n",
      "         [-1.4144,  2.6508, -0.0996,  ..., -0.1121,  0.2904,  1.4066]],\n",
      "\n",
      "        [[-1.0315,  0.8745, -1.7816,  ...,  0.6388,  0.3328, -0.3122],\n",
      "         [-0.5492,  1.5015,  0.1782,  ..., -0.1891,  0.6282,  0.6068],\n",
      "         [-0.5476,  2.7782,  0.5743,  ..., -0.7655,  1.5492,  0.9248],\n",
      "         ...,\n",
      "         [-0.7172,  1.1259,  0.8947,  ..., -0.3233,  1.2481,  1.1302],\n",
      "         [-0.3435, -0.0249, -0.4336,  ...,  0.6013,  0.1531,  0.9444],\n",
      "         [-1.3065,  2.5513, -0.4970,  ...,  0.2181,  0.3281,  1.4046]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[[-1.0878,  1.2102, -1.3789,  ...,  1.1455,  0.1895,  1.0707],\n",
      "          [ 0.8665, -1.5603,  0.1354,  ..., -0.0495,  0.1593, -0.1572]],\n",
      "\n",
      "         [[-0.2102,  2.0157,  1.3490,  ...,  1.2642,  0.3863, -0.9916],\n",
      "          [-0.7890, -2.1095,  0.0661,  ..., -0.7951,  0.8925,  0.4499]],\n",
      "\n",
      "         [[-2.1776,  2.3204,  1.2400,  ...,  0.4794,  0.6675, -0.8232],\n",
      "          [-0.7908, -2.5155,  0.2508,  ..., -0.3121,  1.1311,  1.0622]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.9691,  0.8463,  0.7775,  ...,  0.9193, -0.1725,  0.6369],\n",
      "          [-0.9901, -1.4500,  1.2258,  ..., -0.6537,  1.3339,  0.3835]],\n",
      "\n",
      "         [[-0.5320,  0.4215, -0.0111,  ...,  1.7587, -0.3542,  0.0384],\n",
      "          [-0.6126, -2.7001, -0.8135,  ..., -1.4066, -0.0681,  1.1627]],\n",
      "\n",
      "         [[-1.4144,  2.6508, -0.0996,  ...,  1.2805, -0.2722, -0.7515],\n",
      "          [-0.1753, -1.5480, -0.3376,  ..., -0.1121,  0.2904,  1.4066]]],\n",
      "\n",
      "\n",
      "        [[[-1.0315,  0.8745, -1.7816,  ...,  0.9127,  0.0420,  0.8318],\n",
      "          [ 1.2669, -0.9200,  0.1918,  ...,  0.6388,  0.3328, -0.3122]],\n",
      "\n",
      "         [[-0.5492,  1.5015,  0.1782,  ...,  1.8722, -0.4044, -0.7830],\n",
      "          [ 0.5474, -1.0941,  0.9973,  ..., -0.1891,  0.6282,  0.6068]],\n",
      "\n",
      "         [[-0.5476,  2.7782,  0.5743,  ...,  0.4251, -0.0042, -0.8595],\n",
      "          [-0.3177, -2.2132,  0.5119,  ..., -0.7655,  1.5492,  0.9248]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.7172,  1.1259,  0.8947,  ...,  1.7707, -0.3925, -0.2114],\n",
      "          [-0.5463, -0.6512,  1.0917,  ..., -0.3233,  1.2481,  1.1302]],\n",
      "\n",
      "         [[-0.3435, -0.0249, -0.4336,  ...,  1.4356, -1.3802, -0.7963],\n",
      "          [ 1.0188, -1.4260,  0.3093,  ...,  0.6013,  0.1531,  0.9444]],\n",
      "\n",
      "         [[-1.3065,  2.5513, -0.4970,  ...,  1.2095, -0.3593, -0.8650],\n",
      "          [ 0.0808, -1.2824, -0.2125,  ...,  0.2181,  0.3281,  1.4046]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.8651,  1.3497,  0.4584,  ...,  1.3365, -0.1987, -0.0233],\n",
      "          [-0.8964,  1.3602,  0.5627,  ...,  1.3122, -0.1960, -0.1188],\n",
      "          [-0.8880,  1.3615,  0.5176,  ...,  1.3265, -0.2072, -0.1296],\n",
      "          ...,\n",
      "          [-0.8969,  1.3987,  0.4932,  ...,  1.2901, -0.1531, -0.0878],\n",
      "          [-0.9325,  1.3951,  0.4780,  ...,  1.2898, -0.1927, -0.1240],\n",
      "          [-0.8794,  1.3160,  0.4746,  ...,  1.3233, -0.2105, -0.0904]],\n",
      "\n",
      "         [[-0.2176, -2.1197,  0.1113,  ..., -0.6437,  0.6189,  0.7833],\n",
      "          [-0.2641, -2.0208,  0.1135,  ..., -0.6041,  0.6737,  0.8113],\n",
      "          [-0.3042, -2.0141,  0.0837,  ..., -0.6211,  0.6821,  0.8117],\n",
      "          ...,\n",
      "          [-0.2770, -2.0508,  0.0476,  ..., -0.6401,  0.6231,  0.8280],\n",
      "          [-0.3234, -2.0347,  0.0713,  ..., -0.6668,  0.6680,  0.8235],\n",
      "          [-0.2585, -2.0124,  0.0735,  ..., -0.5782,  0.6719,  0.7561]]],\n",
      "\n",
      "\n",
      "        [[[-0.8902,  0.8359, -0.3946,  ...,  0.9854, -0.3853, -0.2252],\n",
      "          [-0.7858,  0.9806, -0.3242,  ...,  1.0761, -0.4108, -0.2654],\n",
      "          [-0.6771,  1.0897, -0.2627,  ...,  1.1065, -0.3659, -0.3433],\n",
      "          ...,\n",
      "          [-0.6739,  1.1243, -0.2591,  ...,  1.1270, -0.4091, -0.3434],\n",
      "          [-0.7411,  0.9700, -0.3698,  ...,  1.0659, -0.3638, -0.2995],\n",
      "          [-0.7109,  1.0754, -0.2670,  ...,  1.0972, -0.3593, -0.3112]],\n",
      "\n",
      "         [[ 0.2788, -1.2092,  0.1339,  ...,  0.2781,  0.9059,  0.6790],\n",
      "          [ 0.1943, -1.2829,  0.1852,  ...,  0.1611,  0.9035,  0.7409],\n",
      "          [ 0.1788, -1.2489,  0.1961,  ...,  0.1656,  0.9126,  0.7307],\n",
      "          ...,\n",
      "          [ 0.2201, -1.3255,  0.2482,  ...,  0.1122,  0.8697,  0.7393],\n",
      "          [ 0.2036, -1.2369,  0.2038,  ...,  0.1782,  0.9078,  0.7368],\n",
      "          [ 0.2220, -1.2847,  0.2053,  ...,  0.1643,  0.8811,  0.6999]]]],\n",
      "       grad_fn=<ScaledDotProductFlashAttentionForCpuBackward0>)\n",
      "tensor([[[[-0.8651,  1.3497,  0.4584,  ...,  1.3365, -0.1987, -0.0233],\n",
      "          [-0.2176, -2.1197,  0.1113,  ..., -0.6437,  0.6189,  0.7833]],\n",
      "\n",
      "         [[-0.8964,  1.3602,  0.5627,  ...,  1.3122, -0.1960, -0.1188],\n",
      "          [-0.2641, -2.0208,  0.1135,  ..., -0.6041,  0.6737,  0.8113]],\n",
      "\n",
      "         [[-0.8880,  1.3615,  0.5176,  ...,  1.3265, -0.2072, -0.1296],\n",
      "          [-0.3042, -2.0141,  0.0837,  ..., -0.6211,  0.6821,  0.8117]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.8969,  1.3987,  0.4932,  ...,  1.2901, -0.1531, -0.0878],\n",
      "          [-0.2770, -2.0508,  0.0476,  ..., -0.6401,  0.6231,  0.8280]],\n",
      "\n",
      "         [[-0.9325,  1.3951,  0.4780,  ...,  1.2898, -0.1927, -0.1240],\n",
      "          [-0.3234, -2.0347,  0.0713,  ..., -0.6668,  0.6680,  0.8235]],\n",
      "\n",
      "         [[-0.8794,  1.3160,  0.4746,  ...,  1.3233, -0.2105, -0.0904],\n",
      "          [-0.2585, -2.0124,  0.0735,  ..., -0.5782,  0.6719,  0.7561]]],\n",
      "\n",
      "\n",
      "        [[[-0.8902,  0.8359, -0.3946,  ...,  0.9854, -0.3853, -0.2252],\n",
      "          [ 0.2788, -1.2092,  0.1339,  ...,  0.2781,  0.9059,  0.6790]],\n",
      "\n",
      "         [[-0.7858,  0.9806, -0.3242,  ...,  1.0761, -0.4108, -0.2654],\n",
      "          [ 0.1943, -1.2829,  0.1852,  ...,  0.1611,  0.9035,  0.7409]],\n",
      "\n",
      "         [[-0.6771,  1.0897, -0.2627,  ...,  1.1065, -0.3659, -0.3433],\n",
      "          [ 0.1788, -1.2489,  0.1961,  ...,  0.1656,  0.9126,  0.7307]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6739,  1.1243, -0.2591,  ...,  1.1270, -0.4091, -0.3434],\n",
      "          [ 0.2201, -1.3255,  0.2482,  ...,  0.1122,  0.8697,  0.7393]],\n",
      "\n",
      "         [[-0.7411,  0.9700, -0.3698,  ...,  1.0659, -0.3638, -0.2995],\n",
      "          [ 0.2036, -1.2369,  0.2038,  ...,  0.1782,  0.9078,  0.7368]],\n",
      "\n",
      "         [[-0.7109,  1.0754, -0.2670,  ...,  1.0972, -0.3593, -0.3112],\n",
      "          [ 0.2220, -1.2847,  0.2053,  ...,  0.1643,  0.8811,  0.6999]]]],\n",
      "       grad_fn=<TransposeBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_pooler_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: classifier\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from chop.pipelines import CompressionPipeline\n",
    "from chop import MaseGraph\n",
    "\n",
    "mg = MaseGraph(model)\n",
    "pipe = CompressionPipeline()\n",
    "\n",
    "quantization_config = {\n",
    "    \"by\": \"type\",\n",
    "    \"default\": {\n",
    "        \"config\": {\n",
    "            \"name\": None,\n",
    "        }\n",
    "    },\n",
    "    \"linear\": {\n",
    "        \"config\": {\n",
    "            \"name\": \"integer\",\n",
    "            # data\n",
    "            \"data_in_width\": 8,\n",
    "            \"data_in_frac_width\": 4,\n",
    "            # weight\n",
    "            \"weight_width\": 8,\n",
    "            \"weight_frac_width\": 4,\n",
    "            # bias\n",
    "            \"bias_width\": 8,\n",
    "            \"bias_frac_width\": 4,\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "pruning_config = {\n",
    "    \"weight\": {\n",
    "        \"sparsity\": 0.5,\n",
    "        \"method\": \"l1-norm\",\n",
    "        \"scope\": \"local\",\n",
    "    },\n",
    "    \"activation\": {\n",
    "        \"sparsity\": 0.5,\n",
    "        \"method\": \"l1-norm\",\n",
    "        \"scope\": \"local\",\n",
    "    },\n",
    "}\n",
    "\n",
    "mg, _ = pipe(\n",
    "    mg,\n",
    "    pass_args={\n",
    "        \"quantize_transform_pass\": quantization_config,\n",
    "        \"prune_transform_pass\": pruning_config,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, export the MaseGraph for the compressed checkpoint to be used in future tutorials for hardware generation and distributed deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mExporting MaseGraph to /home/khl22/tutorial_5_nas_compressed.pt, /home/khl22/tutorial_5_nas_compressed.mz\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mExporting GraphModule to /home/khl22/tutorial_5_nas_compressed.pt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mSaving state_dict format\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mExporting MaseMetadata to /home/khl22/tutorial_5_nas_compressed.mz\u001b[0m\n",
      "\u001b[33mWARNING \u001b[0m \u001b[34mFailed to pickle call_function node: finfo\u001b[0m\n",
      "\u001b[33mWARNING \u001b[0m \u001b[34mcannot pickle 'torch.finfo' object\u001b[0m\n",
      "\u001b[33mWARNING \u001b[0m \u001b[34mFailed to pickle call_function node: getattr_3\u001b[0m\n",
      "\u001b[33mWARNING \u001b[0m \u001b[34mcannot pickle 'torch.finfo' object\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "mg.export(f\"{Path.home()}/tutorial_5_nas_compressed\", save_format=\"state_dict\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plena2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
