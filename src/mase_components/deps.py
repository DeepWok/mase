"""

Contains the single source of truth for modules and their dependencies.

Entry format:
"<group>/<module>": [<group1>, <group2>, ...]

"""

MASE_HW_DEPS = {
    # Activations
    "activation_layers/fixed_relu": [],
    "activation_layers/fixed_leaky_relu": [],
    "activation_layers/fixed_tanh": ["cast"],
    "activation_layers/fixed_selu": [
        "cast",
        "activation_layers",
        "scalar_operators/fixed",
    ],
    "activation_layers/fixed_gelu": [
        "common",
        "memory",
        "activation_layers",
    ],
    "activation_layers/fixed_softsign": [
        "common",
        "activation_layers",
        "linear_layers/fixed_operators",
    ],
    "activation_layers/fixed_softplus": ["activation_layers"],
    "activation_layers/fixed_hardshrink": ["common", "cast"],
    "activation_layers/fixed_hardswish": ["common", "fixed_arithmetic"],
    "activation_layers/fixed_silu": ["common", "cast", "activation_layers"],
    "activation_layers/fixed_elu": ["common", "cast", "activation_layers"],
    "activation_layers/fixed_sigmoid": ["common", "cast", "activation_layers"],
    "activation_layers/fixed_softshrink": ["common", "cast"],
    "activation_layers/fixed_logsigmoid": ["common", "cast", "activation_layers"],
    "activation_layers/fixed_softmax": [
        "common",
        "cast",
        "fixed_arithmetic",
        "conv",
        "activation_layers",
    ],
    "activation_layers/fixed_softermax": [
        "common",
        "cast",
        "fixed_arithmetic",
        "conv",
        "matmul",
        "activation_layers",
    ],
    # Attention
    "transformer_layers/fixed_self_attention": [
        "transformer_layers",
        "activation_layers",
        "arbiters",
        "cast",
        "common",
        "linear_layers/fixed_operators",
        "linear_layers/fixed_linear_layer",
        "linear_layers/matmul",
    ],
    "transformer_layers/fixed_self_attention_head": [
        "transformer_layers",
        "cast",
        "common",
        "linear_layers/fixed_operators",
        "linear_layers/fixed_linear_layer",
        "matmul",
        "activation_layers",
    ],
    "transformer_layers/fixed_self_attention_single_precision_wrapper": [
        "transformer_layers",
        "activation_layers",
        "arbiters",
        "cast",
        "common",
        "linear_layers/fixed_operators",
        "linear_layers/fixed_linear_layer",
        "matmul",
    ],
    "arithmetic/mac": ["fixed_arithmetic", "float_arithmetic"],
    # Binary arithmetic
    "binary_arith/binary_activation_layer_binary_mult": [],
    "binary_arith/binary_activation_layer_binary_vector_mult": [
        "binary_arith",
        "common",
    ],
    "binary_arith/binary_activation_layer_binary_adder_tree_layer": [],
    "binary_arith/binary_activation_layer_binary_adder_tree": [
        "binary_arith",
        "common",
    ],
    "binary_arith/binary_activation_layer_binary_dot_product": [
        "binary_arith",
        "common",
    ],
    "binary_arith/fixed_activation_layer_binary_mult": [],
    "binary_arith/fixed_activation_layer_binary_vector_mult": [
        "binary_arith",
        "common",
    ],
    "binary_arith/fixed_activation_layer_binary_dot_product": [
        "binary_arith",
        "fixed_arithmetic",
        "common",
    ],
    "buffers/hybrid_buffer": ["buffers"],
    # Linear
    "linear_layers/fixed_linear_layer/fixed_linear": [
        "cast",
        "common",
        "memory",
        "linear_layers/matmul",
        "linear_layers/fixed_operators",
        "scalar_operators/fixed",
    ],
    "linear_layers/binary_activation_layer_binary_linear": [
        "cast",
        "linear_layers/fixed_linear_layer",
        "linear_layers/fixed_operators",
        "binary_arith",
        "common",
    ],
    "linear_layers/fixed_activation_layer_binary_linear": [
        "cast",
        "linear_layers/fixed_linear_layer",
        "linear_layers/fixed_operators",
        "binary_arith",
        "common",
    ],
    # Fixed arithmetic
    "fixed_arithmetic/fixed_range_reduction": [],
    "fixed_arithmetic/fixed_lut_index": [],
    "fixed_arithmetic/fixed_range_augmentation": [],
    "fixed_arithmetic/fixed_mult": [],
    "fixed_arithmetic/fixed_accumulator": ["common"],
    "fixed_arithmetic/fixed_adder_tree": ["fixed_arithmetic", "common"],
    "fixed_arithmetic/fixed_vector_mult": ["fixed_arithmetic", "common"],
    "fixed_arithmetic/fixed_dot_product": ["fixed_arithmetic", "common"],
    "fixed_arithmetic/fixed_matmul_core": [
        "fixed_arithmetic",
        "common",
        "linear",
        "cast",
        "matmul",
    ],
    # Fixed math
    "fixed_math/fixed_exp": ["fixed_math", "cast"],
    "fixed_math/fixed_isqrt": ["fixed_math", "fixed_arithmetic", "common"],
    "fixed_math/fixed_nr_stage": ["fixed_math", "common"],
    "fixed_math/fixed_series_approx": ["fixed_math"],
    # Float arithmetic
    "float_arithmetic/float_mac": ["float_arithmetic"],
    "float_arithmetic/float_multiplier": ["float_arithmetic"],
    # Cast
    "cast/fixed_cast": [],
    "cast/fixed_rounding": ["cast"],
    "cast/fixed_signed_cast": ["cast"],
    "cast/bram_cast": ["memory"],
    "cast/bram2hs_cast": ["memory"],
    "cast/hs2bram_cast": ["memory"],
    # Common
    "common/cut_data": ["common"],
    "common/wrap_data": ["common"],
    "common/lut": [],
    "common/join2": [],
    "common/register_slice": ["common"],
    # Memory
    "memory/skid_buffer": [],
    "memory/fifo": ["memory"],
    "memory/input_buffer": ["memory"],
    "memory/repeat_circular_buffer": ["memory"],
    "memory/ram_block": [],
    "memory/unpacked_fifo": ["memory"],
    "memory/unpacked_skid_buffer": ["memory"],
    # Convolution
    "convolution_layers/convolution": [
        "cast",
        "convolution_layers",
        "common",
        "memory",
        "linear_layers/fixed_linear_layer",
        "linear_layers/fixed_operators",
        "linear_layers/matmul",
    ],
    "convolution_layers/binary_activation_layer_binary_convolution": [
        "cast",
        "conv",
        "linear",
        "common",
        "fixed_arithmetic",
    ],
    "conv/sliding_window": ["cast", "conv", "linear", "common", "fixed_arithmetic"],
    "conv/padding": ["cast", "conv", "linear", "common", "fixed_arithmetic"],
    # Matmul
    "matmul/simple_matmul": ["common", "linear", "cast", "fixed_arithmetic", "matmul"],
    "matmul/fixed_matmul": ["common", "linear", "cast", "fixed_arithmetic", "matmul"],
    "matmul/matmul": ["common", "linear", "cast", "fixed_arithmetic", "matmul"],
    "matmul/test_chain_matmul": [
        "common",
        "linear",
        "cast",
        "fixed_arithmetic",
        "matmul",
    ],
    "matmul/transpose": [],
    "matmul/matrix_stream_transpose": ["common", "matmul"],
    # Norm
    "norm/group_norm_2d": ["common", "matmul", "fixed_arithmetic", "norm", "cast"],
    "norm/rms_norm_2d": ["common", "matmul", "fixed_arithmetic", "norm", "cast"],
    "norm/batch_norm_2d": ["norm", "common", "cast", "matmul"],
    # LLM int8
    "llm/scatter": ["llm"],
    "llm/dequantizer": ["llm", "common", "cast", "fixed_arithmetic"],
    "llm/fixed_comparator_tree_layer": ["llm"],
    "llm/fixed_comparator_tree": ["llm", "common"],
    "llm/fixed_linear_dequant": ["llm", "common", "cast", "fixed_arithmetic"],
    "llm/fixed_matmul_core_dequant": ["llm", "common", "cast", "fixed_arithmetic"],
    "llm/quantizer_top": ["llm", "cast", "common", "fixed_arithmetic"],
    "llm/quantizer_part": ["llm", "cast", "common", "fixed_arithmetic"],
    "llm/find_max": ["llm", "common"],
    "llm/quantized_matmul": [
        "llm",
        "fixed_arithmetic",
        "cast",
        "linear",
        "matmul",
        "common",
    ],
    "llm/llm_int8_top": [
        "llm",
        "fixed_arithmetic",
        "cast",
        "linear",
        "matmul",
        "common",
    ],
    # ViT
    "ViT/fixed_patch_embed": [
        "conv",
        "ViT",
        "cast",
        "matmul",
        "linear",
        "attention",
        "common",
        "fixed_arithmetic",
    ],
    "ViT/fixed_msa": [
        "conv",
        "ViT",
        "cast",
        "matmul",
        "linear",
        "attention",
        "common",
        "fixed_arithmetic",
    ],
}
