{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "pip install --no-cache-dir --index-url https://pypi.nvidia.com pytorch-quantization !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    " ./ch transform --config configs/examples/toy_uniform_tensorRT.toml --load /root/mase/TensorRTDev/jsc-tiny_classification_jsc_2024-03-03/software/training_ckpts/best.ckpt --load-type pl\n",
    "./ch train --config configs/examples/toy_uniform_tensorRT.toml\n",
    "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sudo apt update && sudo apt upgrade -y \n",
    "\n",
    "wget https://repo.continuum.io/archive/Anaconda3-2023.09-0-Linux-x86_64.sh \n",
    "\n",
    "bash Anaconda3-2023.09-0-Linux-x86_64.sh \n",
    "\n",
    "Close and reopen terminal\n",
    "\n",
    "source /root/.bashrc\n",
    "\n",
    "conda config --set auto_activate_base false\n",
    "\n",
    "git clone https://github.com/mau-mar/mase/\n",
    "\n",
    "cd mase\n",
    "\n",
    "bash scripts/init-conda.sh\n",
    "\n",
    "source /opt/conda/etc/profile.d/conda.sh\n",
    "\n",
    "conda activate mase\n",
    "\n",
    "conda config --add channels conda-forge\n",
    "\n",
    "git checkout origin/mauro-tensorRT-integration\n",
    "\n",
    "cuda-python\n",
    "absl-py\n",
    "scipy\n",
    "prettytable\n",
    "sphinx-glpi-theme\n",
    "\n",
    "./ch train --config configs/examples/toy_uniform_tensorRT.toml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/mase/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mSet logging level to info\u001b[0m\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0306 10:52:30.346410 139983958759232 logger.py:44] Set logging level to info\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "from pprint import pprint as pp\n",
    "\n",
    "# # figure out the correct path\n",
    "machop_path = Path(\".\").resolve().parent /\"machop\"\n",
    "assert machop_path.exists(), \"Failed to find machop at: {}\".format(machop_path)\n",
    "sys.path.append(str(machop_path))\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch_tensorrt\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import pytorch_quantization\n",
    "from pytorch_quantization import nn as quant_nn\n",
    "from pytorch_quantization import quant_modules\n",
    "from pytorch_quantization.tensor_quant import QuantDescriptor\n",
    "from pytorch_quantization import calib\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(pytorch_quantization.__version__)\n",
    "\n",
    "from chop.dataset import MaseDataModule, get_dataset_info\n",
    "from chop.tools.logger import set_logging_verbosity\n",
    "\n",
    "from chop.passes.graph import (\n",
    "    save_node_meta_param_interface_pass,\n",
    "    report_node_meta_param_analysis_pass,\n",
    "    profile_statistics_analysis_pass,\n",
    "    add_common_metadata_analysis_pass,\n",
    "    init_metadata_analysis_pass,\n",
    "    add_software_metadata_analysis_pass,\n",
    "    tensorrt_calibrate_transform_pass,\n",
    "    tensorrt_train_transform_pass,\n",
    "    tensorrt_quantize_transform_pass,\n",
    "    tensorrt_analysis_pass,\n",
    "    )\n",
    "from chop.tools.get_input import InputGenerator\n",
    "from chop.tools.checkpoint_load import load_model\n",
    "from chop.ir import MaseGraph\n",
    "\n",
    "from chop.models import get_model_info, get_model\n",
    "\n",
    "set_logging_verbosity(\"info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from /root/mase/TensorRTDev/jsc-tiny_classification_jsc_2024-03-05/software/training_ckpts/best.ckpt\u001b[0m\n",
      "I0306 10:52:35.560015 139983958759232 checkpoint_load.py:85] Loaded pytorch lightning checkpoint from /root/mase/TensorRTDev/jsc-tiny_classification_jsc_2024-03-05/software/training_ckpts/best.ckpt\n"
     ]
    }
   ],
   "source": [
    "model_name = \"jsc-tiny\"\n",
    "dataset_name = \"jsc\"\n",
    "max_epochs = 1\n",
    "batch_size = 256\n",
    "learning_rate = 1e-3\n",
    "accelerator = \"gpu\"\n",
    "\n",
    "data_module = MaseDataModule(\n",
    "    name=dataset_name,\n",
    "    batch_size=batch_size,\n",
    "    model_name=model_name,\n",
    "    num_workers=0,\n",
    ")\n",
    "data_module.prepare_data()\n",
    "data_module.setup()\n",
    "\n",
    "# üìùÔ∏è change this CHECKPOINT_PATH to the one you trained in Lab1\n",
    "CHECKPOINT_PATH = \"/root/mase/TensorRTDev/jsc-tiny_classification_jsc_2024-03-05/software/training_ckpts/best.ckpt\"\n",
    "#CHECKPOINT_PATH = \"/root/mase/TensorRTDev/jsc-trt_classification_jsc_2024-03-05/software/training_ckpts/best.ckpt\"\n",
    "#CHECKPOINT_PATH = \"/root/mase/TensorRTDev/jsc-toy_classification_jsc_2024-03-05/software/training_ckpts/best.ckpt\"\n",
    "\n",
    "model_info = get_model_info(model_name)\n",
    "# quant_modules.initialize()\n",
    "model = get_model(\n",
    "    model_name,\n",
    "    task=\"cls\",\n",
    "    dataset_info=data_module.dataset_info,\n",
    "    pretrained=False)\n",
    "\n",
    "model = load_model(load_name=CHECKPOINT_PATH, load_type=\"pl\", model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg = MaseGraph(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorRT Quantize Config: {'by': 'type', 'calibrator': ['percentile', 'max', 'mse', 'entropy'], 'percentiles': [99], 'report': True, 'linear': {'config': {'quantize': True}, 'input': {'calibrator': 'histogram', 'quantize_axis': False}, 'weight': {'calibrator': 'histogram', 'quantize_axis': False}}, 'default': {'config': {'quantize': True, 'input': {'calibrator': 'histogram', 'quantize_axis': False}, 'weight': {'calibrator': 'histogram', 'quantize_axis': False}}}}\n",
      "TensorRT Train Config: {}\n",
      "TensorRT Quantize Config: {'by': 'type', 'default': {'config': {'name': 'integer', 'data_in_width': 8, 'data_in_frac_width': 4, 'weight_width': 8, 'weight_frac_width': 9, 'bias_width': 8, 'bias_frac_width': 9}}}\n",
      "TensorRT Analysis Config: {'analysis': ['latency', 'accuracy', 'gpu_power', 'F1_score', 'recall', 'precision'], 'num_batches': 5}\n"
     ]
    }
   ],
   "source": [
    "import toml\n",
    "\n",
    "# Path to your TOML file\n",
    "toml_file_path = '/root/mase/machop/configs/examples/jsc_trt_quantization.toml'\n",
    "\n",
    "# Reading TOML file and converting it into a Python dictionary\n",
    "with open(toml_file_path, 'r') as toml_file:\n",
    "    pass_args = toml.load(toml_file)\n",
    "\n",
    "# Extract the 'passes.tensorrt-calibrate' section and its children\n",
    "tensorrt_calibrate_config = pass_args.get('passes', {}).get('tensorrt-calibrate', {})\n",
    "# Extract the 'passes.tensorrt-quantize' section and its children\n",
    "tensorrt_quantize_config = pass_args.get('passes', {}).get('tensorrt-quantize', {})\n",
    "# Extract the 'passes.tensorrt-train' section and its children\n",
    "tensorrt_train_config = pass_args.get('passes', {}).get('tensorrt-train', {})\n",
    "# Extract the 'passes.tensorrt-analysis' section and its children\n",
    "tensorrt_analysis_config = pass_args.get('passes', {}).get('tensorrt-analysis', {})\n",
    "\n",
    "# Print or return the extracted section\n",
    "print(\"TensorRT Quantize Config:\", tensorrt_calibrate_config)\n",
    "print(\"TensorRT Train Config:\", tensorrt_train_config)\n",
    "print(\"TensorRT Quantize Config:\", tensorrt_quantize_config)\n",
    "print(\"TensorRT Analysis Config:\", tensorrt_analysis_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'classification'\n",
    "\n",
    "# get the input generator\n",
    "input_generator = InputGenerator(\n",
    "    data_module=data_module,\n",
    "    model_info=model_info,\n",
    "    task=task,\n",
    "    which_dataloader=\"val\",\n",
    ")\n",
    "\n",
    "train_generator = InputGenerator(\n",
    "    model_info=model_info,\n",
    "    data_module=data_module,\n",
    "    task=task,\n",
    "    which_dataloader=\"train\",\n",
    ")\n",
    "\n",
    "val_generator = InputGenerator(\n",
    "    model_info=model_info,\n",
    "    data_module=data_module,\n",
    "    task=task,\n",
    "    which_dataloader=\"train\",\n",
    ")\n",
    "\n",
    "configs = [tensorrt_calibrate_config, tensorrt_train_config, tensorrt_quantize_config, tensorrt_analysis_config]\n",
    "for config in configs:\n",
    "    # config[\"train_generator\"] = train_generator\n",
    "    # config[\"val_generator\"] = val_generator\n",
    "    config['data_module'] = data_module\n",
    "    config['accelerator'] = 'cuda' if pass_args['accelerator'] == 'gpu' else pass_args['accelerator']\n",
    "    if config['accelerator'] == 'gpu':\n",
    "        os.environ['CUDA_MODULE_LOADING'] = 'LAZY'\n",
    "\n",
    "# a demonstration of how to feed an input value to the model\n",
    "dummy_in = next(iter(input_generator))\n",
    "_ = model(**dummy_in)\n",
    "\n",
    "mg, _ = init_metadata_analysis_pass(mg, None)\n",
    "mg, _ = add_common_metadata_analysis_pass(mg, {\"dummy_in\": dummy_in})\n",
    "mg, _ = add_software_metadata_analysis_pass(mg, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0306 10:53:03.924566 139983958759232 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0306 10:53:03.927824 139983958759232 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0306 10:53:03.929439 139983958759232 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0306 10:53:03.930501 139983958759232 tensor_quantizer.py:239] Call .cuda() if running on GPU after loading calibrated amax.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=37.0021 calibrator=MaxCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0306 10:53:03.931872 139983958759232 calibrate.py:57] seq_blocks.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=37.0021 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "W0306 10:53:03.935932 139983958759232 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([5, 1]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.2._weight_quantizer          : TensorQuantizer(8bit fake axis=0 amax=[1.1850, 5.9336](5) calibrator=MaxCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0306 10:53:03.937882 139983958759232 calibrate.py:57] seq_blocks.2._weight_quantizer          : TensorQuantizer(8bit fake axis=0 amax=[1.1850, 5.9336](5) calibrator=MaxCalibrator scale=1.0 quant)\n",
      "W0306 10:53:03.940307 139983958759232 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=37.0021 calibrator=MaxCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0306 10:53:03.941358 139983958759232 calibrate.py:57] seq_blocks.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=37.0021 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "W0306 10:53:03.943267 139983958759232 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([5, 1]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.2._weight_quantizer          : TensorQuantizer(8bit fake axis=0 amax=[1.1850, 5.9336](5) calibrator=MaxCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0306 10:53:03.944659 139983958759232 calibrate.py:57] seq_blocks.2._weight_quantizer          : TensorQuantizer(8bit fake axis=0 amax=[1.1850, 5.9336](5) calibrator=MaxCalibrator scale=1.0 quant)\n",
      "W0306 10:53:03.947347 139983958759232 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=37.0021 calibrator=MaxCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0306 10:53:03.948553 139983958759232 calibrate.py:57] seq_blocks.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=37.0021 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "W0306 10:53:03.950562 139983958759232 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([5, 1]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.2._weight_quantizer          : TensorQuantizer(8bit fake axis=0 amax=[1.1850, 5.9336](5) calibrator=MaxCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0306 10:53:03.952237 139983958759232 calibrate.py:57] seq_blocks.2._weight_quantizer          : TensorQuantizer(8bit fake axis=0 amax=[1.1850, 5.9336](5) calibrator=MaxCalibrator scale=1.0 quant)\n",
      "W0306 10:53:03.954450 139983958759232 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=37.0021 calibrator=MaxCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0306 10:53:03.955621 139983958759232 calibrate.py:57] seq_blocks.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=37.0021 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "W0306 10:53:03.957224 139983958759232 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([5, 1]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.2._weight_quantizer          : TensorQuantizer(8bit fake axis=0 amax=[1.1850, 5.9336](5) calibrator=MaxCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0306 10:53:03.958783 139983958759232 calibrate.py:57] seq_blocks.2._weight_quantizer          : TensorQuantizer(8bit fake axis=0 amax=[1.1850, 5.9336](5) calibrator=MaxCalibrator scale=1.0 quant)\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mSucceeded in calibrating the model in PyTorch!\u001b[0m\n",
      "I0306 10:53:03.960600 139983958759232 calibrate.py:102] Succeeded in calibrating the model in PyTorch!\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "I0306 10:53:03.967773 139983958759232 quantize.py:116] Converting PyTorch model to ONNX...\n",
      "/opt/conda/envs/mase/lib/python3.11/site-packages/pytorch_quantization/tensor_quant.py:363: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if min_amax < 0:\n",
      "/opt/conda/envs/mase/lib/python3.11/site-packages/pytorch_quantization/tensor_quant.py:366: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  max_bound = torch.tensor((2.0**(num_bits - 1 + int(unsigned))) - 1.0, device=amax.device)\n",
      "/opt/conda/envs/mase/lib/python3.11/site-packages/pytorch_quantization/tensor_quant.py:376: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if min_amax <= epsilon:  # Treat amax smaller than minimum representable of fp16 0\n",
      "/opt/conda/envs/mase/lib/python3.11/site-packages/pytorch_quantization/tensor_quant.py:382: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if min_amax <= epsilon:\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /root/mase/mase_output/TensorRT/Quantization/ONNX/2024_03_06/version_2/model.onnx\u001b[0m\n",
      "I0306 10:53:04.111609 139983958759232 quantize.py:126] ONNX Conversion Complete. Stored ONNX model to /root/mase/mase_output/TensorRT/Quantization/ONNX/2024_03_06/version_2/model.onnx\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "I0306 10:53:04.114022 139983958759232 quantize.py:82] Converting PyTorch model to TensorRT...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03/06/2024-10:53:11] [TRT] [W] CUDA lazy loading is not enabled. Enabling it can significantly reduce device memory usage and speed up TensorRT initialization. See \"Lazy Loading\" section of CUDA documentation https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#lazy-loading\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /root/mase/mase_output/TensorRT/Quantization/TRT/2024_03_06/version_2/model.trt\u001b[0m\n",
      "I0306 10:54:02.100973 139983958759232 quantize.py:111] TensorRT Conversion Complete. Stored trt model to /root/mase/mase_output/TensorRT/Quantization/TRT/2024_03_06/version_2/model.trt\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting TensorRT transformation analysis\u001b[0m\n",
      "I0306 10:54:12.304700 139983958759232 analysis.py:76] Starting TensorRT transformation analysis\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03/06/2024-10:54:12] [TRT] [W] CUDA lazy loading is not enabled. Enabling it can significantly reduce device memory usage and speed up TensorRT initialization. See \"Lazy Loading\" section of CUDA documentation https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#lazy-loading\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'QuantizationAnalysis' object has no attribute 'trt_context'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m mg, trt_dict \u001b[38;5;241m=\u001b[39m tensorrt_quantize_transform_pass(mg, pass_args\u001b[38;5;241m=\u001b[39mtensorrt_quantize_config)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Compare original tensorrt with \u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m mg, _ \u001b[38;5;241m=\u001b[39m \u001b[43mtensorrt_analysis_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrt_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrt_graph_path\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpass_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensorrt_analysis_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Analysis pass\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\n",
      "File \u001b[0;32m~/mase/machop/chop/passes/graph/transforms/tensorrt/quantize/analysis.py:44\u001b[0m, in \u001b[0;36mtensorrt_analysis_pass\u001b[0;34m(original_graph, trt_engine_path, pass_args)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtensorrt_analysis_pass\u001b[39m(original_graph, trt_engine_path, pass_args\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     43\u001b[0m     analysis \u001b[38;5;241m=\u001b[39m QuantizationAnalysis(original_graph, trt_engine_path, pass_args)\n\u001b[0;32m---> 44\u001b[0m     \u001b[43manalysis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mase/machop/chop/passes/graph/transforms/tensorrt/quantize/analysis.py:80\u001b[0m, in \u001b[0;36mQuantizationAnalysis.evaluate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mmatch\u001b[39;00m analysis:\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mcase\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlatency\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 80\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mcase\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     82\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m~/mase/machop/chop/passes/graph/transforms/tensorrt/quantize/analysis.py:119\u001b[0m, in \u001b[0;36mQuantizationAnalysis.eval\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    116\u001b[0m all_accs, all_precisions, all_recalls, all_f1s \u001b[38;5;241m=\u001b[39m [], [], [], []\n\u001b[1;32m    117\u001b[0m all_losses, all_latencies, all_gpu_powers, all_gpu_energy, all_flops \u001b[38;5;241m=\u001b[39m [], [], [], [], []\n\u001b[0;32m--> 119\u001b[0m search_spaces \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moriginal_graph, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrt_context\u001b[49m]\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# Iterate over different configurations\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, graph \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(search_spaces):\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;66;03m# Initialize lists to store metrics for each configuration\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'QuantizationAnalysis' object has no attribute 'trt_context'"
     ]
    }
   ],
   "source": [
    "'''  \n",
    "./ch transform --config configs/examples/jsc_trt_quantization.toml --load ../TensorRTDev/jsc-tiny_classification_jsc_2024-03-05/software/training_ckpts/best.ckpt --load-type pl\n",
    "./ch transform --config configs/examples/jsc_trt_quantization.toml --load ../TensorRTDev/jsc-trt_classification_jsc_2024-03-05/software/training_ckpts/best.ckpt --load-type pl\n",
    "./ch transform --config configs/examples/jsc_trt_quantization.toml --load ../TensorRTDev/jsc-toy_classification_jsc_2024-03-05/software/training_ckpts/best.ckpt --load-type pl\n",
    "'''\n",
    "\n",
    "# Restart kernel and re-run previous cells to avoid any issues\n",
    "\n",
    "# Calibrate model (passing data samples to the quantizer and deciding the best amax for activations)\n",
    "mg, _ = tensorrt_calibrate_transform_pass(mg, pass_args=tensorrt_calibrate_config)\n",
    "\n",
    "# # Conduct QAT\n",
    "# mg, _ = tensorrt_train_transform_pass(mg, pass_args=tensorrt_train_config)\n",
    "\n",
    "# Convert and store to ONNX and then TensorRT\n",
    "mg, trt_dict = tensorrt_quantize_transform_pass(mg, pass_args=tensorrt_quantize_config)\n",
    "\n",
    "# Compare original tensorrt with \n",
    "mg, _ = tensorrt_analysis_pass(mg, trt_dict['trt_graph_path'], pass_args=tensorrt_analysis_config)\n",
    "\n",
    "# Analysis pass\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chop.passes.graph import (\n",
    "    save_node_meta_param_interface_pass,\n",
    "    report_node_meta_param_analysis_pass,\n",
    "    profile_statistics_analysis_pass,\n",
    "    add_common_metadata_analysis_pass,\n",
    "    init_metadata_analysis_pass,\n",
    "    add_software_metadata_analysis_pass,\n",
    "    tensorrt_calibrate_transform_pass,\n",
    "    tensorrt_train_transform_pass,\n",
    "    tensorrt_quantize_transform_pass,\n",
    "    tensorrt_analysis_pass,\n",
    "    )\n",
    "\n",
    "mg, _ = tensorrt_analysis_pass(mg, trt_dict['trt_graph_path'], pass_args=tensorrt_analysis_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for name, module in mg.model.named_modules():\n",
    "    print(i,module)\n",
    "    i += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
