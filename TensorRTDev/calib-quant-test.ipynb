{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "pip install --no-cache-dir --index-url https://pypi.nvidia.com pytorch-quantization !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    " ./ch transform --config configs/examples/toy_uniform_tensorRT.toml --load /root/mase/TensorRTDev/jsc-tiny_classification_jsc_2024-03-03/software/training_ckpts/best.ckpt --load-type pl\n",
    "./ch train --config configs/examples/toy_uniform_tensorRT.toml\n",
    "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sudo apt update && sudo apt upgrade -y \n",
    "\n",
    "wget https://repo.continuum.io/archive/Anaconda3-2023.09-0-Linux-x86_64.sh \n",
    "\n",
    "bash Anaconda3-2023.09-0-Linux-x86_64.sh \n",
    "\n",
    "Close and reopen terminal\n",
    "\n",
    "source /root/.bashrc\n",
    "\n",
    "conda config --set auto_activate_base false\n",
    "\n",
    "git clone https://github.com/mau-mar/mase/\n",
    "\n",
    "cd mase\n",
    "\n",
    "bash scripts/init-conda.sh\n",
    "\n",
    "source /opt/conda/etc/profile.d/conda.sh\n",
    "\n",
    "conda activate mase\n",
    "\n",
    "conda config --add channels conda-forge\n",
    "\n",
    "git checkout origin/mauro-tensorRT-integration\n",
    "\n",
    "cuda-python\n",
    "absl-py\n",
    "scipy\n",
    "prettytable\n",
    "sphinx-glpi-theme\n",
    "\n",
    "./ch train --config configs/examples/toy_uniform_tensorRT.toml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/mase/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mSet logging level to info\u001b[0m\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0312 09:54:19.421001 139936087775040 logger.py:44] Set logging level to info\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "from pprint import pprint as pp\n",
    "\n",
    "# # figure out the correct path\n",
    "machop_path = Path(\".\").resolve().parent /\"machop\"\n",
    "assert machop_path.exists(), \"Failed to find machop at: {}\".format(machop_path)\n",
    "sys.path.append(str(machop_path))\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch_tensorrt\n",
    "import copy\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import pytorch_quantization\n",
    "from pytorch_quantization import nn as quant_nn\n",
    "from pytorch_quantization import quant_modules\n",
    "from pytorch_quantization.tensor_quant import QuantDescriptor\n",
    "from pytorch_quantization import calib\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(pytorch_quantization.__version__)\n",
    "\n",
    "from chop.dataset import MaseDataModule, get_dataset_info\n",
    "from chop.tools.logger import set_logging_verbosity\n",
    "\n",
    "from chop.passes.graph import (\n",
    "    save_node_meta_param_interface_pass,\n",
    "    report_node_meta_param_analysis_pass,\n",
    "    profile_statistics_analysis_pass,\n",
    "    add_common_metadata_analysis_pass,\n",
    "    init_metadata_analysis_pass,\n",
    "    add_software_metadata_analysis_pass,\n",
    "    tensorrt_calibrate_transform_pass,\n",
    "    tensorrt_fake_quantize_transform_pass,\n",
    "    tensorrt_train_transform_pass,\n",
    "    tensorrt_quantize_transform_pass,\n",
    "    tensorrt_analysis_pass,\n",
    "    )\n",
    "from chop.passes.graph.utils import deepcopy_mase_graph\n",
    "from chop.tools.get_input import InputGenerator\n",
    "from chop.tools.checkpoint_load import load_model\n",
    "from chop.ir import MaseGraph\n",
    "\n",
    "from chop.models import get_model_info, get_model\n",
    "\n",
    "set_logging_verbosity(\"info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from /root/mase/TensorRTDev/jsc-tiny_classification_jsc_2024-03-05/software/training_ckpts/best.ckpt\u001b[0m\n",
      "I0312 09:54:24.013048 139936087775040 checkpoint_load.py:85] Loaded pytorch lightning checkpoint from /root/mase/TensorRTDev/jsc-tiny_classification_jsc_2024-03-05/software/training_ckpts/best.ckpt\n"
     ]
    }
   ],
   "source": [
    "model_name = \"jsc-tiny\"\n",
    "dataset_name = \"jsc\"\n",
    "max_epochs = 1\n",
    "batch_size = 256\n",
    "learning_rate = 1e-3\n",
    "accelerator = \"gpu\"\n",
    "\n",
    "data_module = MaseDataModule(\n",
    "    name=dataset_name,\n",
    "    batch_size=batch_size,\n",
    "    model_name=model_name,\n",
    "    num_workers=0,\n",
    ")\n",
    "data_module.prepare_data()\n",
    "data_module.setup()\n",
    "\n",
    "# üìùÔ∏è change this CHECKPOINT_PATH to the one you trained in Lab1\n",
    "CHECKPOINT_PATH = \"/root/mase/TensorRTDev/jsc-tiny_classification_jsc_2024-03-05/software/training_ckpts/best.ckpt\"\n",
    "#CHECKPOINT_PATH = \"/root/mase/TensorRTDev/jsc-trt_classification_jsc_2024-03-05/software/training_ckpts/best.ckpt\"\n",
    "#CHECKPOINT_PATH = \"/root/mase/TensorRTDev/jsc-toy_classification_jsc_2024-03-05/software/training_ckpts/best.ckpt\"\n",
    "\n",
    "model_info = get_model_info(model_name)\n",
    "# quant_modules.initialize()\n",
    "model = get_model(\n",
    "    model_name,\n",
    "    task=\"cls\",\n",
    "    dataset_info=data_module.dataset_info,\n",
    "    pretrained=False)\n",
    "\n",
    "model = load_model(load_name=CHECKPOINT_PATH, load_type=\"pl\", model=model)\n",
    "\n",
    "input_generator = InputGenerator(\n",
    "    data_module=data_module,\n",
    "    model_info=model_info,\n",
    "    task=\"cls\",\n",
    "    which_dataloader=\"train\",\n",
    ")\n",
    "\n",
    "dummy_in = next(iter(input_generator))\n",
    "_ = model(**dummy_in)\n",
    "\n",
    "# generate the mase graph and initialize node metadata\n",
    "mg = MaseGraph(model=model)\n",
    "\n",
    "mg, _ = init_metadata_analysis_pass(mg, None)\n",
    "mg, _ = add_common_metadata_analysis_pass(mg, {\"dummy_in\": dummy_in})\n",
    "mg, _ = add_software_metadata_analysis_pass(mg, None)\n",
    "\n",
    "for inputs in data_module.train_dataloader():\n",
    "    xs, ys = inputs\n",
    "    preds = mg.model(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorRT Quantize Config: {'by': 'type', 'calibrator': ['percentile', 'max', 'mse', 'entropy'], 'num_calibration_batches': 100, 'percentiles': [99], 'report': True, 'linear': {'config': {'quantize': True, 'precision': 'INT8'}, 'input': {'calibrator': 'histogram', 'quantize_axis': False}, 'weight': {'calibrator': 'histogram', 'quantize_axis': False}}, 'default': {'config': {'quantize': True, 'precision': 'INT8', 'input': {'calibrator': 'histogram', 'quantize_axis': False}, 'weight': {'calibrator': 'histogram', 'quantize_axis': False}}}}\n",
      "TensorRT Train Config: {'qat_epochs': 10}\n",
      "TensorRT Analysis Config: {'num_batches': 20, 'num_GPU_warmup_batches': 5}\n"
     ]
    }
   ],
   "source": [
    "import toml\n",
    "\n",
    "# Path to your TOML file\n",
    "toml_file_path = '/root/mase/machop/configs/examples/jsc_trt_quantization.toml'\n",
    "\n",
    "# Reading TOML file and converting it into a Python dictionary\n",
    "with open(toml_file_path, 'r') as toml_file:\n",
    "    pass_args = toml.load(toml_file)\n",
    "\n",
    "# Extract the 'passes.tensorrt-quantize' section and its children\n",
    "tensorrt_quantize_config = pass_args.get('passes', {}).get('tensorrt-quantize', {})\n",
    "# Extract the 'passes.tensorrt-train' section and its children\n",
    "tensorrt_train_config = pass_args.get('passes', {}).get('tensorrt-train', {})\n",
    "# Extract the 'passes.tensorrt-analysis' section and its children\n",
    "tensorrt_analysis_config = pass_args.get('passes', {}).get('tensorrt-analysis', {})\n",
    "\n",
    "# Print or return the extracted section\n",
    "print(\"TensorRT Quantize Config:\", tensorrt_quantize_config)\n",
    "print(\"TensorRT Train Config:\", tensorrt_train_config)\n",
    "print(\"TensorRT Analysis Config:\", tensorrt_analysis_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = [tensorrt_quantize_config, tensorrt_train_config, tensorrt_analysis_config]\n",
    "for config in configs:\n",
    "    config['batch_size'] = pass_args['batch_size']\n",
    "    config['data_module'] = data_module\n",
    "    config['accelerator'] = 'cuda' if pass_args['accelerator'] == 'gpu' else pass_args['accelerator']\n",
    "    if config['accelerator'] == 'gpu':\n",
    "        os.environ['CUDA_MODULE_LOADING'] = 'LAZY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0312 09:55:38.641668 139936087775040 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0312 09:55:38.645843 139936087775040 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0312 09:55:38.647467 139936087775040 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0312 09:55:38.648523 139936087775040 tensor_quantizer.py:239] Call .cuda() if running on GPU after loading calibrated amax.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=37.6677 calibrator=MaxCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0312 09:55:38.649965 139936087775040 calibrate.py:61] seq_blocks.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=37.6677 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "W0312 09:55:38.653289 139936087775040 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([5, 1]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.2._weight_quantizer          : TensorQuantizer(8bit fake axis=0 amax=[1.1850, 5.9336](5) calibrator=MaxCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0312 09:55:38.655089 139936087775040 calibrate.py:61] seq_blocks.2._weight_quantizer          : TensorQuantizer(8bit fake axis=0 amax=[1.1850, 5.9336](5) calibrator=MaxCalibrator scale=1.0 quant)\n",
      "W0312 09:55:38.658107 139936087775040 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=37.6677 calibrator=MaxCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0312 09:55:38.659151 139936087775040 calibrate.py:61] seq_blocks.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=37.6677 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "W0312 09:55:38.660724 139936087775040 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([5, 1]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.2._weight_quantizer          : TensorQuantizer(8bit fake axis=0 amax=[1.1850, 5.9336](5) calibrator=MaxCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0312 09:55:38.662202 139936087775040 calibrate.py:61] seq_blocks.2._weight_quantizer          : TensorQuantizer(8bit fake axis=0 amax=[1.1850, 5.9336](5) calibrator=MaxCalibrator scale=1.0 quant)\n",
      "W0312 09:55:38.664121 139936087775040 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=37.6677 calibrator=MaxCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0312 09:55:38.665458 139936087775040 calibrate.py:61] seq_blocks.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=37.6677 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "W0312 09:55:38.666917 139936087775040 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([5, 1]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.2._weight_quantizer          : TensorQuantizer(8bit fake axis=0 amax=[1.1850, 5.9336](5) calibrator=MaxCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0312 09:55:38.668387 139936087775040 calibrate.py:61] seq_blocks.2._weight_quantizer          : TensorQuantizer(8bit fake axis=0 amax=[1.1850, 5.9336](5) calibrator=MaxCalibrator scale=1.0 quant)\n",
      "W0312 09:55:38.670518 139936087775040 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=37.6677 calibrator=MaxCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0312 09:55:38.671510 139936087775040 calibrate.py:61] seq_blocks.2._input_quantizer           : TensorQuantizer(8bit fake per-tensor amax=37.6677 calibrator=MaxCalibrator scale=1.0 quant)\n",
      "W0312 09:55:38.673095 139936087775040 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([5, 1]).\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mseq_blocks.2._weight_quantizer          : TensorQuantizer(8bit fake axis=0 amax=[1.1850, 5.9336](5) calibrator=MaxCalibrator scale=1.0 quant)\u001b[0m\n",
      "I0312 09:55:38.674299 139936087775040 calibrate.py:61] seq_blocks.2._weight_quantizer          : TensorQuantizer(8bit fake axis=0 amax=[1.1850, 5.9336](5) calibrator=MaxCalibrator scale=1.0 quant)\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mSucceeded in calibrating the model in PyTorch!\u001b[0m\n",
      "I0312 09:55:38.676258 139936087775040 calibrate.py:106] Succeeded in calibrating the model in PyTorch!\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to ONNX...\u001b[0m\n",
      "I0312 09:55:38.681105 139936087775040 quantize.py:159] Converting PyTorch model to ONNX...\n",
      "/opt/conda/envs/mase/lib/python3.11/site-packages/pytorch_quantization/tensor_quant.py:363: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if min_amax < 0:\n",
      "/opt/conda/envs/mase/lib/python3.11/site-packages/pytorch_quantization/tensor_quant.py:366: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  max_bound = torch.tensor((2.0**(num_bits - 1 + int(unsigned))) - 1.0, device=amax.device)\n",
      "/opt/conda/envs/mase/lib/python3.11/site-packages/pytorch_quantization/tensor_quant.py:376: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if min_amax <= epsilon:  # Treat amax smaller than minimum representable of fp16 0\n",
      "/opt/conda/envs/mase/lib/python3.11/site-packages/pytorch_quantization/tensor_quant.py:382: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if min_amax <= epsilon:\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mONNX Conversion Complete. Stored ONNX model to /root/mase/mase_output/TensorRT/Quantization/ONNX/2024_03_12/version_3/model.onnx\u001b[0m\n",
      "I0312 09:55:38.868664 139936087775040 quantize.py:176] ONNX Conversion Complete. Stored ONNX model to /root/mase/mase_output/TensorRT/Quantization/ONNX/2024_03_12/version_3/model.onnx\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mConverting PyTorch model to TensorRT...\u001b[0m\n",
      "I0312 09:55:38.870869 139936087775040 quantize.py:72] Converting PyTorch model to TensorRT...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03/12/2024-09:55:47] [TRT] [W] CUDA lazy loading is not enabled. Enabling it can significantly reduce device memory usage and speed up TensorRT initialization. See \"Lazy Loading\" section of CUDA documentation https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#lazy-loading\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mtrt_engine layer_info:\n",
      "{\"Layers\": [{\n",
      "  \"Name\": \"onnx::Mul_36\",\n",
      "  \"LayerType\": \"Constant\",\n",
      "  \"Inputs\": [],\n",
      "  \"Outputs\": [\n",
      "  {\n",
      "    \"Name\": \"(Unnamed Layer* 0) [Constant]_output\",\n",
      "    \"Location\": \"Device\",\n",
      "    \"Dimensions\": [],\n",
      "    \"Format/Datatype\": \"Row major linear FP16 format\"\n",
      "  }],\n",
      "  \"ParameterType\": \"Constant\",\n",
      "  \"weights\": {\"Type\": \"Float\", \"Count\": 1},\n",
      "  \"dimensions\": [],\n",
      "  \"TacticValue\": \"0x0000000000000000\",\n",
      "  \"StreamId\": 0,\n",
      "  \"Metadata\": \"\"\n",
      "},{\n",
      "  \"Name\": \"Identity_4\",\n",
      "  \"LayerType\": \"Reformat\",\n",
      "  \"Inputs\": [\n",
      "  {\n",
      "    \"Name\": \"(Unnamed Layer* 0) [Constant]_output\",\n",
      "    \"Location\": \"Device\",\n",
      "    \"Dimensions\": [],\n",
      "    \"Format/Datatype\": \"Row major linear FP16 format\"\n",
      "  }],\n",
      "  \"Outputs\": [\n",
      "  {\n",
      "    \"Name\": \"onnx::Div_39\",\n",
      "    \"Location\": \"Device\",\n",
      "    \"Dimensions\": [],\n",
      "    \"Format/Datatype\": \"Row major linear FP16 format\"\n",
      "  }],\n",
      "  \"ParameterType\": \"Reformat\",\n",
      "  \"Origin\": \"CAST\",\n",
      "  \"TacticValue\": \"0x00000000000003e8\",\n",
      "  \"StreamId\": 0,\n",
      "  \"Metadata\": \"\"\n",
      "},{\n",
      "  \"Name\": \"Reformatting CopyNode for Input Tensor 0 to (Unnamed Layer* 2) [Shuffle]\",\n",
      "  \"LayerType\": \"Reformat\",\n",
      "  \"Inputs\": [\n",
      "  {\n",
      "    \"Name\": \"input\",\n",
      "    \"Location\": \"Device\",\n",
      "    \"Dimensions\": [256,16],\n",
      "    \"Format/Datatype\": \"Row major linear FP32\"\n",
      "  }],\n",
      "  \"Outputs\": [\n",
      "  {\n",
      "    \"Name\": \"Reformatted Input Tensor 0 to (Unnamed Layer* 2) [Shuffle]\",\n",
      "    \"Location\": \"Device\",\n",
      "    \"Dimensions\": [256,16],\n",
      "    \"Format/Datatype\": \"Row major linear FP16 format\"\n",
      "  }],\n",
      "  \"ParameterType\": \"Reformat\",\n",
      "  \"Origin\": \"REFORMAT\",\n",
      "  \"TacticValue\": \"0x0000000000000000\",\n",
      "  \"StreamId\": 0,\n",
      "  \"Metadata\": \"\"\n",
      "},{\n",
      "  \"Name\": \"(Unnamed Layer* 2) [Shuffle]\",\n",
      "  \"LayerType\": \"NoOp\",\n",
      "  \"Inputs\": [\n",
      "  {\n",
      "    \"Name\": \"Reformatted Input Tensor 0 to (Unnamed Layer* 2) [Shuffle]\",\n",
      "    \"Location\": \"Device\",\n",
      "    \"Dimensions\": [256,16],\n",
      "    \"Format/Datatype\": \"Row major linear FP16 format\"\n",
      "  }],\n",
      "  \"Outputs\": [\n",
      "  {\n",
      "    \"Name\": \"(Unnamed Layer* 2) [Shuffle]_output\",\n",
      "    \"Location\": \"Device\",\n",
      "    \"Dimensions\": [256,16,1,1],\n",
      "    \"Format/Datatype\": \"Row major linear FP16 format\"\n",
      "  }],\n",
      "  \"TacticValue\": \"0x0000000000000000\",\n",
      "  \"StreamId\": 0,\n",
      "  \"Metadata\": \"\"\n",
      "},{\n",
      "  \"Name\": \"/seq_blocks.0/BatchNormalization + /seq_blocks.1/Relu\",\n",
      "  \"LayerType\": \"Scale\",\n",
      "  \"Inputs\": [\n",
      "  {\n",
      "    \"Name\": \"(Unnamed Layer* 2) [Shuffle]_output\",\n",
      "    \"Location\": \"Device\",\n",
      "    \"Dimensions\": [256,16,1,1],\n",
      "    \"Format/Datatype\": \"Row major linear FP16 format\"\n",
      "  }],\n",
      "  \"Outputs\": [\n",
      "  {\n",
      "    \"Name\": \"/seq_blocks.1/Relu_out_tensor\",\n",
      "    \"Location\": \"Device\",\n",
      "    \"Dimensions\": [256,16,1,1],\n",
      "    \"Format/Datatype\": \"Row major linear FP16 format\"\n",
      "  }],\n",
      "  \"ParameterType\": \"Scale\",\n",
      "  \"Mode\": \"CHANNEL\",\n",
      "  \"Shift\": {\"Type\": \"Half\", \"Count\": 16},\n",
      "  \"Scale\": {\"Type\": \"Half\", \"Count\": 16},\n",
      "  \"Power\": {\"Type\": \"Half\", \"Count\": 0},\n",
      "  \"Activation\": \"RELU\",\n",
      "  \"ChannelAxis\": 1,\n",
      "  \"TacticValue\": \"0x0000000000000000\",\n",
      "  \"StreamId\": 0,\n",
      "  \"Metadata\": \"[ONNX Layer: /seq_blocks.0/BatchNormalization]\\u001e[ONNX Layer: /seq_blocks.1/Relu]\"\n",
      "},{\n",
      "  \"Name\": \"Reformatting CopyNode for Input Tensor 0 to PWN(PWN(onnx::Mul_36_clone_1 + (Unnamed Layer* 6) [Shuffle] + unsqueeze_node_after_(Unnamed Layer* 6) [Shuffle]_(Unnamed Layer* 6) [Shuffle]_output + /seq_blocks.2/_input_quantizer/Mul, PWN(/seq_blocks.2/_input_quantizer/Round)), PWN(/seq_blocks.2/_input_quantizer/Clip))\",\n",
      "  \"LayerType\": \"NoOp\",\n",
      "  \"Inputs\": [\n",
      "  {\n",
      "    \"Name\": \"/seq_blocks.1/Relu_out_tensor\",\n",
      "    \"Location\": \"Device\",\n",
      "    \"Dimensions\": [256,16,1,1],\n",
      "    \"Format/Datatype\": \"Row major linear FP16 format\"\n",
      "  }],\n",
      "  \"Outputs\": [\n",
      "  {\n",
      "    \"Name\": \"Reformatted Input Tensor 0 to PWN(PWN(onnx::Mul_36_clone_1 + (Unnamed Layer* 6) [Shuffle] + unsqueeze_node_after_(Unnamed Layer* 6) [Shuffle]_(Unnamed Layer* 6) [Shuffle]_output + /seq_blocks.2/_input_quantizer/Mul, PWN(/seq_blocks.2/_input_quantizer/Round)), PWN(/seq_blocks.2/_input_quantizer/Clip))\",\n",
      "    \"Location\": \"Device\",\n",
      "    \"Dimensions\": [256,16,1,1],\n",
      "    \"Format/Datatype\": \"Channel major FP16 format where channel % 2 == 0\"\n",
      "  }],\n",
      "  \"TacticValue\": \"0x0000000000000000\",\n",
      "  \"StreamId\": 0,\n",
      "  \"Metadata\": \"\"\n",
      "},{\n",
      "  \"Name\": \"PWN(PWN(onnx::Mul_36_clone_1 + (Unnamed Layer* 6) [Shuffle] + unsqueeze_node_after_(Unnamed Layer* 6) [Shuffle]_(Unnamed Layer* 6) [Shuffle]_output + /seq_blocks.2/_input_quantizer/Mul, PWN(/seq_blocks.2/_input_quantizer/Round)), PWN(/seq_blocks.2/_input_quantizer/Clip))\",\n",
      "  \"LayerType\": \"PointWiseV2\",\n",
      "  \"Inputs\": [\n",
      "  {\n",
      "    \"Name\": \"Reformatted Input Tensor 0 to PWN(PWN(onnx::Mul_36_clone_1 + (Unnamed Layer* 6) [Shuffle] + unsqueeze_node_after_(Unnamed Layer* 6) [Shuffle]_(Unnamed Layer* 6) [Shuffle]_output + /seq_blocks.2/_input_quantizer/Mul, PWN(/seq_blocks.2/_input_quantizer/Round)), PWN(/seq_blocks.2/_input_quantizer/Clip))\",\n",
      "    \"Location\": \"Device\",\n",
      "    \"Dimensions\": [256,16,1,1],\n",
      "    \"Format/Datatype\": \"Channel major FP16 format where channel % 2 == 0\"\n",
      "  }],\n",
      "  \"Outputs\": [\n",
      "  {\n",
      "    \"Name\": \"/seq_blocks.2/_input_quantizer/Clip_out_tensor\",\n",
      "    \"Location\": \"Device\",\n",
      "    \"Dimensions\": [256,16,1,1],\n",
      "    \"Format/Datatype\": \"Channel major FP16 format where channel % 2 == 0\"\n",
      "  }],\n",
      "  \"ParameterType\": \"PointWise\",\n",
      "  \"ParameterSubType\": \"PointWiseExpression\",\n",
      "  \"NbInputArgs\": 1,\n",
      "  \"InputArgs\": [\"arg0\"],\n",
      "  \"NbOutputVars\": 1,\n",
      "  \"OutputVars\": [\"var3\"],\n",
      "  \"NbParams\": 0,\n",
      "  \"Params\": [],\n",
      "  \"NbLiterals\": 6,\n",
      "  \"Literals\": [\"0.000000e+00f\", \"3.371592e+00f\", \"0.000000e+00f\", \"1.000000e+00f\", \"-1.280000e+02f\", \"1.270000e+02f\"],\n",
      "  \"NbOperations\": 4,\n",
      "  \"Operations\": [\"auto const var0 = pwgen::iMul(arg0, literal1);\", \"auto const var1 = pwgen::iRound(var0);\", \"auto const var2 = pwgen::iMin(literal5, var1);\", \"auto const var3 = pwgen::iMax(literal4, var2);\"],\n",
      "  \"TacticValue\": \"0x000000000000001d\",\n",
      "  \"StreamId\": 0,\n",
      "  \"Metadata\": \"[ONNX Layer: /seq_blocks.2/_input_quantizer/Mul]\\u001e[ONNX Layer: /seq_blocks.2/_input_quantizer/Round]\\u001e[ONNX Layer: /seq_blocks.2/_input_quantizer/Clip]\"\n",
      "},{\n",
      "  \"Name\": \"Reformatting CopyNode for Input Tensor 0 to squeeze_after_/seq_blocks.2/_input_quantizer/Clip\",\n",
      "  \"LayerType\": \"NoOp\",\n",
      "  \"Inputs\": [\n",
      "  {\n",
      "    \"Name\": \"/seq_blocks.2/_input_quantizer/Clip_out_tensor\",\n",
      "    \"Location\": \"Device\",\n",
      "    \"Dimensions\": [256,16,1,1],\n",
      "    \"Format/Datatype\": \"Channel major FP16 format where channel % 2 == 0\"\n",
      "  }],\n",
      "  \"Outputs\": [\n",
      "  {\n",
      "    \"Name\": \"Reformatted Input Tensor 0 to squeeze_after_/seq_blocks.2/_input_quantizer/Clip\",\n",
      "    \"Location\": \"Device\",\n",
      "    \"Dimensions\": [256,16,1,1],\n",
      "    \"Format/Datatype\": \"Row major linear FP16 format\"\n",
      "  }],\n",
      "  \"TacticValue\": \"0x0000000000000000\",\n",
      "  \"StreamId\": 0,\n",
      "  \"Metadata\": \"\"\n",
      "},{\n",
      "  \"Name\": \"squeeze_after_/seq_blocks.2/_input_quantizer/Clip\",\n",
      "  \"LayerType\": \"NoOp\",\n",
      "  \"Inputs\": [\n",
      "  {\n",
      "    \"Name\": \"Reformatted Input Tensor 0 to squeeze_after_/seq_blocks.2/_input_quantizer/Clip\",\n",
      "    \"Location\": \"Device\",\n",
      "    \"Dimensions\": [256,16,1,1],\n",
      "    \"Format/Datatype\": \"Row major linear FP16 format\"\n",
      "  }],\n",
      "  \"Outputs\": [\n",
      "  {\n",
      "    \"Name\": \"squeeze_after_/seq_blocks.2/_input_quantizer/Clip_out_tensor\",\n",
      "    \"Location\": \"Device\",\n",
      "    \"Dimensions\": [256,16],\n",
      "    \"Format/Datatype\": \"Row major linear FP16 format\"\n",
      "  }],\n",
      "  \"TacticValue\": \"0x0000000000000000\",\n",
      "  \"StreamId\": 0,\n",
      "  \"Metadata\": \"\"\n",
      "},{\n",
      "  \"Name\": \"(Unnamed Layer* 10) [Shuffle]\",\n",
      "  \"LayerType\": \"NoOp\",\n",
      "  \"Inputs\": [\n",
      "  {\n",
      "    \"Name\": \"onnx::Div_39\",\n",
      "    \"Location\": \"Device\",\n",
      "    \"Dimensions\": [],\n",
      "    \"Format/Datatype\": \"Row major linear FP16 format\"\n",
      "  }],\n",
      "  \"Outputs\": [\n",
      "  {\n",
      "    \"Name\": \"(Unnamed Layer* 10) [Shuffle]_output\",\n",
      "    \"Location\": \"Device\",\n",
      "    \"Dimensions\": [1,1],\n",
      "    \"Format/Datatype\": \"Row major linear FP16 format\"\n",
      "  }],\n",
      "  \"TacticValue\": \"0x0000000000000000\",\n",
      "  \"StreamId\": 0,\n",
      "  \"Metadata\": \"\"\n",
      "},{\n",
      "  \"Name\": \"/seq_blocks.2/_input_quantizer/Div\",\n",
      "  \"LayerType\": \"ElementWise\",\n",
      "  \"Inputs\": [\n",
      "  {\n",
      "    \"Name\": \"squeeze_after_/seq_blocks.2/_input_quantizer/Clip_out_tensor\",\n",
      "    \"Location\": \"Device\",\n",
      "    \"Dimensions\": [256,16],\n",
      "    \"Format/Datatype\": \"Row major linear FP16 format\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"(Unnamed Layer* 10) [Shuffle]_output\",\n",
      "    \"Location\": \"Device\",\n",
      "    \"Dimensions\": [1,1],\n",
      "    \"Format/Datatype\": \"Row major linear FP16 format\"\n",
      "  }],\n",
      "  \"Outputs\": [\n",
      "  {\n",
      "    \"Name\": \"/seq_blocks.2/_input_quantizer/Div_output_0\",\n",
      "    \"Location\": \"Device\",\n",
      "    \"Dimensions\": [256,16],\n",
      "    \"Format/Datatype\": \"Row major linear FP16 format\"\n",
      "  }],\n",
      "  \"ParameterType\": \"ElementWise\",\n",
      "  \"ElementWiseOperation\": \"DIV\",\n",
      "  \"Activation\": \"NONE\",\n",
      "  \"TacticValue\": \"0x0000000000000001\",\n",
      "  \"StreamId\": 0,\n",
      "  \"Metadata\": \"[ONNX Layer: /seq_blocks.2/_input_quantizer/Div]\"\n",
      "},{\n",
      "  \"Name\": \"onnx::Round_41\",\n",
      "  \"LayerType\": \"Constant\",\n",
      "  \"Inputs\": [],\n",
      "  \"Outputs\": [\n",
      "  {\n",
      "    \"Name\": \"(Unnamed Layer* 12) [Constant]_output\",\n",
      "    \"Location\": \"Device\",\n",
      "    \"Dimensions\": [5,16],\n",
      "    \"Format/Datatype\": \"Row major linear FP16 format\"\n",
      "  }],\n",
      "  \"ParameterType\": \"Constant\",\n",
      "  \"weights\": {\"Type\": \"Float\", \"Count\": 80},\n",
      "  \"dimensions\": [5,16],\n",
      "  \"TacticValue\": \"0x0000000000000000\",\n",
      "  \"StreamId\": 0,\n",
      "  \"Metadata\": \"\"\n",
      "},{\n",
      "  \"Name\": \"onnx::Div_44\",\n",
      "  \"LayerType\": \"Constant\",\n",
      "  \"Inputs\": [],\n",
      "  \"Outputs\": [\n",
      "  {\n",
      "    \"Name\": \"(Unnamed Layer* 15) [Constant]_output\",\n",
      "    \"Location\": \"Device\",\n",
      "    \"Dimensions\": [5,1],\n",
      "    \"Format/Datatype\": \"Row major linear FP16 format\"\n",
      "  }],\n",
      "  \"ParameterType\": \"Constant\",\n",
      "  \"weights\": {\"Type\": \"Float\", \"Count\": 5},\n",
      "  \"dimensions\": [5,1],\n",
      "  \"TacticValue\": \"0x0000000000000000\",\n",
      "  \"StreamId\": 0,\n",
      "  \"Metadata\": \"\"\n",
      "},{\n",
      "  \"Name\": \"PWN(PWN(PWN(/seq_blocks.2/_weight_quantizer/Round), PWN(/seq_blocks.2/_weight_quantizer/Clip)), /seq_blocks.2/_weight_quantizer/Div)\",\n",
      "  \"LayerType\": \"PointWiseV2\",\n",
      "  \"Inputs\": [\n",
      "  {\n",
      "    \"Name\": \"(Unnamed Layer* 12) [Constant]_output\",\n",
      "    \"Location\": \"Device\",\n",
      "    \"Dimensions\": [5,16],\n",
      "    \"Format/Datatype\": \"Row major linear FP16 format\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"(Unnamed Layer* 15) [Constant]_output\",\n",
      "    \"Location\": \"Device\",\n",
      "    \"Dimensions\": [5,1],\n",
      "    \"Format/Datatype\": \"Row major linear FP16 format\"\n",
      "  }],\n",
      "  \"Outputs\": [\n",
      "  {\n",
      "    \"Name\": \"/seq_blocks.2/_weight_quantizer/Div_output_0\",\n",
      "    \"Location\": \"Device\",\n",
      "    \"Dimensions\": [5,16],\n",
      "    \"Format/Datatype\": \"Row major linear FP16 format\"\n",
      "  }],\n",
      "  \"ParameterType\": \"PointWise\",\n",
      "  \"ParameterSubType\": \"PointWiseExpression\",\n",
      "  \"NbInputArgs\": 2,\n",
      "  \"InputArgs\": [\"arg0\", \"arg1\"],\n",
      "  \"NbOutputVars\": 1,\n",
      "  \"OutputVars\": [\"var3\"],\n",
      "  \"NbParams\": 0,\n",
      "  \"Params\": [],\n",
      "  \"NbLiterals\": 4,\n",
      "  \"Literals\": [\"0.000000e+00f\", \"1.000000e+00f\", \"-1.280000e+02f\", \"1.270000e+02f\"],\n",
      "  \"NbOperations\": 4,\n",
      "  \"Operations\": [\"auto const var0 = pwgen::iRound(arg0);\", \"auto const var1 = pwgen::iMin(literal3, var0);\", \"auto const var2 = pwgen::iMax(literal2, var1);\", \"auto const var3 = pwgen::iDiv(var2, arg1);\"],\n",
      "  \"TacticValue\": \"0x000000000000001c\",\n",
      "  \"StreamId\": 0,\n",
      "  \"Metadata\": \"[ONNX Layer: /seq_blocks.2/_weight_quantizer/Round]\\u001e[ONNX Layer: /seq_blocks.2/_weight_quantizer/Clip]\\u001e[ONNX Layer: /seq_blocks.2/_weight_quantizer/Div]\"\n",
      "},{\n",
      "  \"Name\": \"/seq_blocks.2/Gemm\",\n",
      "  \"LayerType\": \"CaskGemmMatrixMultiply\",\n",
      "  \"Inputs\": [\n",
      "  {\n",
      "    \"Name\": \"/seq_blocks.2/_input_quantizer/Div_output_0\",\n",
      "    \"Location\": \"Device\",\n",
      "    \"Dimensions\": [256,16],\n",
      "    \"Format/Datatype\": \"Row major linear FP16 format\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"/seq_blocks.2/_weight_quantizer/Div_output_0\",\n",
      "    \"Location\": \"Device\",\n",
      "    \"Dimensions\": [5,16],\n",
      "    \"Format/Datatype\": \"Row major linear FP16 format\"\n",
      "  }],\n",
      "  \"Outputs\": [\n",
      "  {\n",
      "    \"Name\": \"/seq_blocks.2/Gemm_output_0\",\n",
      "    \"Location\": \"Device\",\n",
      "    \"Dimensions\": [256,5],\n",
      "    \"Format/Datatype\": \"Row major linear FP16 format\"\n",
      "  }],\n",
      "  \"ParameterType\": \"MatrixMultiply\",\n",
      "  \"MatrixOpA\": \"NONE\",\n",
      "  \"MatrixOpB\": \"TRANSPOSE\",\n",
      "  \"Alpha\": 1,\n",
      "  \"Beta\": 0,\n",
      "  \"TacticName\": \"sm75_xmma_gemm_f16f16_f16f16_f16_tn_n_tilesize32x32x64_stage1_warpsize2x2x1_tensor16x8x8_aligna2_alignc2\",\n",
      "  \"TacticValue\": \"0x0000000000020277\",\n",
      "  \"StreamId\": 0,\n",
      "  \"Metadata\": \"[ONNX Layer: /seq_blocks.2/Gemm]\\u001e\"\n",
      "},{\n",
      "  \"Name\": \"PWN(/seq_blocks.3/Relu)\",\n",
      "  \"LayerType\": \"PointWiseV2\",\n",
      "  \"Inputs\": [\n",
      "  {\n",
      "    \"Name\": \"/seq_blocks.2/Gemm_output_0\",\n",
      "    \"Location\": \"Device\",\n",
      "    \"Dimensions\": [256,5],\n",
      "    \"Format/Datatype\": \"Row major linear FP16 format\"\n",
      "  }],\n",
      "  \"Outputs\": [\n",
      "  {\n",
      "    \"Name\": \"Reformatted Output Tensor 0 to PWN(/seq_blocks.3/Relu)\",\n",
      "    \"Location\": \"Device\",\n",
      "    \"Dimensions\": [256,5],\n",
      "    \"Format/Datatype\": \"Row major linear FP16 format\"\n",
      "  }],\n",
      "  \"ParameterType\": \"PointWise\",\n",
      "  \"ParameterSubType\": \"PointWiseExpression\",\n",
      "  \"NbInputArgs\": 1,\n",
      "  \"InputArgs\": [\"arg0\"],\n",
      "  \"NbOutputVars\": 1,\n",
      "  \"OutputVars\": [\"var0\"],\n",
      "  \"NbParams\": 0,\n",
      "  \"Params\": [],\n",
      "  \"NbLiterals\": 4,\n",
      "  \"Literals\": [\"0.000000e+00f\", \"1.000000e+00f\", \"0.000000e+00f\", \"0.000000e+00f\"],\n",
      "  \"NbOperations\": 1,\n",
      "  \"Operations\": [\"auto const var0 = pwgen::iMax(arg0, literal0);\"],\n",
      "  \"TacticValue\": \"0x000000000000001c\",\n",
      "  \"StreamId\": 0,\n",
      "  \"Metadata\": \"[ONNX Layer: /seq_blocks.3/Relu]\"\n",
      "},{\n",
      "  \"Name\": \"Reformatting CopyNode for Output Tensor 0 to PWN(/seq_blocks.3/Relu)\",\n",
      "  \"LayerType\": \"Reformat\",\n",
      "  \"Inputs\": [\n",
      "  {\n",
      "    \"Name\": \"Reformatted Output Tensor 0 to PWN(/seq_blocks.3/Relu)\",\n",
      "    \"Location\": \"Device\",\n",
      "    \"Dimensions\": [256,5],\n",
      "    \"Format/Datatype\": \"Row major linear FP16 format\"\n",
      "  }],\n",
      "  \"Outputs\": [\n",
      "  {\n",
      "    \"Name\": \"35\",\n",
      "    \"Location\": \"Device\",\n",
      "    \"Dimensions\": [256,5],\n",
      "    \"Format/Datatype\": \"Row major linear FP32\"\n",
      "  }],\n",
      "  \"ParameterType\": \"Reformat\",\n",
      "  \"Origin\": \"REFORMAT\",\n",
      "  \"TacticValue\": \"0x0000000000000000\",\n",
      "  \"StreamId\": 0,\n",
      "  \"Metadata\": \"\"\n",
      "}],\n",
      "\"Bindings\": [\"input\"\n",
      ",\"35\"\n",
      "]}\n",
      "\u001b[0m\n",
      "I0312 09:56:20.052978 139936087775040 quantize.py:149] trt_engine layer_info:\n",
      "{\"Layers\": [{\n",
      "  \"Name\": \"onnx::Mul_36\",\n",
      "  \"LayerType\": \"Constant\",\n",
      "  \"Inputs\": [],\n",
      "  \"Outputs\": [\n",
      "  {\n",
      "    \"Name\": \"(Unnamed Layer* 0) [Constant]_output\",\n",
      "    \"Location\": \"Device\",\n",
      "    \"Dimensions\": [],\n",
      "    \"Format/Datatype\": \"Row major linear FP16 format\"\n",
      "  }],\n",
      "  \"ParameterType\": \"Constant\",\n",
      "  \"weights\": {\"Type\": \"Float\", \"Count\": 1},\n",
      "  \"dimensions\": [],\n",
      "  \"TacticValue\": \"0x0000000000000000\",\n",
      "  \"StreamId\": 0,\n",
      "  \"Metadata\": \"\"\n",
      "},{\n",
      "  \"Name\": \"Identity_4\",\n",
      "  \"LayerType\": \"Reformat\",\n",
      "  \"Inputs\": [\n",
      "  {\n",
      "    \"Name\": \"(Unnamed Layer* 0) [Constant]_output\",\n",
      "    \"Location\": \"Device\",\n",
      "    \"Dimensions\": [],\n",
      "    \"Format/Datatype\": \"Row major linear FP16 format\"\n",
      "  }],\n",
      "  \"Outputs\": [\n",
      "  {\n",
      "    \"Name\": \"onnx::Div_39\",\n",
      "    \"Location\": \"Device\",\n",
      "    \"Dimensions\": [],\n",
      "    \"Format/Datatype\": \"Row major linear FP16 format\"\n",
      "  }],\n",
      "  \"ParameterType\": \"Reformat\",\n",
      "  \"Origin\": \"CAST\",\n",
      "  \"TacticValue\": \"0x00000000000003e8\",\n",
      "  \"StreamId\": 0,\n",
      "  \"Metadata\": \"\"\n",
      "},{\n",
      "  \"Name\": \"Reformatting CopyNode for Input Tensor 0 to (Unnamed Layer* 2) [Shuffle]\",\n",
      "  \"LayerType\": \"Reformat\",\n",
      "  \"Inputs\": [\n",
      "  {\n",
      "    \"Name\": \"input\",\n",
      "    \"Location\": \"Device\",\n",
      "    \"Dimensions\": [256,16],\n",
      "    \"Format/Datatype\": \"Row major linear FP32\"\n",
      "  }],\n",
      "  \"Outputs\": [\n",
      "  {\n",
      "    \"Name\": \"Reformatted Input Tensor 0 to (Unnamed Layer* 2) [Shuffle]\",\n",
      "    \"Location\": \"Device\",\n",
      "    \"Dimensions\": [256,16],\n",
      "    \"Format/Datatype\": \"Row major linear FP16 format\"\n",
      "  }],\n",
      "  \"ParameterType\": \"Reformat\",\n",
      "  \"Origin\": \"REFORMAT\",\n",
      "  \"TacticValue\": \"0x0000000000000000\",\n",
      "  \"StreamId\": 0,\n",
      "  \"Metadata\": \"\"\n",
      "},{\n",
      "  \"Name\": \"(Unnamed Layer* 2) [Shuffle]\",\n",
      "  \"LayerType\": \"NoOp\",\n",
      "  \"Inputs\": [\n",
      "  {\n",
      "    \"Name\": \"Reformatted Input Tensor 0 to (Unnamed Layer* 2) [Shuffle]\",\n",
      "    \"Location\": \"Device\",\n",
      "    \"Dimensions\": [256,16],\n",
      "    \"Format/Datatype\": \"Row major linear FP16 format\"\n",
      "  }],\n",
      "  \"Outputs\": [\n",
      "  {\n",
      "    \"Name\": \"(Unnamed Layer* 2) [Shuffle]_output\",\n",
      "    \"Location\": \"Device\",\n",
      "    \"Dimensions\": [256,16,1,1],\n",
      "    \"Format/Datatype\": \"Row major linear FP16 format\"\n",
      "  }],\n",
      "  \"TacticValue\": \"0x0000000000000000\",\n",
      "  \"StreamId\": 0,\n",
      "  \"Metadata\": \"\"\n",
      "},{\n",
      "  \"Name\": \"/seq_blocks.0/BatchNormalization + /seq_blocks.1/Relu\",\n",
      "  \"LayerType\": \"Scale\",\n",
      "  \"Inputs\": [\n",
      "  {\n",
      "    \"Name\": \"(Unnamed Layer* 2) [Shuffle]_output\",\n",
      "    \"Location\": \"Device\",\n",
      "    \"Dimensions\": [256,16,1,1],\n",
      "    \"Format/Datatype\": \"Row major linear FP16 format\"\n",
      "  }],\n",
      "  \"Outputs\": [\n",
      "  {\n",
      "    \"Name\": \"/seq_blocks.1/Relu_out_tensor\",\n",
      "    \"Location\": \"Device\",\n",
      "    \"Dimensions\": [256,16,1,1],\n",
      "    \"Format/Datatype\": \"Row major linear FP16 format\"\n",
      "  }],\n",
      "  \"ParameterType\": \"Scale\",\n",
      "  \"Mode\": \"CHANNEL\",\n",
      "  \"Shift\": {\"Type\": \"Half\", \"Count\": 16},\n",
      "  \"Scale\": {\"Type\": \"Half\", \"Count\": 16},\n",
      "  \"Power\": {\"Type\": \"Half\", \"Count\": 0},\n",
      "  \"Activation\": \"RELU\",\n",
      "  \"ChannelAxis\": 1,\n",
      "  \"TacticValue\": \"0x0000000000000000\",\n",
      "  \"StreamId\": 0,\n",
      "  \"Metadata\": \"[ONNX Layer: /seq_blocks.0/BatchNormalization]\\u001e[ONNX Layer: /seq_blocks.1/Relu]\"\n",
      "},{\n",
      "  \"Name\": \"Reformatting CopyNode for Input Tensor 0 to PWN(PWN(onnx::Mul_36_clone_1 + (Unnamed Layer* 6) [Shuffle] + unsqueeze_node_after_(Unnamed Layer* 6) [Shuffle]_(Unnamed Layer* 6) [Shuffle]_output + /seq_blocks.2/_input_quantizer/Mul, PWN(/seq_blocks.2/_input_quantizer/Round)), PWN(/seq_blocks.2/_input_quantizer/Clip))\",\n",
      "  \"LayerType\": \"NoOp\",\n",
      "  \"Inputs\": [\n",
      "  {\n",
      "    \"Name\": \"/seq_blocks.1/Relu_out_tensor\",\n",
      "    \"Location\": \"Device\",\n",
      "    \"Dimensions\": [256,16,1,1],\n",
      "    \"Format/Datatype\": \"Row major linear FP16 format\"\n",
      "  }],\n",
      "  \"Outputs\": [\n",
      "  {\n",
      "    \"Name\": \"Reformatted Input Tensor 0 to PWN(PWN(onnx::Mul_36_clone_1 + (Unnamed Layer* 6) [Shuffle] + unsqueeze_node_after_(Unnamed Layer* 6) [Shuffle]_(Unnamed Layer* 6) [Shuffle]_output + /seq_blocks.2/_input_quantizer/Mul, PWN(/seq_blocks.2/_input_quantizer/Round)), PWN(/seq_blocks.2/_input_quantizer/Clip))\",\n",
      "    \"Location\": \"Device\",\n",
      "    \"Dimensions\": [256,16,1,1],\n",
      "    \"Format/Datatype\": \"Channel major FP16 format where channel % 2 == 0\"\n",
      "  }],\n",
      "  \"TacticValue\": \"0x0000000000000000\",\n",
      "  \"StreamId\": 0,\n",
      "  \"Metadata\": \"\"\n",
      "},{\n",
      "  \"Name\": \"PWN(PWN(onnx::Mul_36_clone_1 + (Unnamed Layer* 6) [Shuffle] + unsqueeze_node_after_(Unnamed Layer* 6) [Shuffle]_(Unnamed Layer* 6) [Shuffle]_output + /seq_blocks.2/_input_quantizer/Mul, PWN(/seq_blocks.2/_input_quantizer/Round)), PWN(/seq_blocks.2/_input_quantizer/Clip))\",\n",
      "  \"LayerType\": \"PointWiseV2\",\n",
      "  \"Inputs\": [\n",
      "  {\n",
      "    \"Name\": \"Reformatted Input Tensor 0 to PWN(PWN(onnx::Mul_36_clone_1 + (Unnamed Layer* 6) [Shuffle] + unsqueeze_node_after_(Unnamed Layer* 6) [Shuffle]_(Unnamed Layer* 6) [Shuffle]_output + /seq_blocks.2/_input_quantizer/Mul, PWN(/seq_blocks.2/_input_quantizer/Round)), PWN(/seq_blocks.2/_input_quantizer/Clip))\",\n",
      "    \"Location\": \"Device\",\n",
      "    \"Dimensions\": [256,16,1,1],\n",
      "    \"Format/Datatype\": \"Channel major FP16 format where channel % 2 == 0\"\n",
      "  }],\n",
      "  \"Outputs\": [\n",
      "  {\n",
      "    \"Name\": \"/seq_blocks.2/_input_quantizer/Clip_out_tensor\",\n",
      "    \"Location\": \"Device\",\n",
      "    \"Dimensions\": [256,16,1,1],\n",
      "    \"Format/Datatype\": \"Channel major FP16 format where channel % 2 == 0\"\n",
      "  }],\n",
      "  \"ParameterType\": \"PointWise\",\n",
      "  \"ParameterSubType\": \"PointWiseExpression\",\n",
      "  \"NbInputArgs\": 1,\n",
      "  \"InputArgs\": [\"arg0\"],\n",
      "  \"NbOutputVars\": 1,\n",
      "  \"OutputVars\": [\"var3\"],\n",
      "  \"NbParams\": 0,\n",
      "  \"Params\": [],\n",
      "  \"NbLiterals\": 6,\n",
      "  \"Literals\": [\"0.000000e+00f\", \"3.371592e+00f\", \"0.000000e+00f\", \"1.000000e+00f\", \"-1.280000e+02f\", \"1.270000e+02f\"],\n",
      "  \"NbOperations\": 4,\n",
      "  \"Operations\": [\"auto const var0 = pwgen::iMul(arg0, literal1);\", \"auto const var1 = pwgen::iRound(var0);\", \"auto const var2 = pwgen::iMin(literal5, var1);\", \"auto const var3 = pwgen::iMax(literal4, var2);\"],\n",
      "  \"TacticValue\": \"0x000000000000001d\",\n",
      "  \"StreamId\": 0,\n",
      "  \"Metadata\": \"[ONNX Layer: /seq_blocks.2/_input_quantizer/Mul]\\u001e[ONNX Layer: /seq_blocks.2/_input_quantizer/Round]\\u001e[ONNX Layer: /seq_blocks.2/_input_quantizer/Clip]\"\n",
      "},{\n",
      "  \"Name\": \"Reformatting CopyNode for Input Tensor 0 to squeeze_after_/seq_blocks.2/_input_quantizer/Clip\",\n",
      "  \"LayerType\": \"NoOp\",\n",
      "  \"Inputs\": [\n",
      "  {\n",
      "    \"Name\": \"/seq_blocks.2/_input_quantizer/Clip_out_tensor\",\n",
      "    \"Location\": \"Device\",\n",
      "    \"Dimensions\": [256,16,1,1],\n",
      "    \"Format/Datatype\": \"Channel major FP16 format where channel % 2 == 0\"\n",
      "  }],\n",
      "  \"Outputs\": [\n",
      "  {\n",
      "    \"Name\": \"Reformatted Input Tensor 0 to squeeze_after_/seq_blocks.2/_input_quantizer/Clip\",\n",
      "    \"Location\": \"Device\",\n",
      "    \"Dimensions\": [256,16,1,1],\n",
      "    \"Format/Datatype\": \"Row major linear FP16 format\"\n",
      "  }],\n",
      "  \"TacticValue\": \"0x0000000000000000\",\n",
      "  \"StreamId\": 0,\n",
      "  \"Metadata\": \"\"\n",
      "},{\n",
      "  \"Name\": \"squeeze_after_/seq_blocks.2/_input_quantizer/Clip\",\n",
      "  \"LayerType\": \"NoOp\",\n",
      "  \"Inputs\": [\n",
      "  {\n",
      "    \"Name\": \"Reformatted Input Tensor 0 to squeeze_after_/seq_blocks.2/_input_quantizer/Clip\",\n",
      "    \"Location\": \"Device\",\n",
      "    \"Dimensions\": [256,16,1,1],\n",
      "    \"Format/Datatype\": \"Row major linear FP16 format\"\n",
      "  }],\n",
      "  \"Outputs\": [\n",
      "  {\n",
      "    \"Name\": \"squeeze_after_/seq_blocks.2/_input_quantizer/Clip_out_tensor\",\n",
      "    \"Location\": \"Device\",\n",
      "    \"Dimensions\": [256,16],\n",
      "    \"Format/Datatype\": \"Row major linear FP16 format\"\n",
      "  }],\n",
      "  \"TacticValue\": \"0x0000000000000000\",\n",
      "  \"StreamId\": 0,\n",
      "  \"Metadata\": \"\"\n",
      "},{\n",
      "  \"Name\": \"(Unnamed Layer* 10) [Shuffle]\",\n",
      "  \"LayerType\": \"NoOp\",\n",
      "  \"Inputs\": [\n",
      "  {\n",
      "    \"Name\": \"onnx::Div_39\",\n",
      "    \"Location\": \"Device\",\n",
      "    \"Dimensions\": [],\n",
      "    \"Format/Datatype\": \"Row major linear FP16 format\"\n",
      "  }],\n",
      "  \"Outputs\": [\n",
      "  {\n",
      "    \"Name\": \"(Unnamed Layer* 10) [Shuffle]_output\",\n",
      "    \"Location\": \"Device\",\n",
      "    \"Dimensions\": [1,1],\n",
      "    \"Format/Datatype\": \"Row major linear FP16 format\"\n",
      "  }],\n",
      "  \"TacticValue\": \"0x0000000000000000\",\n",
      "  \"StreamId\": 0,\n",
      "  \"Metadata\": \"\"\n",
      "},{\n",
      "  \"Name\": \"/seq_blocks.2/_input_quantizer/Div\",\n",
      "  \"LayerType\": \"ElementWise\",\n",
      "  \"Inputs\": [\n",
      "  {\n",
      "    \"Name\": \"squeeze_after_/seq_blocks.2/_input_quantizer/Clip_out_tensor\",\n",
      "    \"Location\": \"Device\",\n",
      "    \"Dimensions\": [256,16],\n",
      "    \"Format/Datatype\": \"Row major linear FP16 format\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"(Unnamed Layer* 10) [Shuffle]_output\",\n",
      "    \"Location\": \"Device\",\n",
      "    \"Dimensions\": [1,1],\n",
      "    \"Format/Datatype\": \"Row major linear FP16 format\"\n",
      "  }],\n",
      "  \"Outputs\": [\n",
      "  {\n",
      "    \"Name\": \"/seq_blocks.2/_input_quantizer/Div_output_0\",\n",
      "    \"Location\": \"Device\",\n",
      "    \"Dimensions\": [256,16],\n",
      "    \"Format/Datatype\": \"Row major linear FP16 format\"\n",
      "  }],\n",
      "  \"ParameterType\": \"ElementWise\",\n",
      "  \"ElementWiseOperation\": \"DIV\",\n",
      "  \"Activation\": \"NONE\",\n",
      "  \"TacticValue\": \"0x0000000000000001\",\n",
      "  \"StreamId\": 0,\n",
      "  \"Metadata\": \"[ONNX Layer: /seq_blocks.2/_input_quantizer/Div]\"\n",
      "},{\n",
      "  \"Name\": \"onnx::Round_41\",\n",
      "  \"LayerType\": \"Constant\",\n",
      "  \"Inputs\": [],\n",
      "  \"Outputs\": [\n",
      "  {\n",
      "    \"Name\": \"(Unnamed Layer* 12) [Constant]_output\",\n",
      "    \"Location\": \"Device\",\n",
      "    \"Dimensions\": [5,16],\n",
      "    \"Format/Datatype\": \"Row major linear FP16 format\"\n",
      "  }],\n",
      "  \"ParameterType\": \"Constant\",\n",
      "  \"weights\": {\"Type\": \"Float\", \"Count\": 80},\n",
      "  \"dimensions\": [5,16],\n",
      "  \"TacticValue\": \"0x0000000000000000\",\n",
      "  \"StreamId\": 0,\n",
      "  \"Metadata\": \"\"\n",
      "},{\n",
      "  \"Name\": \"onnx::Div_44\",\n",
      "  \"LayerType\": \"Constant\",\n",
      "  \"Inputs\": [],\n",
      "  \"Outputs\": [\n",
      "  {\n",
      "    \"Name\": \"(Unnamed Layer* 15) [Constant]_output\",\n",
      "    \"Location\": \"Device\",\n",
      "    \"Dimensions\": [5,1],\n",
      "    \"Format/Datatype\": \"Row major linear FP16 format\"\n",
      "  }],\n",
      "  \"ParameterType\": \"Constant\",\n",
      "  \"weights\": {\"Type\": \"Float\", \"Count\": 5},\n",
      "  \"dimensions\": [5,1],\n",
      "  \"TacticValue\": \"0x0000000000000000\",\n",
      "  \"StreamId\": 0,\n",
      "  \"Metadata\": \"\"\n",
      "},{\n",
      "  \"Name\": \"PWN(PWN(PWN(/seq_blocks.2/_weight_quantizer/Round), PWN(/seq_blocks.2/_weight_quantizer/Clip)), /seq_blocks.2/_weight_quantizer/Div)\",\n",
      "  \"LayerType\": \"PointWiseV2\",\n",
      "  \"Inputs\": [\n",
      "  {\n",
      "    \"Name\": \"(Unnamed Layer* 12) [Constant]_output\",\n",
      "    \"Location\": \"Device\",\n",
      "    \"Dimensions\": [5,16],\n",
      "    \"Format/Datatype\": \"Row major linear FP16 format\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"(Unnamed Layer* 15) [Constant]_output\",\n",
      "    \"Location\": \"Device\",\n",
      "    \"Dimensions\": [5,1],\n",
      "    \"Format/Datatype\": \"Row major linear FP16 format\"\n",
      "  }],\n",
      "  \"Outputs\": [\n",
      "  {\n",
      "    \"Name\": \"/seq_blocks.2/_weight_quantizer/Div_output_0\",\n",
      "    \"Location\": \"Device\",\n",
      "    \"Dimensions\": [5,16],\n",
      "    \"Format/Datatype\": \"Row major linear FP16 format\"\n",
      "  }],\n",
      "  \"ParameterType\": \"PointWise\",\n",
      "  \"ParameterSubType\": \"PointWiseExpression\",\n",
      "  \"NbInputArgs\": 2,\n",
      "  \"InputArgs\": [\"arg0\", \"arg1\"],\n",
      "  \"NbOutputVars\": 1,\n",
      "  \"OutputVars\": [\"var3\"],\n",
      "  \"NbParams\": 0,\n",
      "  \"Params\": [],\n",
      "  \"NbLiterals\": 4,\n",
      "  \"Literals\": [\"0.000000e+00f\", \"1.000000e+00f\", \"-1.280000e+02f\", \"1.270000e+02f\"],\n",
      "  \"NbOperations\": 4,\n",
      "  \"Operations\": [\"auto const var0 = pwgen::iRound(arg0);\", \"auto const var1 = pwgen::iMin(literal3, var0);\", \"auto const var2 = pwgen::iMax(literal2, var1);\", \"auto const var3 = pwgen::iDiv(var2, arg1);\"],\n",
      "  \"TacticValue\": \"0x000000000000001c\",\n",
      "  \"StreamId\": 0,\n",
      "  \"Metadata\": \"[ONNX Layer: /seq_blocks.2/_weight_quantizer/Round]\\u001e[ONNX Layer: /seq_blocks.2/_weight_quantizer/Clip]\\u001e[ONNX Layer: /seq_blocks.2/_weight_quantizer/Div]\"\n",
      "},{\n",
      "  \"Name\": \"/seq_blocks.2/Gemm\",\n",
      "  \"LayerType\": \"CaskGemmMatrixMultiply\",\n",
      "  \"Inputs\": [\n",
      "  {\n",
      "    \"Name\": \"/seq_blocks.2/_input_quantizer/Div_output_0\",\n",
      "    \"Location\": \"Device\",\n",
      "    \"Dimensions\": [256,16],\n",
      "    \"Format/Datatype\": \"Row major linear FP16 format\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"/seq_blocks.2/_weight_quantizer/Div_output_0\",\n",
      "    \"Location\": \"Device\",\n",
      "    \"Dimensions\": [5,16],\n",
      "    \"Format/Datatype\": \"Row major linear FP16 format\"\n",
      "  }],\n",
      "  \"Outputs\": [\n",
      "  {\n",
      "    \"Name\": \"/seq_blocks.2/Gemm_output_0\",\n",
      "    \"Location\": \"Device\",\n",
      "    \"Dimensions\": [256,5],\n",
      "    \"Format/Datatype\": \"Row major linear FP16 format\"\n",
      "  }],\n",
      "  \"ParameterType\": \"MatrixMultiply\",\n",
      "  \"MatrixOpA\": \"NONE\",\n",
      "  \"MatrixOpB\": \"TRANSPOSE\",\n",
      "  \"Alpha\": 1,\n",
      "  \"Beta\": 0,\n",
      "  \"TacticName\": \"sm75_xmma_gemm_f16f16_f16f16_f16_tn_n_tilesize32x32x64_stage1_warpsize2x2x1_tensor16x8x8_aligna2_alignc2\",\n",
      "  \"TacticValue\": \"0x0000000000020277\",\n",
      "  \"StreamId\": 0,\n",
      "  \"Metadata\": \"[ONNX Layer: /seq_blocks.2/Gemm]\\u001e\"\n",
      "},{\n",
      "  \"Name\": \"PWN(/seq_blocks.3/Relu)\",\n",
      "  \"LayerType\": \"PointWiseV2\",\n",
      "  \"Inputs\": [\n",
      "  {\n",
      "    \"Name\": \"/seq_blocks.2/Gemm_output_0\",\n",
      "    \"Location\": \"Device\",\n",
      "    \"Dimensions\": [256,5],\n",
      "    \"Format/Datatype\": \"Row major linear FP16 format\"\n",
      "  }],\n",
      "  \"Outputs\": [\n",
      "  {\n",
      "    \"Name\": \"Reformatted Output Tensor 0 to PWN(/seq_blocks.3/Relu)\",\n",
      "    \"Location\": \"Device\",\n",
      "    \"Dimensions\": [256,5],\n",
      "    \"Format/Datatype\": \"Row major linear FP16 format\"\n",
      "  }],\n",
      "  \"ParameterType\": \"PointWise\",\n",
      "  \"ParameterSubType\": \"PointWiseExpression\",\n",
      "  \"NbInputArgs\": 1,\n",
      "  \"InputArgs\": [\"arg0\"],\n",
      "  \"NbOutputVars\": 1,\n",
      "  \"OutputVars\": [\"var0\"],\n",
      "  \"NbParams\": 0,\n",
      "  \"Params\": [],\n",
      "  \"NbLiterals\": 4,\n",
      "  \"Literals\": [\"0.000000e+00f\", \"1.000000e+00f\", \"0.000000e+00f\", \"0.000000e+00f\"],\n",
      "  \"NbOperations\": 1,\n",
      "  \"Operations\": [\"auto const var0 = pwgen::iMax(arg0, literal0);\"],\n",
      "  \"TacticValue\": \"0x000000000000001c\",\n",
      "  \"StreamId\": 0,\n",
      "  \"Metadata\": \"[ONNX Layer: /seq_blocks.3/Relu]\"\n",
      "},{\n",
      "  \"Name\": \"Reformatting CopyNode for Output Tensor 0 to PWN(/seq_blocks.3/Relu)\",\n",
      "  \"LayerType\": \"Reformat\",\n",
      "  \"Inputs\": [\n",
      "  {\n",
      "    \"Name\": \"Reformatted Output Tensor 0 to PWN(/seq_blocks.3/Relu)\",\n",
      "    \"Location\": \"Device\",\n",
      "    \"Dimensions\": [256,5],\n",
      "    \"Format/Datatype\": \"Row major linear FP16 format\"\n",
      "  }],\n",
      "  \"Outputs\": [\n",
      "  {\n",
      "    \"Name\": \"35\",\n",
      "    \"Location\": \"Device\",\n",
      "    \"Dimensions\": [256,5],\n",
      "    \"Format/Datatype\": \"Row major linear FP32\"\n",
      "  }],\n",
      "  \"ParameterType\": \"Reformat\",\n",
      "  \"Origin\": \"REFORMAT\",\n",
      "  \"TacticValue\": \"0x0000000000000000\",\n",
      "  \"StreamId\": 0,\n",
      "  \"Metadata\": \"\"\n",
      "}],\n",
      "\"Bindings\": [\"input\"\n",
      ",\"35\"\n",
      "]}\n",
      "\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTensorRT Conversion Complete. Stored trt model to /root/mase/mase_output/TensorRT/Quantization/TRT/2024_03_12/version_6/model.trt\u001b[0m\n",
      "I0312 09:56:20.059824 139936087775040 quantize.py:154] TensorRT Conversion Complete. Stored trt model to /root/mase/mase_output/TensorRT/Quantization/TRT/2024_03_12/version_6/model.trt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03/12/2024-09:56:20] [TRT] [W] CUDA lazy loading is not enabled. Enabling it can significantly reduce device memory usage and speed up TensorRT initialization. See \"Lazy Loading\" section of CUDA documentation https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#lazy-loading\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "TensorRT Engine Input/Output Information:\n",
      "Index | Type    | DataType | Static Shape         | Dynamic Shape        | Name\n",
      "------|---------|----------|----------------------|----------------------|-----------------------\n",
      "0     | Input   | FLOAT    | (256, 16)              | (256, 16)              | input\n",
      "1     | Output  | FLOAT    | (256, 5)               | (256, 5)               | 35\u001b[0m\n",
      "I0312 09:56:20.342786 139936087775040 analysis.py:111] \n",
      "TensorRT Engine Input/Output Information:\n",
      "Index | Type    | DataType | Static Shape         | Dynamic Shape        | Name\n",
      "------|---------|----------|----------------------|----------------------|-----------------------\n",
      "0     | Input   | FLOAT    | (256, 16)              | (256, 16)              | input\n",
      "1     | Output  | FLOAT    | (256, 5)               | (256, 5)               | 35\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mStarting TensorRT transformation analysis\u001b[0m\n",
      "I0312 09:56:20.344804 139936087775040 analysis.py:215] Starting TensorRT transformation analysis\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Configuration Original Model:\n",
      "Metric                    | Value\n",
      "--------------------------|-----------------------\n",
      "Average Accuracy         | 0.699386477470398\n",
      "Average Precision        | 0.7028905153274536\n",
      "Average Recall           | 0.6973958015441895\n",
      "Average F1 Score         | 0.697779655456543\n",
      "Average Loss             | 0.8983033816019694\n",
      "Average Latency          | 0.7218624075253804 milliseconds\n",
      "Average GPU Power Usage  | 66.97226666666666 watts\n",
      "Average GPU Energy Usage | 1.3429100459286607e-08 kW/hr\u001b[0m\n",
      "I0312 09:56:20.758443 139936087775040 analysis.py:306] \n",
      "Configuration Original Model:\n",
      "Metric                    | Value\n",
      "--------------------------|-----------------------\n",
      "Average Accuracy         | 0.699386477470398\n",
      "Average Precision        | 0.7028905153274536\n",
      "Average Recall           | 0.6973958015441895\n",
      "Average F1 Score         | 0.697779655456543\n",
      "Average Loss             | 0.8983033816019694\n",
      "Average Latency          | 0.7218624075253804 milliseconds\n",
      "Average GPU Power Usage  | 66.97226666666666 watts\n",
      "Average GPU Energy Usage | 1.3429100459286607e-08 kW/hr\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "Configuration TensorRT Quantized Model:\n",
      "Metric                    | Value\n",
      "--------------------------|-----------------------\n",
      "Average Accuracy         | 0.7143192291259766\n",
      "Average Precision        | 0.7226994037628174\n",
      "Average Recall           | 0.7132812738418579\n",
      "Average F1 Score         | 0.7139862775802612\n",
      "Average Loss             | 0.8742726842562357\n",
      "Average Latency          | 0.22142506539821624 milliseconds\n",
      "Average GPU Power Usage  | 66.67286666666666 watts\n",
      "Average GPU Energy Usage | 4.100845517209227e-09 kW/hr\u001b[0m\n",
      "I0312 09:56:21.102709 139936087775040 analysis.py:306] \n",
      "Configuration TensorRT Quantized Model:\n",
      "Metric                    | Value\n",
      "--------------------------|-----------------------\n",
      "Average Accuracy         | 0.7143192291259766\n",
      "Average Precision        | 0.7226994037628174\n",
      "Average Recall           | 0.7132812738418579\n",
      "Average F1 Score         | 0.7139862775802612\n",
      "Average Loss             | 0.8742726842562357\n",
      "Average Latency          | 0.22142506539821624 milliseconds\n",
      "Average GPU Power Usage  | 66.67286666666666 watts\n",
      "Average GPU Energy Usage | 4.100845517209227e-09 kW/hr\n"
     ]
    }
   ],
   "source": [
    "'''  \n",
    "./ch transform --config configs/examples/jsc_trt_quantization.toml --load ../TensorRTDev/jsc-tiny_classification_jsc_2024-03-05/software/training_ckpts/best.ckpt --load-type pl\n",
    "./ch transform --config configs/examples/jsc_trt_quantization.toml --load ../TensorRTDev/jsc-trt_classification_jsc_2024-03-05/software/training_ckpts/best.ckpt --load-type pl\n",
    "./ch transform --config configs/examples/jsc_trt_quantization.toml --load ../TensorRTDev/jsc-toy_classification_jsc_2024-03-05/software/training_ckpts/best.ckpt --load-type pl\n",
    "'''\n",
    "# Restart kernel and re-run previous cells to avoid any issues\n",
    "# mg_og = deepcopy_mase_graph(mg)\n",
    "mg_original = copy.deepcopy(mg.model)\n",
    "\n",
    "# Calibrate model (passing data samples to the quantizer and deciding the best amax for activations)\n",
    "mg, _ = tensorrt_calibrate_transform_pass(mg, pass_args=tensorrt_quantize_config)\n",
    "\n",
    "# # Conduct QAT\n",
    "# mg, _ = tensorrt_train_transform_pass(mg, pass_args=tensorrt_train_config)\n",
    "\n",
    "# Convert and store to ONNX and then TensorRT\n",
    "mg, trt_meta = tensorrt_quantize_transform_pass(mg, pass_args=tensorrt_quantize_config)\n",
    "\n",
    "# Compare original tensorrt with quantized graph\n",
    "mg_original, _ = tensorrt_analysis_pass(mg_original, trt_meta['trt_graph_path'], pass_args=tensorrt_analysis_config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
