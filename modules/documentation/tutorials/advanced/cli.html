
<!DOCTYPE html>


<html lang="en" data-content_root="../../../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Advanced: Using Mase CLI &#8212; MASE 0.0.1 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/graphviz.css?v=4ae1632d" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/sphinx-data-viewer/jsonview.bundle.css?v=f6ef2277" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/sphinx-needs/libs/html/datatables.min.css?v=4b4fd840" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/sphinx-needs/common_css/need_links.css?v=2150a916" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/sphinx-needs/common_css/need_style.css?v=92936fa5" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/sphinx-needs/common_css/needstable.css?v=5e1b6797" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/sphinx-needs/common_css/need_toggle.css?v=5c6620df" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/sphinx-needs/common_css/need_core.css?v=f5b60a78" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/sphinx-needs/modern.css?v=803738c0" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../../../_static/jquery.js?v=5d32c60e"></script>
    <script src="../../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
    <script src="../../../../_static/documentation_options.js?v=e645c8fa"></script>
    <script src="../../../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script src="../../../../_static/sphinx-data-viewer/jsonview.bundle.js?v=18cd53c5"></script>
    <script src="../../../../_static/sphinx-data-viewer/jsonview_loader.js?v=f7ff7e7d"></script>
    <script src="../../../../_static/sphinx-needs/libs/html/datatables.min.js?v=8a4aee21"></script>
    <script src="../../../../_static/sphinx-needs/libs/html/datatables_loader.js?v=a2cae175"></script>
    <script src="../../../../_static/sphinx-needs/libs/html/sphinx_needs_collapse.js?v=dca66431"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'modules/documentation/tutorials/advanced/cli';</script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
    <link rel="next" title="Developer: Guide on how to add a new model into Machop" href="../developer/Add-model-to-machop.html" />
    <link rel="prev" title="Advanced: ONNX Runtime Tutorial" href="onnxrt_quantization_tutorial.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../../../index.html">
  
  
  
  
  
  
    <p class="title logo__title">MASE 0.0.1 documentation</p>
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Overview</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../installation.html">Installation</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../getting_started/Get-started-using-uv.html">Getting Started using uv</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../getting_started/Get-started-using-Docker.html">Getting Started using Docker</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../getting_started/Get-started-students.html">Additional Instructions for Imperial College Students</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../quickstart.html">Quickstart</a></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../../tutorials.html">Tutorials</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../tutorial_1_introduction_to_mase.html">Tutorial 1: Introduction to the Mase IR, MaseGraph and Torch FX passes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorial_2_lora_finetune.html">Tutorial 2: Finetuning Bert for Sequence Classification using a LoRA adapter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorial_3_qat.html">Tutorial 3: Running Quantization-Aware Training (QAT) on Bert</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorial_4_pruning.html">Tutorial 4: Unstructured Pruning on Bert</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorial_5_nas_optuna.html">Tutorial 5: Neural Architecture Search (NAS) with Mase and Optuna</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorial_6_mixed_precision_search.html">Tutorial 6: Mixed Precision Quantization Search with Mase and Optuna</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorial_7_distributed_deployment.html">Tutorial 7: Deploying a Model for Inference on Distributed Clusters</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorial_9_kernel_fusion.html">Tutorial 9: Running Kernel Fusion for Inference Acceleration on GPUs</a></li>
<li class="toctree-l2"><a class="reference internal" href="tensorRT_quantization_tutorial.html">Advanced: TensorRT Quantization Tutorial</a></li>
<li class="toctree-l2"><a class="reference internal" href="onnxrt_quantization_tutorial.html">Advanced: ONNX Runtime Tutorial</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Advanced: Using Mase CLI</a></li>
<li class="toctree-l2"><a class="reference internal" href="../developer/Add-model-to-machop.html">Developer: Guide on how to add a new model into Machop</a></li>
<li class="toctree-l2"><a class="reference internal" href="../developer/doc_writing.html">Developer: How to write documentations in MASE</a></li>
<li class="toctree-l2"><a class="reference internal" href="../developer/how_to_extend_search.html">Developer: How to extend search</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../health.html">Repository Health</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../specifications.html">Coding Style Specifications</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../specifications/C-coding-style-specifications.html">C/C++ Coding Style Specifications</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../specifications/Python-coding-style-specifications.html">Python Coding Style Specifications</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../specifications/Verilog-coding-style-specifications.html">Verilog Coding Style Specifications</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Machop API</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../machop.html">Machop Documentation</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../chop/actions.html">chop.actions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../chop/datasets.html">chop.datasets</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../chop/distributed.html">chop.distributed</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../chop/ir.html">chop.ir</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../chop/models.html">chop.models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../chop/nn.html">chop.nn</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../chop/nn_quantized.html">chop.nn.quantized</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../chop/nn_quantized_functional.html">chop.nn.quantized.functional</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../chop/nn_quantized_modules.html">chop.nn.quantized.modules</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../chop/passes.html">chop.passes</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../chop/passes_module.html">chop.passes.module</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../chop/module_analysis/quantization.html">chop.passes.module.transform.quantize</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../chop/module_transform/quantization.html">chop.passes.module.transform.quantize</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../chop/transform/onn.html">chop.passes.module.transforms.onn</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../chop/passes_graph.html">chop.passes.graph</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../chop/analysis/add_metadata.html">chop.passes.graph.analysis.add_metadata</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../chop/analysis/autosharding.html">chop.passes.graph.analysis.autosharding</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../chop/analysis/init_metadata.html">chop.passes.graph.analysis.init_metadata</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../chop/analysis/report.html">chop.passes.graph.analysis.report</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../chop/analysis/statistical_profiler.html">chop.passes.graph.analysis.statistical_profiler.profile_statistics</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../chop/analysis/verify.html">chop.passes.graph.analysis.verify.verify</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../chop/analysis/quantization.html">chop.passes.graph.calculate_avg_bits_mg_analysis_pass</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../chop/analysis/pruning.html">chop.passes.graph.pruning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../chop/analysis/runtime.html">chop.passes.graph.analysis.runtime</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../chop/transform/pruning.html">chop.passes.transform.pruning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../chop/transform/quantize.html">chop.passes.transform.quantize</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../chop/transform/utils.html">chop.passes.transform.utils</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../chop/transform/tensorrt.html">chop.passes.transform.tensorrt</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../chop/interface/save_and_load.html">chop.passes.interface.save_and_load</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../chop/interface/tensorrt.html">chop.passes.interface.tensorrt</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../chop/interface/onnxrt.html">chop.passes.interface.onnxrt</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../../../chop/pipelines.html">chop.pipelines</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../chop/tools.html">chop.tools</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Advanced Deep Learning Systems</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../adls_2024.html">Advanced Deep Learning Systems: 2024/2025</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../labs_2024/lab_0_introduction.html">Lab 0: Introduction to Mase</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../labs_2024/lab_1_compression.html">Lab 1: Model Compression (Quantization and Pruning)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../labs_2024/lab_2_nas.html">Lab 2: Neural Architecture Search</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../labs_2024/lab_3_mixed_precision_search.html">Lab 3: Mixed Precision Search</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../labs_2024/lab4-software.html">Lab 4 (Software Stream) Performance Engineering</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../labs_2024/setup_docker_env.html">ADLS Docker Environment Setup</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../adls_2023.html">Advanced Deep Learning Systems: 2023/2024</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../labs_2023/lab1.html">Lab 1 for Advanced Deep Learning Systems (ADLS)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../labs_2023/lab2.html">Lab 2 for Advanced Deep Learning Systems (ADLS)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../labs_2023/lab3.html">Lab 3 for Advanced Deep Learning Systems (ADLS)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../labs_2023/lab4-software.html">Lab 4 (Software Stream) for Advanced Deep Learning Systems (ADLS)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../labs_2023/setup_docker_env.html">ADLS Docker Environment Setup</a></li>
</ul>
</details></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../../../_sources/modules/documentation/tutorials/advanced/cli.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Advanced: Using Mase CLI</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#run-the-train-action-with-the-cli">Run the train action with the CLI</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#command-line-interface">Command line interface</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#training-implementation">Training implementation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#models">Models</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#output">Output</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#training-logs">Training Logs</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#test-command">Test command</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#quantise-transform">Quantise transform</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#quantization-aware-training-qat">Quantization-aware Training (QAT)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#quantise-transform-by-type">Quantise transform by Type</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mixed-precision-search-on-manual-model">Mixed-precision search on manual model</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#search-for-mixed-precision-quantization-scheme">Search for Mixed-Precision Quantization Scheme</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#search-config">Search config</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#launch-the-precision-search">Launch the Precision Search</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#search-logs">Search Logs</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mixed-precision-search-on-mase-graph">Mixed-precision search on MASE Graph</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#commands">Commands</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Search Config</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#run-the-search">Run the search</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="advanced-using-mase-cli">
<h1>Advanced: Using Mase CLI<a class="headerlink" href="#advanced-using-mase-cli" title="Link to this heading">#</a></h1>
<p>The Mase CLI has been deprecated, but the following tutorials are kept here for legacy reasons.</p>
<section id="run-the-train-action-with-the-cli">
<h2>Run the train action with the CLI<a class="headerlink" href="#run-the-train-action-with-the-cli" title="Link to this heading">#</a></h2>
<p>MASE has several functionalities, and this document aims to introduce the simplest <code class="docutils literal notranslate"><span class="pre">train</span></code> and <code class="docutils literal notranslate"><span class="pre">eval</span></code> pipelines.</p>
<section id="command-line-interface">
<h3>Command line interface<a class="headerlink" href="#command-line-interface" title="Link to this heading">#</a></h3>
<p>MASE actually supports usage in two modes:</p>
<ul class="simple">
<li><p>A direct <code class="docutils literal notranslate"><span class="pre">import</span></code> as a module (eg. <code class="docutils literal notranslate"><span class="pre">machop/examples/toy/main.py</span></code>).</p></li>
<li><p>Through the command line interface (the focus of this document).</p></li>
</ul>
<p>In this case, we can try a toymodel, the command looks like the following</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># assuming you you are at the our-stuff/mase directory</span>
<span class="nb">cd</span><span class="w"> </span>src
./ch<span class="w"> </span>train<span class="w"> </span>toy<span class="w"> </span>toy_tiny<span class="w"> </span>--config<span class="w"> </span>../configs/archive/test/train.toml<span class="w"> </span>--max-epochs<span class="w"> </span><span class="m">3</span>
</pre></div>
</div>
<blockquote>
<div><p><strong>Note:</strong> This is training is for demonstration purposes, we picked a very small model/dataset to make it runnable even on CPU-based devices. It does not mean to achieve a useful accuracy!</p>
</div></blockquote>
<p>You can fetch all command-line arguments:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[nix-shell:~/Projects/mase/src]$ ./ch -help
INFO     Set logging level to debug
WARNING  TensorRT pass is unavailable because the following dependencies are not installed: pytorch_quantization, tensorrt, pycuda, cuda.
usage: ch [--config PATH] [--task TASK] [--load PATH] [--load-type] [--batch-size NUM] [--debug] [--log-level] [--report-to {wandb,tensorboard}] [--seed NUM] [--quant-config TOML]
          [--training-optimizer TYPE] [--trainer-precision TYPE] [--learning-rate NUM] [--weight-decay NUM] [--max-epochs NUM] [--max-steps NUM] [--accumulate-grad-batches NUM]
          [--log-every-n-steps NUM] [--cpu NUM] [--gpu NUM] [--nodes NUM] [--accelerator TYPE] [--strategy TYPE] [--auto-requeue] [--github-ci] [--disable-dataset-cache]
          [--target STR] [--num-targets NUM] [--run-emit] [--skip-build] [--skip-test] [--pretrained] [--max-token-len NUM] [--project-dir DIR] [--project NAME] [--profile]
          [--no-warnings] [-h] [-V] [--info [TYPE]]
          action [model] [dataset]

Chop is a simple utility, part of the MASE tookit, to train, test and transform (i.e. prune or quantise) a supported model.

main arguments:
  action                action to perform. One of (train|test|transform|search|emit|simulate)
  model                 name of a supported model. Required if configuration NOT provided.
  dataset               name of a supported dataset. Required if configuration NOT provided.

general options:
  --config PATH         path to a configuration file in the TOML format. Manual CLI overrides for arguments have a higher precedence. Required if the action is transform. (default:
                        None)
  --task TASK           task to perform. One of (classification|cls|translation|tran|language_modeling|lm) (default: classification)
  --load PATH           path to load the model from. (default: None)
  --load-type           the type of checkpoint to be loaded; it&#39;s disregarded if --load is NOT specified. It is designed to and must be used in tandem with --load. One of
                        (pt|pl|mz|hf) (default: mz)
  --batch-size NUM      batch size for training and evaluation. (default: 128)
  --debug               run the action in debug mode, which enables verbose logging, custom exception hook that uses ipdb, and sets the PL trainer to run in &quot;fast_dev_run&quot; mode.
                        (default: False)
  --log-level           verbosity level of the logger; it&#39;s only effective when --debug flag is NOT passed in. One of (debug|info|warning|error|critical) (default: info)
  --report-to {wandb,tensorboard}
                        reporting tool for logging metrics. One of (wandb|tensorboard) (default: tensorboard)
  --seed NUM            seed for random number generators set via Pytorch Lightning&#39;s seed_everything function. (default: 0)
  --quant-config TOML   path to a configuration file in the TOML format. Manual CLI overrides for arguments have a higher precedence. (default: None)

trainer options:
  --training-optimizer TYPE
                        name of supported optimiser for training. One of (adam|sgd|adamw) (default: adam)
  --trainer-precision TYPE
                        numeric precision for training. One of (16-mixed|32|64|bf16) (default: 16-mixed)
  --learning-rate NUM   initial learning rate for training. (default: 1e-05)
  --weight-decay NUM    weight decay for training. (default: 0)
  --max-epochs NUM      maximum number of epochs for training. (default: 20)
  --max-steps NUM       maximum number of steps for training. A negative value disables this option. (default: -1)
  --accumulate-grad-batches NUM
                        number of batches to accumulate gradients. (default: 1)
  --log-every-n-steps NUM
                        log every n steps. No logs if num_batches &lt; log_every_n_steps. (default: 50))

runtime environment options:
  --cpu NUM, --num-workers NUM
                        number of CPU workers; the default varies across systems and is set to os.cpu_count(). (default: 12)
  --gpu NUM, --num-devices NUM
                        number of GPU devices. (default: 1)
  --nodes NUM           number of nodes. (default: 1)
  --accelerator TYPE    type of accelerator for training. One of (auto|cpu|gpu|mps) (default: auto)
  --strategy TYPE       type of strategy for training. One of (auto|ddp|ddp_find_unused_parameters_true) (default: auto)
  --auto-requeue        enable automatic job resubmission on SLURM managed cluster. (default: False)
  --github-ci           set the execution environment to GitHub&#39;s CI pipeline; it&#39;s used in the MASE verilog emitter transform pass to skip simulations. (default: False)
  --disable-dataset-cache
                        disable caching of datasets. (default: False)

hardware generation options:
  --target STR          target FPGA for hardware synthesis. (default: xcu250-figd2104-2L-e)
  --num-targets NUM     number of FPGA devices. (default: 100)
  --run-emit
  --skip-build
  --skip-test

language model options:
  --pretrained          load pretrained checkpoint from HuggingFace/Torchvision when initialising models. (default: False)
  --max-token-len NUM   maximum number of tokens. A negative value will use tokenizer.model_max_length. (default: 512)

project options:
  --project-dir DIR     directory to save the project to. (default: /Users/yz10513/Projects/mase/mase_output)
  --project NAME        name of the project. (default: {MODEL-NAME}_{TASK-TYPE}_{DATASET-NAME}_{TIMESTAMP})
  --profile
  --no-warnings

information:
  -h, --help            show this help message and exit
  -V, --version         show version and exit
  --info [TYPE]         list information about supported models or/and datasets and exit. One of (all|model|dataset) (default: all)

Maintained by the DeepWok Lab. Raise issues at https://github.com/JianyiCheng/mase-tools/issues
(.venv)
[nix-shell:~/Projects/mase/src]$
</pre></div>
</div>
</section>
<section id="training-implementation">
<h3>Training implementation<a class="headerlink" href="#training-implementation" title="Link to this heading">#</a></h3>
<p>The core train file is <code class="docutils literal notranslate"><span class="pre">mase/src/chop/actions/train.py</span></code>, and the model is wrapped using <code class="docutils literal notranslate"><span class="pre">torch_lightning</span></code>(<a class="reference external" href="https://www.pytorchlightning.ai/index.html">https://www.pytorchlightning.ai/index.html</a>). These wrappers are different for various tasks, as you can see in <code class="docutils literal notranslate"><span class="pre">src/chop/tools/plt_wrapper/__init__.py</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_model_wrapper</span><span class="p">(</span><span class="n">model_info</span><span class="p">,</span> <span class="n">task</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">model_info</span><span class="o">.</span><span class="n">is_physical_model</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">JetSubstructureModelWrapper</span>
    <span class="k">elif</span> <span class="n">model_info</span><span class="o">.</span><span class="n">is_nerf_model</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">NeRFModelWrapper</span>
    <span class="k">elif</span> <span class="n">model_info</span><span class="o">.</span><span class="n">is_vision_model</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">VisionModelWrapper</span>
    <span class="k">elif</span> <span class="n">model_info</span><span class="o">.</span><span class="n">is_nlp_model</span><span class="p">:</span>
        <span class="k">match</span> <span class="n">task</span><span class="p">:</span>
            <span class="k">case</span> <span class="s2">&quot;classification&quot;</span> <span class="o">|</span> <span class="s2">&quot;cls&quot;</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">NLPClassificationModelWrapper</span>
            <span class="k">case</span> <span class="s2">&quot;language_modeling&quot;</span> <span class="o">|</span> <span class="s2">&quot;lm&quot;</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">NLPLanguageModelingModelWrapper</span>
            <span class="k">case</span> <span class="s2">&quot;translation&quot;</span> <span class="o">|</span> <span class="s2">&quot;tran&quot;</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">NLPTranslationModelWrapper</span>
            <span class="k">case</span><span class="w"> </span><span class="k">_</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Task </span><span class="si">{</span><span class="n">task</span><span class="si">}</span><span class="s2"> is not supported for </span><span class="si">{</span><span class="n">model_info</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>This is because different tasks may have a different <code class="docutils literal notranslate"><span class="pre">forward</span></code> pass and also might use different manipulations on data and also its evaluation metrics.
These <code class="docutils literal notranslate"><span class="pre">Wrapper</span></code> also defines the detailed <code class="docutils literal notranslate"><span class="pre">training_flow</span></code>, if we use <code class="docutils literal notranslate"><span class="pre">src/chop/tools/splt_wrapper/base.py</span></code> as an example, <code class="docutils literal notranslate"><span class="pre">training_step</span></code> and <code class="docutils literal notranslate"><span class="pre">validation_step</span></code> are defined in this class.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>class<span class="w"> </span>WrapperBase<span class="o">(</span>pl.LightningModule<span class="o">)</span>:
<span class="w">    </span>def<span class="w"> </span>forward<span class="o">(</span>self,<span class="w"> </span>x<span class="o">)</span>:
<span class="w">        </span><span class="k">return</span><span class="w"> </span>self.model<span class="o">(</span>x<span class="o">)</span>

<span class="w">    </span>def<span class="w"> </span>training_step<span class="o">(</span>self,<span class="w"> </span>batch,<span class="w"> </span>batch_idx<span class="o">)</span>:
<span class="w">        </span>x,<span class="w"> </span><span class="nv">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span>batch<span class="o">[</span><span class="m">0</span><span class="o">]</span>,<span class="w"> </span>batch<span class="o">[</span><span class="m">1</span><span class="o">]</span>
<span class="w">        </span><span class="nv">y_hat</span><span class="w"> </span><span class="o">=</span><span class="w"> </span>self.forward<span class="o">(</span>x<span class="o">)</span>
<span class="w">        </span><span class="nv">loss</span><span class="w"> </span><span class="o">=</span><span class="w"> </span>self.loss_fn<span class="o">(</span>y_hat,<span class="w"> </span>y<span class="o">)</span>

<span class="w">        </span>self.acc_train<span class="o">(</span>y_hat,<span class="w"> </span>y<span class="o">)</span>
<span class="w">        </span>self.log<span class="o">(</span><span class="s2">&quot;train_acc_step&quot;</span>,<span class="w"> </span>self.acc_train,<span class="w"> </span><span class="nv">prog_bar</span><span class="o">=</span>True<span class="o">)</span>
<span class="w">        </span>self.log<span class="o">(</span><span class="s2">&quot;train_loss_step&quot;</span>,<span class="w"> </span>loss<span class="o">)</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span>loss

<span class="w">    </span>def<span class="w"> </span>validation_step<span class="o">(</span>self,<span class="w"> </span>batch,<span class="w"> </span>batch_idx<span class="o">)</span>:
<span class="w">        </span>...

<span class="w">    </span>def<span class="w"> </span>test_step<span class="o">(</span>self,<span class="w"> </span>batch,<span class="w"> </span>batch_idx<span class="o">)</span>:
<span class="w">				</span>...
</pre></div>
</div>
</section>
<section id="models">
<h3>Models<a class="headerlink" href="#models" title="Link to this heading">#</a></h3>
<p>Models are mainly implemented in <code class="docutils literal notranslate"><span class="pre">src/chop/models/__init__.py</span> </code>, and the <code class="docutils literal notranslate"><span class="pre">get_model_info</span></code> contains all currently supported models.
One can also instantiate a custom model and add it to our flow like <code class="docutils literal notranslate"><span class="pre">src/chop/models/toys</span></code>.</p>
</section>
<section id="output">
<h3>Output<a class="headerlink" href="#output" title="Link to this heading">#</a></h3>
<p>MASE produces an output directory after running the training flow. The output directory is found at <code class="docutils literal notranslate"><span class="pre">../mase_output/&lt;model&gt;_&lt;task&gt;_&lt;dataset&gt;_&lt;current_date&gt;</span></code>.
This directory includes</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">hardware</span></code> - a directory for Verilog hardware generated for the trained model</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">software</span></code> - a directory for any software generated for the trained model (PyTorch checkpoints or MASE models) as well as any generated logs</p></li>
</ul>
</section>
<section id="training-logs">
<h3>Training Logs<a class="headerlink" href="#training-logs" title="Link to this heading">#</a></h3>
<p>MASE creates <a class="reference external" href="https://pytorch.org/tutorials/recipes/recipes/tensorboard_with_pytorch.html">Tensorboard</a> or <a class="reference external" href="https://wandb.ai/site">wandb</a> logs for the training flow - allowing tracking and visualizing metrics such as loss and accuracy. The log files are in <code class="docutils literal notranslate"><span class="pre">&lt;output_dir&gt;/software/tensorboard/lightning_logs/version_&lt;n&gt;</span></code>.</p>
<p>Run Tensorboard to visualise the logs using:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>tensorboard<span class="w"> </span>--logdir<span class="w"> </span>&lt;path_to_log_files&gt;
</pre></div>
</div>
<p>If you are using VSCode, this will show up popup asking if you want to open Tensorboard in your browser. Select yes.</p>
<p>If you look at the training printouts, you should have seen something like the following</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>INFO<span class="w">     </span>Initialising<span class="w"> </span>model<span class="w"> </span><span class="s1">&#39;toy&#39;</span>...
INFO<span class="w">     </span>Initialising<span class="w"> </span>dataset<span class="w"> </span><span class="s1">&#39;toy_tiny&#39;</span>...
INFO<span class="w">     </span>Project<span class="w"> </span>will<span class="w"> </span>be<span class="w"> </span>created<span class="w"> </span>at<span class="w"> </span>../mase_output/toy_classification_toy_tiny_2024-06-13
INFO<span class="w">     </span>Training<span class="w"> </span>model<span class="w"> </span><span class="s1">&#39;toy&#39;</span>...
</pre></div>
</div>
<p>This means the <code class="docutils literal notranslate"><span class="pre">path_to_log_files</span></code> is <code class="docutils literal notranslate"><span class="pre">../mase_output/toy_classification_toy_tiny_2024-06-13</span></code>.</p>
<p>Full command should be something like</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>tensorboard<span class="w"> </span>--logdir<span class="w"> </span>../mase_output/toy_classification_toy_tiny_2024-06-13/software/tensorboard/lightning_logs/version_2
</pre></div>
</div>
</section>
<section id="test-command">
<h3>Test command<a class="headerlink" href="#test-command" title="Link to this heading">#</a></h3>
<p>To test the model trained above you can use:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># After training, you will have your checkpoint under mase-tools/mase_output</span>
<span class="c1"># For example, the checkpoint is under ../mase_output/toy_classification_toy-tiny_2023-07-03/software/training_ckpts/best.ckpt</span>
./ch<span class="w"> </span><span class="nb">test</span><span class="w"> </span>toy<span class="w"> </span>toy_tiny<span class="w"> </span>--config<span class="w"> </span>../configs/archive/test/train.toml<span class="w"> </span>--load<span class="w"> </span>../mase_output/toy_classification_toy_tiny_2024-06-13/software/training_ckpts/best.ckpt<span class="sb">```</span>


<span class="c1">## Run the transform action with the CLI</span>

<span class="c1">### Train a model</span>

<span class="sb">```</span>bash
./ch<span class="w"> </span>train<span class="w"> </span>toy<span class="w"> </span>toy_tiny<span class="w"> </span>--config<span class="w"> </span>../configs/archive/test/train.toml<span class="w"> </span>--max-epochs<span class="w"> </span><span class="m">3</span>
</pre></div>
</div>
</section>
<section id="quantise-transform">
<h3>Quantise transform<a class="headerlink" href="#quantise-transform" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>The above command should have automatically saved a checkpoint file (<code class="docutils literal notranslate"><span class="pre">your_post_training_checkpoint</span></code>) for you, which was <code class="docutils literal notranslate"><span class="pre">../mase_output/toy_classification_toy_tiny_2024-06-20/software/training_ckpts/best.ckpt</span></code>, you should use these generated checkpoint files for later command line instructions.</p></li>
<li><p>Quantise it with fixed-point quantisers</p></li>
<li><p>The load path <code class="docutils literal notranslate"><span class="pre">--load</span></code> changes with your generation time of course</p></li>
</ul>
<p>The config takes the following format:</p>
<div class="highlight-toml notranslate"><div class="highlight"><pre><span></span><span class="c1"># basics</span>
<span class="n">model</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;toy&quot;</span>
<span class="n">dataset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;toy-tiny&quot;</span>

<span class="k">[passes.quantize]</span>
<span class="n">by</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;type&quot;</span>
<span class="n">report</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">true</span>

<span class="k">[passes.quantize.default.config]</span>
<span class="n">name</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;integer&quot;</span>
<span class="n">data_in_width</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">8</span>
<span class="n">data_in_frac_width</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">4</span>
<span class="n">weight_width</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">8</span>
<span class="n">weight_frac_width</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">9</span>
<span class="n">bias_width</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">8</span>
<span class="n">bias_frac_width</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">9</span>
</pre></div>
</div>
<p>With the config, we can quantise the whole network to integer arithmetic by doing:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./ch<span class="w"> </span>transform<span class="w"> </span>toy<span class="w"> </span>toy_tiny<span class="w"> </span>--config<span class="w"> </span>../configs/examples/toy_uniform.toml<span class="w"> </span>--load<span class="w"> </span>your_post_training_checkpoint<span class="w"> </span>--load-type<span class="w"> </span>pl
</pre></div>
</div>
<blockquote>
<div><p><strong><em>NOTE:</em></strong> the file name <code class="docutils literal notranslate"><span class="pre">your_post_training_checkpoint</span></code> is subject to change, this should be the checkpoint file generated from the training action.</p>
</div></blockquote>
</section>
<section id="quantization-aware-training-qat">
<h3>Quantization-aware Training (QAT)<a class="headerlink" href="#quantization-aware-training-qat" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Load and do Quantisation-aware-training (QAT) with a transformed model</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./ch<span class="w"> </span>train<span class="w"> </span>--config<span class="w"> </span>../configs/examples/toy_uniform.toml<span class="w"> </span>--model<span class="w"> </span>toy<span class="w"> </span>--load<span class="w"> </span>your_post_transform_mz<span class="w"> </span>--load-type<span class="w"> </span>mz<span class="w">  </span>--max-epochs<span class="w"> </span><span class="m">3</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Quantise it with fixed-point quantisers</p></li>
<li><p>The load path <code class="docutils literal notranslate"><span class="pre">--load</span></code> changes with your generation time of course</p></li>
</ul>
<blockquote>
<div><p><strong><em>NOTE:</em></strong> <code class="docutils literal notranslate"><span class="pre">transform</span></code> by default saves transformed models in a mase format called <code class="docutils literal notranslate"><span class="pre">xxx.mz</span></code>, fine-tuning the transformed model only need to load this <code class="docutils literal notranslate"><span class="pre">.mz</span></code> format.</p>
</div></blockquote>
</section>
<section id="quantise-transform-by-type">
<h3>Quantise transform by Type<a class="headerlink" href="#quantise-transform-by-type" title="Link to this heading">#</a></h3>
<div class="highlight-toml notranslate"><div class="highlight"><pre><span></span><span class="c1"># basics</span>
<span class="n">model</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;toy&quot;</span>
<span class="n">dataset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;toy-tiny&quot;</span>

<span class="k">[passes.quantize]</span>
<span class="n">by</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;type&quot;</span>
<span class="n">report</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">true</span>

<span class="k">[passes.quantize.default.config]</span>
<span class="n">name</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;NA&quot;</span>

<span class="k">[passes.quantize.linear.config]</span>
<span class="n">name</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;integer&quot;</span>
<span class="n">data_in_width</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">8</span>
<span class="n">data_in_frac_width</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">4</span>
<span class="n">weight_width</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">8</span>
<span class="n">weight_frac_width</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">9</span>
<span class="n">bias_width</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">8</span>
<span class="n">bias_frac_width</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">9</span>
</pre></div>
</div>
<p>We recommend you to take a look at the configuration file at <code class="docutils literal notranslate"><span class="pre">mase/configs/examples/toy_uniform.toml</span></code>. In this case, only linear layers are quantised!</p>
</section>
</section>
<section id="mixed-precision-search-on-manual-model">
<h2>Mixed-precision search on manual model<a class="headerlink" href="#mixed-precision-search-on-manual-model" title="Link to this heading">#</a></h2>
<p>This tutorial shows how to search for mixed-precision quantization strategy for OPT model on Wikitext2 dataset.</p>
<blockquote>
<div><p><strong>Note</strong>: Manual model refers to the model named as <code class="docutils literal notranslate"><span class="pre">&lt;model_arch&gt;_quantized</span></code> at <code class="docutils literal notranslate"><span class="pre">mase-tools/machop/chop/models/manual</span></code>. Usually these are models that cannot be directly converted to MASE Graph.</p>
</div></blockquote>
<section id="search-for-mixed-precision-quantization-scheme">
<h3>Search for Mixed-Precision Quantization Scheme<a class="headerlink" href="#search-for-mixed-precision-quantization-scheme" title="Link to this heading">#</a></h3>
<p>What is included in this search:</p>
<ul class="simple">
<li><p>The checkpoint facebook/opt-125m is loaded from HuggingFace.</p></li>
<li><p>A search space is built for OPT-125M, where each matmul/linear layer operand may have a distinct precision.</p></li>
<li><p>The search is launched. In each trial:</p>
<ul>
<li><p>A quantization config (<code class="docutils literal notranslate"><span class="pre">q_config</span></code>) is sampled from the search space.</p></li>
<li><p>The pretrained OPT-125M is quantized with <code class="docutils literal notranslate"><span class="pre">q_config</span></code></p></li>
<li><p>Software runner evaluates the quantized OPT and return some metrics. In this example, the perplexity on WikiText2 is returned.</p></li>
<li><p>Hardware runner evaluates the quantized OPT and return some metrics. In this example, the average bitwidth is returned.</p></li>
<li><p>The trial objective is calculated.</p></li>
</ul>
</li>
</ul>
<p>and search for fixed-point precision on Wikitext2 dataset.</p>
<section id="search-config">
<h4>Search config<a class="headerlink" href="#search-config" title="Link to this heading">#</a></h4>
<p>Here is the search part in <code class="docutils literal notranslate"><span class="pre">configs/examples/search_opt_quantized_tpe_search.toml</span></code> looks like the following.</p>
<div class="highlight-toml notranslate"><div class="highlight"><pre><span></span><span class="k">[search.search_space]</span>
<span class="c1"># the search space name defined in mase</span>
<span class="n">name</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;module/manual_hf/quantize/llm_mixed_precision_ptq&quot;</span>

<span class="k">[search.search_space.setup]</span>
<span class="n">model_parallel</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">false</span>

<span class="k">[search.search_space.seed.default]</span>
<span class="c1"># Since we are doing mixed-precision search.</span>
<span class="c1"># Only one &quot;name&quot; is allowed (len(name) == 1)</span>
<span class="n">name</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;integer&quot;</span><span class="p">]</span>
<span class="c1"># precision search space is specified using the following lists</span>
<span class="n">data_in_width</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span><span class="w"> </span><span class="mi">8</span><span class="p">,</span><span class="w"> </span><span class="mi">10</span><span class="p">]</span>
<span class="n">data_in_frac_width</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span><span class="w"> </span><span class="mi">6</span><span class="p">]</span>
<span class="n">weight_width</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span><span class="w"> </span><span class="mi">8</span><span class="p">,</span><span class="w"> </span><span class="mi">10</span><span class="p">]</span>
<span class="n">weight_frac_width</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span><span class="w"> </span><span class="mi">6</span><span class="p">]</span>
<span class="n">bias_width</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span><span class="w"> </span><span class="mi">8</span><span class="p">,</span><span class="w"> </span><span class="mi">10</span><span class="p">]</span>
<span class="n">bias_frac_width</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span><span class="w"> </span><span class="mi">6</span><span class="p">]</span>

<span class="k">[search.strategy]</span>
<span class="n">name</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;optuna&quot;</span>
<span class="n">eval_mode</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">true</span>

<span class="c1"># software (sw) runner and hardware (hw) runner evaluates the quantized model to guide the search</span>
<span class="c1"># here we evaluate the perplexity and average bitwidth of the quantized model</span>
<span class="k">[search.strategy.sw_runner.basic_evaluation]</span>
<span class="n">data_loader</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;val_dataloader&quot;</span>
<span class="n">num_samples</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">512</span>

<span class="k">[search.strategy.hw_runner.average_bitwidth]</span>
<span class="n">compare_to</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">32</span><span class="w"> </span><span class="c1"># compare to FP32</span>

<span class="k">[search.strategy.setup]</span>
<span class="c1"># evaluating perplexity requires GPUs so we only launch 1 job.</span>
<span class="n">n_jobs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span>
<span class="c1"># we run 10 trials in total for demostration.</span>
<span class="n">n_trials</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">10</span>
<span class="n">timeout</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">20000</span>
<span class="c1"># Optuna supports a range of search algorithms, including Random, TPE, Genetic, etc.</span>
<span class="n">sampler</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;TPE&quot;</span>
<span class="n">model_parallel</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">false</span>
<span class="n">sum_scaled_metrics</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">false</span><span class="w"> </span><span class="c1"># false for multi-objective, true for single objecive</span>

<span class="k">[search.strategy.metrics]</span>
<span class="n">perplexity</span><span class="p">.</span><span class="n">scale</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1.0</span>
<span class="n">perplexity</span><span class="p">.</span><span class="n">direction</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;minimize&quot;</span>
<span class="n">average_bitwidth</span><span class="p">.</span><span class="n">scale</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1.0</span>
<span class="n">average_bitwidth</span><span class="p">.</span><span class="n">direction</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;minimize&quot;</span>
</pre></div>
</div>
</section>
<section id="launch-the-precision-search">
<h4>Launch the Precision Search<a class="headerlink" href="#launch-the-precision-search" title="Link to this heading">#</a></h4>
<p>Run the search:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>machop
./ch<span class="w"> </span>search<span class="w"> </span>--config<span class="w"> </span>../configs/examples/search_opt_quantized_tpe_search.toml
</pre></div>
</div>
<p>When the search is done, the best quantization config will be printed out. Since we run multi-objective search. There may be multiple best trials found by Optuna.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Best trial(s):
|    |   number | software_metrics                     | hardware_metrics                                     | scaled_metrics                                  |
|----+----------+--------------------------------------+------------------------------------------------------+-------------------------------------------------|
|  0 |        0 | {&#39;loss&#39;: 12.43, &#39;perplexity&#39;: 6.13}  | {&#39;average_bitwidth&#39;: 7.194, &#39;memory_density&#39;: 4.448} | {&#39;average_bitwidth&#39;: 7.194, &#39;perplexity&#39;: 6.13} |
|  1 |        2 | {&#39;loss&#39;: 11.0, &#39;perplexity&#39;: 21.102} | {&#39;average_bitwidth&#39;: 6.0, &#39;memory_density&#39;: 5.333}   | {&#39;average_bitwidth&#39;: 6.0, &#39;perplexity&#39;: 21.102} |
</pre></div>
</div>
<p>Usually the TPE can optimize the average bitwidth and perplexity trade-off.</p>
</section>
<section id="search-logs">
<h4>Search Logs<a class="headerlink" href="#search-logs" title="Link to this heading">#</a></h4>
<p>The complete search results will be saved in <code class="docutils literal notranslate"><span class="pre">mase/mase_output/opt_quantized_wikitext2/software/search_ckpts/log.json</span></code>.</p>
<p>Here is part of the <code class="docutils literal notranslate"><span class="pre">log.json</span></code> recording all search details.</p>
<p>For example, <code class="docutils literal notranslate"><span class="pre">log[&quot;0&quot;][&quot;user_attrs_sampled_config&quot;]</span></code> is the sampled quantization config of trial 0. Expand it and you will set the precision of each matmul/linear layers operands.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>{
    &quot;0&quot;:{
        &quot;number&quot;:0,
        &quot;values_0&quot;:0.5,
        &quot;values_1&quot;:0.7849056604,
        &quot;user_attrs_hardware_metrics&quot;:{
            &quot;average_bitwidth&quot;:3.9245283019
        },
        &quot;user_attrs_sampled_config&quot;:{
            &quot;seq_blocks_0&quot;:{
                &quot;config&quot;:{
                    &quot;name&quot;:&quot;integer&quot;,
                    &quot;data_in_width&quot;:4,
                    &quot;data_in_frac_width&quot;:4,
                    &quot;weight_width&quot;:2,
                    &quot;weight_frac_width&quot;:8,
                    &quot;bias_width&quot;:2,
                    &quot;bias_frac_width&quot;:8
                }
            },
            ...
        },
        &quot;user_attrs_scaled_metrics&quot;:{
            &quot;accuracy&quot;:0.5,
            &quot;average_bitwidth&quot;:0.7849056604
        },
        &quot;user_attrs_software_metrics&quot;:{
            &quot;loss&quot;:0.6922941208,
            &quot;accuracy&quot;:0.5
        },
        &quot;state&quot;:&quot;COMPLETE&quot;,
        &quot;datetime_start&quot;:1694095030315,
        &quot;datetime_complete&quot;:1694095031289,
        &quot;duration&quot;:974
    },
    &quot;1&quot;:{
        &quot;number&quot;:1,
        &quot;values_0&quot;:0.5747232437,
        &quot;values_1&quot;:0.8150943396,
        &quot;user_attrs_hardware_metrics&quot;:{
            &quot;average_bitwidth&quot;:4.0754716981
        },
        &quot;user_attrs_sampled_config&quot;:{
            &quot;seq_blocks_0&quot;:{
                &quot;config&quot;:{
                    &quot;name&quot;:&quot;integer&quot;,
                    &quot;data_in_width&quot;:8,
                    &quot;data_in_frac_width&quot;:3,
                    &quot;weight_width&quot;:4,
                    &quot;weight_frac_width&quot;:7,
                    &quot;bias_width&quot;:4,
                    &quot;bias_frac_width&quot;:3
                }
            },
            ...
        },
        &quot;user_attrs_scaled_metrics&quot;:{
            &quot;accuracy&quot;:0.5747232437,
            &quot;average_bitwidth&quot;:0.8150943396
        },
        &quot;user_attrs_software_metrics&quot;:{
            &quot;loss&quot;:0.6845972538,
            &quot;accuracy&quot;:0.5747232437
        },
        &quot;state&quot;:&quot;COMPLETE&quot;,
        &quot;datetime_start&quot;:1694095031290,
        &quot;datetime_complete&quot;:1694095032462,
        &quot;duration&quot;:1172
    },
    ...
}
</pre></div>
</div>
</section>
</section>
</section>
<section id="mixed-precision-search-on-mase-graph">
<h2>Mixed-precision search on MASE Graph<a class="headerlink" href="#mixed-precision-search-on-mase-graph" title="Link to this heading">#</a></h2>
<p>This tutorial shows how to search for mixed-precision quantization strategy for JSC model (a small toy model).</p>
<section id="commands">
<h3>Commands<a class="headerlink" href="#commands" title="Link to this heading">#</a></h3>
<p>First we train a model on the dataset. After training for some epochs, we get a model with some validation accuracy. The checkpoint is saved at an auto-created location. You can refer to <em>Run the train action with the CLI</em> for more detailed explanation.</p>
<p>The reason why we need a pre-trained model is because we would like to do a post-training-quantization (PTQ) search. This means the quantization happens on a pre-trained model. We then use the PTQ accuracy as a proxy signal for our search.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>src
./ch<span class="w"> </span>train<span class="w"> </span>jsc-tiny<span class="w"> </span>jsc<span class="w"> </span>--max-epochs<span class="w"> </span><span class="m">3</span><span class="w"> </span>--batch-size<span class="w"> </span><span class="m">256</span><span class="w"> </span>--accelerator<span class="w"> </span>cpu<span class="w"> </span>--project<span class="w"> </span>tmp<span class="w"> </span>--debug<span class="w"> </span>--cpu<span class="w"> </span><span class="m">0</span>
</pre></div>
</div>
<ul class="simple">
<li><p>For the interest of time, we do not train this to convergence, apparently one can adjust <code class="docutils literal notranslate"><span class="pre">--max-epochs</span></code> for longer training epochs.</p></li>
<li><p>We choose to train on <code class="docutils literal notranslate"><span class="pre">cpu</span></code> and <code class="docutils literal notranslate"><span class="pre">--cpu</span> <span class="pre">0</span></code> avoids multiprocessing dataloader issues.</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># search command</span>
./ch<span class="w"> </span>search<span class="w"> </span>--config<span class="w"> </span>../configs/examples/jsc_toy_by_type.toml<span class="w"> </span>--task<span class="w"> </span>cls<span class="w"> </span>--accelerator<span class="o">=</span>cpu<span class="w"> </span>--load<span class="w"> </span>../mase_output/tmp/software/training_ckpts/best.ckpt<span class="w"> </span>--load-type<span class="w"> </span>pl<span class="w"> </span>--cpu<span class="w"> </span><span class="m">0</span>
</pre></div>
</div>
<ul class="simple">
<li><p>The line above issues the search with a configuration file, we discuss the configuration in later sections.</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># train searched network</span>
./ch<span class="w"> </span>train<span class="w"> </span>jsc-tiny<span class="w"> </span>jsc<span class="w"> </span>--max-epochs<span class="w"> </span><span class="m">3</span><span class="w"> </span>--batch-size<span class="w"> </span><span class="m">256</span><span class="w"> </span>--accelerator<span class="w"> </span>cpu<span class="w"> </span>--project<span class="w"> </span>tmp<span class="w"> </span>--debug<span class="w"> </span>--load<span class="w"> </span>../mase_output/jsc-tiny/software/transform/transformed_ckpt/graph_module.mz<span class="w"> </span>--load-type<span class="w"> </span>mz

<span class="c1"># view searched results</span>
cat<span class="w"> </span>../mase_output/jsc-tiny/software/search_ckpts/best.json
</pre></div>
</div>
</section>
<section id="id1">
<h3>Search Config<a class="headerlink" href="#id1" title="Link to this heading">#</a></h3>
<p>Here is the search part in <code class="docutils literal notranslate"><span class="pre">configs/examples/jsc_toy_by_type.toml</span></code> looks like the following.</p>
<div class="highlight-toml notranslate"><div class="highlight"><pre><span></span><span class="c1"># basics</span>
<span class="n">model</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;jsc-tiny&quot;</span>
<span class="n">dataset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;jsc&quot;</span>
<span class="n">task</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;cls&quot;</span>

<span class="n">max_epochs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">5</span>
<span class="n">batch_size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">512</span>
<span class="n">learning_rate</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1e-2</span>
<span class="n">accelerator</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;gpu&quot;</span>
<span class="n">project</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;jsc-tiny&quot;</span>
<span class="n">seed</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">42</span>
<span class="n">log_every_n_steps</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">5</span>

<span class="k">[passes.quantize]</span>
<span class="n">by</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;type&quot;</span>
<span class="k">[passes.quantize.default.config]</span>
<span class="n">name</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;NA&quot;</span>
<span class="k">[passes.quantize.linear.config]</span>
<span class="n">name</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;integer&quot;</span>
<span class="s2">&quot;data_in_width&quot;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">8</span>
<span class="s2">&quot;data_in_frac_width&quot;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">4</span>
<span class="s2">&quot;weight_width&quot;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">8</span>
<span class="s2">&quot;weight_frac_width&quot;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">4</span>
<span class="s2">&quot;bias_width&quot;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">8</span>
<span class="s2">&quot;bias_frac_width&quot;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">4</span>

<span class="k">[transform]</span>
<span class="n">style</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;graph&quot;</span>


<span class="k">[search.search_space]</span>
<span class="n">name</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;graph/quantize/mixed_precision_ptq&quot;</span>

<span class="k">[search.search_space.setup]</span>
<span class="n">by</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;name&quot;</span>

<span class="k">[search.search_space.seed.default.config]</span>
<span class="c1"># the only choice &quot;NA&quot; is used to indicate that layers are not quantized by default</span>
<span class="n">name</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;NA&quot;</span><span class="p">]</span>

<span class="k">[search.search_space.seed.linear.config]</span>
<span class="c1"># if search.search_space.setup.by = &quot;type&quot;, this seed will be used to quantize all torch.nn.Linear/ F.linear</span>
<span class="n">name</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;integer&quot;</span><span class="p">]</span>
<span class="n">data_in_width</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="mi">4</span><span class="p">,</span><span class="w"> </span><span class="mi">8</span><span class="p">]</span>
<span class="n">data_in_frac_width</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;NA&quot;</span><span class="p">]</span><span class="w"> </span><span class="c1"># &quot;NA&quot; means data_in_frac_width = data_in_width // 2</span>
<span class="n">weight_width</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span><span class="w"> </span><span class="mi">8</span><span class="p">]</span>
<span class="n">weight_frac_width</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;NA&quot;</span><span class="p">]</span>
<span class="n">bias_width</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span><span class="w"> </span><span class="mi">8</span><span class="p">]</span>
<span class="n">bias_frac_width</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;NA&quot;</span><span class="p">]</span>

<span class="k">[search.search_space.seed.seq_blocks_2.config]</span>
<span class="c1"># if search.search_space.setup.by = &quot;name&quot;, this seed will be used to quantize the mase graph node with name &quot;seq_blocks_2&quot;</span>
<span class="n">name</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;integer&quot;</span><span class="p">]</span>
<span class="n">data_in_width</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="mi">4</span><span class="p">,</span><span class="w"> </span><span class="mi">8</span><span class="p">]</span>
<span class="n">data_in_frac_width</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;NA&quot;</span><span class="p">]</span>
<span class="n">weight_width</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span><span class="w"> </span><span class="mi">8</span><span class="p">]</span>
<span class="n">weight_frac_width</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;NA&quot;</span><span class="p">]</span>
<span class="n">bias_width</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span><span class="w"> </span><span class="mi">8</span><span class="p">]</span>
<span class="n">bias_frac_width</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;NA&quot;</span><span class="p">]</span>

<span class="k">[search.strategy]</span>
<span class="n">name</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;optuna&quot;</span>
<span class="n">eval_mode</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">true</span>

<span class="k">[search.strategy.sw_runner.basic_evaluation]</span>
<span class="n">data_loader</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;val_dataloader&quot;</span>
<span class="n">num_samples</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">512</span>

<span class="k">[search.strategy.hw_runner.average_bitwidth]</span>
<span class="n">compare_to</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">32</span><span class="w"> </span><span class="c1"># compare to FP32</span>

<span class="k">[search.strategy.setup]</span>
<span class="n">n_jobs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span>
<span class="n">n_trials</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">5</span>
<span class="n">timeout</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">20000</span>
<span class="n">sampler</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;tpe&quot;</span>
<span class="c1"># sum_scaled_metrics = true # single objective</span>
<span class="c1"># direction = &quot;maximize&quot;</span>
<span class="n">sum_scaled_metrics</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">false</span><span class="w"> </span><span class="c1"># multi objective</span>

<span class="k">[search.strategy.metrics]</span>
<span class="c1"># loss.scale = 1.0</span>
<span class="c1"># loss.direction = &quot;minimize&quot;</span>
<span class="n">accuracy</span><span class="p">.</span><span class="n">scale</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1.0</span>
<span class="n">accuracy</span><span class="p">.</span><span class="n">direction</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;maximize&quot;</span>
<span class="n">average_bitwidth</span><span class="p">.</span><span class="n">scale</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.2</span>
<span class="n">average_bitwidth</span><span class="p">.</span><span class="n">direction</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;minimize&quot;</span>
</pre></div>
</div>
</section>
<section id="run-the-search">
<h3>Run the search<a class="headerlink" href="#run-the-search" title="Link to this heading">#</a></h3>
<p>When the search is completed, we will see the Pareto frontier trials (<code class="docutils literal notranslate"><span class="pre">sum_scaled_metrics</span> <span class="pre">=</span> <span class="pre">false</span></code>) or the best trials (<code class="docutils literal notranslate"><span class="pre">sum_scaled_metrics</span> <span class="pre">=</span> <span class="pre">true</span></code>) printed in the terminal.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>[2023-09-06 15:54:24][chop.actions.search.strategies.optuna][INFO] Best trial(s):
Best trial(s):
|    |   number | software_metrics                   | hardware_metrics            | scaled_metrics                                 |
|----+----------+------------------------------------+-----------------------------+------------------------------------------------|
|  0 |        0 | {&#39;loss&#39;: 0.668, &#39;accuracy&#39;: 0.668} | {&#39;average_bitwidth&#39;: 2.038} | {&#39;accuracy&#39;: 0.668, &#39;average_bitwidth&#39;: 0.408} |
|  1 |        4 | {&#39;loss&#39;: 0.526, &#39;accuracy&#39;: 0.729} | {&#39;average_bitwidth&#39;: 4.151} | {&#39;accuracy&#39;: 0.729, &#39;average_bitwidth&#39;: 0.83}  |
|  2 |        5 | {&#39;loss&#39;: 0.55, &#39;accuracy&#39;: 0.691}  | {&#39;average_bitwidth&#39;: 2.113} | {&#39;accuracy&#39;: 0.691, &#39;average_bitwidth&#39;: 0.423} |
|  3 |       10 | {&#39;loss&#39;: 0.542, &#39;accuracy&#39;: 0.691} | {&#39;average_bitwidth&#39;: 2.189} | {&#39;accuracy&#39;: 0.691, &#39;average_bitwidth&#39;: 0.438} |
|  4 |       13 | {&#39;loss&#39;: 0.556, &#39;accuracy&#39;: 0.681} | {&#39;average_bitwidth&#39;: 2.075} | {&#39;accuracy&#39;: 0.681, &#39;average_bitwidth&#39;: 0.415} |
|  5 |       19 | {&#39;loss&#39;: 0.563, &#39;accuracy&#39;: 0.663} | {&#39;average_bitwidth&#39;: 2.0}   | {&#39;accuracy&#39;: 0.663, &#39;average_bitwidth&#39;: 0.4}   |
</pre></div>
</div>
<p>The entire searching log is saved in <code class="docutils literal notranslate"><span class="pre">../mase_output/jsc-tiny/software/search_ckpts/log.json</span></code>.</p>
<p>Here is part of the <code class="docutils literal notranslate"><span class="pre">log.json</span></code></p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>{
    &quot;0&quot;:{
        &quot;number&quot;:0,
        &quot;values_0&quot;:0.5,
        &quot;values_1&quot;:0.7849056604,
        &quot;user_attrs_hardware_metrics&quot;:{
            &quot;average_bitwidth&quot;:3.9245283019
        },
        &quot;user_attrs_sampled_config&quot;:{
            &quot;seq_blocks_0&quot;:{
                &quot;config&quot;:{
                    &quot;name&quot;:&quot;integer&quot;,
                    &quot;data_in_width&quot;:4,
                    &quot;data_in_frac_width&quot;:4,
                    &quot;weight_width&quot;:2,
                    &quot;weight_frac_width&quot;:8,
                    &quot;bias_width&quot;:2,
                    &quot;bias_frac_width&quot;:8
                }
            },
            ...
        },
        &quot;user_attrs_scaled_metrics&quot;:{
            &quot;accuracy&quot;:0.5,
            &quot;average_bitwidth&quot;:0.7849056604
        },
        &quot;user_attrs_software_metrics&quot;:{
            &quot;loss&quot;:0.6922941208,
            &quot;accuracy&quot;:0.5
        },
        &quot;state&quot;:&quot;COMPLETE&quot;,
        &quot;datetime_start&quot;:1694095030315,
        &quot;datetime_complete&quot;:1694095031289,
        &quot;duration&quot;:974
    },
    &quot;1&quot;:{
        &quot;number&quot;:1,
        &quot;values_0&quot;:0.5747232437,
        &quot;values_1&quot;:0.8150943396,
        &quot;user_attrs_hardware_metrics&quot;:{
            &quot;average_bitwidth&quot;:4.0754716981
        },
        &quot;user_attrs_sampled_config&quot;:{
            &quot;seq_blocks_0&quot;:{
                &quot;config&quot;:{
                    &quot;name&quot;:&quot;integer&quot;,
                    &quot;data_in_width&quot;:8,
                    &quot;data_in_frac_width&quot;:3,
                    &quot;weight_width&quot;:4,
                    &quot;weight_frac_width&quot;:7,
                    &quot;bias_width&quot;:4,
                    &quot;bias_frac_width&quot;:3
                }
            },
            ...
        },
        &quot;user_attrs_scaled_metrics&quot;:{
            &quot;accuracy&quot;:0.5747232437,
            &quot;average_bitwidth&quot;:0.8150943396
        },
        &quot;user_attrs_software_metrics&quot;:{
            &quot;loss&quot;:0.6845972538,
            &quot;accuracy&quot;:0.5747232437
        },
        &quot;state&quot;:&quot;COMPLETE&quot;,
        &quot;datetime_start&quot;:1694095031290,
        &quot;datetime_complete&quot;:1694095032462,
        &quot;duration&quot;:1172
    },
    &quot;2&quot;:{
        &quot;number&quot;:2,
        &quot;values_0&quot;:0.5498154759,
        &quot;values_1&quot;:0.8,
        &quot;user_attrs_hardware_metrics&quot;:{
            &quot;average_bitwidth&quot;:4.0
        },
        &quot;user_attrs_sampled_config&quot;:{
            &quot;seq_blocks_0&quot;:{
                &quot;config&quot;:{
                    &quot;name&quot;:&quot;integer&quot;,
                    &quot;data_in_width&quot;:4,
                    &quot;data_in_frac_width&quot;:3,
                    &quot;weight_width&quot;:2,
                    &quot;weight_frac_width&quot;:4,
                    &quot;bias_width&quot;:8,
                    &quot;bias_frac_width&quot;:4
                }
            },
            ...
        },
        &quot;user_attrs_scaled_metrics&quot;:{
            &quot;accuracy&quot;:0.5498154759,
            &quot;average_bitwidth&quot;:0.8
        },
        &quot;user_attrs_software_metrics&quot;:{
            &quot;loss&quot;:0.6868978143,
            &quot;accuracy&quot;:0.5498154759
        },
        &quot;state&quot;:&quot;COMPLETE&quot;,
        &quot;datetime_start&quot;:1694095032463,
        &quot;datetime_complete&quot;:1694095033622,
        &quot;duration&quot;:1159
    },
    ...
}
</pre></div>
</div>
</section>
</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="onnxrt_quantization_tutorial.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Advanced: ONNX Runtime Tutorial</p>
      </div>
    </a>
    <a class="right-next"
       href="../developer/Add-model-to-machop.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Developer: Guide on how to add a new model into Machop</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#run-the-train-action-with-the-cli">Run the train action with the CLI</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#command-line-interface">Command line interface</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#training-implementation">Training implementation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#models">Models</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#output">Output</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#training-logs">Training Logs</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#test-command">Test command</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#quantise-transform">Quantise transform</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#quantization-aware-training-qat">Quantization-aware Training (QAT)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#quantise-transform-by-type">Quantise transform by Type</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mixed-precision-search-on-manual-model">Mixed-precision search on manual model</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#search-for-mixed-precision-quantization-scheme">Search for Mixed-Precision Quantization Scheme</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#search-config">Search config</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#launch-the-precision-search">Launch the Precision Search</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#search-logs">Search Logs</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mixed-precision-search-on-mase-graph">Mixed-precision search on MASE Graph</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#commands">Commands</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Search Config</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#run-the-search">Run the search</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By DeepWok
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
       Copyright 2023, DeepWok.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>